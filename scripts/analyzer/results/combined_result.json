{
  "chasten_result": {
    "configuration": {
      "chastenversion": "0.2.0",
      "debuglevel": "ERROR",
      "debugdestination": "CONSOLE",
      "projectname": "lazytracker",
      "configdirectory": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/Config",
      "searchpath": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten",
      "fileuuid": "ce624ee59e0344d4bac1371d8ca2d5e5",
      "datetime": "2024-07-17 21:02:02.101434",
      "checkinclude": {
        "attribute": "",
        "value": "",
        "confidence": 0
      },
      "checkexclude": {
        "attribute": "",
        "value": "",
        "confidence": 0
      }
    },
    "sources": [
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/mutmut_config.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 4,
              "linematch": "if context.mutation_id.operator == \"delete\":",
              "linematch_context": "    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    \n    if context.mutation_id.operator == \"delete\":\n        # Allow statement deletion mutations\n        return\n    elif any(op in context.source for op in arithmetic_operators):\n        # Allow arithmetic operator mutations\n        return"
            },
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "elif any(op in context.source for op in arithmetic_operators):",
              "linematch_context": "    \n    if context.mutation_id.operator == \"delete\":\n        # Allow statement deletion mutations\n        return\n    elif any(op in context.source for op in arithmetic_operators):\n        # Allow arithmetic operator mutations\n        return\n    else:\n        # Skip all other mutations\n        context.skip = True"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_util.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_createchecks.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "if not valid_api_key:",
              "linematch_context": "@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "if not valid_api_key:",
              "linematch_context": "    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 101,
              "coloffset": 8,
              "linematch": "if \":open_file_folder:\" in node.label:  # type: ignore",
              "linematch_context": "    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 54,
              "coloffset": 4,
              "linematch": "if match_list == []:",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 148,
              "coloffset": 4,
              "linematch": "if is_in_closed_interval(count, min, max):",
              "linematch_context": "@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_constants.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "if dir1 != dir2:",
              "linematch_context": "    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "if util.is_url(checks_file_name):",
              "linematch_context": "    \"\"\"Validate a checks file.\"\"\"\n    checks_file_validated = False\n    checks_file_invalidates_entire_config = False\n    # specified check file is URL\n    if util.is_url(checks_file_name):\n        # extract the configuration details\n        (\n            checks_file_extracted_valid,\n            configuration_file_yaml_str,\n            yaml_data_dict,"
            },
            {
              "lineno": 157,
              "coloffset": 4,
              "linematch": "if not checks_file_extracted_valid:",
              "linematch_context": "        return (checks_file_validated, checks_file_invalidates_entire_config, {})\n    # the checks file could not be extracted in a valid\n    # fashion and thus there is no need to continue the\n    # validation of this file or any of the other check file\n    if not checks_file_extracted_valid:\n        checks_file_validated = False\n    # the checks file could be extract and thus the\n    # function should proceed to validate a checks configuration file\n    else:\n        # validate checks file"
            },
            {
              "lineno": 126,
              "coloffset": 4,
              "linematch": "elif chasten_user_config_url_str != \"\":",
              "linematch_context": "        checks_file_source = checks_file_name\n    # assume check file name is a file path\n    # will not support checks files being local paths\n    # if config file is a URL\n    elif chasten_user_config_url_str != \"\":\n        output.logger.error(\n            f\"\\nChecks file directive was a Path when config was a URL (given: '{checks_file_name}')\\n\"\n        )\n        checks_file_validated = False\n        checks_file_invalidates_entire_config = True"
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "elif (Path(chasten_user_config_dir_str) / Path(checks_file_name)).exists():",
              "linematch_context": "        checks_file_validated = False\n        checks_file_invalidates_entire_config = True\n        return (checks_file_validated, checks_file_invalidates_entire_config, {})\n    # checks file exists in local filesystem\n    elif (Path(chasten_user_config_dir_str) / Path(checks_file_name)).exists():\n        # extract the configuration details\n        (\n            checks_file_extracted_valid,\n            configuration_file_path_str,\n            configuration_file_yaml_str,"
            },
            {
              "lineno": 188,
              "coloffset": 4,
              "linematch": "if config == \"\":",
              "linematch_context": "    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":\n        # there is no configuration file specified and thus\n        # this function should access the platform-specific\n        # configuration directory detected by platformdirs\n        # detect and store the platform-specific user\n        # configuration directory by default"
            },
            {
              "lineno": 334,
              "coloffset": 4,
              "linematch": "if config_file_validated and check_files_validated:",
              "linematch_context": "    check_files_validated = all(checks_files_validated_list)\n    # the files validated correctly; return an indicator to\n    # show that validation worked and then return the overall\n    # dictionary that contains the listing of valid checks\n    if config_file_validated and check_files_validated:\n        return (True, overall_checks_dict)\n    # there was at least one validation error\n    return (False, {})\n\n"
            },
            {
              "lineno": 202,
              "coloffset": 4,
              "linematch": "elif util.is_url(config):",
              "linematch_context": "    # there is a specified configuration directory path or url;\n    # this overrides the use of the configuration files that\n    # may exist inside of the platform-specific directory.\n    # input configuration is valid URL\n    elif util.is_url(config):\n        # re-parse input config so it is of type URL\n        chasten_user_config_url_str = str(parse_url(config))\n        output.console.print(\n            \":sparkles: Configuration URL:\"\n            + constants.markers.Space"
            },
            {
              "lineno": 221,
              "coloffset": 4,
              "linematch": "elif Path(config).exists():",
              "linematch_context": "            parse_url(chasten_user_config_url_str)\n        )\n        configuration_file_source = chasten_user_config_url_str\n    # input configuration exists and is valid file path\n    elif Path(config).exists():\n        # input configuration is a directory\n        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file"
            },
            {
              "lineno": 223,
              "coloffset": 8,
              "linematch": "if Path(config).is_dir():",
              "linematch_context": "        configuration_file_source = chasten_user_config_url_str\n    # input configuration exists and is valid file path\n    elif Path(config).exists():\n        # input configuration is a directory\n        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file\n        elif Path(config).is_file():\n            # re-parse input config so it is of type Path"
            },
            {
              "lineno": 250,
              "coloffset": 8,
              "linematch": "if chasten_user_config_file_str != \"\":",
              "linematch_context": "        )\n        # optional argument if chasten_user_config_file_str is not empty\n        # argument will be supplied as unpacked dict\n        chasten_user_config_file_str_argument = {}\n        if chasten_user_config_file_str != \"\":\n            chasten_user_config_file_str_argument[\n                \"configuration_file\"\n            ] = chasten_user_config_file_str\n        # extract the configuration details\n        ("
            },
            {
              "lineno": 266,
              "coloffset": 8,
              "linematch": "if not configuration_valid:",
              "linematch_context": "        )\n        # it was not possible to extract the configuration details and\n        # thus this function should return immediately with False\n        # to indicate the failure and an empty configuration dictionary\n        if not configuration_valid:\n            return (False, {})\n        # create a visualization of the user's configuration directory;\n        # display details about the configuration directory in console\n        display_configuration_directory(chasten_user_config_dir_str, verbose)\n        configuration_file_source = chasten_user_config_dir_str"
            },
            {
              "lineno": 227,
              "coloffset": 8,
              "linematch": "elif Path(config).is_file():",
              "linematch_context": "        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file\n        elif Path(config).is_file():\n            # re-parse input config so it is of type Path\n            config_as_path = Path(config)\n            # get directory containing config file\n            chasten_user_config_dir_str = str(\n                Path(*config_as_path.parts[: len(config_as_path.parts) - 1])"
            },
            {
              "lineno": 321,
              "coloffset": 8,
              "linematch": "if checks_file_invalidates_entire_config:",
              "linematch_context": "            chasten_user_config_file_str,\n        )\n        # checks file invalidates entire configuration\n        # indicate invalid configuration\n        if checks_file_invalidates_entire_config:\n            return (False, {})\n        # keep track of the validation of all of validation\n        # records for each of the check files\n        checks_files_validated_list.append(checks_file_validated)\n        # add the listing of checks from the current yaml_data_dict to"
            },
            {
              "lineno": 356,
              "coloffset": 4,
              "linematch": "if not configuration_file_path.exists():",
              "linematch_context": "    # the configuration file does not exist and thus\n    # the extraction process cannot continue, the use of\n    # these return values indicates that the extraction\n    # failed and any future steps cannot continue\n    if not configuration_file_path.exists():\n        output.logger.error(\n            f\"\\nFinding config or check file Path failed for {configuration_file_path}.\\n\"\n        )\n        return (False, None, None, None)  # type: ignore\n    configuration_file_yaml_str = configuration_file_path.read_text()"
            },
            {
              "lineno": 368,
              "coloffset": 8,
              "linematch": "if yaml_success:",
              "linematch_context": "        (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n            user_configuration_file_text.read()\n        )\n        # return success status, filename, file contents, and yaml parsed data upon success\n        if yaml_success:\n            return (\n                True,\n                str(configuration_file_path),\n                configuration_file_yaml_str,\n                yaml_data,"
            },
            {
              "lineno": 393,
              "coloffset": 4,
              "linematch": "if response.ok:",
              "linematch_context": "    \"\"\"\n    # create request with given URL as source\n    response = requests.get(str(chasten_user_config_url))\n    # the URL response is OK\n    if response.ok:\n        # assume URL endpoint returns raw text\n        configuration_file_yaml_str = response.text\n    # the URL indicates a problem with the response\n    else:\n        output.logger.error("
            },
            {
              "lineno": 406,
              "coloffset": 4,
              "linematch": "if yaml_success:",
              "linematch_context": "    (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n        configuration_file_yaml_str\n    )\n    # return success status, filename, file contents, and yaml parsed data upon success\n    if yaml_success:\n        return (True, configuration_file_yaml_str, yaml_data)\n    else:\n        output.logger.error(\n            f\"\\nParsing YAML from config or check file URL failed for {chasten_user_config_url}.\\n\"\n        )"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/util.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "\ndef get_human_readable_boolean(answer: bool) -> str:\n    \"\"\"Produce a human-readable Yes or No for a boolean value of True or False.\"\"\"\n    # the provided answer is true\n    if answer:\n        return constants.humanreadable.Yes\n    # the provided answer is false\n    return constants.humanreadable.No\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "if OpSystem == \"Windows\":",
              "linematch_context": "def executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\"\n    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\"\n        executable_name += \".exe\"\n    virtual_env_location = sys.prefix\n    return virtual_env_location + exe_directory + executable_name\n"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:\n        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n\n\ndef get_chasten_version() -> str:"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "if url_parsed.scheme not in [\"http\", \"https\"]:",
              "linematch_context": "    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url\n    url_parsed = parse_url(url)\n    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:\n        return False\n    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\"\n    query_character = \"?\" if url_parsed.query is not None else \"\"\n    fragment_character = \"#\" if url_parsed.fragment is not None else \"\""
            },
            {
              "lineno": 100,
              "coloffset": 8,
              "linematch": "if url_piece is not None:",
              "linematch_context": "    # convert every item to a string and piece the url back together\n    # to make sure it matches what was given\n    url_reassembled = \"\"\n    for url_piece in url_pieces:\n        if url_piece is not None:\n            url_reassembled += str(url_piece)\n    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "if \"description\" in check:",
              "linematch_context": "def extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:\n    \"\"\"Extract the description that may optionally be stored in a check.\"\"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if \"description\" in check:\n        return str(check[\"description\"])\n    return \"\"\n\n\ndef create_attribute_label(attribute: Union[str, int, None], label: str) -> str:"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "if attribute:",
              "linematch_context": "    # the default in the case when attribute is None\n    labeled_attribute = \"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if attribute:\n        labeled_attribute = f\"{label} = {attribute}\"\n    return labeled_attribute\n\n\ndef join_attribute_labels(attribute_labels: List[str]) -> str:"
            },
            {
              "lineno": 52,
              "coloffset": 8,
              "linematch": "if i > 0:",
              "linematch_context": "    # comma and space after it\n    for i, attribute_label in enumerate(attribute_labels):\n        # only add the comma and the space when the for loop\n        # is not dealing with the final value in the list of labels\n        if i > 0:\n            joined_attribute_labels += constants.markers.Comma_Space\n        # append the new attribute label to the running list\n        joined_attribute_labels += attribute_label  # type: ignore\n    return joined_attribute_labels\n"
            },
            {
              "lineno": 61,
              "coloffset": 4,
              "linematch": "if min_value is None and max_value is None:",
              "linematch_context": "\n\ndef is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    if min_value is None and max_value is None:\n        return False\n    return True\n\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "if min_value is None and max_value is None:",
              "linematch_context": "    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value\n    # both of the values are None and thus the comparision is vacuously true\n    if min_value is None and max_value is None:\n        return True\n    # both are not None and thus the count must be in the closed interval\n    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None"
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "if min_value is not None and max_value is not None:",
              "linematch_context": "    # both of the values are None and thus the comparision is vacuously true\n    if min_value is None and max_value is None:\n        return True\n    # both are not None and thus the count must be in the closed interval\n    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:"
            },
            {
              "lineno": 85,
              "coloffset": 4,
              "linematch": "if min_value is not None:",
              "linematch_context": "    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "if max_value is not None:",
              "linematch_context": "    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False"
            },
            {
              "lineno": 86,
              "coloffset": 8,
              "linematch": "if count >= min_value:",
              "linematch_context": "        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True"
            },
            {
              "lineno": 90,
              "coloffset": 8,
              "linematch": "if count <= max_value:",
              "linematch_context": "        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False\n"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "if check_status:",
              "linematch_context": "\n\ndef make_checks_status_message(check_status: bool) -> str:\n    \"\"\"Make a check status message in human readable format.\"\"\"\n    if check_status:\n        return f\":smiley: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    return (\n        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    )\n"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "if criterion is not None:",
              "linematch_context": "    # the converted criterion's default is an empty string\n    new_criterion: Union[str, int] = \"\"\n    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly"
            },
            {
              "lineno": 116,
              "coloffset": 8,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "if publish:",
              "linematch_context": "    \"\"\"Output the final diagnostic message before control is given to a different tool.\"\"\"\n    # output a \"final\" prompt about either the publication platform of a reminder\n    # that the remainder of the output comes from running a local datasette instance\n    # the database will be published to an external platform\n    if publish:\n        output.console.print(\n            f\":sparkles: Debugging output from publishing datasette to '{datasette_platform}':\"\n        )\n    # the database will be displayed through a localhost-based server\n    else:"
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "if executable_path:",
              "linematch_context": "    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\"\n    )\n    if executable_path:\n        output.console.print(\n            f\"{constants.markers.Indent}{small_bullet_unicode} Program: '{output.shorten_file_name(executable_path, 120)}'\"\n        )\n    else:\n        output.console.print("
            },
            {
              "lineno": 160,
              "coloffset": 4,
              "linematch": "if publish:",
              "linematch_context": "    # output diagnostic information about the datasette instance; note\n    # that the output must appear here and not from the calling function\n    # because once the datasette instance starts the chasten tool can\n    # no longer produce output in the console\n    if publish:\n        label = \":sparkles: Details for datasette publishing:\"\n    else:\n        label = \":sparkles: Details for datasette startup:\"\n    display_datasette_details(\n        label,"
            },
            {
              "lineno": 172,
              "coloffset": 4,
              "linematch": "if not found_executable:",
              "linematch_context": "        full_executable_name,\n    )\n    # since it was not possible to find the executable for datasette, display and\n    # error message and then exit this function since no further steps are possible\n    if not found_executable:\n        output.console.print(\n            f\":person_shrugging: Was not able to find {constants.datasette.Datasette_Executable}\"\n        )\n        return None\n    # run the localhost server because the"
            },
            {
              "lineno": 179,
              "coloffset": 4,
              "linematch": "if not publish:",
              "linematch_context": "        )\n        return None\n    # run the localhost server because the\n    # function was not asked to publish a database\n    if not publish:\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),"
            },
            {
              "lineno": 182,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "    # function was not asked to publish a database\n    if not publish:\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                str(database_path),\n                \"-m\",\n                str(metadata),"
            },
            {
              "lineno": 204,
              "coloffset": 4,
              "linematch": "elif publish:",
              "linematch_context": "        # there is debugging output in the console to indicate this option.\n        proc = subprocess.Popen(cmd)\n        proc.wait()\n    # publish the datasette instance to the chosen datasette platform\n    elif publish:\n        # get information about the datasette executable, confirming that\n        # it is available in the virtual environment created by chasten\n        (\n            found_publish_platform_executable,\n            publish_platform_executable,"
            },
            {
              "lineno": 214,
              "coloffset": 8,
              "linematch": "if not found_publish_platform_executable:",
              "linematch_context": "        ) = filesystem.can_find_executable(util.executable_name(datasette_platform))\n        # was not able to find the fly or vercel executable (the person using this\n        # program has to install separately, following the instructions for the\n        # datasette-publish-fly plugin) and thus need to exit and not proceed\n        if not found_publish_platform_executable:\n            output.console.print(\n                f\":person_shrugging: Was not able to find '{datasette_platform}'\"\n            )\n            return None\n        # was able to find the fly or vercel executable that will support the"
            },
            {
              "lineno": 231,
              "coloffset": 8,
              "linematch": "if datasette_platform == constants.chasten.Executable_Fly:",
              "linematch_context": "        # create the customized running argument for either fly or vercel; note\n        # that these programs take different arguments for specifying the name\n        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option"
            },
            {
              "lineno": 238,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                \"publish\",\n                datasette_platform,\n                str(database_path),"
            },
            {
              "lineno": 233,
              "coloffset": 8,
              "linematch": "elif datasette_platform == constants.chasten.Executable_Vercel:",
              "linematch_context": "        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:"
            },
            {
              "lineno": 278,
              "coloffset": 4,
              "linematch": "if exec_found:",
              "linematch_context": "        result_file,\n    ]\n    executable = util.executable_name(\"frogmouth\", OpSystem)\n    exec_found, executable_path = filesystem.can_find_executable(executable)\n    if exec_found:\n        # run frogmouth with specified path\n        output.console.print(\"\\n\ud83d\udc38 Frogmouth Information\\n\")\n        output.console.print(f\" {small_bullet_unicode} Venv: {sys.prefix}\")\n        output.console.print(f\" {small_bullet_unicode} Program: {executable_path}\")\n        proc = subprocess.Popen(cmd)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "if config is not None:",
              "linematch_context": "def detect_configuration(config: Optional[Path]) -> str:\n    \"\"\"Detect the configuration.\"\"\"\n    # there is a specified configuration directory path and thus\n    # this overrides the use of the platform-specific configuration\n    if config is not None:\n        chasten_user_config_dir_str = str(config)\n    # there is no configuration directory specified and thus\n    # this function should access the platform-specific\n    # configuration directory detected by platformdirs\n    else:"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "if force:",
              "linematch_context": "    # create a path out of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # recursively delete the configuration directory and all of its\n    # contents because the force parameter permits deletion\n    if force:\n        shutil.rmtree(chasten_user_config_dir_path)\n    # create the configuration directory, a step that\n    # may fail if the directory already exists; in this\n    # case the FileExistsError will be passed to caller\n    chasten_user_config_dir_path.mkdir(parents=True)"
            },
            {
              "lineno": 131,
              "coloffset": 4,
              "linematch": "if tree is None:",
              "linematch_context": "def create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")\n    # add the new file node to the tree since\n    # the tree has already been created\n    else:\n        tree = tree.add(f\":open_file_folder: {path.name}\")"
            },
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "if path.is_dir():",
              "linematch_context": "    # the tree has already been created\n    else:\n        tree = tree.add(f\":open_file_folder: {path.name}\")\n    # recursively process the directory\n    if path.is_dir():\n        for item in path.iterdir():\n            if item.is_dir():\n                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")"
            },
            {
              "lineno": 140,
              "coloffset": 12,
              "linematch": "if item.is_dir():",
              "linematch_context": "        tree = tree.add(f\":open_file_folder: {path.name}\")\n    # recursively process the directory\n    if path.is_dir():\n        for item in path.iterdir():\n            if item.is_dir():\n                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")\n    # return the tree now containing all nodes\n    return tree"
            },
            {
              "lineno": 151,
              "coloffset": 4,
              "linematch": "if file is not None:",
              "linematch_context": "\ndef confirm_valid_file(file: Path) -> bool:\n    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():\n            return True\n    # the file was either none or not valid\n    return False"
            },
            {
              "lineno": 153,
              "coloffset": 8,
              "linematch": "if file.is_file() and file.exists():",
              "linematch_context": "    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():\n            return True\n    # the file was either none or not valid\n    return False\n\n"
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "if directory is not None:",
              "linematch_context": "\ndef confirm_valid_directory(directory: Path) -> bool:\n    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True\n    # the directory was either none or not valid\n    return False"
            },
            {
              "lineno": 164,
              "coloffset": 8,
              "linematch": "if directory.is_dir() and directory.exists():",
              "linematch_context": "    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True\n    # the directory was either none or not valid\n    return False\n\n"
            },
            {
              "lineno": 183,
              "coloffset": 4,
              "linematch": "if save:",
              "linematch_context": "    results_content: results.Chasten,\n    save: bool = False,\n) -> str:\n    \"\"\"Write the results of a Chasten subclass of Pydantic BaseModel to the specified directory.\"\"\"\n    if save:\n        # extract the unique hexadecimal code that will ensure that\n        # this file name is unique when it is being saved\n        results_file_uuid = results_content.configuration.fileuuid\n        # extract the current date and time when results were created\n        formatted_datetime = results_content.configuration._datetime"
            },
            {
              "lineno": 311,
              "coloffset": 4,
              "linematch": "if executable_path is not None:",
              "linematch_context": "    # use the shutil.which function to find the path of the executable\n    executable_path = shutil.which(executable_name)\n    # the executable is available in the path, so\n    # signal that it is found and return the full path\n    if executable_path is not None:\n        return (True, executable_path)\n    # the executable is not available, so signal its\n    # absence and then return an emptry string instead of a path\n    return (False, constants.markers.Nothing)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/createchecks.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 70,
              "coloffset": 8,
              "linematch": "if len(lines) == 2:  # noqa: PLR2004",
              "linematch_context": "\ndef load_user_api_key(file):\n    with open(file, \"r\") as f:\n        lines = f.read().strip().split(\"\\n\")\n        if len(lines) == 2:  # noqa: PLR2004\n            key = lines[0].encode()\n            encrypted_key = lines[1]\n        fernet = Fernet(key)\n        return fernet.decrypt(encrypted_key.encode()).decode()\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/validate.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "if constants.checks.Check_Chasten in configuration.keys():",
              "linematch_context": "    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files\n            # and return them in a list with a boolean\n            # indicate to show that checks files were found"
            },
            {
              "lineno": 109,
              "coloffset": 8,
              "linematch": "if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:",
              "linematch_context": "    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files\n            # and return them in a list with a boolean\n            # indicate to show that checks files were found\n            checks_file_name_list = configuration[constants.checks.Check_Chasten][\n                constants.checks.Check_File"
            },
            {
              "lineno": 161,
              "coloffset": 4,
              "linematch": "if not validated:",
              "linematch_context": "    output.console.print(\n        f\":sparkles: Validated {file_name}? {util.get_human_readable_boolean(validated)}\"\n    )\n    # there was a validation error, so display the error report\n    if not validated:\n        output.console.print(f\":person_shrugging: Validation errors:\\n\\n{errors}\")\n    # validation worked correctly, so display the configuration file\n    else:\n        output.opt_print_log(verbose, newline=\"\")\n        output.opt_print_log(verbose, label=f\":sparkles: Contents of {file_name}:\\n\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 27,
              "coloffset": 12,
              "linematch": "if strip_row:",
              "linematch_context": "    check_list = []\n    with open(file_name) as file:\n        for row in file:\n            strip_row = row.strip()  # Remove leading/trailing white spaces\n            if strip_row:\n                check_list.append(strip_row.split(\",\"))\n    return check_list\n\n\ndef write_checks(check_list: List[List[str]]) -> str:"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "if len(check_list) != 0:",
              "linematch_context": "\n\ndef write_checks(check_list: List[List[str]]) -> str:\n    \"\"\"Generate structured output based on the contents of the file.\"\"\"\n    if len(check_list) != 0:\n        result = \"Make a YAML file that checks for:\"\n        for checks in check_list:\n            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\"\n            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\"\n        return result"
            },
            {
              "lineno": 120,
              "coloffset": 8,
              "linematch": "if event.input.id == \"Check\":",
              "linematch_context": "\n    def on_input_changed(self, event: Input.Changed) -> None:\n        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True"
            },
            {
              "lineno": 122,
              "coloffset": 8,
              "linematch": "elif event.validation_result is not None:",
              "linematch_context": "        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:"
            },
            {
              "lineno": 123,
              "coloffset": 12,
              "linematch": "if event.validation_result.is_valid:",
              "linematch_context": "        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":"
            },
            {
              "lineno": 128,
              "coloffset": 8,
              "linematch": "if event.button.id == \"Exact\":",
              "linematch_context": "                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit(\n                self"
            },
            {
              "lineno": 131,
              "coloffset": 8,
              "linematch": "elif event.button.id == \"done\":",
              "linematch_context": "    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit(\n                self\n            )  # Exit the application if the \"Done\" button is clicked\n        elif event.button.id == \"clear\":\n            with open(CHECK_STORAGE, \"w\") as file:"
            },
            {
              "lineno": 135,
              "coloffset": 8,
              "linematch": "elif event.button.id == \"clear\":",
              "linematch_context": "        elif event.button.id == \"done\":\n            config_App.exit(\n                self\n            )  # Exit the application if the \"Done\" button is clicked\n        elif event.button.id == \"clear\":\n            with open(CHECK_STORAGE, \"w\") as file:\n                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:"
            },
            {
              "lineno": 140,
              "coloffset": 8,
              "linematch": "elif self.Valid:",
              "linematch_context": "            with open(CHECK_STORAGE, \"w\") as file:\n                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )"
            },
            {
              "lineno": 141,
              "coloffset": 12,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "if check_attribute is None or check_match is None:",
              "linematch_context": "    filtered_checks = []\n    # at least one aspect of the inputs was not specified (likely due to\n    # the fact that the command-line argument(s) were not used) and thus\n    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:\n        return checks\n    # the function's inputs are valid and so perform the filtering\n    for check in checks:\n        # extract the contents of the requested attribute for inclusion\n        check_requested_include_attribute = check[check_attribute]"
            },
            {
              "lineno": 36,
              "coloffset": 8,
              "linematch": "if (fuzzy_value >= check_confidence) and include:",
              "linematch_context": "        # --> specified match string\n        fuzzy_value = fuzz.ratio(check_match, check_requested_include_attribute)\n        # include the check if the fuzzy inclusion value is above (or equal to) threshold\n        # and the purpose of the function call is to include values\n        if (fuzzy_value >= check_confidence) and include:\n            filtered_checks.append(check)\n        # include the check if the fuzzy inclusion value is below threshold\n        # and the purpose of the function call is to exclude values;\n        # note that not including a value means that it excludes\n        elif (fuzzy_value < check_confidence) and not include:"
            },
            {
              "lineno": 41,
              "coloffset": 8,
              "linematch": "elif (fuzzy_value < check_confidence) and not include:",
              "linematch_context": "            filtered_checks.append(check)\n        # include the check if the fuzzy inclusion value is below threshold\n        # and the purpose of the function call is to exclude values;\n        # note that not including a value means that it excludes\n        elif (fuzzy_value < check_confidence) and not include:\n            filtered_checks.append(check)\n    return filtered_checks\n\n\ndef filter_matches("
            },
            {
              "lineno": 58,
              "coloffset": 8,
              "linematch": "if isinstance(match, data_type):",
              "linematch_context": "    for match in match_list:\n        # if the current match is of the\n        # specified type, then keep it in\n        # the list of the matching matches\n        if isinstance(match, data_type):\n            subset_match_list.append(match)\n        # if the current match is not of the\n        # specified type, then keep it in\n        # the list of non-matching matches\n        else:"
            },
            {
              "lineno": 82,
              "coloffset": 8,
              "linematch": "if current_match_file_name in match_dict:",
              "linematch_context": "    for current_match in match_list:\n        # extract the name of the file for the current match\n        current_match_file_name = str(current_match.path)\n        # already storing matches for this file\n        if current_match_file_name in match_dict:\n            # extract the existing list of matches for this file\n            current_match_file_list = match_dict[current_match_file_name]\n            current_match_file_list.append(current_match)\n        # not already storing matches for this file\n        else:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 91,
              "coloffset": 4,
              "linematch": "if not publish:",
              "linematch_context": "        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\"\n    )\n    # do not display a port if the task is publishing to fly.io\n    # because that step does not support port specification\n    if not publish:\n        output.console.print(\n            f\"{constants.markers.Indent}{small_bullet_unicode} Port: {port}\"\n        )\n\n"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "if filesystem.confirm_valid_file(CHECK_STORAGE):",
              "linematch_context": "    \"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"\n    # creates a textual object for better user interface\n    app.run()\n    # Checks if the file storing the wanted checks exists and is valid\n    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks\n        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))\n        # Checks if API key storage file exists\n        if filesystem.confirm_valid_file(API_KEY_STORAGE):\n            # prints the human readable checks to the terminal"
            },
            {
              "lineno": 118,
              "coloffset": 8,
              "linematch": "if filesystem.confirm_valid_file(API_KEY_STORAGE):",
              "linematch_context": "    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks\n        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))\n        # Checks if API key storage file exists\n        if filesystem.confirm_valid_file(API_KEY_STORAGE):\n            # prints the human readable checks to the terminal\n            output.console.print(result)\n            # loads the decrypted API Key\n            api_key = createchecks.load_user_api_key(API_KEY_STORAGE)\n            # calls the function to generate the yaml file"
            },
            {
              "lineno": 198,
              "coloffset": 4,
              "linematch": "if task == enumerations.ConfigureTask.VALIDATE:",
              "linematch_context": "    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the configuration directory and its contents\n    if task == enumerations.ConfigureTask.VALIDATE:\n        # validate the configuration files:\n        # --> config.yml (or url pointing to one)\n        # --> checks.yml (or whatever file/url is reference in config.yml)\n        (validated, _) = configuration.validate_configuration_files(config, verbose)\n        # some aspect of the configuration was not"
            },
            {
              "lineno": 211,
              "coloffset": 4,
              "linematch": "if task == enumerations.ConfigureTask.CREATE:",
              "linematch_context": "                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n            )\n            sys.exit(constants.markers.Non_Zero_Exit)\n    # create the configuration directory and a starting version of the configuration file\n    if task == enumerations.ConfigureTask.CREATE:\n        # attempt to create the configuration directory\n        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs"
            },
            {
              "lineno": 205,
              "coloffset": 8,
              "linematch": "if not validated:",
              "linematch_context": "        # --> checks.yml (or whatever file/url is reference in config.yml)\n        (validated, _) = configuration.validate_configuration_files(config, verbose)\n        # some aspect of the configuration was not\n        # valid, so exit early and signal an error\n        if not validated:\n            output.console.print(\n                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n            )\n            sys.exit(constants.markers.Non_Zero_Exit)\n    # create the configuration directory and a starting version of the configuration file"
            },
            {
              "lineno": 217,
              "coloffset": 12,
              "linematch": "if config is None:",
              "linematch_context": "        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs\n            if config is None:\n                configuration_directory = None\n            else:\n                configuration_directory = Path(config)\n            created_directory_path = filesystem.create_configuration_directory(\n                configuration_directory, force"
            },
            {
              "lineno": 241,
              "coloffset": 12,
              "linematch": "if not force:",
              "linematch_context": "        # cannot re-create the configuration directory, so display\n        # a message and suggest the use of --force the next time;\n        # exit early and signal an error with a non-zero exist code\n        except FileExistsError:\n            if not force:\n                output.console.print(\n                    \"\\n:person_shrugging: Configuration directory already exists.\"\n                )\n                output.console.print(\n                    \"Use --force to recreate configuration directory and its containing files.\""
            },
            {
              "lineno": 395,
              "coloffset": 4,
              "linematch": "if not validated:",
              "linematch_context": "        config, verbose\n    )\n    # some aspect of the configuration was not\n    # valid, so exit early and signal an error\n    if not validated:\n        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n        )\n        output.logger.debug(\"Cannot perform analysis due to configuration error(s)\")\n        sys.exit(constants.markers.Non_Zero_Exit)"
            },
            {
              "lineno": 421,
              "coloffset": 4,
              "linematch": "if not filesystem.confirm_valid_directory(",
              "linematch_context": "    # not possible to analyze the Python source files in this directory\n    # OR\n    # the specified search path is not valid and thus it is\n    # not possible to analyze the specific Python source code file\n    if not filesystem.confirm_valid_directory(\n        input_path\n    ) and not filesystem.confirm_valid_file(input_path):\n        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\"\n        )"
            },
            {
              "lineno": 428,
              "coloffset": 4,
              "linematch": "if store_result:",
              "linematch_context": "        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\"\n        )\n        sys.exit(constants.markers.Non_Zero_Exit)\n    if store_result:\n        # creates an empty string for storing results temporarily\n        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):"
            },
            {
              "lineno": 461,
              "coloffset": 4,
              "linematch": "if xpath == \"1.0\":",
              "linematch_context": "    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version\n    if xpath == \"1.0\":\n        output.logger.debug(\"Using XPath version 1.0\")\n    else:\n        output.logger.debug(\"Using XPath version 2.0\")\n    # iterate through and perform each of the checks\n    for current_check in check_list:"
            },
            {
              "lineno": 643,
              "coloffset": 4,
              "linematch": "if saved_file_name:",
              "linematch_context": "    saved_file_name = filesystem.write_chasten_results(\n        output_directory, project, chasten_results_save, save\n    )\n    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")\n    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:"
            },
            {
              "lineno": 646,
              "coloffset": 4,
              "linematch": "if save_XML is not None or view_XML is not None:",
              "linematch_context": "    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")\n    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901"
            },
            {
              "lineno": 709,
              "coloffset": 4,
              "linematch": "if not all_checks_passed:",
              "linematch_context": "    all_checks_passed = all(check_status_list)\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file\n            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n            output.console.print("
            },
            {
              "lineno": 722,
              "coloffset": 4,
              "linematch": "if store_result:",
              "linematch_context": "    output.console.print(\n        f\"\\n:joy: All checks passed. Elapsed Time: {elapsed_time} seconds\"\n    )\n    output.logger.debug(\"Analysis complete.\")\n    if store_result:\n        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")\n        if display:"
            },
            {
              "lineno": 433,
              "coloffset": 8,
              "linematch": "if filesystem.confirm_valid_file(analysis_file_dir):",
              "linematch_context": "        # creates an empty string for storing results temporarily\n        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )"
            },
            {
              "lineno": 434,
              "coloffset": 12,
              "linematch": "if not force:",
              "linematch_context": "        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )\n                    sys.exit(0)"
            },
            {
              "lineno": 435,
              "coloffset": 16,
              "linematch": "if display:",
              "linematch_context": "        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )\n                    sys.exit(0)\n                else:"
            },
            {
              "lineno": 488,
              "coloffset": 8,
              "linematch": "if xpath == \"1.0\":",
              "linematch_context": "        # this looks for matches across all path(s) in the specified source path\n        # match_generator = pyastgrepsearch.search_python_files(\n        #         paths=valid_directories, expression=current_xpath_pattern, xpath2=True\n        # )\n        if xpath == \"1.0\":\n            match_generator = pyastgrepsearch.search_python_files(\n                paths=valid_directories, expression=current_xpath_pattern, xpath2=False\n            )\n        else:\n            match_generator = pyastgrepsearch.search_python_files("
            },
            {
              "lineno": 510,
              "coloffset": 8,
              "linematch": "if checks.is_checkable(min_count, max_count):",
              "linematch_context": "        # correspond so that processing of matches takes place per-file\n        match_dict = process.organize_matches(match_generator_list)\n        # perform an enforceable check if it is warranted for this check\n        current_check_save = None\n        if checks.is_checkable(min_count, max_count):\n            # determine whether or not the number of found matches is within mix and max\n            check_status = checks.check_match_count(\n                len(match_generator_list), min_count, max_count\n            )\n            # keep track of the outcome for this check"
            },
            {
              "lineno": 531,
              "coloffset": 8,
              "linematch": "if store_result:",
              "linematch_context": "        output.console.print(\n            f\"  {check_status_symbol} id: '{check_id}', name: '{check_name}'\"\n            + f\", pattern: '{current_xpath_pattern_escape}', min={min_count}, max={max_count}\"\n        )\n        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\""
            },
            {
              "lineno": 551,
              "coloffset": 8,
              "linematch": "if len(match_generator_list) == 0:",
              "linematch_context": "            filename=str(str(vd) for vd in valid_directories)\n        )\n        # there were no matches and thus the current_check_save of None\n        # should be recorded inside of the source of the results\n        if len(match_generator_list) == 0:\n            current_result_source.check = current_check_save\n        # iteratively analyze:\n        # a) A specific file name\n        # b) All of the matches for that file name\n        # Note: the goal is to only process matches for a"
            },
            {
              "lineno": 580,
              "coloffset": 12,
              "linematch": "if store_result:",
              "linematch_context": "            # display minimal diagnostic output\n            output.console.print(\n                f\"    {small_bullet_unicode} {file_name} - {len(matches_list)} matches\"\n            )\n            if store_result:\n                # stores details of checks in string to be stored later\n                analysis_result += f\"    - {file_name} - {len(matches_list)} matches\\n\"\n            # extract the lines of source code for this file; note that all of\n            # these matches are organized for the same file and thus it is\n            # acceptable to extract the lines of the file from the first match"
            },
            {
              "lineno": 587,
              "coloffset": 12,
              "linematch": "if len(matches_list) > 0:",
              "linematch_context": "            # extract the lines of source code for this file; note that all of\n            # these matches are organized for the same file and thus it is\n            # acceptable to extract the lines of the file from the first match\n            # a long as there are matches available for analysis\n            if len(matches_list) > 0:\n                current_result_source._filelines = matches_list[0].file_lines\n            # iterate through all of the matches that are specifically\n            # connected to this source that is connected to a specific file name\n            for current_match in matches_list:\n                if isinstance(current_match, pyastgrepsearch.Match):"
            },
            {
              "lineno": 592,
              "coloffset": 16,
              "linematch": "if isinstance(current_match, pyastgrepsearch.Match):",
              "linematch_context": "                current_result_source._filelines = matches_list[0].file_lines\n            # iterate through all of the matches that are specifically\n            # connected to this source that is connected to a specific file name\n            for current_match in matches_list:\n                if isinstance(current_match, pyastgrepsearch.Match):\n                    current_result_source._filelines = current_match.file_lines\n                    # extract the direct line number for this match\n                    position_end = current_match.position.lineno\n                    # extract the column offset for this match\n                    column_offset = current_match.position.col_offset"
            },
            {
              "lineno": 649,
              "coloffset": 12,
              "linematch": "if os.path.isdir(input_path):",
              "linematch_context": "    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)"
            },
            {
              "lineno": 652,
              "coloffset": 20,
              "linematch": "if (",
              "linematch_context": "        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)\n                        and str(each_file).endswith(\".py\")\n                    ):\n                        # Read the bytes of the input path and store them in the 'contents' variable"
            },
            {
              "lineno": 666,
              "coloffset": 24,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                        )\n                        # Convert the Abstract Syntax Tree (AST) into an XML representation\n                        xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                        # Check if view_xml is chosen\n                        if view_XML is not None:\n                            output.console.print(\n                                pyastgrep.xml.tostring(\n                                    xml_root, pretty_print=True\n                                ).decode(\"utf-8\")\n                            )"
            },
            {
              "lineno": 672,
              "coloffset": 20,
              "linematch": "elif os.path.isdir(each_file):",
              "linematch_context": "                                pyastgrep.xml.tostring(\n                                    xml_root, pretty_print=True\n                                ).decode(\"utf-8\")\n                            )\n                    elif os.path.isdir(each_file):\n                        for sub_file in os.listdir(each_file):\n                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901\n                            if str(sub_file).endswith(\".py\"):\n                                contents = Path(sub_file).read_bytes()\n                                _, ast = pyastgrep.files.parse_python_file("
            },
            {
              "lineno": 675,
              "coloffset": 28,
              "linematch": "if str(sub_file).endswith(\".py\"):",
              "linematch_context": "                            )\n                    elif os.path.isdir(each_file):\n                        for sub_file in os.listdir(each_file):\n                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901\n                            if str(sub_file).endswith(\".py\"):\n                                contents = Path(sub_file).read_bytes()\n                                _, ast = pyastgrep.files.parse_python_file(\n                                    contents, sub_file, auto_dedent=False\n                                )\n                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            },
            {
              "lineno": 682,
              "coloffset": 32,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                                    contents, sub_file, auto_dedent=False\n                                )\n                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                                # Check if view_xml is chosen\n                                if view_XML is not None:\n                                    output.console.print(\n                                        pyastgrep.xml.tostring(\n                                            xml_root, pretty_print=True\n                                        ).decode(\"utf-8\")\n                                    )"
            },
            {
              "lineno": 688,
              "coloffset": 12,
              "linematch": "elif os.path.isfile(input_path) and str(input_path).endswith(\".py\"):",
              "linematch_context": "                                        pyastgrep.xml.tostring(\n                                            xml_root, pretty_print=True\n                                        ).decode(\"utf-8\")\n                                    )\n            elif os.path.isfile(input_path) and str(input_path).endswith(\".py\"):\n                contents = Path(input_path).read_bytes()\n                _, ast = pyastgrep.files.parse_python_file(\n                    contents, input_path, auto_dedent=False\n                )\n                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            },
            {
              "lineno": 695,
              "coloffset": 16,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                    contents, input_path, auto_dedent=False\n                )\n                xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                # Check if view_xml is chosen\n                if view_XML is not None:\n                    output.console.print(\n                        pyastgrep.xml.tostring(xml_root, pretty_print=True).decode(\n                            \"utf-8\"\n                        )\n                    )"
            },
            {
              "lineno": 711,
              "coloffset": 8,
              "linematch": "if store_result:",
              "linematch_context": "    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file\n            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n            output.console.print(\n                f\"\\n:sparkles: Results saved in: {os.path.abspath(analysis_file_dir)}\\n\"\n            )"
            },
            {
              "lineno": 727,
              "coloffset": 8,
              "linematch": "if display:",
              "linematch_context": "        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")\n        if display:\n            database.display_results_frog_mouth(result_path, util.get_OS())\n\n\n@cli.command()\ndef integrate(  # noqa: PLR0913"
            },
            {
              "lineno": 796,
              "coloffset": 4,
              "linematch": "if combined_json_file_name:",
              "linematch_context": "    combined_json_file_name = filesystem.write_dict_results(\n        combined_json_dict, output_directory, project\n    )\n    # output the name of the saved file if saving successfully took place\n    if combined_json_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{combined_json_file_name}'\")\n        output.logger.debug(f\"Saved the file '{combined_json_file_name}'.\")\n    # \"flatten\" (i.e., \"un-nest\") the now-saved combined JSON file using flatterer\n    # create the SQLite3 database and then configure the database for use in datasette\n    combined_flattened_directory = filesystem.write_flattened_csv_and_database("
            },
            {
              "lineno": 808,
              "coloffset": 4,
              "linematch": "if combined_flattened_directory:",
              "linematch_context": "        project,\n    )\n    output.logger.debug(\"Flattened JSON and created SQLite database.\")\n    # output the name of the saved file if saving successfully took place\n    if combined_flattened_directory:\n        output.console.print(\n            f\"\\n:sparkles: Created this directory structure in {Path(combined_flattened_directory).parent}:\"\n        )\n        combined_directory_tree = filesystem.create_directory_tree_visualization(\n            Path(combined_flattened_directory)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "CL001",
          "name": "single-nested-if",
          "description": "Ensure the presence of single nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If",
          "passed": false,
          "matches": [
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "if verbose:",
              "linematch_context": "def print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")\n        # iterate through each of the configuration keyword arguments\n        for configuration_current in configurations:\n            # print the name and the value of the keyword argument\n            console.print("
            },
            {
              "lineno": 61,
              "coloffset": 8,
              "linematch": "if verbose:",
              "linematch_context": "    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument\n        # to the console if verbose mode is enabled\n        if verbose:\n            console.print(contents[current])\n        # always log the information to the configured logger\n        logger.debug(contents[current])\n\n"
            },
            {
              "lineno": 122,
              "coloffset": 8,
              "linematch": "if directory not in grouped_files:",
              "linematch_context": "        file_name = file_path.name\n        # update the dictionary that uses:\n        # --> a Path key for the containing directory\n        # --> a list of strings for the contained files\n        if directory not in grouped_files:\n            grouped_files[directory] = []\n        grouped_files[directory].append(file_name)\n    # return the dictionary of files organized by directory\n    return grouped_files\n"
            },
            {
              "lineno": 132,
              "coloffset": 4,
              "linematch": "if len(file_name) > max_length:",
              "linematch_context": "\ndef shorten_file_name(file_name: str, max_length: int) -> str:\n    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long\n    if len(file_name) > max_length:\n        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name\n\n\ndef print_list_contents(container: List[Path]) -> None:"
            },
            {
              "lineno": 169,
              "coloffset": 4,
              "linematch": "if not verbose:",
              "linematch_context": "    # 2) Note: the _match object that is inside of a Match BaseModel subclass\n    # is an instance of pyastgrepsearch.Match and contains the entire details\n    # about the specific match, including the entire source code. This object\n    # is not saved to the JSON file by default, as evidenced by the underscore\n    if not verbose:\n        return None\n    opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")\n    # iterate through the the list of sources inside of the resulting analysis\n    for current_source in chasten.sources:\n        # extract the current check from this source"
            },
            {
              "lineno": 209,
              "coloffset": 8,
              "linematch": "if len(current_check._matches) > 0:  # type: ignore",
              "linematch_context": "                expand=False,\n                title=f\"{combined_attribute_label}\",\n            )\n        )\n        if len(current_check._matches) > 0:  # type: ignore\n            # display the details about the number of matches and the name of the source's file\n            opt_print_log(verbose, blank=constants.markers.Empty_String)\n            opt_print_log(\n                verbose,\n                label=f\":tada: Found a total of {len(current_check._matches)} matches for '{check_name}' in {current_source.filename}\","
            },
            {
              "lineno": 218,
              "coloffset": 16,
              "linematch": "if isinstance(current_match, pyastgrepsearch.Match):  # type: ignore",
              "linematch_context": "                label=f\":tada: Found a total of {len(current_check._matches)} matches for '{check_name}' in {current_source.filename}\",\n            )\n            # iterate through each of the matches and display all of their details\n            for current_match in current_check._matches:  # type: ignore\n                if isinstance(current_match, pyastgrepsearch.Match):  # type: ignore\n                    # display a label for matching output information\n                    opt_print_log(verbose, blank=constants.markers.Empty_String)\n                    opt_print_log(verbose, label=\":sparkles: Matching source code:\")\n                    # extract the direct line number for this match\n                    position_end = current_match.position.lineno"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 223,
              "coloffset": 8,
              "linematch": "if Path(config).is_dir():",
              "linematch_context": "        configuration_file_source = chasten_user_config_url_str\n    # input configuration exists and is valid file path\n    elif Path(config).exists():\n        # input configuration is a directory\n        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file\n        elif Path(config).is_file():\n            # re-parse input config so it is of type Path"
            },
            {
              "lineno": 250,
              "coloffset": 8,
              "linematch": "if chasten_user_config_file_str != \"\":",
              "linematch_context": "        )\n        # optional argument if chasten_user_config_file_str is not empty\n        # argument will be supplied as unpacked dict\n        chasten_user_config_file_str_argument = {}\n        if chasten_user_config_file_str != \"\":\n            chasten_user_config_file_str_argument[\n                \"configuration_file\"\n            ] = chasten_user_config_file_str\n        # extract the configuration details\n        ("
            },
            {
              "lineno": 266,
              "coloffset": 8,
              "linematch": "if not configuration_valid:",
              "linematch_context": "        )\n        # it was not possible to extract the configuration details and\n        # thus this function should return immediately with False\n        # to indicate the failure and an empty configuration dictionary\n        if not configuration_valid:\n            return (False, {})\n        # create a visualization of the user's configuration directory;\n        # display details about the configuration directory in console\n        display_configuration_directory(chasten_user_config_dir_str, verbose)\n        configuration_file_source = chasten_user_config_dir_str"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 86,
              "coloffset": 8,
              "linematch": "if count >= min_value:",
              "linematch_context": "        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True"
            },
            {
              "lineno": 90,
              "coloffset": 8,
              "linematch": "if count <= max_value:",
              "linematch_context": "        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False\n"
            },
            {
              "lineno": 116,
              "coloffset": 8,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 182,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "    # function was not asked to publish a database\n    if not publish:\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                str(database_path),\n                \"-m\",\n                str(metadata),"
            },
            {
              "lineno": 214,
              "coloffset": 8,
              "linematch": "if not found_publish_platform_executable:",
              "linematch_context": "        ) = filesystem.can_find_executable(util.executable_name(datasette_platform))\n        # was not able to find the fly or vercel executable (the person using this\n        # program has to install separately, following the instructions for the\n        # datasette-publish-fly plugin) and thus need to exit and not proceed\n        if not found_publish_platform_executable:\n            output.console.print(\n                f\":person_shrugging: Was not able to find '{datasette_platform}'\"\n            )\n            return None\n        # was able to find the fly or vercel executable that will support the"
            },
            {
              "lineno": 231,
              "coloffset": 8,
              "linematch": "if datasette_platform == constants.chasten.Executable_Fly:",
              "linematch_context": "        # create the customized running argument for either fly or vercel; note\n        # that these programs take different arguments for specifying the name\n        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option"
            },
            {
              "lineno": 238,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                \"publish\",\n                datasette_platform,\n                str(database_path),"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 140,
              "coloffset": 12,
              "linematch": "if item.is_dir():",
              "linematch_context": "        tree = tree.add(f\":open_file_folder: {path.name}\")\n    # recursively process the directory\n    if path.is_dir():\n        for item in path.iterdir():\n            if item.is_dir():\n                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")\n    # return the tree now containing all nodes\n    return tree"
            },
            {
              "lineno": 153,
              "coloffset": 8,
              "linematch": "if file.is_file() and file.exists():",
              "linematch_context": "    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():\n            return True\n    # the file was either none or not valid\n    return False\n\n"
            },
            {
              "lineno": 164,
              "coloffset": 8,
              "linematch": "if directory.is_dir() and directory.exists():",
              "linematch_context": "    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True\n    # the directory was either none or not valid\n    return False\n\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/validate.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 109,
              "coloffset": 8,
              "linematch": "if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:",
              "linematch_context": "    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files\n            # and return them in a list with a boolean\n            # indicate to show that checks files were found\n            checks_file_name_list = configuration[constants.checks.Check_Chasten][\n                constants.checks.Check_File"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 123,
              "coloffset": 12,
              "linematch": "if event.validation_result.is_valid:",
              "linematch_context": "        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":"
            },
            {
              "lineno": 141,
              "coloffset": 12,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 118,
              "coloffset": 8,
              "linematch": "if filesystem.confirm_valid_file(API_KEY_STORAGE):",
              "linematch_context": "    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks\n        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))\n        # Checks if API key storage file exists\n        if filesystem.confirm_valid_file(API_KEY_STORAGE):\n            # prints the human readable checks to the terminal\n            output.console.print(result)\n            # loads the decrypted API Key\n            api_key = createchecks.load_user_api_key(API_KEY_STORAGE)\n            # calls the function to generate the yaml file"
            },
            {
              "lineno": 205,
              "coloffset": 8,
              "linematch": "if not validated:",
              "linematch_context": "        # --> checks.yml (or whatever file/url is reference in config.yml)\n        (validated, _) = configuration.validate_configuration_files(config, verbose)\n        # some aspect of the configuration was not\n        # valid, so exit early and signal an error\n        if not validated:\n            output.console.print(\n                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n            )\n            sys.exit(constants.markers.Non_Zero_Exit)\n    # create the configuration directory and a starting version of the configuration file"
            },
            {
              "lineno": 217,
              "coloffset": 12,
              "linematch": "if config is None:",
              "linematch_context": "        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs\n            if config is None:\n                configuration_directory = None\n            else:\n                configuration_directory = Path(config)\n            created_directory_path = filesystem.create_configuration_directory(\n                configuration_directory, force"
            },
            {
              "lineno": 241,
              "coloffset": 12,
              "linematch": "if not force:",
              "linematch_context": "        # cannot re-create the configuration directory, so display\n        # a message and suggest the use of --force the next time;\n        # exit early and signal an error with a non-zero exist code\n        except FileExistsError:\n            if not force:\n                output.console.print(\n                    \"\\n:person_shrugging: Configuration directory already exists.\"\n                )\n                output.console.print(\n                    \"Use --force to recreate configuration directory and its containing files.\""
            },
            {
              "lineno": 433,
              "coloffset": 8,
              "linematch": "if filesystem.confirm_valid_file(analysis_file_dir):",
              "linematch_context": "        # creates an empty string for storing results temporarily\n        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )"
            },
            {
              "lineno": 434,
              "coloffset": 12,
              "linematch": "if not force:",
              "linematch_context": "        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )\n                    sys.exit(0)"
            },
            {
              "lineno": 435,
              "coloffset": 16,
              "linematch": "if display:",
              "linematch_context": "        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )\n                    sys.exit(0)\n                else:"
            },
            {
              "lineno": 649,
              "coloffset": 12,
              "linematch": "if os.path.isdir(input_path):",
              "linematch_context": "    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)"
            },
            {
              "lineno": 652,
              "coloffset": 20,
              "linematch": "if (",
              "linematch_context": "        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)\n                        and str(each_file).endswith(\".py\")\n                    ):\n                        # Read the bytes of the input path and store them in the 'contents' variable"
            },
            {
              "lineno": 666,
              "coloffset": 24,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                        )\n                        # Convert the Abstract Syntax Tree (AST) into an XML representation\n                        xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                        # Check if view_xml is chosen\n                        if view_XML is not None:\n                            output.console.print(\n                                pyastgrep.xml.tostring(\n                                    xml_root, pretty_print=True\n                                ).decode(\"utf-8\")\n                            )"
            },
            {
              "lineno": 675,
              "coloffset": 28,
              "linematch": "if str(sub_file).endswith(\".py\"):",
              "linematch_context": "                            )\n                    elif os.path.isdir(each_file):\n                        for sub_file in os.listdir(each_file):\n                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901\n                            if str(sub_file).endswith(\".py\"):\n                                contents = Path(sub_file).read_bytes()\n                                _, ast = pyastgrep.files.parse_python_file(\n                                    contents, sub_file, auto_dedent=False\n                                )\n                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            },
            {
              "lineno": 682,
              "coloffset": 32,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                                    contents, sub_file, auto_dedent=False\n                                )\n                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                                # Check if view_xml is chosen\n                                if view_XML is not None:\n                                    output.console.print(\n                                        pyastgrep.xml.tostring(\n                                            xml_root, pretty_print=True\n                                        ).decode(\"utf-8\")\n                                    )"
            },
            {
              "lineno": 695,
              "coloffset": 16,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                    contents, input_path, auto_dedent=False\n                )\n                xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                # Check if view_xml is chosen\n                if view_XML is not None:\n                    output.console.print(\n                        pyastgrep.xml.tostring(xml_root, pretty_print=True).decode(\n                            \"utf-8\"\n                        )\n                    )"
            },
            {
              "lineno": 711,
              "coloffset": 8,
              "linematch": "if store_result:",
              "linematch_context": "    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file\n            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n            output.console.print(\n                f\"\\n:sparkles: Results saved in: {os.path.abspath(analysis_file_dir)}\\n\"\n            )"
            },
            {
              "lineno": 727,
              "coloffset": 8,
              "linematch": "if display:",
              "linematch_context": "        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")\n        if display:\n            database.display_results_frog_mouth(result_path, util.get_OS())\n\n\n@cli.command()\ndef integrate(  # noqa: PLR0913"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "CL002",
          "name": "double-nested-if",
          "description": "Ensure the presence of double nested 'if' statements within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body//If[ancestor::If and not(parent::orelse)]",
          "passed": false,
          "matches": [
            {
              "lineno": 218,
              "coloffset": 16,
              "linematch": "if isinstance(current_match, pyastgrepsearch.Match):  # type: ignore",
              "linematch_context": "                label=f\":tada: Found a total of {len(current_check._matches)} matches for '{check_name}' in {current_source.filename}\",\n            )\n            # iterate through each of the matches and display all of their details\n            for current_match in current_check._matches:  # type: ignore\n                if isinstance(current_match, pyastgrepsearch.Match):  # type: ignore\n                    # display a label for matching output information\n                    opt_print_log(verbose, blank=constants.markers.Empty_String)\n                    opt_print_log(verbose, label=\":sparkles: Matching source code:\")\n                    # extract the direct line number for this match\n                    position_end = current_match.position.lineno"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/mutmut_config.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 7,
              "linematch": "if context.mutation_id.operator == \"delete\":",
              "linematch_context": "    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    \n    if context.mutation_id.operator == \"delete\":\n        # Allow statement deletion mutations\n        return\n    elif any(op in context.source for op in arithmetic_operators):\n        # Allow arithmetic operator mutations\n        return"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configApp.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 52,
              "coloffset": 11,
              "linematch": "assert configApp.split_file(file) == CSV_CHECK_LIST",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given(\n    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            },
            {
              "lineno": 52,
              "coloffset": 11,
              "linematch": "assert configApp.split_file(file) == CSV_CHECK_LIST",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given(\n    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            },
            {
              "lineno": 52,
              "coloffset": 11,
              "linematch": "assert configApp.split_file(file) == CSV_CHECK_LIST",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given(\n    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_debug.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_util.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 33,
              "coloffset": 15,
              "linematch": "assert str_answer == \"No\"",
              "linematch_context": "    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:"
            },
            {
              "lineno": 33,
              "coloffset": 15,
              "linematch": "assert str_answer == \"No\"",
              "linematch_context": "    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:"
            },
            {
              "lineno": 33,
              "coloffset": 15,
              "linematch": "assert str_answer == \"No\"",
              "linematch_context": "    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:"
            },
            {
              "lineno": 33,
              "coloffset": 15,
              "linematch": "assert str_answer == \"No\"",
              "linematch_context": "    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:"
            },
            {
              "lineno": 41,
              "coloffset": 11,
              "linematch": "assert result is True",
              "linematch_context": "@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_createchecks.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 22,
              "coloffset": 11,
              "linematch": "assert result is True",
              "linematch_context": "    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n\n\n# @pytest.mark.api\n# def test_invalid_api_key():\n#     \"\"\"Test is_valid_api_key function with an invalid api key.\"\"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 45,
              "coloffset": 11,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 11,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 55,
              "coloffset": 15,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 55,
              "coloffset": 15,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 55,
              "coloffset": 15,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 55,
              "coloffset": 15,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 115,
              "coloffset": 41,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 136,
              "coloffset": 11,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_main.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            },
            {
              "lineno": 534,
              "coloffset": 11,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_constants.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            },
            {
              "lineno": 73,
              "coloffset": 15,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 188,
              "coloffset": 7,
              "linematch": "if config == \"\":",
              "linematch_context": "    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":\n        # there is no configuration file specified and thus\n        # this function should access the platform-specific\n        # configuration directory detected by platformdirs\n        # detect and store the platform-specific user\n        # configuration directory by default"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/util.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 103,
              "coloffset": 11,
              "linematch": "return str(parse_url(url)).lower() == url_reassembled.lower()",
              "linematch_context": "    for url_piece in url_pieces:\n        if url_piece is not None:\n            url_reassembled += str(url_piece)\n    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed"
            },
            {
              "lineno": 103,
              "coloffset": 11,
              "linematch": "return str(parse_url(url)).lower() == url_reassembled.lower()",
              "linematch_context": "    for url_piece in url_pieces:\n        if url_piece is not None:\n            url_reassembled += str(url_piece)\n    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 116,
              "coloffset": 11,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            },
            {
              "lineno": 116,
              "coloffset": 11,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            },
            {
              "lineno": 68,
              "coloffset": 46,
              "linematch": "return min(max_value, value) == value and max(min_value, value) == value",
              "linematch_context": "\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:"
            },
            {
              "lineno": 68,
              "coloffset": 46,
              "linematch": "return min(max_value, value) == value and max(min_value, value) == value",
              "linematch_context": "\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:"
            },
            {
              "lineno": 116,
              "coloffset": 11,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            },
            {
              "lineno": 116,
              "coloffset": 11,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            },
            {
              "lineno": 116,
              "coloffset": 11,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 233,
              "coloffset": 13,
              "linematch": "elif datasette_platform == constants.chasten.Executable_Vercel:",
              "linematch_context": "        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:"
            },
            {
              "lineno": 233,
              "coloffset": 13,
              "linematch": "elif datasette_platform == constants.chasten.Executable_Vercel:",
              "linematch_context": "        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 131,
              "coloffset": 7,
              "linematch": "if tree is None:",
              "linematch_context": "def create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")\n    # add the new file node to the tree since\n    # the tree has already been created\n    else:\n        tree = tree.add(f\":open_file_folder: {path.name}\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/createchecks.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 70,
              "coloffset": 11,
              "linematch": "if len(lines) == 2:  # noqa: PLR2004",
              "linematch_context": "\ndef load_user_api_key(file):\n    with open(file, \"r\") as f:\n        lines = f.read().strip().split(\"\\n\")\n        if len(lines) == 2:  # noqa: PLR2004\n            key = lines[0].encode()\n            encrypted_key = lines[1]\n        fernet = Fernet(key)\n        return fernet.decrypt(encrypted_key.encode()).decode()\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 141,
              "coloffset": 15,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            },
            {
              "lineno": 141,
              "coloffset": 15,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            },
            {
              "lineno": 141,
              "coloffset": 15,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            },
            {
              "lineno": 141,
              "coloffset": 15,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            },
            {
              "lineno": 141,
              "coloffset": 15,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            },
            {
              "lineno": 141,
              "coloffset": 15,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 24,
              "coloffset": 34,
              "linematch": "if check_attribute is None or check_match is None:",
              "linematch_context": "    filtered_checks = []\n    # at least one aspect of the inputs was not specified (likely due to\n    # the fact that the command-line argument(s) were not used) and thus\n    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:\n        return checks\n    # the function's inputs are valid and so perform the filtering\n    for check in checks:\n        # extract the contents of the requested attribute for inclusion\n        check_requested_include_attribute = check[check_attribute]"
            },
            {
              "lineno": 24,
              "coloffset": 34,
              "linematch": "if check_attribute is None or check_match is None:",
              "linematch_context": "    filtered_checks = []\n    # at least one aspect of the inputs was not specified (likely due to\n    # the fact that the command-line argument(s) were not used) and thus\n    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:\n        return checks\n    # the function's inputs are valid and so perform the filtering\n    for check in checks:\n        # extract the contents of the requested attribute for inclusion\n        check_requested_include_attribute = check[check_attribute]"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "BOOL001",
          "name": "boolean-comparison",
          "description": "Using = or == operators to compare boolean values",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Compare/ops/Is | .//FunctionDef//Compare/ops/Eq",
          "passed": false,
          "matches": [
            {
              "lineno": 535,
              "coloffset": 19,
              "linematch": "if check_status_symbol == \"[green]\\u2713[/green]\"",
              "linematch_context": "        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\"\n            )\n            # stores check type in a string to stored in file later\n            analysis_result += (\n                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            },
            {
              "lineno": 535,
              "coloffset": 19,
              "linematch": "if check_status_symbol == \"[green]\\u2713[/green]\"",
              "linematch_context": "        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\"\n            )\n            # stores check type in a string to stored in file later\n            analysis_result += (\n                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            },
            {
              "lineno": 217,
              "coloffset": 15,
              "linematch": "if config is None:",
              "linematch_context": "        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs\n            if config is None:\n                configuration_directory = None\n            else:\n                configuration_directory = Path(config)\n            created_directory_path = filesystem.create_configuration_directory(\n                configuration_directory, force"
            },
            {
              "lineno": 535,
              "coloffset": 19,
              "linematch": "if check_status_symbol == \"[green]\\u2713[/green]\"",
              "linematch_context": "        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\"\n            )\n            # stores check type in a string to stored in file later\n            analysis_result += (\n                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            },
            {
              "lineno": 535,
              "coloffset": 19,
              "linematch": "if check_status_symbol == \"[green]\\u2713[/green]\"",
              "linematch_context": "        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\"\n            )\n            # stores check type in a string to stored in file later\n            analysis_result += (\n                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            },
            {
              "lineno": 535,
              "coloffset": 19,
              "linematch": "if check_status_symbol == \"[green]\\u2713[/green]\"",
              "linematch_context": "        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\"\n            )\n            # stores check type in a string to stored in file later\n            analysis_result += (\n                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            },
            {
              "lineno": 535,
              "coloffset": 19,
              "linematch": "if check_status_symbol == \"[green]\\u2713[/green]\"",
              "linematch_context": "        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\"\n            )\n            # stores check type in a string to stored in file later\n            analysis_result += (\n                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/mutmut_config.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 3,
              "coloffset": 0,
              "linematch": "def pre_mutation(context):",
              "linematch_context": "from mutmut import context\n\ndef pre_mutation(context):\n    arithmetic_operators = ['+', '-', '*', '/']\n    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    "
            },
            {
              "lineno": 19,
              "coloffset": 0,
              "linematch": "def configure(context):",
              "linematch_context": "    else:\n        # Skip all other mutations\n        context.skip = True\n\ndef configure(context):\n    context.pre_mutation = pre_mutation"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configApp.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 33,
              "coloffset": 0,
              "linematch": "def test_write_checks():",
              "linematch_context": "\"\"\"\n\n\n# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n"
            },
            {
              "lineno": 40,
              "coloffset": 0,
              "linematch": "def test_write_checks_empty_file():",
              "linematch_context": "    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\"\n    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data"
            },
            {
              "lineno": 46,
              "coloffset": 0,
              "linematch": "def test_split_file(tmpdir):",
              "linematch_context": "    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)"
            },
            {
              "lineno": 63,
              "coloffset": 0,
              "linematch": "def test_store_in_file(Pattern, Matches, Exact, tmpdir):",
              "linematch_context": "    Exact=st.booleans(),\n)\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_database.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 8,
              "coloffset": 0,
              "linematch": "def test_create_chasten_view():",
              "linematch_context": "\nfrom chasten import database\n\n\ndef test_create_chasten_view():\n    \"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"\n    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_debug.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 8,
              "coloffset": 0,
              "linematch": "def test_debug_level_values():",
              "linematch_context": "\nfrom chasten.debug import DebugDestination, DebugLevel\n\n\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\""
            },
            {
              "lineno": 17,
              "coloffset": 0,
              "linematch": "def test_debug_level_isinstance():",
              "linematch_context": "    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)"
            },
            {
              "lineno": 26,
              "coloffset": 0,
              "linematch": "def test_debug_level_iteration():",
              "linematch_context": "    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():"
            },
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def test_debug_destination_values():",
              "linematch_context": "    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n"
            },
            {
              "lineno": 37,
              "coloffset": 0,
              "linematch": "def test_debug_destination_isinstance():",
              "linematch_context": "    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n"
            },
            {
              "lineno": 43,
              "coloffset": 0,
              "linematch": "def test_debug_destination_iteration():",
              "linematch_context": "    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():"
            },
            {
              "lineno": 48,
              "coloffset": 0,
              "linematch": "def test_level_destination_invalid():",
              "linematch_context": "    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugLevel(\"INVALID\")\n\n"
            },
            {
              "lineno": 54,
              "coloffset": 0,
              "linematch": "def test_debug_destination_invalid():",
              "linematch_context": "    with pytest.raises(ValueError):\n        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugDestination(\"INVALID\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configuration.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 13,
              "coloffset": 0,
              "linematch": "def test_fuzz_create_use_config_dir(",
              "linematch_context": "\n\n@given(applicationname=strategies.text(), applicationauthor=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_create_use_config_dir(\n    applicationname: str, applicationauthor: str\n) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor"
            },
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def test_fuzz_configure_logging(debug_level, debug_dest):",
              "linematch_context": "    ),\n    debug_dest=strategies.sampled_from([\"CONSOLE\", \"SYSLOG\"]),\n)\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 46,
              "coloffset": 0,
              "linematch": "def test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):",
              "linematch_context": "    ),\n    debug_dest=strategies.sampled_from([\"CONSOLE-WRONG\", \"SYSLOG-WRONG\"]),\n)\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_util.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 0,
              "linematch": "def test_human_readable_boolean() -> None:",
              "linematch_context": "\nfrom chasten import constants, util\n\n\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n"
            },
            {
              "lineno": 20,
              "coloffset": 0,
              "linematch": "def test_fuzz_human_readable_boolean(answer: bool) -> None:",
              "linematch_context": "\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    util.get_human_readable_boolean(answer=answer)\n\n\n@given(answer=st.booleans())"
            },
            {
              "lineno": 27,
              "coloffset": 0,
              "linematch": "def test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:",
              "linematch_context": "\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:"
            },
            {
              "lineno": 38,
              "coloffset": 0,
              "linematch": "def test_is_url_correct(url: str) -> None:",
              "linematch_context": "\n\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n"
            },
            {
              "lineno": 46,
              "coloffset": 0,
              "linematch": "def test_total_amount_passed(check_status_list: list[bool]):",
              "linematch_context": "\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_createchecks.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 0,
              "linematch": "def get_valid_api_key():",
              "linematch_context": "\nfrom chasten.createchecks import generate_yaml_config, is_valid_api_key\n\n\ndef get_valid_api_key():\n    \"\"\"Retrive and return api key from env variable\"\"\"\n    return os.getenv(\"API_KEY\")\n\n\n@pytest.mark.api"
            },
            {
              "lineno": 15,
              "coloffset": 0,
              "linematch": "def test_valid_api_key():",
              "linematch_context": "    return os.getenv(\"API_KEY\")\n\n\n@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n"
            },
            {
              "lineno": 34,
              "coloffset": 0,
              "linematch": "def test_generate_yaml_config():",
              "linematch_context": "#     assert result is False\n\n\n@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 14,
              "coloffset": 0,
              "linematch": "def test_valid_directory() -> None:",
              "linematch_context": "\nfrom chasten import constants, filesystem\n\n\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True"
            },
            {
              "lineno": 22,
              "coloffset": 0,
              "linematch": "def test_invalid_directory() -> None:",
              "linematch_context": "    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False"
            },
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def test_valid_file() -> None:",
              "linematch_context": "    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True"
            },
            {
              "lineno": 39,
              "coloffset": 0,
              "linematch": "def test_invalid_file() -> None:",
              "linematch_context": "    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False"
            },
            {
              "lineno": 50,
              "coloffset": 0,
              "linematch": "def test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:",
              "linematch_context": "\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_directory(directory=directory)\n\n\n@given(file=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 57,
              "coloffset": 0,
              "linematch": "def test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:",
              "linematch_context": "\n\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):"
            },
            {
              "lineno": 62,
              "coloffset": 0,
              "linematch": "def test_create_directory_tree(tmpdir):",
              "linematch_context": "    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()"
            },
            {
              "lineno": 90,
              "coloffset": 0,
              "linematch": "def test_fuzz_create_directory_tree(directory):",
              "linematch_context": "\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label"
            },
            {
              "lineno": 111,
              "coloffset": 0,
              "linematch": "def test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):",
              "linematch_context": "    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            },
            {
              "lineno": 124,
              "coloffset": 0,
              "linematch": "def test_create_config_dir_already_exist_throw_exception(",
              "linematch_context": "    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the"
            },
            {
              "lineno": 142,
              "coloffset": 0,
              "linematch": "def test_create_config_dir_already_exist_no_exception_when_no_force(",
              "linematch_context": "        filesystem.create_configuration_directory(force=False)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_no_force(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the"
            },
            {
              "lineno": 160,
              "coloffset": 0,
              "linematch": "def test_create_config_dir_already_exist_no_exception_when_force(",
              "linematch_context": "        filesystem.create_configuration_directory(force=False)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_force(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the"
            },
            {
              "lineno": 176,
              "coloffset": 0,
              "linematch": "def test_detect_configuration_with_input_config_directory(tmp_path):",
              "linematch_context": "    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()"
            },
            {
              "lineno": 186,
              "coloffset": 0,
              "linematch": "def test_detect_configuration_with_input_config_directory_use_default(",
              "linematch_context": "    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the"
            },
            {
              "lineno": 203,
              "coloffset": 0,
              "linematch": "def test_create_main_configuration_file(mock_user_config_dir, tmp_path):",
              "linematch_context": "    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            },
            {
              "lineno": 227,
              "coloffset": 0,
              "linematch": "def test_create_checks_configuration_file(mock_user_config_dir, tmp_path):",
              "linematch_context": "    )\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_checks_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def test_filter_matches(match_list, data_type):",
              "linematch_context": "    ),\n    data_type=st.just(pyastgrepsearch.Match),\n)\n@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)"
            },
            {
              "lineno": 42,
              "coloffset": 0,
              "linematch": "def test_filter_matches_no_matches(match_list):",
              "linematch_context": "\n\n@given(match_list=st.lists(st.integers()))\n@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n"
            },
            {
              "lineno": 51,
              "coloffset": 0,
              "linematch": "def test_filter_matches_only_int_matches(match_list, data_type):",
              "linematch_context": "\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_validate.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 10,
              "coloffset": 0,
              "linematch": "def test_validate_config_valid_realistic():",
              "linematch_context": "\nfrom chasten.validate import JSON_SCHEMA_CONFIG, validate_configuration\n\n\ndef test_validate_config_valid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }"
            },
            {
              "lineno": 22,
              "coloffset": 0,
              "linematch": "def test_validate_config_invalid_realistic():",
              "linematch_context": "    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }"
            },
            {
              "lineno": 39,
              "coloffset": 0,
              "linematch": "def test_validate_empty_config(config):",
              "linematch_context": "@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})\n)\n@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n"
            },
            {
              "lineno": 49,
              "coloffset": 0,
              "linematch": "def test_integers(config):",
              "linematch_context": "\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 27,
              "coloffset": 0,
              "linematch": "def test_extract_min_max():",
              "linematch_context": "    },\n}\n\n\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa"
            },
            {
              "lineno": 35,
              "coloffset": 0,
              "linematch": "def test_extract_max():",
              "linematch_context": "    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa"
            },
            {
              "lineno": 43,
              "coloffset": 0,
              "linematch": "def test_extract_min():",
              "linematch_context": "    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,"
            },
            {
              "lineno": 56,
              "coloffset": 0,
              "linematch": "def test_extract_min_max_missing():",
              "linematch_context": "    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None"
            },
            {
              "lineno": 64,
              "coloffset": 0,
              "linematch": "def test_extract_description():",
              "linematch_context": "    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"description\": \"described test\",\n        \"count\": {"
            },
            {
              "lineno": 76,
              "coloffset": 0,
              "linematch": "def test_extract_desription_none():",
              "linematch_context": "    }\n    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,"
            },
            {
              "lineno": 94,
              "coloffset": 0,
              "linematch": "def test_make_checks_status_message(bool_status: bool, expected: str):",
              "linematch_context": "        (True, \":smiley: Did the check pass? Yes\"),\n        (False, \":worried: Did the check pass? No\"),\n    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))"
            },
            {
              "lineno": 101,
              "coloffset": 0,
              "linematch": "def test_extract_min_max_hypothesis(check):",
              "linematch_context": "\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n"
            },
            {
              "lineno": 111,
              "coloffset": 0,
              "linematch": "def test_integers(check):",
              "linematch_context": "\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n"
            },
            {
              "lineno": 133,
              "coloffset": 0,
              "linematch": "def test_check_match_count_expected(count, min_value, max_value, expected):",
              "linematch_context": "        (1, 2, None, False),\n        (3, None, 2, False),\n    ],\n)\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n"
            },
            {
              "lineno": 145,
              "coloffset": 0,
              "linematch": "def test_check_match_count(count, min, max):",
              "linematch_context": "    st.integers(min_value=0, max_value=25),\n    st.integers(min_value=0, max_value=25),\n)\n@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_main.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 78,
              "coloffset": 0,
              "linematch": "def cwd():",
              "linematch_context": "\"\"\"\n\n\n@pytest.fixture\ndef cwd():\n    \"\"\"Define a test fixture for the current working directory.\"\"\"\n    return os.getcwd()\n\n\ndef test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):"
            },
            {
              "lineno": 83,
              "coloffset": 0,
              "linematch": "def test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):",
              "linematch_context": "    \"\"\"Define a test fixture for the current working directory.\"\"\"\n    return os.getcwd()\n\n\ndef test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # create some temporary directories;\n    # note that there is no code inside of this directory\n    # and thus chasten does not actually have any\n    # Python source code that it can analyze"
            },
            {
              "lineno": 119,
              "coloffset": 0,
              "linematch": "def test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):",
              "linematch_context": "    )\n    assert result.exit_code == 0\n\n\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 141,
              "coloffset": 0,
              "linematch": "def test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):",
              "linematch_context": "    )\n    assert result.exit_code in [0, 1]\n\n\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 165,
              "coloffset": 0,
              "linematch": "def test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):",
              "linematch_context": "    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory"
            },
            {
              "lineno": 190,
              "coloffset": 0,
              "linematch": "def test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):",
              "linematch_context": "    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\""
            },
            {
              "lineno": 222,
              "coloffset": 0,
              "linematch": "def test_cli_analyze_incorrect_arguments_correct_config(tmpdir):",
              "linematch_context": "    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory"
            },
            {
              "lineno": 354,
              "coloffset": 0,
              "linematch": "def test_cli_configure_create_config_when_does_not_exist(",
              "linematch_context": "#     assert result.exit_code == 1\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_create_config_when_does_not_exist(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the"
            },
            {
              "lineno": 375,
              "coloffset": 0,
              "linematch": "def test_cli_configure_cannot_create_config_when_does_exist(",
              "linematch_context": "    assert result.exit_code == 0\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_cannot_create_config_when_does_exist(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the"
            },
            {
              "lineno": 401,
              "coloffset": 0,
              "linematch": "def test_fuzz_cli_analyze_single_directory(cwd, directory):",
              "linematch_context": "\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_fuzz_cli_analyze_single_directory(cwd, directory):\n    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")"
            },
            {
              "lineno": 421,
              "coloffset": 0,
              "linematch": "def test_analyze_store_results_file_does_not_exist(cwd, tmpdir):",
              "linematch_context": "    )\n    assert result.exit_code == 0\n\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 445,
              "coloffset": 0,
              "linematch": "def test_analyze_store_results_file_exists_no_force(cwd, tmpdir):",
              "linematch_context": "    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist"
            },
            {
              "lineno": 480,
              "coloffset": 0,
              "linematch": "def test_analyze_store_results_file_exists_force(cwd, tmpdir):",
              "linematch_context": "        in result.output\n    )\n\n\ndef test_analyze_store_results_file_exists_force(cwd, tmpdir):\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()"
            },
            {
              "lineno": 515,
              "coloffset": 0,
              "linematch": "def test_analyze_store_results_valid_path(directory, cwd):",
              "linematch_context": "\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_analyze_store_results_valid_path(directory, cwd):\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_constants.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 0,
              "linematch": "def test_filesystem_constants():",
              "linematch_context": "\nfrom chasten import constants\n\n\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\""
            },
            {
              "lineno": 29,
              "coloffset": 0,
              "linematch": "def test_fuzz_init(directory, configfile, checksfile, extra, yes, no):  # noqa: PLR0913",
              "linematch_context": "    yes=strategies.text(),\n    no=strategies.text(),\n)\n@pytest.mark.fuzz\ndef test_fuzz_init(directory, configfile, checksfile, extra, yes, no):  # noqa: PLR0913\n    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory"
            },
            {
              "lineno": 45,
              "coloffset": 0,
              "linematch": "def test_fuzz_immutable(fs, hr):",
              "linematch_context": "    fs=strategies.builds(constants.Filesystem),\n    hr=strategies.builds(constants.Humanreadable),\n)\n@pytest.mark.fuzz\ndef test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\""
            },
            {
              "lineno": 62,
              "coloffset": 0,
              "linematch": "def test_fuzz_distinct(dir1, dir2, filename, extra):",
              "linematch_context": "    filename=strategies.text(),\n    extra=strategies.text(),\n)\n@pytest.mark.fuzz\ndef test_fuzz_distinct(dir1, dir2, filename, extra):\n    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem("
            },
            {
              "lineno": 78,
              "coloffset": 0,
              "linematch": "def test_fuzz_dataclass_equality(directory, filename, extra):",
              "linematch_context": "\n\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 20,
              "coloffset": 0,
              "linematch": "def configure_tracebacks() -> None:",
              "linematch_context": "\nfrom chasten import constants, filesystem, output, util, validate\n\n\ndef configure_tracebacks() -> None:\n    \"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"\n    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:"
            },
            {
              "lineno": 25,
              "coloffset": 0,
              "linematch": "def user_config_dir(application_name: str, application_author: str) -> str:",
              "linematch_context": "    \"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"\n    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:\n    \"\"\"Return the user's configuration directory using platformdirs.\"\"\"\n    # access the directory and then return it based on the\n    # provided name of the application and the application's author\n    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str"
            },
            {
              "lineno": 33,
              "coloffset": 0,
              "linematch": "def configure_logging(",
              "linematch_context": "    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str\n\n\ndef configure_logging(\n    debug_level: str = constants.logging.Default_Logging_Level,\n    debug_dest: str = constants.logging.Default_Logging_Destination,\n) -> Tuple[logging.Logger, bool]:\n    \"\"\"Configure standard Python logging package.\"\"\"\n    # use the specified logger with the specified destination"
            },
            {
              "lineno": 53,
              "coloffset": 0,
              "linematch": "def configure_logging_console(",
              "linematch_context": "    except AttributeError:\n        return (configure_logging_console(debug_level), False)\n\n\ndef configure_logging_console(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use rich.\"\"\"\n    # use the RichHandler to provide formatted\n    # debugging output in the console"
            },
            {
              "lineno": 70,
              "coloffset": 0,
              "linematch": "def configure_logging_syslog(",
              "linematch_context": "    logger = logging.getLogger()\n    return logger\n\n\ndef configure_logging_syslog(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use syslog.\"\"\"\n    # use the SysLogHandler to send output to a localhost on a port\n    syslog_handler = logging.handlers.SysLogHandler("
            },
            {
              "lineno": 89,
              "coloffset": 0,
              "linematch": "def display_configuration_directory(",
              "linematch_context": "    logger = logging.getLogger()\n    return logger\n\n\ndef display_configuration_directory(\n    chasten_user_config_dir_str: str, verbose: bool = False\n) -> None:\n    \"\"\"Display information about the configuration in the console.\"\"\"\n    # create a visualization of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)"
            },
            {
              "lineno": 103,
              "coloffset": 0,
              "linematch": "def validate_checks_file(",
              "linematch_context": "    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,\n    checks_file_name: str,\n    chasten_user_config_url_str: str,\n    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,"
            },
            {
              "lineno": 177,
              "coloffset": 0,
              "linematch": "def validate_configuration_files(",
              "linematch_context": "        yaml_data_dict,\n    )\n\n\ndef validate_configuration_files(\n    config: str,\n    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:"
            },
            {
              "lineno": 340,
              "coloffset": 0,
              "linematch": "def extract_configuration_details_from_config_dir(",
              "linematch_context": "    # there was at least one validation error\n    return (False, {})\n\n\ndef extract_configuration_details_from_config_dir(\n    chasten_user_config_dir_str: Path,\n    configuration_file: str = constants.filesystem.Main_Configuration_File,\n) -> Tuple[bool, str, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config directory.\n"
            },
            {
              "lineno": 383,
              "coloffset": 0,
              "linematch": "def extract_configuration_details_from_config_url(",
              "linematch_context": "            )\n            return (False, None, None, None)  # type: ignore\n\n\ndef extract_configuration_details_from_config_url(\n    chasten_user_config_url: Url,\n) -> Tuple[bool, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config URL.\n\n    chasten_user_config_url -- URL to config or checks yaml file."
            },
            {
              "lineno": 415,
              "coloffset": 0,
              "linematch": "def convert_configuration_text_to_yaml(",
              "linematch_context": "        )\n        return (False, None, None)  # type: ignore\n\n\ndef convert_configuration_text_to_yaml(\n    configuration_file_contents_str: str,\n) -> Tuple[bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Return details about the configuration.\"\"\"\n    yaml_data = None\n    try:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/server.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 39,
              "coloffset": 0,
              "linematch": "def start_syslog_server():",
              "linematch_context": "        # write the logging message to a file using a rotating file handler\n        logger.debug(enhanced_message)\n\n\ndef start_syslog_server():\n    \"\"\"Start a syslog server.\"\"\"\n    global logger  # noqa: PLW0602\n    # always log all of the messages to a file\n    logger.setLevel(logging.DEBUG)\n    # create a RotatingFileHandler such that:"
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "def handle(self):",
              "linematch_context": "\nclass SyslogUDPHandler(socketserver.BaseRequestHandler):\n    \"\"\"Syslog UDP handler for receiving debugging messages.\"\"\"\n\n    def handle(self):\n        \"\"\"Receive a message and then display it in output and log it to a file.\"\"\"\n        global logger  # noqa: PLW0602\n        # receive the message from the syslog logging client\n        message = bytes.decode(\n            self.request[0].strip(), encoding=constants.server.Utf8_Encoding"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/util.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 16,
              "coloffset": 0,
              "linematch": "def get_human_readable_boolean(answer: bool) -> str:",
              "linematch_context": "xmark_unicode = \"\\u2717\"\ndefault_chasten_semver = \"0.0.0\"\n\n\ndef get_human_readable_boolean(answer: bool) -> str:\n    \"\"\"Produce a human-readable Yes or No for a boolean value of True or False.\"\"\"\n    # the provided answer is true\n    if answer:\n        return constants.humanreadable.Yes\n    # the provided answer is false"
            },
            {
              "lineno": 25,
              "coloffset": 0,
              "linematch": "def get_OS() -> str:",
              "linematch_context": "    # the provided answer is false\n    return constants.humanreadable.No\n\n\ndef get_OS() -> str:\n    \"\"\"Gets the Operating system of the user.\"\"\"\n    OpSystem = platform.system()\n    return OpSystem\n\n"
            },
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:",
              "linematch_context": "    OpSystem = platform.system()\n    return OpSystem\n\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\"\n    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\""
            },
            {
              "lineno": 42,
              "coloffset": 0,
              "linematch": "def get_symbol_boolean(answer: bool) -> str:",
              "linematch_context": "    virtual_env_location = sys.prefix\n    return virtual_env_location + exe_directory + executable_name\n\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:\n        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n"
            },
            {
              "lineno": 49,
              "coloffset": 0,
              "linematch": "def get_chasten_version() -> str:",
              "linematch_context": "        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n\n\ndef get_chasten_version() -> str:\n    \"\"\"Use importlib to extract the version of the package.\"\"\"\n    # attempt to determine the current version of the entire package,\n    # bearing in mind that this program appears on PyPI with the name \"chasten\";\n    # this will then return the version string specified with the version attribute\n    # in the [tool.poetry] section of the pyproject.toml file"
            },
            {
              "lineno": 68,
              "coloffset": 0,
              "linematch": "def join_and_preserve(data, start, end):",
              "linematch_context": "        version_string_of_foo = default_chasten_semver\n    return version_string_of_foo\n\n\ndef join_and_preserve(data, start, end):\n    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:"
            },
            {
              "lineno": 73,
              "coloffset": 0,
              "linematch": "def is_url(url: str) -> bool:",
              "linematch_context": "    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:\n    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url\n    url_parsed = parse_url(url)\n    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:"
            },
            {
              "lineno": 106,
              "coloffset": 0,
              "linematch": "def total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:",
              "linematch_context": "    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed\n    try:\n        # calculate total amount of checks in list\n        count_total = len(check_status_list)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 8,
              "coloffset": 0,
              "linematch": "def extract_min_max(",
              "linematch_context": "\nfrom chasten import constants, enumerations, util\n\n\ndef extract_min_max(\n    check: Dict[str, Union[str, Dict[str, int]]]\n) -> Tuple[Union[int, None], Union[int, None]]:\n    \"\"\"Extract the minimum and maximum values from the checks dictionary.\"\"\"\n    # extract information about the count attribute\n    # and the min and max values if they exist"
            },
            {
              "lineno": 19,
              "coloffset": 0,
              "linematch": "def extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:",
              "linematch_context": "    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore\n    return (min_count, max_count)\n\n\ndef extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:\n    \"\"\"Extract the description that may optionally be stored in a check.\"\"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if \"description\" in check:\n        return str(check[\"description\"])"
            },
            {
              "lineno": 28,
              "coloffset": 0,
              "linematch": "def create_attribute_label(attribute: Union[str, int, None], label: str) -> str:",
              "linematch_context": "        return str(check[\"description\"])\n    return \"\"\n\n\ndef create_attribute_label(attribute: Union[str, int, None], label: str) -> str:\n    \"\"\"Create an attribute label string for display as long as it is not null.\"\"\"\n    # define an empty attribute string, which is\n    # the default in the case when attribute is None\n    labeled_attribute = \"\"\n    # the attribute is not None and thus the function"
            },
            {
              "lineno": 40,
              "coloffset": 0,
              "linematch": "def join_attribute_labels(attribute_labels: List[str]) -> str:",
              "linematch_context": "        labeled_attribute = f\"{label} = {attribute}\"\n    return labeled_attribute\n\n\ndef join_attribute_labels(attribute_labels: List[str]) -> str:\n    \"\"\"Join all of the attribute labels in a comma-separated list.\"\"\"\n    # start the joined attribute labels with the empty string,\n    # which is what it will be by default as well\n    joined_attribute_labels = constants.markers.Empty_String\n    # incrementally create the list of labelled attributes,"
            },
            {
              "lineno": 59,
              "coloffset": 0,
              "linematch": "def is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:",
              "linematch_context": "        joined_attribute_labels += attribute_label  # type: ignore\n    return joined_attribute_labels\n\n\ndef is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    if min_value is None and max_value is None:\n        return False\n    return True\n"
            },
            {
              "lineno": 66,
              "coloffset": 0,
              "linematch": "def is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:",
              "linematch_context": "        return False\n    return True\n\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count("
            },
            {
              "lineno": 71,
              "coloffset": 0,
              "linematch": "def check_match_count(",
              "linematch_context": "    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:\n    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value"
            },
            {
              "lineno": 97,
              "coloffset": 0,
              "linematch": "def make_checks_status_message(check_status: bool) -> str:",
              "linematch_context": "    # between the minimum and the maximum value, inclusively\n    return False\n\n\ndef make_checks_status_message(check_status: bool) -> str:\n    \"\"\"Make a check status message in human readable format.\"\"\"\n    if check_status:\n        return f\":smiley: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    return (\n        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\""
            },
            {
              "lineno": 106,
              "coloffset": 0,
              "linematch": "def fix_check_criterion(",
              "linematch_context": "        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    )\n\n\ndef fix_check_criterion(\n    criterion: Union[enumerations.FilterableAttribute, str, int]\n) -> Union[str, int]:\n    \"\"\"Remove null values from a criterion.\"\"\"\n    # the converted criterion's default is an empty string\n    new_criterion: Union[str, int] = \"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 40,
              "coloffset": 0,
              "linematch": "def create_chasten_view(chasten_database_name: str) -> None:",
              "linematch_context": "# create a small bullet for display in the output\nsmall_bullet_unicode = constants.markers.Small_Bullet_Unicode\n\n\ndef create_chasten_view(chasten_database_name: str) -> None:\n    \"\"\"Create a view that combines results in the database tables.\"\"\"\n    database = Database(chasten_database_name)\n    # create a \"virtual table\" (i.e., a view) that is the result\n    # of running the pre-defined query; note that this query\n    # organizes all of chasten's results into a single table."
            },
            {
              "lineno": 54,
              "coloffset": 0,
              "linematch": "def enable_full_text_search(chasten_database_name: str) -> None:",
              "linematch_context": "        constants.chasten.Chasten_Database_View, CHASTEN_SQL_SELECT_QUERY\n    )\n\n\ndef enable_full_text_search(chasten_database_name: str) -> None:\n    \"\"\"Enable full-text search in the specific SQLite3 database.\"\"\"\n    database = Database(chasten_database_name)\n    # enable full-text search on the main database table\n    database[\"main\"].enable_fts(\n        ["
            },
            {
              "lineno": 87,
              "coloffset": 0,
              "linematch": "def display_final_diagnostic_message(datasette_platform: str, publish: bool):",
              "linematch_context": "    # note that sqlite-utils does not support the enabling of\n    # full-text search on the view called chasten_complete\n\n\ndef display_final_diagnostic_message(datasette_platform: str, publish: bool):\n    \"\"\"Output the final diagnostic message before control is given to a different tool.\"\"\"\n    # output a \"final\" prompt about either the publication platform of a reminder\n    # that the remainder of the output comes from running a local datasette instance\n    # the database will be published to an external platform\n    if publish:"
            },
            {
              "lineno": 104,
              "coloffset": 0,
              "linematch": "def display_datasette_details(",
              "linematch_context": "        )\n    output.console.print()\n\n\ndef display_datasette_details(\n    label: str,\n    virtual_env_location: str,\n    executable_path: str,\n    full_executable_name: str,\n) -> None:"
            },
            {
              "lineno": 131,
              "coloffset": 0,
              "linematch": "def start_datasette_server(  # noqa: PLR0912, PLR0913",
              "linematch_context": "        )\n    output.console.print()\n\n\ndef start_datasette_server(  # noqa: PLR0912, PLR0913\n    database_path: Path,\n    datasette_metadata: Path,\n    datasette_platform: str = enumerations.DatasettePublicationPlatform.FLY.value,\n    datasette_port: int = 8001,\n    publish: bool = False,"
            },
            {
              "lineno": 270,
              "coloffset": 0,
              "linematch": "def display_results_frog_mouth(result_file, OpSystem) -> None:",
              "linematch_context": "        proc = subprocess.Popen(cmd)\n        proc.wait()\n\n\ndef display_results_frog_mouth(result_file, OpSystem) -> None:\n    \"\"\"Run frogmouth as a subprocess of chasten\"\"\"\n    cmd = [\n        \"frogmouth\",\n        result_file,\n    ]"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 69,
              "coloffset": 0,
              "linematch": "def detect_configuration(config: Optional[Path]) -> str:",
              "linematch_context": "    \"checks.yml\": CHECKS_FILE_DEFAULT_CONTENTS,\n}\n\n\ndef detect_configuration(config: Optional[Path]) -> str:\n    \"\"\"Detect the configuration.\"\"\"\n    # there is a specified configuration directory path and thus\n    # this overrides the use of the platform-specific configuration\n    if config is not None:\n        chasten_user_config_dir_str = str(config)"
            },
            {
              "lineno": 89,
              "coloffset": 0,
              "linematch": "def create_configuration_directory(",
              "linematch_context": "    # return in string form the detected configuration directory\n    return chasten_user_config_dir_str\n\n\ndef create_configuration_directory(\n    config: Optional[Path] = None, force: bool = False\n) -> Union[Path, NoReturn]:\n    \"\"\"Create the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)"
            },
            {
              "lineno": 108,
              "coloffset": 0,
              "linematch": "def create_configuration_file(",
              "linematch_context": "    chasten_user_config_dir_path.mkdir(parents=True)\n    return chasten_user_config_dir_path\n\n\ndef create_configuration_file(\n    config: Path, config_file_name: str = constants.filesystem.Main_Configuration_File\n) -> None:\n    \"\"\"Create the main configuration file in the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)"
            },
            {
              "lineno": 127,
              "coloffset": 0,
              "linematch": "def create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore",
              "linematch_context": "    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]\n    chasten_user_config_main_file.write_text(file_contents)\n\n\ndef create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")"
            },
            {
              "lineno": 148,
              "coloffset": 0,
              "linematch": "def confirm_valid_file(file: Path) -> bool:",
              "linematch_context": "    # return the tree now containing all nodes\n    return tree\n\n\ndef confirm_valid_file(file: Path) -> bool:\n    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():"
            },
            {
              "lineno": 159,
              "coloffset": 0,
              "linematch": "def confirm_valid_directory(directory: Path) -> bool:",
              "linematch_context": "    # the file was either none or not valid\n    return False\n\n\ndef confirm_valid_directory(directory: Path) -> bool:\n    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():"
            },
            {
              "lineno": 170,
              "coloffset": 0,
              "linematch": "def get_default_directory_list() -> List[Path]:",
              "linematch_context": "    # the directory was either none or not valid\n    return False\n\n\ndef get_default_directory_list() -> List[Path]:\n    \"\"\"Return the default directory list that is the current working directory by itself.\"\"\"\n    default_directory_list = [Path(constants.filesystem.Current_Directory)]\n    return default_directory_list\n\n"
            },
            {
              "lineno": 176,
              "coloffset": 0,
              "linematch": "def write_chasten_results(",
              "linematch_context": "    default_directory_list = [Path(constants.filesystem.Current_Directory)]\n    return default_directory_list\n\n\ndef write_chasten_results(\n    results_path: Path,\n    projectname: str,\n    results_content: results.Chasten,\n    save: bool = False,\n) -> str:"
            },
            {
              "lineno": 212,
              "coloffset": 0,
              "linematch": "def write_dict_results(",
              "linematch_context": "    # return the name of the file that was created during saving\n    return constants.markers.Empty_String\n\n\ndef write_dict_results(\n    results_json: str,\n    results_path: Path,\n    projectname: str,\n) -> str:\n    \"\"\"Write a JSON file with results to the specified directory.\"\"\""
            },
            {
              "lineno": 239,
              "coloffset": 0,
              "linematch": "def write_flattened_csv_and_database(",
              "linematch_context": "    # return the name of the file that contains the JSON dictionary contents\n    return complete_results_file_name\n\n\ndef write_flattened_csv_and_database(\n    combined_results_json: str,\n    results_path: Path,\n    projectname: str,\n) -> str:\n    \"\"\"Write flattened CSV files with results to the specified directory and create the database.\"\"\""
            },
            {
              "lineno": 291,
              "coloffset": 0,
              "linematch": "def get_json_results(json_paths: List[Path]) -> List[Dict[Any, Any]]:",
              "linematch_context": "    # return the name of the directory that contains the flattened CSV files\n    return flattened_output_directory_str\n\n\ndef get_json_results(json_paths: List[Path]) -> List[Dict[Any, Any]]:\n    \"\"\"Get a list of dictionaries, one the contents of each JSON file path.\"\"\"\n    # create an empty list of dictionaries\n    json_dicts_list: List[Dict[Any, Any]] = []\n    # iterate through each of the provided paths to a JSON file\n    for json_path in json_paths:"
            },
            {
              "lineno": 305,
              "coloffset": 0,
              "linematch": "def can_find_executable(executable_name: str) -> Tuple[bool, str]:",
              "linematch_context": "    # return the list of JSON dictionaries\n    return json_dicts_list\n\n\ndef can_find_executable(executable_name: str) -> Tuple[bool, str]:\n    \"\"\"Determine whether or not it is possible to find an executable.\"\"\"\n    # use the shutil.which function to find the path of the executable\n    executable_path = shutil.which(executable_name)\n    # the executable is available in the path, so\n    # signal that it is found and return the full path"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/createchecks.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 59,
              "coloffset": 0,
              "linematch": "def save_user_api_key(user_api_key):",
              "linematch_context": "\nAPI_KEY_FILE = \"userapikey.txt\"\n\n\ndef save_user_api_key(user_api_key):\n    key = Fernet.generate_key()\n    fernet = Fernet(key)\n    encrypted_key = fernet.encrypt(user_api_key.encode()).decode()\n    with open(API_KEY_FILE, \"w\") as f:\n        f.write(key.decode() + \"\\n\" + encrypted_key)"
            },
            {
              "lineno": 67,
              "coloffset": 0,
              "linematch": "def load_user_api_key(file):",
              "linematch_context": "    with open(API_KEY_FILE, \"w\") as f:\n        f.write(key.decode() + \"\\n\" + encrypted_key)\n\n\ndef load_user_api_key(file):\n    with open(file, \"r\") as f:\n        lines = f.read().strip().split(\"\\n\")\n        if len(lines) == 2:  # noqa: PLR2004\n            key = lines[0].encode()\n            encrypted_key = lines[1]"
            },
            {
              "lineno": 77,
              "coloffset": 0,
              "linematch": "def is_valid_api_key(api_key):",
              "linematch_context": "        fernet = Fernet(key)\n        return fernet.decrypt(encrypted_key.encode()).decode()\n\n\ndef is_valid_api_key(api_key):\n    try:\n        openai.api_key = api_key\n        openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"system\", \"content\": \"Test message\"}],"
            },
            {
              "lineno": 89,
              "coloffset": 0,
              "linematch": "def generate_yaml_config(file: Path, user_api_key, user_input: str) -> str:",
              "linematch_context": "    except openai.error.OpenAIError:\n        return False\n\n\ndef generate_yaml_config(file: Path, user_api_key, user_input: str) -> str:\n    try:\n        openai.api_key = user_api_key\n\n        prompts = [\n            genscript"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/validate.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 102,
              "coloffset": 0,
              "linematch": "def extract_checks_file_name(",
              "linematch_context": "    },\n}\n\n\ndef extract_checks_file_name(\n    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():"
            },
            {
              "lineno": 121,
              "coloffset": 0,
              "linematch": "def validate_configuration(",
              "linematch_context": "    # contents were not found and thus returen no filenames\n    return (False, [constants.markers.Empty_String])\n\n\ndef validate_configuration(\n    configuration: Dict[str, Dict[str, Any]],\n    schema: Dict[str, Any] = JSON_SCHEMA_CONFIG,\n) -> Tuple[bool, str]:\n    \"\"\"Validate the main configuration.\"\"\"\n    # indicate that validation passed; since there"
            },
            {
              "lineno": 140,
              "coloffset": 0,
              "linematch": "def validate_checks_configuration(",
              "linematch_context": "        error_message = error_message.lstrip()\n        return (False, error_message)\n\n\ndef validate_checks_configuration(\n    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, str]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    return validate_configuration(configuration, JSON_SCHEMA_CHECKS)\n"
            },
            {
              "lineno": 147,
              "coloffset": 0,
              "linematch": "def validate_file(",
              "linematch_context": "    \"\"\"Validate the checks configuration.\"\"\"\n    return validate_configuration(configuration, JSON_SCHEMA_CHECKS)\n\n\ndef validate_file(\n    file_name: str,\n    configuration_file_yaml_str: str,\n    yaml_data_dict: Dict[str, Dict[str, Any]],\n    json_schema: Dict[str, Any] = JSON_SCHEMA_CONFIG,\n    verbose: bool = False,"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 21,
              "coloffset": 0,
              "linematch": "def split_file(file_name: Path) -> List[List[str]]:",
              "linematch_context": "}\nCHECK_DEFAULT = [\"\", \"1\", False]\n\n\ndef split_file(file_name: Path) -> List[List[str]]:\n    \"\"\"Split a csv file into a list of lists.\"\"\"\n    check_list = []\n    with open(file_name) as file:\n        for row in file:\n            strip_row = row.strip()  # Remove leading/trailing white spaces"
            },
            {
              "lineno": 32,
              "coloffset": 0,
              "linematch": "def write_checks(check_list: List[List[str]]) -> str:",
              "linematch_context": "                check_list.append(strip_row.split(\",\"))\n    return check_list\n\n\ndef write_checks(check_list: List[List[str]]) -> str:\n    \"\"\"Generate structured output based on the contents of the file.\"\"\"\n    if len(check_list) != 0:\n        result = \"Make a YAML file that checks for:\"\n        for checks in check_list:\n            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            },
            {
              "lineno": 43,
              "coloffset": 0,
              "linematch": "def store_in_file(File: Path, Pattern, Matches, Exact):",
              "linematch_context": "        return result\n    return \"[red][ERROR][/red] No checks were supplied\"\n\n\ndef store_in_file(File: Path, Pattern, Matches, Exact):\n    \"\"\"Store inputed values into a text file\"\"\"\n    File.touch()\n    with open(File, \"a\") as file:\n        file.write(f\"\\n{Pattern},{Matches},{Exact}\")  # Append input data to the file\n"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "def compose(self) -> ComposeResult:",
              "linematch_context": "\n\n# Static widget to display user input and validation results\nclass answers(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Check_Input\n        yield Match_Input\n\n"
            },
            {
              "lineno": 71,
              "coloffset": 4,
              "linematch": "def compose(self) -> ComposeResult:",
              "linematch_context": "\n\n# Static widget to display buttons for user interactions\nclass button_prompts(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")"
            },
            {
              "lineno": 117,
              "coloffset": 4,
              "linematch": "def on_input_changed(self, event: Input.Changed) -> None:",
              "linematch_context": "    \"\"\"\n    Check: ClassVar[list] = [\"\", \"1\", False]\n    Valid: bool = False\n\n    def on_input_changed(self, event: Input.Changed) -> None:\n        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:"
            },
            {
              "lineno": 127,
              "coloffset": 4,
              "linematch": "def on_button_pressed(self, event: Button.Pressed) -> None:",
              "linematch_context": "            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit("
            },
            {
              "lineno": 158,
              "coloffset": 4,
              "linematch": "def compose(self) -> ComposeResult:",
              "linematch_context": "        else:\n            self.query_one(Pretty).update([\"Invalid Input Please enter a Integer\"])\n            Match_Input.value = \"\"  # Clear the \"Matches\" input field\n\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield answers()  # Display the input fields for user input\n        yield button_prompts()  # Display the buttons for user interaction"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 0,
              "linematch": "def include_or_exclude_checks(",
              "linematch_context": "\nfrom chasten import constants, enumerations\n\n\ndef include_or_exclude_checks(\n    checks: List[Dict[str, Union[str, Dict[str, int]]]],\n    check_attribute: enumerations.FilterableAttribute,\n    check_match: str,\n    check_confidence: int = constants.checks.Check_Confidence,\n    include: bool = True,"
            },
            {
              "lineno": 46,
              "coloffset": 0,
              "linematch": "def filter_matches(",
              "linematch_context": "            filtered_checks.append(check)\n    return filtered_checks\n\n\ndef filter_matches(\n    match_list: List[Union[pyastgrepsearch.Match, Any]],\n    data_type,\n) -> Tuple[List[pyastgrepsearch.Match], List[Any]]:\n    \"\"\"Filter the list of matches based on the provided data type.\"\"\"\n    subset_match_list = []"
            },
            {
              "lineno": 69,
              "coloffset": 0,
              "linematch": "def organize_matches(",
              "linematch_context": "    # return both of the created lists\n    return (subset_match_list, did_not_match_list)\n\n\ndef organize_matches(\n    match_list: List[pyastgrepsearch.Match],\n) -> Dict[str, List[pyastgrepsearch.Match]]:\n    \"\"\"Organize the matches on a per-file basis to support simplified processing.\"\"\"\n    match_dict: Dict[str, List[pyastgrepsearch.Match]] = {}\n    # iterate through each of the matches in the list, with"
            },
            {
              "lineno": 97,
              "coloffset": 0,
              "linematch": "def combine_dicts(dict_list: List[Dict[Any, Any]]) -> str:",
              "linematch_context": "            match_dict[current_match_file_name] = current_match_list\n    return match_dict\n\n\ndef combine_dicts(dict_list: List[Dict[Any, Any]]) -> str:\n    \"\"\"Combine all dictionaries in the list into a single list of dictionaries as a string.\"\"\"\n    # combine all of the dictionaries in the list into\n    # a single string that is a list of each JSON-based\n    # dictionary represented as a string; this leads to:\n    # ["
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 45,
              "coloffset": 0,
              "linematch": "def output_preamble(",
              "linematch_context": "# Region: Helper functions {{{\n# ---\n\n\ndef output_preamble(\n    verbose: bool,\n    debug_level: debug.DebugLevel = debug.DebugLevel.ERROR,\n    debug_destination: debug.DebugDestination = debug.DebugDestination.CONSOLE,\n    **kwargs,\n) -> None:"
            },
            {
              "lineno": 72,
              "coloffset": 0,
              "linematch": "def display_serve_or_publish_details(",
              "linematch_context": "        **kwargs,\n    )\n\n\ndef display_serve_or_publish_details(\n    label: str,\n    database_path: Path,\n    metadata: Path,\n    port: int = 8001,\n    publish: bool = False,"
            },
            {
              "lineno": 107,
              "coloffset": 0,
              "linematch": "def create_checks(",
              "linematch_context": "# ---\n\n\n@cli.command()\ndef create_checks(\n    filename: Path = typer.Option(\"checks.yml\", help=\"YAML file name\")\n) -> None:\n    \"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"\n    # creates a textual object for better user interface\n    app.run()"
            },
            {
              "lineno": 154,
              "coloffset": 0,
              "linematch": "def configure(  # noqa: PLR0913",
              "linematch_context": "        )\n\n\n@cli.command()\ndef configure(  # noqa: PLR0913\n    task: enumerations.ConfigureTask = typer.Argument(\n        enumerations.ConfigureTask.VALIDATE.value\n    ),\n    config: str = typer.Option(\n        None,"
            },
            {
              "lineno": 252,
              "coloffset": 0,
              "linematch": "def analyze(  # noqa: PLR0912, PLR0913, PLR0915",
              "linematch_context": "            sys.exit(constants.markers.Non_Zero_Exit)\n\n\n@cli.command()\ndef analyze(  # noqa: PLR0912, PLR0913, PLR0915\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    xpath: Path = typer.Option(\n        str,\n        \"--xpath-version\",\n        \"-xp\","
            },
            {
              "lineno": 732,
              "coloffset": 0,
              "linematch": "def integrate(  # noqa: PLR0913",
              "linematch_context": "            database.display_results_frog_mouth(result_path, util.get_OS())\n\n\n@cli.command()\ndef integrate(  # noqa: PLR0913\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    json_path: List[Path] = typer.Argument(\n        help=\"Directories, files, or globs for chasten's JSON result file(s).\",\n    ),\n    output_directory: Path = typer.Option("
            },
            {
              "lineno": 821,
              "coloffset": 0,
              "linematch": "def datasette_serve(  # noqa: PLR0913",
              "linematch_context": "        output.logger.debug(\"Integrate function completed successfully.\")\n\n\n@cli.command()\ndef datasette_serve(  # noqa: PLR0913\n    database_path: Path = typer.Argument(\n        help=\"SQLite3 database file storing chasten's results.\",\n        exists=True,\n        file_okay=True,\n        dir_okay=False,"
            },
            {
              "lineno": 896,
              "coloffset": 0,
              "linematch": "def datasette_publish(  # noqa: PLR0913",
              "linematch_context": "    )\n\n\n@cli.command()\ndef datasette_publish(  # noqa: PLR0913\n    database_path: Path = typer.Argument(\n        help=\"SQLite3 database file storing chasten's results.\",\n        exists=True,\n        file_okay=True,\n        dir_okay=False,"
            },
            {
              "lineno": 972,
              "coloffset": 0,
              "linematch": "def log() -> None:",
              "linematch_context": "    )\n\n\n@cli.command()\ndef log() -> None:\n    \"\"\"\ud83e\udd9a Start the logging server.\"\"\"\n    # display the header\n    output.print_header()\n    # display details about the server\n    output.print_server()"
            },
            {
              "lineno": 988,
              "coloffset": 0,
              "linematch": "def version():",
              "linematch_context": "    server.start_syslog_server()\n\n\n@cli.command()\ndef version():\n    \"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\"\n    # Get Chasten version from util file\n    version_string = util.get_chasten_version()\n    # output chasten version\n    typer.echo(f\"chasten {version_string}\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "ANNOT001",
          "name": "missing-annotations",
          "description": "A function does not explicitly annotate arguments/parameters or the expected output",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[not(args/arg/annotation) or not(returns)]",
          "passed": false,
          "matches": [
            {
              "lineno": 25,
              "coloffset": 0,
              "linematch": "def setup(",
              "linematch_context": "# define a small bullet for display\nsmall_bullet_unicode = constants.markers.Small_Bullet_Unicode\n\n\ndef setup(\n    debug_level: debug.DebugLevel, debug_destination: debug.DebugDestination\n) -> None:\n    \"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"\n    global logger\n    # configure the use of rich for improved terminal output:"
            },
            {
              "lineno": 40,
              "coloffset": 0,
              "linematch": "def print_diagnostics(verbose: bool, **configurations: Any) -> None:",
              "linematch_context": "        debug_level.value, debug_destination.value\n    )\n\n\ndef print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")"
            },
            {
              "lineno": 54,
              "coloffset": 0,
              "linematch": "def opt_print_log(verbose: bool, **contents: Any) -> None:",
              "linematch_context": "                f\"{constants.markers.Indent}{configuration_current} = {configurations[configuration_current]}\"\n            )\n\n\ndef opt_print_log(verbose: bool, **contents: Any) -> None:\n    \"\"\"Produce logging information and only print when not verbose.\"\"\"\n    global console  # noqa: PLW0602\n    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument"
            },
            {
              "lineno": 67,
              "coloffset": 0,
              "linematch": "def print_header() -> None:",
              "linematch_context": "        # always log the information to the configured logger\n        logger.debug(contents[current])\n\n\ndef print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline"
            },
            {
              "lineno": 77,
              "coloffset": 0,
              "linematch": "def print_server() -> None:",
              "linematch_context": "    )\n    console.print(constants.chasten.Website)\n\n\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n"
            },
            {
              "lineno": 84,
              "coloffset": 0,
              "linematch": "def print_test_start() -> None:",
              "linematch_context": "    console.print(constants.output.Syslog)\n    console.print()\n\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n"
            },
            {
              "lineno": 91,
              "coloffset": 0,
              "linematch": "def print_test_finish() -> None:",
              "linematch_context": "    console.print(constants.output.Test_Start)\n    console.print()\n\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()"
            },
            {
              "lineno": 99,
              "coloffset": 0,
              "linematch": "def print_footer() -> None:",
              "linematch_context": "    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n\n"
            },
            {
              "lineno": 105,
              "coloffset": 0,
              "linematch": "def group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:",
              "linematch_context": "    global console  # noqa: PLW0602\n    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\"\n    # create an empty dictionary\n    grouped_files: Dict[Path, List[str]] = {}\n    # iterate through each of the full paths\n    # and extract the containing directory"
            },
            {
              "lineno": 129,
              "coloffset": 0,
              "linematch": "def shorten_file_name(file_name: str, max_length: int) -> str:",
              "linematch_context": "    # return the dictionary of files organized by directory\n    return grouped_files\n\n\ndef shorten_file_name(file_name: str, max_length: int) -> str:\n    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long\n    if len(file_name) > max_length:\n        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name"
            },
            {
              "lineno": 137,
              "coloffset": 0,
              "linematch": "def print_list_contents(container: List[Path]) -> None:",
              "linematch_context": "        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name\n\n\ndef print_list_contents(container: List[Path]) -> None:\n    \"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"\n    global console  # noqa: PLW0602\n    # group all of the files by the directory that contains them;\n    # note that this is important because the contain can contain\n    # paths that specify files in different directories"
            },
            {
              "lineno": 160,
              "coloffset": 0,
              "linematch": "def print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:",
              "linematch_context": "                f\"  {small_bullet_unicode} file(s) {int(filecount)} in this directory\"\n            )\n\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/validate.py",
        "check": {
          "id": "KF001",
          "name": "key-function",
          "description": "The use of .keys() function",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//Call/func/Attribute[@attr=\"keys\"]",
          "passed": true,
          "matches": [
            {
              "lineno": 107,
              "coloffset": 41,
              "linematch": "if constants.checks.Check_Chasten in configuration.keys():",
              "linematch_context": "    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files\n            # and return them in a list with a boolean\n            # indicate to show that checks files were found"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/mutmut_config.py",
        "check": {
          "id": "FLV001",
          "name": "function-uses-loop-variable",
          "description": "The loop variable is not bound in the function definition, so it will always have the value it had in the last iteration",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[body//comprehension/target/Name]",
          "passed": true,
          "matches": [
            {
              "lineno": 3,
              "coloffset": 0,
              "linematch": "def pre_mutation(context):",
              "linematch_context": "from mutmut import context\n\ndef pre_mutation(context):\n    arithmetic_operators = ['+', '-', '*', '/']\n    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    "
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "FLV001",
          "name": "function-uses-loop-variable",
          "description": "The loop variable is not bound in the function definition, so it will always have the value it had in the last iteration",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[body//comprehension/target/Name]",
          "passed": true,
          "matches": [
            {
              "lineno": 62,
              "coloffset": 0,
              "linematch": "def test_create_directory_tree(tmpdir):",
              "linematch_context": "    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()"
            },
            {
              "lineno": 90,
              "coloffset": 0,
              "linematch": "def test_fuzz_create_directory_tree(directory):",
              "linematch_context": "\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "FLV001",
          "name": "function-uses-loop-variable",
          "description": "The loop variable is not bound in the function definition, so it will always have the value it had in the last iteration",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[body//comprehension/target/Name]",
          "passed": true,
          "matches": [
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def test_filter_matches(match_list, data_type):",
              "linematch_context": "    ),\n    data_type=st.just(pyastgrepsearch.Match),\n)\n@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "FLV001",
          "name": "function-uses-loop-variable",
          "description": "The loop variable is not bound in the function definition, so it will always have the value it had in the last iteration",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[body//comprehension/target/Name]",
          "passed": true,
          "matches": [
            {
              "lineno": 252,
              "coloffset": 0,
              "linematch": "def analyze(  # noqa: PLR0912, PLR0913, PLR0915",
              "linematch_context": "            sys.exit(constants.markers.Non_Zero_Exit)\n\n\n@cli.command()\ndef analyze(  # noqa: PLR0912, PLR0913, PLR0915\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    xpath: Path = typer.Option(\n        str,\n        \"--xpath-version\",\n        \"-xp\","
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "FLV001",
          "name": "function-uses-loop-variable",
          "description": "The loop variable is not bound in the function definition, so it will always have the value it had in the last iteration",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[body//comprehension/target/Name]",
          "passed": true,
          "matches": [
            {
              "lineno": 160,
              "coloffset": 0,
              "linematch": "def print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:",
              "linematch_context": "                f\"  {small_bullet_unicode} file(s) {int(filecount)} in this directory\"\n            )\n\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "F002",
          "name": "number-of-conditions-in-function",
          "description": "Ensure the number of conditions (if, if-else, and switch) in a function is within acceptable limits.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//If/following-sibling::If | .//FunctionDef//If/following-sibling::Elif | .//FunctionDef//If/following-sibling::Else",
          "passed": false,
          "matches": [
            {
              "lineno": 157,
              "coloffset": 4,
              "linematch": "if not checks_file_extracted_valid:",
              "linematch_context": "        return (checks_file_validated, checks_file_invalidates_entire_config, {})\n    # the checks file could not be extracted in a valid\n    # fashion and thus there is no need to continue the\n    # validation of this file or any of the other check file\n    if not checks_file_extracted_valid:\n        checks_file_validated = False\n    # the checks file could be extract and thus the\n    # function should proceed to validate a checks configuration file\n    else:\n        # validate checks file"
            },
            {
              "lineno": 250,
              "coloffset": 8,
              "linematch": "if chasten_user_config_file_str != \"\":",
              "linematch_context": "        )\n        # optional argument if chasten_user_config_file_str is not empty\n        # argument will be supplied as unpacked dict\n        chasten_user_config_file_str_argument = {}\n        if chasten_user_config_file_str != \"\":\n            chasten_user_config_file_str_argument[\n                \"configuration_file\"\n            ] = chasten_user_config_file_str\n        # extract the configuration details\n        ("
            },
            {
              "lineno": 266,
              "coloffset": 8,
              "linematch": "if not configuration_valid:",
              "linematch_context": "        )\n        # it was not possible to extract the configuration details and\n        # thus this function should return immediately with False\n        # to indicate the failure and an empty configuration dictionary\n        if not configuration_valid:\n            return (False, {})\n        # create a visualization of the user's configuration directory;\n        # display details about the configuration directory in console\n        display_configuration_directory(chasten_user_config_dir_str, verbose)\n        configuration_file_source = chasten_user_config_dir_str"
            },
            {
              "lineno": 334,
              "coloffset": 4,
              "linematch": "if config_file_validated and check_files_validated:",
              "linematch_context": "    check_files_validated = all(checks_files_validated_list)\n    # the files validated correctly; return an indicator to\n    # show that validation worked and then return the overall\n    # dictionary that contains the listing of valid checks\n    if config_file_validated and check_files_validated:\n        return (True, overall_checks_dict)\n    # there was at least one validation error\n    return (False, {})\n\n"
            },
            {
              "lineno": 406,
              "coloffset": 4,
              "linematch": "if yaml_success:",
              "linematch_context": "    (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n        configuration_file_yaml_str\n    )\n    # return success status, filename, file contents, and yaml parsed data upon success\n    if yaml_success:\n        return (True, configuration_file_yaml_str, yaml_data)\n    else:\n        output.logger.error(\n            f\"\\nParsing YAML from config or check file URL failed for {chasten_user_config_url}.\\n\"\n        )"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "F002",
          "name": "number-of-conditions-in-function",
          "description": "Ensure the number of conditions (if, if-else, and switch) in a function is within acceptable limits.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//If/following-sibling::If | .//FunctionDef//If/following-sibling::Elif | .//FunctionDef//If/following-sibling::Else",
          "passed": false,
          "matches": [
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "if min_value is not None and max_value is not None:",
              "linematch_context": "    # both of the values are None and thus the comparision is vacuously true\n    if min_value is None and max_value is None:\n        return True\n    # both are not None and thus the count must be in the closed interval\n    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:"
            },
            {
              "lineno": 85,
              "coloffset": 4,
              "linematch": "if min_value is not None:",
              "linematch_context": "    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "if max_value is not None:",
              "linematch_context": "    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "F002",
          "name": "number-of-conditions-in-function",
          "description": "Ensure the number of conditions (if, if-else, and switch) in a function is within acceptable limits.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//If/following-sibling::If | .//FunctionDef//If/following-sibling::Elif | .//FunctionDef//If/following-sibling::Else",
          "passed": false,
          "matches": [
            {
              "lineno": 172,
              "coloffset": 4,
              "linematch": "if not found_executable:",
              "linematch_context": "        full_executable_name,\n    )\n    # since it was not possible to find the executable for datasette, display and\n    # error message and then exit this function since no further steps are possible\n    if not found_executable:\n        output.console.print(\n            f\":person_shrugging: Was not able to find {constants.datasette.Datasette_Executable}\"\n        )\n        return None\n    # run the localhost server because the"
            },
            {
              "lineno": 179,
              "coloffset": 4,
              "linematch": "if not publish:",
              "linematch_context": "        )\n        return None\n    # run the localhost server because the\n    # function was not asked to publish a database\n    if not publish:\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),"
            },
            {
              "lineno": 231,
              "coloffset": 8,
              "linematch": "if datasette_platform == constants.chasten.Executable_Fly:",
              "linematch_context": "        # create the customized running argument for either fly or vercel; note\n        # that these programs take different arguments for specifying the name\n        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option"
            },
            {
              "lineno": 238,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                \"publish\",\n                datasette_platform,\n                str(database_path),"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "F002",
          "name": "number-of-conditions-in-function",
          "description": "Ensure the number of conditions (if, if-else, and switch) in a function is within acceptable limits.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//If/following-sibling::If | .//FunctionDef//If/following-sibling::Elif | .//FunctionDef//If/following-sibling::Else",
          "passed": false,
          "matches": [
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "if path.is_dir():",
              "linematch_context": "    # the tree has already been created\n    else:\n        tree = tree.add(f\":open_file_folder: {path.name}\")\n    # recursively process the directory\n    if path.is_dir():\n        for item in path.iterdir():\n            if item.is_dir():\n                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "F002",
          "name": "number-of-conditions-in-function",
          "description": "Ensure the number of conditions (if, if-else, and switch) in a function is within acceptable limits.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//If/following-sibling::If | .//FunctionDef//If/following-sibling::Elif | .//FunctionDef//If/following-sibling::Else",
          "passed": false,
          "matches": [
            {
              "lineno": 211,
              "coloffset": 4,
              "linematch": "if task == enumerations.ConfigureTask.CREATE:",
              "linematch_context": "                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n            )\n            sys.exit(constants.markers.Non_Zero_Exit)\n    # create the configuration directory and a starting version of the configuration file\n    if task == enumerations.ConfigureTask.CREATE:\n        # attempt to create the configuration directory\n        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs"
            },
            {
              "lineno": 421,
              "coloffset": 4,
              "linematch": "if not filesystem.confirm_valid_directory(",
              "linematch_context": "    # not possible to analyze the Python source files in this directory\n    # OR\n    # the specified search path is not valid and thus it is\n    # not possible to analyze the specific Python source code file\n    if not filesystem.confirm_valid_directory(\n        input_path\n    ) and not filesystem.confirm_valid_file(input_path):\n        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\"\n        )"
            },
            {
              "lineno": 428,
              "coloffset": 4,
              "linematch": "if store_result:",
              "linematch_context": "        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\"\n        )\n        sys.exit(constants.markers.Non_Zero_Exit)\n    if store_result:\n        # creates an empty string for storing results temporarily\n        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):"
            },
            {
              "lineno": 461,
              "coloffset": 4,
              "linematch": "if xpath == \"1.0\":",
              "linematch_context": "    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version\n    if xpath == \"1.0\":\n        output.logger.debug(\"Using XPath version 1.0\")\n    else:\n        output.logger.debug(\"Using XPath version 2.0\")\n    # iterate through and perform each of the checks\n    for current_check in check_list:"
            },
            {
              "lineno": 510,
              "coloffset": 8,
              "linematch": "if checks.is_checkable(min_count, max_count):",
              "linematch_context": "        # correspond so that processing of matches takes place per-file\n        match_dict = process.organize_matches(match_generator_list)\n        # perform an enforceable check if it is warranted for this check\n        current_check_save = None\n        if checks.is_checkable(min_count, max_count):\n            # determine whether or not the number of found matches is within mix and max\n            check_status = checks.check_match_count(\n                len(match_generator_list), min_count, max_count\n            )\n            # keep track of the outcome for this check"
            },
            {
              "lineno": 531,
              "coloffset": 8,
              "linematch": "if store_result:",
              "linematch_context": "        output.console.print(\n            f\"  {check_status_symbol} id: '{check_id}', name: '{check_name}'\"\n            + f\", pattern: '{current_xpath_pattern_escape}', min={min_count}, max={max_count}\"\n        )\n        if store_result:\n            # makes the check marks or x's appear as words instead for markdown\n            check_pass = (\n                \"PASSED:\"\n                if check_status_symbol == \"[green]\\u2713[/green]\"\n                else \"FAILED:\""
            },
            {
              "lineno": 551,
              "coloffset": 8,
              "linematch": "if len(match_generator_list) == 0:",
              "linematch_context": "            filename=str(str(vd) for vd in valid_directories)\n        )\n        # there were no matches and thus the current_check_save of None\n        # should be recorded inside of the source of the results\n        if len(match_generator_list) == 0:\n            current_result_source.check = current_check_save\n        # iteratively analyze:\n        # a) A specific file name\n        # b) All of the matches for that file name\n        # Note: the goal is to only process matches for a"
            },
            {
              "lineno": 587,
              "coloffset": 12,
              "linematch": "if len(matches_list) > 0:",
              "linematch_context": "            # extract the lines of source code for this file; note that all of\n            # these matches are organized for the same file and thus it is\n            # acceptable to extract the lines of the file from the first match\n            # a long as there are matches available for analysis\n            if len(matches_list) > 0:\n                current_result_source._filelines = matches_list[0].file_lines\n            # iterate through all of the matches that are specifically\n            # connected to this source that is connected to a specific file name\n            for current_match in matches_list:\n                if isinstance(current_match, pyastgrepsearch.Match):"
            },
            {
              "lineno": 643,
              "coloffset": 4,
              "linematch": "if saved_file_name:",
              "linematch_context": "    saved_file_name = filesystem.write_chasten_results(\n        output_directory, project, chasten_results_save, save\n    )\n    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")\n    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:"
            },
            {
              "lineno": 646,
              "coloffset": 4,
              "linematch": "if save_XML is not None or view_XML is not None:",
              "linematch_context": "    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")\n    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901"
            },
            {
              "lineno": 709,
              "coloffset": 4,
              "linematch": "if not all_checks_passed:",
              "linematch_context": "    all_checks_passed = all(check_status_list)\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file\n            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n            output.console.print("
            },
            {
              "lineno": 722,
              "coloffset": 4,
              "linematch": "if store_result:",
              "linematch_context": "    output.console.print(\n        f\"\\n:joy: All checks passed. Elapsed Time: {elapsed_time} seconds\"\n    )\n    output.logger.debug(\"Analysis complete.\")\n    if store_result:\n        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")\n        if display:"
            },
            {
              "lineno": 808,
              "coloffset": 4,
              "linematch": "if combined_flattened_directory:",
              "linematch_context": "        project,\n    )\n    output.logger.debug(\"Flattened JSON and created SQLite database.\")\n    # output the name of the saved file if saving successfully took place\n    if combined_flattened_directory:\n        output.console.print(\n            f\"\\n:sparkles: Created this directory structure in {Path(combined_flattened_directory).parent}:\"\n        )\n        combined_directory_tree = filesystem.create_directory_tree_visualization(\n            Path(combined_flattened_directory)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/mutmut_config.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "elif any(op in context.source for op in arithmetic_operators):",
              "linematch_context": "    \n    if context.mutation_id.operator == \"delete\":\n        # Allow statement deletion mutations\n        return\n    elif any(op in context.source for op in arithmetic_operators):\n        # Allow arithmetic operator mutations\n        return\n    else:\n        # Skip all other mutations\n        context.skip = True"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 126,
              "coloffset": 4,
              "linematch": "elif chasten_user_config_url_str != \"\":",
              "linematch_context": "        checks_file_source = checks_file_name\n    # assume check file name is a file path\n    # will not support checks files being local paths\n    # if config file is a URL\n    elif chasten_user_config_url_str != \"\":\n        output.logger.error(\n            f\"\\nChecks file directive was a Path when config was a URL (given: '{checks_file_name}')\\n\"\n        )\n        checks_file_validated = False\n        checks_file_invalidates_entire_config = True"
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "elif (Path(chasten_user_config_dir_str) / Path(checks_file_name)).exists():",
              "linematch_context": "        checks_file_validated = False\n        checks_file_invalidates_entire_config = True\n        return (checks_file_validated, checks_file_invalidates_entire_config, {})\n    # checks file exists in local filesystem\n    elif (Path(chasten_user_config_dir_str) / Path(checks_file_name)).exists():\n        # extract the configuration details\n        (\n            checks_file_extracted_valid,\n            configuration_file_path_str,\n            configuration_file_yaml_str,"
            },
            {
              "lineno": 202,
              "coloffset": 4,
              "linematch": "elif util.is_url(config):",
              "linematch_context": "    # there is a specified configuration directory path or url;\n    # this overrides the use of the configuration files that\n    # may exist inside of the platform-specific directory.\n    # input configuration is valid URL\n    elif util.is_url(config):\n        # re-parse input config so it is of type URL\n        chasten_user_config_url_str = str(parse_url(config))\n        output.console.print(\n            \":sparkles: Configuration URL:\"\n            + constants.markers.Space"
            },
            {
              "lineno": 221,
              "coloffset": 4,
              "linematch": "elif Path(config).exists():",
              "linematch_context": "            parse_url(chasten_user_config_url_str)\n        )\n        configuration_file_source = chasten_user_config_url_str\n    # input configuration exists and is valid file path\n    elif Path(config).exists():\n        # input configuration is a directory\n        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file"
            },
            {
              "lineno": 223,
              "coloffset": 8,
              "linematch": "if Path(config).is_dir():",
              "linematch_context": "        configuration_file_source = chasten_user_config_url_str\n    # input configuration exists and is valid file path\n    elif Path(config).exists():\n        # input configuration is a directory\n        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file\n        elif Path(config).is_file():\n            # re-parse input config so it is of type Path"
            },
            {
              "lineno": 227,
              "coloffset": 8,
              "linematch": "elif Path(config).is_file():",
              "linematch_context": "        if Path(config).is_dir():\n            # re-parse input config so it is of type Path\n            chasten_user_config_dir_str = str(Path(config))\n        # input configuration is a file\n        elif Path(config).is_file():\n            # re-parse input config so it is of type Path\n            config_as_path = Path(config)\n            # get directory containing config file\n            chasten_user_config_dir_str = str(\n                Path(*config_as_path.parts[: len(config_as_path.parts) - 1])"
            },
            {
              "lineno": 250,
              "coloffset": 8,
              "linematch": "if chasten_user_config_file_str != \"\":",
              "linematch_context": "        )\n        # optional argument if chasten_user_config_file_str is not empty\n        # argument will be supplied as unpacked dict\n        chasten_user_config_file_str_argument = {}\n        if chasten_user_config_file_str != \"\":\n            chasten_user_config_file_str_argument[\n                \"configuration_file\"\n            ] = chasten_user_config_file_str\n        # extract the configuration details\n        ("
            },
            {
              "lineno": 266,
              "coloffset": 8,
              "linematch": "if not configuration_valid:",
              "linematch_context": "        )\n        # it was not possible to extract the configuration details and\n        # thus this function should return immediately with False\n        # to indicate the failure and an empty configuration dictionary\n        if not configuration_valid:\n            return (False, {})\n        # create a visualization of the user's configuration directory;\n        # display details about the configuration directory in console\n        display_configuration_directory(chasten_user_config_dir_str, verbose)\n        configuration_file_source = chasten_user_config_dir_str"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 86,
              "coloffset": 8,
              "linematch": "if count >= min_value:",
              "linematch_context": "        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True"
            },
            {
              "lineno": 90,
              "coloffset": 8,
              "linematch": "if count <= max_value:",
              "linematch_context": "        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False\n"
            },
            {
              "lineno": 116,
              "coloffset": 8,
              "linematch": "if type(criterion) is enumerations.FilterableAttribute:",
              "linematch_context": "    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 182,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "    # function was not asked to publish a database\n    if not publish:\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                str(database_path),\n                \"-m\",\n                str(metadata),"
            },
            {
              "lineno": 204,
              "coloffset": 4,
              "linematch": "elif publish:",
              "linematch_context": "        # there is debugging output in the console to indicate this option.\n        proc = subprocess.Popen(cmd)\n        proc.wait()\n    # publish the datasette instance to the chosen datasette platform\n    elif publish:\n        # get information about the datasette executable, confirming that\n        # it is available in the virtual environment created by chasten\n        (\n            found_publish_platform_executable,\n            publish_platform_executable,"
            },
            {
              "lineno": 214,
              "coloffset": 8,
              "linematch": "if not found_publish_platform_executable:",
              "linematch_context": "        ) = filesystem.can_find_executable(util.executable_name(datasette_platform))\n        # was not able to find the fly or vercel executable (the person using this\n        # program has to install separately, following the instructions for the\n        # datasette-publish-fly plugin) and thus need to exit and not proceed\n        if not found_publish_platform_executable:\n            output.console.print(\n                f\":person_shrugging: Was not able to find '{datasette_platform}'\"\n            )\n            return None\n        # was able to find the fly or vercel executable that will support the"
            },
            {
              "lineno": 231,
              "coloffset": 8,
              "linematch": "if datasette_platform == constants.chasten.Executable_Fly:",
              "linematch_context": "        # create the customized running argument for either fly or vercel; note\n        # that these programs take different arguments for specifying the name\n        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option"
            },
            {
              "lineno": 233,
              "coloffset": 8,
              "linematch": "elif datasette_platform == constants.chasten.Executable_Vercel:",
              "linematch_context": "        # of the application as it will be deployed on the platform\n        running_argument = \"\"\n        if datasette_platform == constants.chasten.Executable_Fly:\n            running_argument = \"--app=chasten\"\n        elif datasette_platform == constants.chasten.Executable_Vercel:\n            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:"
            },
            {
              "lineno": 238,
              "coloffset": 8,
              "linematch": "if metadata is not None:",
              "linematch_context": "            running_argument = \"--project=chasten\"\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        # there was a metadata parameter, so include it\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),\n                \"publish\",\n                datasette_platform,\n                str(database_path),"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 140,
              "coloffset": 12,
              "linematch": "if item.is_dir():",
              "linematch_context": "        tree = tree.add(f\":open_file_folder: {path.name}\")\n    # recursively process the directory\n    if path.is_dir():\n        for item in path.iterdir():\n            if item.is_dir():\n                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")\n    # return the tree now containing all nodes\n    return tree"
            },
            {
              "lineno": 153,
              "coloffset": 8,
              "linematch": "if file.is_file() and file.exists():",
              "linematch_context": "    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():\n            return True\n    # the file was either none or not valid\n    return False\n\n"
            },
            {
              "lineno": 164,
              "coloffset": 8,
              "linematch": "if directory.is_dir() and directory.exists():",
              "linematch_context": "    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True\n    # the directory was either none or not valid\n    return False\n\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/validate.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 109,
              "coloffset": 8,
              "linematch": "if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:",
              "linematch_context": "    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files\n            # and return them in a list with a boolean\n            # indicate to show that checks files were found\n            checks_file_name_list = configuration[constants.checks.Check_Chasten][\n                constants.checks.Check_File"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 122,
              "coloffset": 8,
              "linematch": "elif event.validation_result is not None:",
              "linematch_context": "        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:"
            },
            {
              "lineno": 123,
              "coloffset": 12,
              "linematch": "if event.validation_result.is_valid:",
              "linematch_context": "        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":"
            },
            {
              "lineno": 131,
              "coloffset": 8,
              "linematch": "elif event.button.id == \"done\":",
              "linematch_context": "    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit(\n                self\n            )  # Exit the application if the \"Done\" button is clicked\n        elif event.button.id == \"clear\":\n            with open(CHECK_STORAGE, \"w\") as file:"
            },
            {
              "lineno": 135,
              "coloffset": 8,
              "linematch": "elif event.button.id == \"clear\":",
              "linematch_context": "        elif event.button.id == \"done\":\n            config_App.exit(\n                self\n            )  # Exit the application if the \"Done\" button is clicked\n        elif event.button.id == \"clear\":\n            with open(CHECK_STORAGE, \"w\") as file:\n                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:"
            },
            {
              "lineno": 140,
              "coloffset": 8,
              "linematch": "elif self.Valid:",
              "linematch_context": "            with open(CHECK_STORAGE, \"w\") as file:\n                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )"
            },
            {
              "lineno": 141,
              "coloffset": 12,
              "linematch": "if event.button.id == \"next\":",
              "linematch_context": "                file.write(\n                    \"\"\n                )  # Clears Checks.txt file when \"Clear Check\" button is clicked\n        elif self.Valid:\n            if event.button.id == \"next\":\n                # If \"Next Check!\" is clicked and input is valid, record the input data to a file\n                store_in_file(\n                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]\n                )\n                self.Check[0] = \"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 41,
              "coloffset": 8,
              "linematch": "elif (fuzzy_value < check_confidence) and not include:",
              "linematch_context": "            filtered_checks.append(check)\n        # include the check if the fuzzy inclusion value is below threshold\n        # and the purpose of the function call is to exclude values;\n        # note that not including a value means that it excludes\n        elif (fuzzy_value < check_confidence) and not include:\n            filtered_checks.append(check)\n    return filtered_checks\n\n\ndef filter_matches("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 118,
              "coloffset": 8,
              "linematch": "if filesystem.confirm_valid_file(API_KEY_STORAGE):",
              "linematch_context": "    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks\n        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))\n        # Checks if API key storage file exists\n        if filesystem.confirm_valid_file(API_KEY_STORAGE):\n            # prints the human readable checks to the terminal\n            output.console.print(result)\n            # loads the decrypted API Key\n            api_key = createchecks.load_user_api_key(API_KEY_STORAGE)\n            # calls the function to generate the yaml file"
            },
            {
              "lineno": 205,
              "coloffset": 8,
              "linematch": "if not validated:",
              "linematch_context": "        # --> checks.yml (or whatever file/url is reference in config.yml)\n        (validated, _) = configuration.validate_configuration_files(config, verbose)\n        # some aspect of the configuration was not\n        # valid, so exit early and signal an error\n        if not validated:\n            output.console.print(\n                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n            )\n            sys.exit(constants.markers.Non_Zero_Exit)\n    # create the configuration directory and a starting version of the configuration file"
            },
            {
              "lineno": 217,
              "coloffset": 12,
              "linematch": "if config is None:",
              "linematch_context": "        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs\n            if config is None:\n                configuration_directory = None\n            else:\n                configuration_directory = Path(config)\n            created_directory_path = filesystem.create_configuration_directory(\n                configuration_directory, force"
            },
            {
              "lineno": 241,
              "coloffset": 12,
              "linematch": "if not force:",
              "linematch_context": "        # cannot re-create the configuration directory, so display\n        # a message and suggest the use of --force the next time;\n        # exit early and signal an error with a non-zero exist code\n        except FileExistsError:\n            if not force:\n                output.console.print(\n                    \"\\n:person_shrugging: Configuration directory already exists.\"\n                )\n                output.console.print(\n                    \"Use --force to recreate configuration directory and its containing files.\""
            },
            {
              "lineno": 433,
              "coloffset": 8,
              "linematch": "if filesystem.confirm_valid_file(analysis_file_dir):",
              "linematch_context": "        # creates an empty string for storing results temporarily\n        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )"
            },
            {
              "lineno": 434,
              "coloffset": 12,
              "linematch": "if not force:",
              "linematch_context": "        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )\n                    sys.exit(0)"
            },
            {
              "lineno": 435,
              "coloffset": 16,
              "linematch": "if display:",
              "linematch_context": "        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):\n            if not force:\n                if display:\n                    database.display_results_frog_mouth(\n                        analysis_file_dir, util.get_OS()\n                    )\n                    sys.exit(0)\n                else:"
            },
            {
              "lineno": 649,
              "coloffset": 12,
              "linematch": "if os.path.isdir(input_path):",
              "linematch_context": "    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)"
            },
            {
              "lineno": 652,
              "coloffset": 20,
              "linematch": "if (",
              "linematch_context": "        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)\n                        and str(each_file).endswith(\".py\")\n                    ):\n                        # Read the bytes of the input path and store them in the 'contents' variable"
            },
            {
              "lineno": 666,
              "coloffset": 24,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                        )\n                        # Convert the Abstract Syntax Tree (AST) into an XML representation\n                        xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                        # Check if view_xml is chosen\n                        if view_XML is not None:\n                            output.console.print(\n                                pyastgrep.xml.tostring(\n                                    xml_root, pretty_print=True\n                                ).decode(\"utf-8\")\n                            )"
            },
            {
              "lineno": 672,
              "coloffset": 20,
              "linematch": "elif os.path.isdir(each_file):",
              "linematch_context": "                                pyastgrep.xml.tostring(\n                                    xml_root, pretty_print=True\n                                ).decode(\"utf-8\")\n                            )\n                    elif os.path.isdir(each_file):\n                        for sub_file in os.listdir(each_file):\n                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901\n                            if str(sub_file).endswith(\".py\"):\n                                contents = Path(sub_file).read_bytes()\n                                _, ast = pyastgrep.files.parse_python_file("
            },
            {
              "lineno": 675,
              "coloffset": 28,
              "linematch": "if str(sub_file).endswith(\".py\"):",
              "linematch_context": "                            )\n                    elif os.path.isdir(each_file):\n                        for sub_file in os.listdir(each_file):\n                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901\n                            if str(sub_file).endswith(\".py\"):\n                                contents = Path(sub_file).read_bytes()\n                                _, ast = pyastgrep.files.parse_python_file(\n                                    contents, sub_file, auto_dedent=False\n                                )\n                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            },
            {
              "lineno": 682,
              "coloffset": 32,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                                    contents, sub_file, auto_dedent=False\n                                )\n                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                                # Check if view_xml is chosen\n                                if view_XML is not None:\n                                    output.console.print(\n                                        pyastgrep.xml.tostring(\n                                            xml_root, pretty_print=True\n                                        ).decode(\"utf-8\")\n                                    )"
            },
            {
              "lineno": 688,
              "coloffset": 12,
              "linematch": "elif os.path.isfile(input_path) and str(input_path).endswith(\".py\"):",
              "linematch_context": "                                        pyastgrep.xml.tostring(\n                                            xml_root, pretty_print=True\n                                        ).decode(\"utf-8\")\n                                    )\n            elif os.path.isfile(input_path) and str(input_path).endswith(\".py\"):\n                contents = Path(input_path).read_bytes()\n                _, ast = pyastgrep.files.parse_python_file(\n                    contents, input_path, auto_dedent=False\n                )\n                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            },
            {
              "lineno": 695,
              "coloffset": 16,
              "linematch": "if view_XML is not None:",
              "linematch_context": "                    contents, input_path, auto_dedent=False\n                )\n                xml_root = pyastgrep.asts.ast_to_xml(ast, {})\n                # Check if view_xml is chosen\n                if view_XML is not None:\n                    output.console.print(\n                        pyastgrep.xml.tostring(xml_root, pretty_print=True).decode(\n                            \"utf-8\"\n                        )\n                    )"
            },
            {
              "lineno": 711,
              "coloffset": 8,
              "linematch": "if store_result:",
              "linematch_context": "    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file\n            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n            output.console.print(\n                f\"\\n:sparkles: Results saved in: {os.path.abspath(analysis_file_dir)}\\n\"\n            )"
            },
            {
              "lineno": 727,
              "coloffset": 8,
              "linematch": "if display:",
              "linematch_context": "        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")\n        if display:\n            database.display_results_frog_mouth(result_path, util.get_OS())\n\n\n@cli.command()\ndef integrate(  # noqa: PLR0913"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "CL001",
          "name": "nested-conditions",
          "description": "Ensure there is at least one nested condition (e.g., if{if{}}) in a function.",
          "min": 1,
          "max": 1,
          "pattern": ".//FunctionDef//If/descendant::If",
          "passed": false,
          "matches": [
            {
              "lineno": 218,
              "coloffset": 16,
              "linematch": "if isinstance(current_match, pyastgrepsearch.Match):  # type: ignore",
              "linematch_context": "                label=f\":tada: Found a total of {len(current_check._matches)} matches for '{check_name}' in {current_source.filename}\",\n            )\n            # iterate through each of the matches and display all of their details\n            for current_match in current_check._matches:  # type: ignore\n                if isinstance(current_match, pyastgrepsearch.Match):  # type: ignore\n                    # display a label for matching output information\n                    opt_print_log(verbose, blank=constants.markers.Empty_String)\n                    opt_print_log(verbose, label=\":sparkles: Matching source code:\")\n                    # extract the direct line number for this match\n                    position_end = current_match.position.lineno"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "C002",
          "name": "nested-loop-conditions",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{if{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[//(If/following-sibling::For | For/following-sibling::If)]",
          "passed": false,
          "matches": [
            {
              "lineno": 20,
              "coloffset": 0,
              "linematch": "def configure_tracebacks() -> None:",
              "linematch_context": "\nfrom chasten import constants, filesystem, output, util, validate\n\n\ndef configure_tracebacks() -> None:\n    \"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"\n    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:"
            },
            {
              "lineno": 25,
              "coloffset": 0,
              "linematch": "def user_config_dir(application_name: str, application_author: str) -> str:",
              "linematch_context": "    \"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"\n    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:\n    \"\"\"Return the user's configuration directory using platformdirs.\"\"\"\n    # access the directory and then return it based on the\n    # provided name of the application and the application's author\n    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str"
            },
            {
              "lineno": 33,
              "coloffset": 0,
              "linematch": "def configure_logging(",
              "linematch_context": "    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str\n\n\ndef configure_logging(\n    debug_level: str = constants.logging.Default_Logging_Level,\n    debug_dest: str = constants.logging.Default_Logging_Destination,\n) -> Tuple[logging.Logger, bool]:\n    \"\"\"Configure standard Python logging package.\"\"\"\n    # use the specified logger with the specified destination"
            },
            {
              "lineno": 53,
              "coloffset": 0,
              "linematch": "def configure_logging_console(",
              "linematch_context": "    except AttributeError:\n        return (configure_logging_console(debug_level), False)\n\n\ndef configure_logging_console(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use rich.\"\"\"\n    # use the RichHandler to provide formatted\n    # debugging output in the console"
            },
            {
              "lineno": 70,
              "coloffset": 0,
              "linematch": "def configure_logging_syslog(",
              "linematch_context": "    logger = logging.getLogger()\n    return logger\n\n\ndef configure_logging_syslog(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use syslog.\"\"\"\n    # use the SysLogHandler to send output to a localhost on a port\n    syslog_handler = logging.handlers.SysLogHandler("
            },
            {
              "lineno": 89,
              "coloffset": 0,
              "linematch": "def display_configuration_directory(",
              "linematch_context": "    logger = logging.getLogger()\n    return logger\n\n\ndef display_configuration_directory(\n    chasten_user_config_dir_str: str, verbose: bool = False\n) -> None:\n    \"\"\"Display information about the configuration in the console.\"\"\"\n    # create a visualization of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)"
            },
            {
              "lineno": 103,
              "coloffset": 0,
              "linematch": "def validate_checks_file(",
              "linematch_context": "    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,\n    checks_file_name: str,\n    chasten_user_config_url_str: str,\n    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,"
            },
            {
              "lineno": 177,
              "coloffset": 0,
              "linematch": "def validate_configuration_files(",
              "linematch_context": "        yaml_data_dict,\n    )\n\n\ndef validate_configuration_files(\n    config: str,\n    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:"
            },
            {
              "lineno": 340,
              "coloffset": 0,
              "linematch": "def extract_configuration_details_from_config_dir(",
              "linematch_context": "    # there was at least one validation error\n    return (False, {})\n\n\ndef extract_configuration_details_from_config_dir(\n    chasten_user_config_dir_str: Path,\n    configuration_file: str = constants.filesystem.Main_Configuration_File,\n) -> Tuple[bool, str, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config directory.\n"
            },
            {
              "lineno": 383,
              "coloffset": 0,
              "linematch": "def extract_configuration_details_from_config_url(",
              "linematch_context": "            )\n            return (False, None, None, None)  # type: ignore\n\n\ndef extract_configuration_details_from_config_url(\n    chasten_user_config_url: Url,\n) -> Tuple[bool, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config URL.\n\n    chasten_user_config_url -- URL to config or checks yaml file."
            },
            {
              "lineno": 415,
              "coloffset": 0,
              "linematch": "def convert_configuration_text_to_yaml(",
              "linematch_context": "        )\n        return (False, None, None)  # type: ignore\n\n\ndef convert_configuration_text_to_yaml(\n    configuration_file_contents_str: str,\n) -> Tuple[bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Return details about the configuration.\"\"\"\n    yaml_data = None\n    try:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/util.py",
        "check": {
          "id": "C002",
          "name": "nested-loop-conditions",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{if{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[//(If/following-sibling::For | For/following-sibling::If)]",
          "passed": false,
          "matches": [
            {
              "lineno": 16,
              "coloffset": 0,
              "linematch": "def get_human_readable_boolean(answer: bool) -> str:",
              "linematch_context": "xmark_unicode = \"\\u2717\"\ndefault_chasten_semver = \"0.0.0\"\n\n\ndef get_human_readable_boolean(answer: bool) -> str:\n    \"\"\"Produce a human-readable Yes or No for a boolean value of True or False.\"\"\"\n    # the provided answer is true\n    if answer:\n        return constants.humanreadable.Yes\n    # the provided answer is false"
            },
            {
              "lineno": 25,
              "coloffset": 0,
              "linematch": "def get_OS() -> str:",
              "linematch_context": "    # the provided answer is false\n    return constants.humanreadable.No\n\n\ndef get_OS() -> str:\n    \"\"\"Gets the Operating system of the user.\"\"\"\n    OpSystem = platform.system()\n    return OpSystem\n\n"
            },
            {
              "lineno": 31,
              "coloffset": 0,
              "linematch": "def executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:",
              "linematch_context": "    OpSystem = platform.system()\n    return OpSystem\n\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\"\n    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\""
            },
            {
              "lineno": 42,
              "coloffset": 0,
              "linematch": "def get_symbol_boolean(answer: bool) -> str:",
              "linematch_context": "    virtual_env_location = sys.prefix\n    return virtual_env_location + exe_directory + executable_name\n\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:\n        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n"
            },
            {
              "lineno": 49,
              "coloffset": 0,
              "linematch": "def get_chasten_version() -> str:",
              "linematch_context": "        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n\n\ndef get_chasten_version() -> str:\n    \"\"\"Use importlib to extract the version of the package.\"\"\"\n    # attempt to determine the current version of the entire package,\n    # bearing in mind that this program appears on PyPI with the name \"chasten\";\n    # this will then return the version string specified with the version attribute\n    # in the [tool.poetry] section of the pyproject.toml file"
            },
            {
              "lineno": 68,
              "coloffset": 0,
              "linematch": "def join_and_preserve(data, start, end):",
              "linematch_context": "        version_string_of_foo = default_chasten_semver\n    return version_string_of_foo\n\n\ndef join_and_preserve(data, start, end):\n    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:"
            },
            {
              "lineno": 73,
              "coloffset": 0,
              "linematch": "def is_url(url: str) -> bool:",
              "linematch_context": "    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:\n    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url\n    url_parsed = parse_url(url)\n    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:"
            },
            {
              "lineno": 106,
              "coloffset": 0,
              "linematch": "def total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:",
              "linematch_context": "    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed\n    try:\n        # calculate total amount of checks in list\n        count_total = len(check_status_list)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "C002",
          "name": "nested-loop-conditions",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{if{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[//(If/following-sibling::For | For/following-sibling::If)]",
          "passed": false,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 0,
              "linematch": "def include_or_exclude_checks(",
              "linematch_context": "\nfrom chasten import constants, enumerations\n\n\ndef include_or_exclude_checks(\n    checks: List[Dict[str, Union[str, Dict[str, int]]]],\n    check_attribute: enumerations.FilterableAttribute,\n    check_match: str,\n    check_confidence: int = constants.checks.Check_Confidence,\n    include: bool = True,"
            },
            {
              "lineno": 46,
              "coloffset": 0,
              "linematch": "def filter_matches(",
              "linematch_context": "            filtered_checks.append(check)\n    return filtered_checks\n\n\ndef filter_matches(\n    match_list: List[Union[pyastgrepsearch.Match, Any]],\n    data_type,\n) -> Tuple[List[pyastgrepsearch.Match], List[Any]]:\n    \"\"\"Filter the list of matches based on the provided data type.\"\"\"\n    subset_match_list = []"
            },
            {
              "lineno": 69,
              "coloffset": 0,
              "linematch": "def organize_matches(",
              "linematch_context": "    # return both of the created lists\n    return (subset_match_list, did_not_match_list)\n\n\ndef organize_matches(\n    match_list: List[pyastgrepsearch.Match],\n) -> Dict[str, List[pyastgrepsearch.Match]]:\n    \"\"\"Organize the matches on a per-file basis to support simplified processing.\"\"\"\n    match_dict: Dict[str, List[pyastgrepsearch.Match]] = {}\n    # iterate through each of the matches in the list, with"
            },
            {
              "lineno": 97,
              "coloffset": 0,
              "linematch": "def combine_dicts(dict_list: List[Dict[Any, Any]]) -> str:",
              "linematch_context": "            match_dict[current_match_file_name] = current_match_list\n    return match_dict\n\n\ndef combine_dicts(dict_list: List[Dict[Any, Any]]) -> str:\n    \"\"\"Combine all dictionaries in the list into a single list of dictionaries as a string.\"\"\"\n    # combine all of the dictionaries in the list into\n    # a single string that is a list of each JSON-based\n    # dictionary represented as a string; this leads to:\n    # ["
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "C002",
          "name": "nested-loop-conditions",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{if{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[//(If/following-sibling::For | For/following-sibling::If)]",
          "passed": false,
          "matches": [
            {
              "lineno": 45,
              "coloffset": 0,
              "linematch": "def output_preamble(",
              "linematch_context": "# Region: Helper functions {{{\n# ---\n\n\ndef output_preamble(\n    verbose: bool,\n    debug_level: debug.DebugLevel = debug.DebugLevel.ERROR,\n    debug_destination: debug.DebugDestination = debug.DebugDestination.CONSOLE,\n    **kwargs,\n) -> None:"
            },
            {
              "lineno": 72,
              "coloffset": 0,
              "linematch": "def display_serve_or_publish_details(",
              "linematch_context": "        **kwargs,\n    )\n\n\ndef display_serve_or_publish_details(\n    label: str,\n    database_path: Path,\n    metadata: Path,\n    port: int = 8001,\n    publish: bool = False,"
            },
            {
              "lineno": 107,
              "coloffset": 0,
              "linematch": "def create_checks(",
              "linematch_context": "# ---\n\n\n@cli.command()\ndef create_checks(\n    filename: Path = typer.Option(\"checks.yml\", help=\"YAML file name\")\n) -> None:\n    \"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"\n    # creates a textual object for better user interface\n    app.run()"
            },
            {
              "lineno": 154,
              "coloffset": 0,
              "linematch": "def configure(  # noqa: PLR0913",
              "linematch_context": "        )\n\n\n@cli.command()\ndef configure(  # noqa: PLR0913\n    task: enumerations.ConfigureTask = typer.Argument(\n        enumerations.ConfigureTask.VALIDATE.value\n    ),\n    config: str = typer.Option(\n        None,"
            },
            {
              "lineno": 252,
              "coloffset": 0,
              "linematch": "def analyze(  # noqa: PLR0912, PLR0913, PLR0915",
              "linematch_context": "            sys.exit(constants.markers.Non_Zero_Exit)\n\n\n@cli.command()\ndef analyze(  # noqa: PLR0912, PLR0913, PLR0915\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    xpath: Path = typer.Option(\n        str,\n        \"--xpath-version\",\n        \"-xp\","
            },
            {
              "lineno": 732,
              "coloffset": 0,
              "linematch": "def integrate(  # noqa: PLR0913",
              "linematch_context": "            database.display_results_frog_mouth(result_path, util.get_OS())\n\n\n@cli.command()\ndef integrate(  # noqa: PLR0913\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    json_path: List[Path] = typer.Argument(\n        help=\"Directories, files, or globs for chasten's JSON result file(s).\",\n    ),\n    output_directory: Path = typer.Option("
            },
            {
              "lineno": 821,
              "coloffset": 0,
              "linematch": "def datasette_serve(  # noqa: PLR0913",
              "linematch_context": "        output.logger.debug(\"Integrate function completed successfully.\")\n\n\n@cli.command()\ndef datasette_serve(  # noqa: PLR0913\n    database_path: Path = typer.Argument(\n        help=\"SQLite3 database file storing chasten's results.\",\n        exists=True,\n        file_okay=True,\n        dir_okay=False,"
            },
            {
              "lineno": 896,
              "coloffset": 0,
              "linematch": "def datasette_publish(  # noqa: PLR0913",
              "linematch_context": "    )\n\n\n@cli.command()\ndef datasette_publish(  # noqa: PLR0913\n    database_path: Path = typer.Argument(\n        help=\"SQLite3 database file storing chasten's results.\",\n        exists=True,\n        file_okay=True,\n        dir_okay=False,"
            },
            {
              "lineno": 972,
              "coloffset": 0,
              "linematch": "def log() -> None:",
              "linematch_context": "    )\n\n\n@cli.command()\ndef log() -> None:\n    \"\"\"\ud83e\udd9a Start the logging server.\"\"\"\n    # display the header\n    output.print_header()\n    # display details about the server\n    output.print_server()"
            },
            {
              "lineno": 988,
              "coloffset": 0,
              "linematch": "def version():",
              "linematch_context": "    server.start_syslog_server()\n\n\n@cli.command()\ndef version():\n    \"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\"\n    # Get Chasten version from util file\n    version_string = util.get_chasten_version()\n    # output chasten version\n    typer.echo(f\"chasten {version_string}\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "C002",
          "name": "nested-loop-conditions",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{if{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[//(If/following-sibling::For | For/following-sibling::If)]",
          "passed": false,
          "matches": [
            {
              "lineno": 25,
              "coloffset": 0,
              "linematch": "def setup(",
              "linematch_context": "# define a small bullet for display\nsmall_bullet_unicode = constants.markers.Small_Bullet_Unicode\n\n\ndef setup(\n    debug_level: debug.DebugLevel, debug_destination: debug.DebugDestination\n) -> None:\n    \"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"\n    global logger\n    # configure the use of rich for improved terminal output:"
            },
            {
              "lineno": 40,
              "coloffset": 0,
              "linematch": "def print_diagnostics(verbose: bool, **configurations: Any) -> None:",
              "linematch_context": "        debug_level.value, debug_destination.value\n    )\n\n\ndef print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")"
            },
            {
              "lineno": 54,
              "coloffset": 0,
              "linematch": "def opt_print_log(verbose: bool, **contents: Any) -> None:",
              "linematch_context": "                f\"{constants.markers.Indent}{configuration_current} = {configurations[configuration_current]}\"\n            )\n\n\ndef opt_print_log(verbose: bool, **contents: Any) -> None:\n    \"\"\"Produce logging information and only print when not verbose.\"\"\"\n    global console  # noqa: PLW0602\n    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument"
            },
            {
              "lineno": 67,
              "coloffset": 0,
              "linematch": "def print_header() -> None:",
              "linematch_context": "        # always log the information to the configured logger\n        logger.debug(contents[current])\n\n\ndef print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline"
            },
            {
              "lineno": 77,
              "coloffset": 0,
              "linematch": "def print_server() -> None:",
              "linematch_context": "    )\n    console.print(constants.chasten.Website)\n\n\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n"
            },
            {
              "lineno": 84,
              "coloffset": 0,
              "linematch": "def print_test_start() -> None:",
              "linematch_context": "    console.print(constants.output.Syslog)\n    console.print()\n\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n"
            },
            {
              "lineno": 91,
              "coloffset": 0,
              "linematch": "def print_test_finish() -> None:",
              "linematch_context": "    console.print(constants.output.Test_Start)\n    console.print()\n\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()"
            },
            {
              "lineno": 99,
              "coloffset": 0,
              "linematch": "def print_footer() -> None:",
              "linematch_context": "    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n\n"
            },
            {
              "lineno": 105,
              "coloffset": 0,
              "linematch": "def group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:",
              "linematch_context": "    global console  # noqa: PLW0602\n    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\"\n    # create an empty dictionary\n    grouped_files: Dict[Path, List[str]] = {}\n    # iterate through each of the full paths\n    # and extract the containing directory"
            },
            {
              "lineno": 129,
              "coloffset": 0,
              "linematch": "def shorten_file_name(file_name: str, max_length: int) -> str:",
              "linematch_context": "    # return the dictionary of files organized by directory\n    return grouped_files\n\n\ndef shorten_file_name(file_name: str, max_length: int) -> str:\n    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long\n    if len(file_name) > max_length:\n        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name"
            },
            {
              "lineno": 137,
              "coloffset": 0,
              "linematch": "def print_list_contents(container: List[Path]) -> None:",
              "linematch_context": "        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name\n\n\ndef print_list_contents(container: List[Path]) -> None:\n    \"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"\n    global console  # noqa: PLW0602\n    # group all of the files by the directory that contains them;\n    # note that this is important because the contain can contain\n    # paths that specify files in different directories"
            },
            {
              "lineno": 160,
              "coloffset": 0,
              "linematch": "def print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:",
              "linematch_context": "                f\"  {small_bullet_unicode} file(s) {int(filecount)} in this directory\"\n            )\n\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "F001",
          "name": "nested-loop-conditions-ff",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{for{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//For[.//For]",
          "passed": true,
          "matches": [
            {
              "lineno": 466,
              "coloffset": 4,
              "linematch": "for current_check in check_list:",
              "linematch_context": "        output.logger.debug(\"Using XPath version 1.0\")\n    else:\n        output.logger.debug(\"Using XPath version 2.0\")\n    # iterate through and perform each of the checks\n    for current_check in check_list:\n        # extract the pattern for the current check\n        current_xpath_pattern = str(\n            current_check[constants.checks.Check_Pattern]\n        )  # type: ignore\n        # extract the minimum and maximum values for the checks, if they exist"
            },
            {
              "lineno": 561,
              "coloffset": 8,
              "linematch": "for file_name, matches_list in match_dict.items():",
              "linematch_context": "        # specific file, ensuring that matches for different files\n        # are not mixed together, which would contaminate the results\n        # Note: this is needed because using pyastgrepsearch will\n        # return results for all of the files that matched the check\n        for file_name, matches_list in match_dict.items():\n            # create the current check\n            current_check_save = results.Check(\n                id=check_id,  # type: ignore\n                name=check_name,  # type: ignore\n                description=check_description,  # type: ignore"
            },
            {
              "lineno": 650,
              "coloffset": 16,
              "linematch": "for each_file in os.listdir(input_path):",
              "linematch_context": "    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901\n                    if (\n                        not os.path.isdir(each_file)\n                        and os.path.isfile(each_file)\n                        and str(each_file).endswith(\".py\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "F001",
          "name": "nested-loop-conditions-ff",
          "description": "Ensure the presence of nested loop-conditions (e.g., for{for{}}) in a function.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef//For[.//For]",
          "passed": true,
          "matches": [
            {
              "lineno": 147,
              "coloffset": 4,
              "linematch": "for directory, files in grouped_files.items():",
              "linematch_context": "    grouped_files = group_files_by_directory(container)\n    # iterate through each of the directories and\n    # --> display the name of the directory\n    # --> display the name of each file stored in this directory\n    for directory, files in grouped_files.items():\n        console.print(f\"{small_bullet_unicode} Directory: {directory}\")\n        filecount = 0\n        for file_name in files:\n            filecount = +1\n            console.print("
            },
            {
              "lineno": 173,
              "coloffset": 4,
              "linematch": "for current_source in chasten.sources:",
              "linematch_context": "    if not verbose:\n        return None\n    opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")\n    # iterate through the the list of sources inside of the resulting analysis\n    for current_source in chasten.sources:\n        # extract the current check from this source\n        current_check: results.Check = current_source.check  # type: ignore\n        current_xpath_pattern = current_check.pattern\n        console.print(\"\\n:tada: Check:\")\n        xpath_syntax = Syntax("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configApp.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert configApp.write_checks(CSV_CHECK_LIST) == expected_check",
              "linematch_context": "# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\""
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"",
              "linematch_context": "\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\"\n    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\""
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert configApp.split_file(file) == CSV_CHECK_LIST",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given(\n    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")",
              "linematch_context": "    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_debug.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 10,
              "coloffset": 4,
              "linematch": "assert DebugLevel.DEBUG == \"DEBUG\"",
              "linematch_context": "\n\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n"
            },
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "assert DebugLevel.INFO == \"INFO\"",
              "linematch_context": "\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n"
            },
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "assert DebugLevel.WARNING == \"WARNING\"",
              "linematch_context": "def test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():"
            },
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "assert DebugLevel.ERROR == \"ERROR\"",
              "linematch_context": "    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\""
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert DebugLevel.CRITICAL == \"CRITICAL\"",
              "linematch_context": "    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)"
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.DEBUG, DebugLevel)",
              "linematch_context": "\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.INFO, DebugLevel)",
              "linematch_context": "\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.WARNING, DebugLevel)",
              "linematch_context": "def test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.ERROR, DebugLevel)",
              "linematch_context": "    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\""
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.CRITICAL, DebugLevel)",
              "linematch_context": "    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]",
              "linematch_context": "\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\""
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "assert DebugDestination.CONSOLE == \"CONSOLE\"",
              "linematch_context": "\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\""
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert DebugDestination.SYSLOG == \"SYSLOG\"",
              "linematch_context": "\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.CONSOLE, DebugDestination)",
              "linematch_context": "\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.SYSLOG, DebugDestination)",
              "linematch_context": "\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configuration.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert user_config_dir_str",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n\n\n@given(\n    debug_level=strategies.sampled_from("
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert applicationname in user_config_dir_str",
              "linematch_context": "    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert logger",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given("
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert created",
              "linematch_context": "def test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from("
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "assert logger",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "assert not created",
              "linematch_context": "def test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_util.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert util.get_human_readable_boolean(answer=True) == \"Yes\"",
              "linematch_context": "\n\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "assert util.get_human_readable_boolean(answer=False) == \"No\"",
              "linematch_context": "\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "assert result is True",
              "linematch_context": "@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier",
              "linematch_context": "@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n\nOpSystem = util.get_OS()\ndatasette_exec = constants.datasette.Datasette_Executable"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "assert stats[0] <= stats[1]",
              "linematch_context": "def test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n\nOpSystem = util.get_OS()\ndatasette_exec = constants.datasette.Datasette_Executable\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_createchecks.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert result is True",
              "linematch_context": "    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n\n\n# @pytest.mark.api\n# def test_invalid_api_key():\n#     \"\"\"Test is_valid_api_key function with an invalid api key.\"\"\""
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "assert result is not None",
              "linematch_context": "    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "assert file_path.is_file()",
              "linematch_context": "\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()\n        assert \"Hello, World\" in content"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert confirmation is True",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "assert confirmation is False",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert filesystem.confirm_valid_directory(None) is False",
              "linematch_context": "    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert confirmation is True",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "assert confirmation is False",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            },
            {
              "lineno": 76,
              "coloffset": 4,
              "linematch": "assert tree.label == f\":open_file_folder: {tmp_dir.name}\"",
              "linematch_context": "    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "assert set(dirs) == {",
              "linematch_context": "    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "assert set(files) == {",
              "linematch_context": "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }\n\n\n@given(directory=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "def test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files"
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert tree.label == f\":open_file_folder: {directory.name}\"",
              "linematch_context": "    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore"
            },
            {
              "lineno": 106,
              "coloffset": 4,
              "linematch": "assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())",
              "linematch_context": "            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):"
            },
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())",
              "linematch_context": "        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\""
            },
            {
              "lineno": 119,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception("
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n"
            },
            {
              "lineno": 135,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n"
            },
            {
              "lineno": 152,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n"
            },
            {
              "lineno": 153,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n"
            },
            {
              "lineno": 170,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n"
            },
            {
              "lineno": 171,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):"
            },
            {
              "lineno": 182,
              "coloffset": 4,
              "linematch": "assert filesystem.detect_configuration(config) == str(config)",
              "linematch_context": "    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 196,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n"
            },
            {
              "lineno": 197,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 199,
              "coloffset": 4,
              "linematch": "assert detected_directory == str(dir_path)",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\""
            },
            {
              "lineno": 211,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content"
            },
            {
              "lineno": 212,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\""
            },
            {
              "lineno": 218,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.exists()",
              "linematch_context": "    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS\n    )"
            },
            {
              "lineno": 220,
              "coloffset": 4,
              "linematch": "assert (",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS\n    )\n\n"
            },
            {
              "lineno": 235,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content"
            },
            {
              "lineno": 236,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\""
            },
            {
              "lineno": 242,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.exists()",
              "linematch_context": "    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert set(filtered) == set(",
              "linematch_context": "def test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n\n@given(match_list=st.lists(st.integers()))"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_validate.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\""
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "assert not is_valid",
              "linematch_context": "            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given("
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "assert errors",
              "linematch_context": "        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "assert \"is not of type\" in errors",
              "linematch_context": "    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})\n)"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "def test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "def test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "assert min_count == 1",
              "linematch_context": "def test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\""
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "assert max_count == 10  # noqa",
              "linematch_context": "    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert min_count is None",
              "linematch_context": "def test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert max_count == 10  # noqa",
              "linematch_context": "    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert min_count == 1",
              "linematch_context": "            \"min\": 1,\n        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\""
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "assert max_count is None",
              "linematch_context": "        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}"
            },
            {
              "lineno": 60,
              "coloffset": 4,
              "linematch": "assert min_count is None",
              "linematch_context": "def test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\""
            },
            {
              "lineno": 61,
              "coloffset": 4,
              "linematch": "assert max_count is None",
              "linematch_context": "    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {"
            },
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "assert \"described test\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {"
            },
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "assert \"\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"\" == extract_description(check)\n\n\n@pytest.mark.parametrize(\n    \"bool_status,expected\",\n    ["
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert make_checks_status_message(bool_status) == expected",
              "linematch_context": "    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):"
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 105,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\","
            },
            {
              "lineno": 115,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 136,
              "coloffset": 4,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_main.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 116,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            configuration_directory,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 0\n\n\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command"
            },
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "assert result.exit_code in [0, 1]",
              "linematch_context": "            configuration_directory,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code in [0, 1]\n\n\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 161,
              "coloffset": 4,
              "linematch": "assert result.exit_code != 0",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    # crashes because the command-line arguments are wrong\n    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\""
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "assert \"Missing argument\" in result.output",
              "linematch_context": "        ],\n    )\n    # crashes because the command-line arguments are wrong\n    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 186,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            wrong_config_dir,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\""
            },
            {
              "lineno": 187,
              "coloffset": 4,
              "linematch": "assert \"Cannot perform analysis due to configuration\" in result.output",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 214,
              "coloffset": 4,
              "linematch": "assert result.exit_code != 0",
              "linematch_context": "        ],\n    )\n    # running the program with an invalid --search-path\n    # should not work and thus a zero exit code is wrong\n    assert result.exit_code != 0\n    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output"
            },
            {
              "lineno": 218,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 2  # noqa",
              "linematch_context": "    assert result.exit_code != 0\n    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\""
            },
            {
              "lineno": 219,
              "coloffset": 4,
              "linematch": "assert \"Usage:\" in result.output",
              "linematch_context": "    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 243,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            correct_config_dir,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\n# def test_cli_analyze_url_config(cwd):\n#     \"\"\"Confirm that using the command-line interface correctly handles a valid URL configuration.\"\"\""
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "assert \"Cannot perform analysis due to configuration\" in result.output",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\n# def test_cli_analyze_url_config(cwd):\n#     \"\"\"Confirm that using the command-line interface correctly handles a valid URL configuration.\"\"\"\n#     # use config files found in chasten-configuration remotely"
            },
            {
              "lineno": 371,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"create\",\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 0\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_cannot_create_config_when_does_exist(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 385,
              "coloffset": 4,
              "linematch": "assert config_directory.exists()",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\","
            },
            {
              "lineno": 395,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            \"create\",\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 418,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--search-path\",\n            str(directory),\n        ],\n    )\n    assert result.exit_code == 0\n\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)"
            },
            {
              "lineno": 441,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--markdown-storage\",\n            tmp_dir,\n        ],\n    )\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\""
            },
            {
              "lineno": 442,
              "coloffset": 4,
              "linematch": "assert \"\u2728 Results saved in:\" in result.output",
              "linematch_context": "            tmp_dir,\n        ],\n    )\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)"
            },
            {
              "lineno": 453,
              "coloffset": 4,
              "linematch": "assert file.exists()",
              "linematch_context": "    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands"
            },
            {
              "lineno": 473,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            tmp_dir,\n        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 1\n    assert (\n        \"File already exists: use --force to recreate markdown directory.\"\n        in result.output\n    )\n"
            },
            {
              "lineno": 474,
              "coloffset": 4,
              "linematch": "assert (",
              "linematch_context": "        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 1\n    assert (\n        \"File already exists: use --force to recreate markdown directory.\"\n        in result.output\n    )\n\n"
            },
            {
              "lineno": 487,
              "coloffset": 4,
              "linematch": "assert file.exists()",
              "linematch_context": "    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands"
            },
            {
              "lineno": 508,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--force\",\n        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])"
            },
            {
              "lineno": 509,
              "coloffset": 4,
              "linematch": "assert \"\u2728 Results saved in:\" in result.output",
              "linematch_context": "        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 534,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_constants.py",
        "check": {
          "id": "NOA001",
          "name": "number-of-assertions",
          "description": "Ensure the presence of assertions within function bodies.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/Assert",
          "passed": false,
          "matches": [
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert constants.filesystem.Current_Directory == \".\"",
              "linematch_context": "\n\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "assert constants.filesystem.Main_Configuration_File == \"config.yml\"",
              "linematch_context": "\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given("
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "assert constants.humanreadable.Yes == \"Yes\"",
              "linematch_context": "def test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given(\n    directory=strategies.text(),"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "assert constants.humanreadable.No == \"No\"",
              "linematch_context": "    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given(\n    directory=strategies.text(),\n    configfile=strategies.text(),"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert fs.Current_Directory == directory",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert hr.Yes == yes",
              "linematch_context": "        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given(\n    fs=strategies.builds(constants.Filesystem),"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "assert hr.No == no",
              "linematch_context": "    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given(\n    fs=strategies.builds(constants.Filesystem),\n    hr=strategies.builds(constants.Humanreadable),"
            },
            {
              "lineno": 82,
              "coloffset": 4,
              "linematch": "assert dir1 == dir2",
              "linematch_context": "def test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    assert fs1 == fs2"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configApp.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "\"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"",
              "linematch_context": "\n\n# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"",
              "linematch_context": "\n# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert configApp.write_checks(CSV_CHECK_LIST) == expected_check",
              "linematch_context": "# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\""
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "\"\"\"Test the write_checks function when list is empty\"\"\"",
              "linematch_context": "\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\"\n    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"",
              "linematch_context": "\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\"\n    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\""
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "\"\"\"Test the split_file function by parsing check data from a file.\"\"\"",
              "linematch_context": "\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST"
            },
            {
              "lineno": 48,
              "coloffset": 4,
              "linematch": "tmp_dir = pathlib.Path(tmpdir)",
              "linematch_context": "\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"check_test.txt\"",
              "linematch_context": "# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "def test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "file.write_text(CHECK_TEST_DEFAULT)",
              "linematch_context": "    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given("
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert configApp.split_file(file) == CSV_CHECK_LIST",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given(\n    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            },
            {
              "lineno": 64,
              "coloffset": 4,
              "linematch": "\"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"",
              "linematch_context": ")\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "tmp_dir = pathlib.Path(tmpdir)",
              "linematch_context": "@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"check_test.txt\"",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "def test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "configApp.store_in_file(file, Pattern, Matches, Exact)",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")",
              "linematch_context": "    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_database.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"",
              "linematch_context": "from chasten import database\n\n\ndef test_create_chasten_view():\n    \"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"\n    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)"
            },
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "chasten_database_name: str = \".example_database\"",
              "linematch_context": "\ndef test_create_chasten_view():\n    \"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"\n    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)\n    # remove the example variable made\n    os.remove(\".example_database\")"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "database.create_chasten_view(chasten_database_name)",
              "linematch_context": "    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)\n    # remove the example variable made\n    os.remove(\".example_database\")"
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "os.remove(\".example_database\")",
              "linematch_context": "    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)\n    # remove the example variable made\n    os.remove(\".example_database\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_debug.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the enumeration values are correct.\"\"\"",
              "linematch_context": "from chasten.debug import DebugDestination, DebugLevel\n\n\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\""
            },
            {
              "lineno": 10,
              "coloffset": 4,
              "linematch": "assert DebugLevel.DEBUG == \"DEBUG\"",
              "linematch_context": "\n\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n"
            },
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "assert DebugLevel.INFO == \"INFO\"",
              "linematch_context": "\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n"
            },
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "assert DebugLevel.WARNING == \"WARNING\"",
              "linematch_context": "def test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():"
            },
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "assert DebugLevel.ERROR == \"ERROR\"",
              "linematch_context": "    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\""
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert DebugLevel.CRITICAL == \"CRITICAL\"",
              "linematch_context": "    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"",
              "linematch_context": "    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)"
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.DEBUG, DebugLevel)",
              "linematch_context": "\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.INFO, DebugLevel)",
              "linematch_context": "\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.WARNING, DebugLevel)",
              "linematch_context": "def test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.ERROR, DebugLevel)",
              "linematch_context": "    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\""
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.CRITICAL, DebugLevel)",
              "linematch_context": "    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to list all of the possible values.\"\"\"",
              "linematch_context": "    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\""
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]",
              "linematch_context": "\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\""
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the enumeration values are correct.\"\"\"",
              "linematch_context": "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "assert DebugDestination.CONSOLE == \"CONSOLE\"",
              "linematch_context": "\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\""
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert DebugDestination.SYSLOG == \"SYSLOG\"",
              "linematch_context": "\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)"
            },
            {
              "lineno": 38,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"",
              "linematch_context": "    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.CONSOLE, DebugDestination)",
              "linematch_context": "\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.SYSLOG, DebugDestination)",
              "linematch_context": "\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"",
              "linematch_context": "    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\""
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that invalid values raise a ValueError.\"\"\"",
              "linematch_context": "    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "with pytest.raises(ValueError):",
              "linematch_context": "\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\""
            },
            {
              "lineno": 55,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that invalid values raise a ValueError.\"\"\"",
              "linematch_context": "        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugDestination(\"INVALID\")"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "with pytest.raises(ValueError):",
              "linematch_context": "\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugDestination(\"INVALID\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configuration.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_create_use_config_dir(\n    applicationname: str, applicationauthor: str\n) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "user_config_dir_str = configuration.user_config_dir(",
              "linematch_context": "def test_fuzz_create_use_config_dir(\n    applicationname: str, applicationauthor: str\n) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert user_config_dir_str",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n\n\n@given(\n    debug_level=strategies.sampled_from("
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert applicationname in user_config_dir_str",
              "linematch_context": "    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"",
              "linematch_context": "    debug_dest=strategies.sampled_from([\"CONSOLE\", \"SYSLOG\"]),\n)\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "logger, created = configuration.configure_logging(debug_level, debug_dest)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert logger",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given("
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert created",
              "linematch_context": "def test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from("
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"",
              "linematch_context": "    debug_dest=strategies.sampled_from([\"CONSOLE-WRONG\", \"SYSLOG-WRONG\"]),\n)\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 48,
              "coloffset": 4,
              "linematch": "logger, created = configuration.configure_logging(debug_level, debug_dest)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "assert logger",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "assert not created",
              "linematch_context": "def test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_util.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"",
              "linematch_context": "from chasten import constants, util\n\n\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert util.get_human_readable_boolean(answer=True) == \"Yes\"",
              "linematch_context": "\n\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "assert util.get_human_readable_boolean(answer=False) == \"No\"",
              "linematch_context": "\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"",
              "linematch_context": "\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    util.get_human_readable_boolean(answer=answer)\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "util.get_human_readable_boolean(answer=answer)",
              "linematch_context": "@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    util.get_human_readable_boolean(answer=answer)\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:"
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"",
              "linematch_context": "\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\""
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "str_answer = util.get_human_readable_boolean(answer=answer)",
              "linematch_context": "@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"",
              "linematch_context": "\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "result = util.is_url(url=url)",
              "linematch_context": "@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "assert result is True",
              "linematch_context": "@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "stats = util.total_amount_passed(check_status_list)",
              "linematch_context": "\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier",
              "linematch_context": "@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n\nOpSystem = util.get_OS()\ndatasette_exec = constants.datasette.Datasette_Executable"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "assert stats[0] <= stats[1]",
              "linematch_context": "def test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n\nOpSystem = util.get_OS()\ndatasette_exec = constants.datasette.Datasette_Executable\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_createchecks.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "\"\"\"Test is_valid_api_key function with a valid api key.\"\"\"",
              "linematch_context": "\n\n@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "valid_api_key = get_valid_api_key()",
              "linematch_context": "\n@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "if not valid_api_key:",
              "linematch_context": "@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "result = is_valid_api_key(valid_api_key)",
              "linematch_context": "    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n\n\n# @pytest.mark.api\n# def test_invalid_api_key():"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert result is True",
              "linematch_context": "    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n\n\n# @pytest.mark.api\n# def test_invalid_api_key():\n#     \"\"\"Test is_valid_api_key function with an invalid api key.\"\"\""
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "valid_api_key = get_valid_api_key()",
              "linematch_context": "\n\n@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "test_genscript = \"Write: 'Hello, World'\"",
              "linematch_context": "\n@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "file_path = \"test_checks.yml\"",
              "linematch_context": "@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "if not valid_api_key:",
              "linematch_context": "    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "file_path = Path(file_path)",
              "linematch_context": "\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "result = generate_yaml_config(file_path, valid_api_key, test_genscript)",
              "linematch_context": "        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "assert result is not None",
              "linematch_context": "    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "assert file_path.is_file()",
              "linematch_context": "\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()\n        assert \"Hello, World\" in content"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "with open(file_path, \"r\") as f:",
              "linematch_context": "    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()\n        assert \"Hello, World\" in content"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "from chasten import constants, filesystem\n\n\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n"
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "directory_str = str(Path(\"./tests/\"))",
              "linematch_context": "\n\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "directory = pathlib.Path(directory_str)",
              "linematch_context": "\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_directory(directory)",
              "linematch_context": "def test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert confirmation is True",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))"
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False"
            },
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "directory_str = str(Path(\"./testsNOT/\"))",
              "linematch_context": "\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n"
            },
            {
              "lineno": 25,
              "coloffset": 4,
              "linematch": "directory = pathlib.Path(directory_str)",
              "linematch_context": "\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n"
            },
            {
              "lineno": 26,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_directory(directory)",
              "linematch_context": "def test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "assert confirmation is False",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert filesystem.confirm_valid_directory(None) is False",
              "linematch_context": "    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))",
              "linematch_context": "\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "this_file = pathlib.Path(file_str)",
              "linematch_context": "\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_file(this_file)",
              "linematch_context": "def test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert confirmation is True",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))",
              "linematch_context": "\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "this_file_not = pathlib.Path(file_str)",
              "linematch_context": "\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_file(this_file_not)",
              "linematch_context": "def test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "assert confirmation is False",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function does not crash.\"\"\"",
              "linematch_context": "\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_directory(directory=directory)\n\n\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "filesystem.confirm_valid_directory(directory=directory)",
              "linematch_context": "@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_directory(directory=directory)\n\n\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:"
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function does not crash.\"\"\"",
              "linematch_context": "\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\""
            },
            {
              "lineno": 59,
              "coloffset": 4,
              "linematch": "filesystem.confirm_valid_file(file=file)",
              "linematch_context": "@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that creation of the textual directory tree works.\"\"\"",
              "linematch_context": "    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "tmp_dir = pathlib.Path(tmpdir)",
              "linematch_context": "\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"file1.txt\").touch()",
              "linematch_context": "    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)"
            },
            {
              "lineno": 68,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"subdir1\").mkdir()",
              "linematch_context": "    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"subdir2\").mkdir()",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"subdir2\" / \"file2.txt\").touch()",
              "linematch_context": "    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node"
            },
            {
              "lineno": 72,
              "coloffset": 4,
              "linematch": "tree = filesystem.create_directory_tree_visualization(tmp_dir)",
              "linematch_context": "    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files"
            },
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            },
            {
              "lineno": 76,
              "coloffset": 4,
              "linematch": "assert tree.label == f\":open_file_folder: {tmp_dir.name}\"",
              "linematch_context": "    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore",
              "linematch_context": "    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore",
              "linematch_context": "    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "assert set(dirs) == {",
              "linematch_context": "    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "assert set(files) == {",
              "linematch_context": "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }\n\n\n@given(directory=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 91,
              "coloffset": 4,
              "linematch": "\"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"",
              "linematch_context": "\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\""
            },
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "tree = filesystem.create_directory_tree_visualization(directory)",
              "linematch_context": "@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "def test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files"
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert tree.label == f\":open_file_folder: {directory.name}\"",
              "linematch_context": "    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore"
            },
            {
              "lineno": 97,
              "coloffset": 4,
              "linematch": "dirs = []",
              "linematch_context": "    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "files = []",
              "linematch_context": "    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore\n        else:"
            },
            {
              "lineno": 100,
              "coloffset": 4,
              "linematch": "for node in tree.children:",
              "linematch_context": "    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names"
            },
            {
              "lineno": 106,
              "coloffset": 4,
              "linematch": "assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())",
              "linematch_context": "            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):"
            },
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())",
              "linematch_context": "        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\""
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"",
              "linematch_context": "\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 116,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n"
            },
            {
              "lineno": 117,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n"
            },
            {
              "lineno": 118,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 119,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception("
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 127,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 131,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force"
            },
            {
              "lineno": 132,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):"
            },
            {
              "lineno": 133,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)"
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n"
            },
            {
              "lineno": 135,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n"
            },
            {
              "lineno": 137,
              "coloffset": 4,
              "linematch": "with pytest.raises(FileExistsError):",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_no_force("
            },
            {
              "lineno": 145,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_no_force(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 149,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force"
            },
            {
              "lineno": 150,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):"
            },
            {
              "lineno": 151,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)"
            },
            {
              "lineno": 152,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n"
            },
            {
              "lineno": 153,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n"
            },
            {
              "lineno": 155,
              "coloffset": 4,
              "linematch": "with pytest.raises(FileExistsError):",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_force("
            },
            {
              "lineno": 163,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_force(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 167,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force"
            },
            {
              "lineno": 168,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)"
            },
            {
              "lineno": 169,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n"
            },
            {
              "lineno": 170,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n"
            },
            {
              "lineno": 171,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):"
            },
            {
              "lineno": 173,
              "coloffset": 4,
              "linematch": "filesystem.create_configuration_directory(force=True)",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with"
            },
            {
              "lineno": 177,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"",
              "linematch_context": "    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)"
            },
            {
              "lineno": 180,
              "coloffset": 4,
              "linematch": "config = tmp_path / \"config\"",
              "linematch_context": "def test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 181,
              "coloffset": 4,
              "linematch": "config.mkdir()",
              "linematch_context": "    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default("
            },
            {
              "lineno": 182,
              "coloffset": 4,
              "linematch": "assert filesystem.detect_configuration(config) == str(config)",
              "linematch_context": "    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 189,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 193,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)"
            },
            {
              "lineno": 194,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)"
            },
            {
              "lineno": 195,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n"
            },
            {
              "lineno": 196,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n"
            },
            {
              "lineno": 197,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 198,
              "coloffset": 4,
              "linematch": "detected_directory = filesystem.detect_configuration(None)",
              "linematch_context": "    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):"
            },
            {
              "lineno": 199,
              "coloffset": 4,
              "linematch": "assert detected_directory == str(dir_path)",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\""
            },
            {
              "lineno": 204,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"",
              "linematch_context": "\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 208,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file"
            },
            {
              "lineno": 209,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore"
            },
            {
              "lineno": 210,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file"
            },
            {
              "lineno": 211,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content"
            },
            {
              "lineno": 212,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\""
            },
            {
              "lineno": 214,
              "coloffset": 4,
              "linematch": "filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text"
            },
            {
              "lineno": 217,
              "coloffset": 4,
              "linematch": "main_configuation_file = dir_path / \"config.yml\"",
              "linematch_context": "    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 218,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.exists()",
              "linematch_context": "    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS\n    )"
            },
            {
              "lineno": 220,
              "coloffset": 4,
              "linematch": "assert (",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS\n    )\n\n"
            },
            {
              "lineno": 228,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"",
              "linematch_context": "\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_checks_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 232,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file"
            },
            {
              "lineno": 233,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore"
            },
            {
              "lineno": 234,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file"
            },
            {
              "lineno": 235,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content"
            },
            {
              "lineno": 236,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\""
            },
            {
              "lineno": 238,
              "coloffset": 4,
              "linematch": "filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text"
            },
            {
              "lineno": 241,
              "coloffset": 4,
              "linematch": "main_configuation_file = dir_path / \"checks.yml\"",
              "linematch_context": "    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 242,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.exists()",
              "linematch_context": "    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"",
              "linematch_context": "    data_type=st.just(pyastgrepsearch.Match),\n)\n@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "filtered, _ = process.filter_matches(match_list, data_type)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert set(filtered) == set(",
              "linematch_context": "def test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n\n@given(match_list=st.lists(st.integers()))"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"",
              "linematch_context": "\n@given(match_list=st.lists(st.integers()))\n@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "data_type = pyastgrepsearch.Match",
              "linematch_context": "@given(match_list=st.lists(st.integers()))\n@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "filtered, _ = process.filter_matches(match_list, data_type)",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"",
              "linematch_context": "\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "filtered, _ = process.filter_matches(match_list, data_type)",
              "linematch_context": "@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 54,
              "coloffset": 4,
              "linematch": "if match_list == []:",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_validate.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"",
              "linematch_context": "from chasten.validate import JSON_SCHEMA_CONFIG, validate_configuration\n\n\ndef test_validate_config_valid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }\n    }"
            },
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "valid_config_correct_schema = {",
              "linematch_context": "\n\ndef test_validate_config_valid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(valid_config_correct_schema)",
              "linematch_context": "        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\""
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {"
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"",
              "linematch_context": "    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }\n    }"
            },
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "valid_config_correct_schema = {",
              "linematch_context": "\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(valid_config_correct_schema)",
              "linematch_context": "        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "assert not is_valid",
              "linematch_context": "            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given("
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "assert errors",
              "linematch_context": "        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "assert \"is not of type\" in errors",
              "linematch_context": "    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})\n)"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"",
              "linematch_context": "    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})\n)\n@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(config)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "def test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"",
              "linematch_context": "@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(config)",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "def test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"",
              "linematch_context": "}\n\n\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}",
              "linematch_context": "\n\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():"
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "assert min_count == 1",
              "linematch_context": "def test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\""
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "assert max_count == 10  # noqa",
              "linematch_context": "    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"",
              "linematch_context": "    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "check = {\"name\": \"test\", \"count\": {\"max\": 10}}",
              "linematch_context": "\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n"
            },
            {
              "lineno": 38,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert min_count is None",
              "linematch_context": "def test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert max_count == 10  # noqa",
              "linematch_context": "    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"",
              "linematch_context": "    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "check = {",
              "linematch_context": "\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },\n    }"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert min_count == 1",
              "linematch_context": "            \"min\": 1,\n        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\""
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "assert max_count is None",
              "linematch_context": "        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}"
            },
            {
              "lineno": 57,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"",
              "linematch_context": "    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n"
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "check = {\"name\": \"test\"}",
              "linematch_context": "\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n"
            },
            {
              "lineno": 59,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)  # type: ignore",
              "linematch_context": "\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():"
            },
            {
              "lineno": 60,
              "coloffset": 4,
              "linematch": "assert min_count is None",
              "linematch_context": "def test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\""
            },
            {
              "lineno": 61,
              "coloffset": 4,
              "linematch": "assert max_count is None",
              "linematch_context": "    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"",
              "linematch_context": "    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"description\": \"described test\",\n        \"count\": {\n            \"min\": 1,"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "check = {",
              "linematch_context": "\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"description\": \"described test\",\n        \"count\": {\n            \"min\": 1,\n        },"
            },
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "assert \"described test\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {"
            },
            {
              "lineno": 77,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"",
              "linematch_context": "    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "check = {",
              "linematch_context": "\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },\n    }"
            },
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "assert \"\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"\" == extract_description(check)\n\n\n@pytest.mark.parametrize(\n    \"bool_status,expected\",\n    ["
            },
            {
              "lineno": 95,
              "coloffset": 4,
              "linematch": "\"\"\"Confirms the output matches the expected message.\"\"\"",
              "linematch_context": "        (False, \":worried: Did the check pass? No\"),\n    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert make_checks_status_message(bool_status) == expected",
              "linematch_context": "    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):"
            },
            {
              "lineno": 102,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"",
              "linematch_context": "\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n"
            },
            {
              "lineno": 103,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))"
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 105,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"",
              "linematch_context": "@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n"
            },
            {
              "lineno": 113,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize("
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\","
            },
            {
              "lineno": 115,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the check of the match count works for simple examples.\"\"\"",
              "linematch_context": "        (3, None, 2, False),\n    ],\n)\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given("
            },
            {
              "lineno": 135,
              "coloffset": 4,
              "linematch": "result = check_match_count(count, min_value, max_value)",
              "linematch_context": "    ],\n)\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),"
            },
            {
              "lineno": 136,
              "coloffset": 4,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 146,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"",
              "linematch_context": "    st.integers(min_value=0, max_value=25),\n)\n@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            },
            {
              "lineno": 147,
              "coloffset": 4,
              "linematch": "confirmation = check_match_count(count, min, max)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            },
            {
              "lineno": 148,
              "coloffset": 4,
              "linematch": "if is_in_closed_interval(count, min, max):",
              "linematch_context": "@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_main.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"",
              "linematch_context": "    return os.getcwd()\n\n\ndef test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # create some temporary directories;\n    # note that there is no code inside of this directory\n    # and thus chasten does not actually have any\n    # Python source code that it can analyze\n    test_one = tmpdir.mkdir(\"test_one\")"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "    # create some temporary directories;\n    # note that there is no code inside of this directory\n    # and thus chasten does not actually have any\n    # Python source code that it can analyze\n    test_one = tmpdir.mkdir(\"test_one\")\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")"
            },
            {
              "lineno": 91,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "    # and thus chasten does not actually have any\n    # Python source code that it can analyze\n    test_one = tmpdir.mkdir(\"test_one\")\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "configuration_directory = test_one / Path(\".chasten\")",
              "linematch_context": "    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)"
            },
            {
              "lineno": 95,
              "coloffset": 4,
              "linematch": "configuration_directory_path = Path(configuration_directory)",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\""
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "configuration_directory_path.mkdir()",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()"
            },
            {
              "lineno": 97,
              "coloffset": 4,
              "linematch": "configuration_file = configuration_directory_path / \"config.yml\"",
              "linematch_context": "    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "configuration_file.touch()",
              "linematch_context": "    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)",
              "linematch_context": "    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke("
            },
            {
              "lineno": 100,
              "coloffset": 4,
              "linematch": "checks_file = configuration_directory_path / \"checks.yml\"",
              "linematch_context": "    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 101,
              "coloffset": 4,
              "linematch": "checks_file.touch()",
              "linematch_context": "    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,\n        ["
            },
            {
              "lineno": 102,
              "coloffset": 4,
              "linematch": "checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)",
              "linematch_context": "    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 116,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            configuration_directory,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 0\n\n\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command"
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"",
              "linematch_context": "    assert result.exit_code == 0\n\n\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")"
            },
            {
              "lineno": 122,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 125,
              "coloffset": 4,
              "linematch": "configuration_directory = cwd / Path(\".chasten\")",
              "linematch_context": "    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\","
            },
            {
              "lineno": 126,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "assert result.exit_code in [0, 1]",
              "linematch_context": "            configuration_directory,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code in [0, 1]\n\n\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 142,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"",
              "linematch_context": "    assert result.exit_code in [0, 1]\n\n\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")"
            },
            {
              "lineno": 144,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 147,
              "coloffset": 4,
              "linematch": "configuration_directory = cwd / Path(\".chasten\")",
              "linematch_context": "    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 149,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            test_one,"
            },
            {
              "lineno": 161,
              "coloffset": 4,
              "linematch": "assert result.exit_code != 0",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    # crashes because the command-line arguments are wrong\n    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\""
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "assert \"Missing argument\" in result.output",
              "linematch_context": "        ],\n    )\n    # crashes because the command-line arguments are wrong\n    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 166,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"",
              "linematch_context": "    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist"
            },
            {
              "lineno": 168,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command"
            },
            {
              "lineno": 169,
              "coloffset": 4,
              "linematch": "project_name = \"test\"",
              "linematch_context": "def test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 172,
              "coloffset": 4,
              "linematch": "wrong_config_dir = \"config\"",
              "linematch_context": "    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 174,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 186,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            wrong_config_dir,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\""
            },
            {
              "lineno": 187,
              "coloffset": 4,
              "linematch": "assert \"Cannot perform analysis due to configuration\" in result.output",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 191,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"",
              "linematch_context": "    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory"
            },
            {
              "lineno": 193,
              "coloffset": 4,
              "linematch": "_ = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\""
            },
            {
              "lineno": 194,
              "coloffset": 4,
              "linematch": "test_one_incorrect_name = \"test_oneFF\"",
              "linematch_context": "def test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command"
            },
            {
              "lineno": 195,
              "coloffset": 4,
              "linematch": "project_name = \"test\"",
              "linematch_context": "    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 198,
              "coloffset": 4,
              "linematch": "wrong_config_dir = \"config\"",
              "linematch_context": "    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 200,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 214,
              "coloffset": 4,
              "linematch": "assert result.exit_code != 0",
              "linematch_context": "        ],\n    )\n    # running the program with an invalid --search-path\n    # should not work and thus a zero exit code is wrong\n    assert result.exit_code != 0\n    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output"
            },
            {
              "lineno": 218,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 2  # noqa",
              "linematch_context": "    assert result.exit_code != 0\n    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\""
            },
            {
              "lineno": 219,
              "coloffset": 4,
              "linematch": "assert \"Usage:\" in result.output",
              "linematch_context": "    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 223,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"",
              "linematch_context": "    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist"
            },
            {
              "lineno": 225,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command"
            },
            {
              "lineno": 226,
              "coloffset": 4,
              "linematch": "project_name = \"test\"",
              "linematch_context": "def test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 229,
              "coloffset": 4,
              "linematch": "correct_config_dir = tmpdir.mkdir(\"config\")",
              "linematch_context": "    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 231,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 243,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            correct_config_dir,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\n# def test_cli_analyze_url_config(cwd):\n#     \"\"\"Confirm that using the command-line interface correctly handles a valid URL configuration.\"\"\""
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "assert \"Cannot perform analysis due to configuration\" in result.output",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\n# def test_cli_analyze_url_config(cwd):\n#     \"\"\"Confirm that using the command-line interface correctly handles a valid URL configuration.\"\"\"\n#     # use config files found in chasten-configuration remotely"
            },
            {
              "lineno": 357,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_create_config_when_does_not_exist(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    # call the configure command"
            },
            {
              "lineno": 361,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\","
            },
            {
              "lineno": 363,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\",\n            \"create\",\n            \"--verbose\","
            },
            {
              "lineno": 371,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"create\",\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 0\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_cannot_create_config_when_does_exist(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 378,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_cannot_create_config_when_does_exist(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")"
            },
            {
              "lineno": 382,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke("
            },
            {
              "lineno": 383,
              "coloffset": 4,
              "linematch": "config_directory = Path(tmp_path / \".chasten\")",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 384,
              "coloffset": 4,
              "linematch": "config_directory.mkdir()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        ["
            },
            {
              "lineno": 385,
              "coloffset": 4,
              "linematch": "assert config_directory.exists()",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\","
            },
            {
              "lineno": 387,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\",\n            \"create\",\n            \"--verbose\","
            },
            {
              "lineno": 395,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            \"create\",\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 402,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"",
              "linematch_context": "@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_fuzz_cli_analyze_single_directory(cwd, directory):\n    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke("
            },
            {
              "lineno": 403,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_fuzz_cli_analyze_single_directory(cwd, directory):\n    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 406,
              "coloffset": 4,
              "linematch": "configuration_directory = cwd / Path(\".chasten\")",
              "linematch_context": "    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,"
            },
            {
              "lineno": 407,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--config\","
            },
            {
              "lineno": 418,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--search-path\",\n            str(directory),\n        ],\n    )\n    assert result.exit_code == 0\n\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)"
            },
            {
              "lineno": 422,
              "coloffset": 4,
              "linematch": "\"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"",
              "linematch_context": "    assert result.exit_code == 0\n\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\""
            },
            {
              "lineno": 423,
              "coloffset": 4,
              "linematch": "tmp_dir = Path(tmpdir)",
              "linematch_context": "\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke("
            },
            {
              "lineno": 424,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 427,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\","
            },
            {
              "lineno": 428,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 441,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--markdown-storage\",\n            tmp_dir,\n        ],\n    )\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\""
            },
            {
              "lineno": 442,
              "coloffset": 4,
              "linematch": "assert \"\u2728 Results saved in:\" in result.output",
              "linematch_context": "            tmp_dir,\n        ],\n    )\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)"
            },
            {
              "lineno": 446,
              "coloffset": 4,
              "linematch": "\"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"",
              "linematch_context": "    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()"
            },
            {
              "lineno": 447,
              "coloffset": 4,
              "linematch": "tmp_dir = Path(tmpdir)",
              "linematch_context": "\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists"
            },
            {
              "lineno": 449,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"analysis.md\"",
              "linematch_context": "def test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\""
            },
            {
              "lineno": 451,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 453,
              "coloffset": 4,
              "linematch": "assert file.exists()",
              "linematch_context": "    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands"
            },
            {
              "lineno": 454,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke("
            },
            {
              "lineno": 457,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 459,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 473,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            tmp_dir,\n        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 1\n    assert (\n        \"File already exists: use --force to recreate markdown directory.\"\n        in result.output\n    )\n"
            },
            {
              "lineno": 474,
              "coloffset": 4,
              "linematch": "assert (",
              "linematch_context": "        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 1\n    assert (\n        \"File already exists: use --force to recreate markdown directory.\"\n        in result.output\n    )\n\n"
            },
            {
              "lineno": 481,
              "coloffset": 4,
              "linematch": "tmp_dir = Path(tmpdir)",
              "linematch_context": "    )\n\n\ndef test_analyze_store_results_file_exists_force(cwd, tmpdir):\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists"
            },
            {
              "lineno": 483,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"analysis.md\"",
              "linematch_context": "\ndef test_analyze_store_results_file_exists_force(cwd, tmpdir):\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\""
            },
            {
              "lineno": 485,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 487,
              "coloffset": 4,
              "linematch": "assert file.exists()",
              "linematch_context": "    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands"
            },
            {
              "lineno": 488,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke("
            },
            {
              "lineno": 491,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 493,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 508,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--force\",\n        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])"
            },
            {
              "lineno": 509,
              "coloffset": 4,
              "linematch": "assert \"\u2728 Results saved in:\" in result.output",
              "linematch_context": "        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 516,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_analyze_store_results_valid_path(directory, cwd):\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 519,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "def test_analyze_store_results_valid_path(directory, cwd):\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\","
            },
            {
              "lineno": 520,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 534,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_constants.py",
        "check": {
          "id": "LOF001",
          "name": "count-test-method-lines",
          "description": "Count the lines within test methods that start with 'test_'.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[starts-with(@name, \"test_\")]/body/*",
          "passed": false,
          "matches": [
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm default values of constants.\"\"\"",
              "linematch_context": "from chasten import constants\n\n\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert constants.filesystem.Current_Directory == \".\"",
              "linematch_context": "\n\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "assert constants.filesystem.Main_Configuration_File == \"config.yml\"",
              "linematch_context": "\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given("
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "assert constants.humanreadable.Yes == \"Yes\"",
              "linematch_context": "def test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given(\n    directory=strategies.text(),"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "assert constants.humanreadable.No == \"No\"",
              "linematch_context": "    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given(\n    directory=strategies.text(),\n    configfile=strategies.text(),"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"",
              "linematch_context": "    no=strategies.text(),\n)\n@pytest.mark.fuzz\ndef test_fuzz_init(directory, configfile, checksfile, extra, yes, no):  # noqa: PLR0913\n    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)"
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "fs = constants.Filesystem(",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_init(directory, configfile, checksfile, extra, yes, no):  # noqa: PLR0913\n    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert fs.Current_Directory == directory",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "hr = constants.Humanreadable(yes, no)",
              "linematch_context": "    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given("
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert hr.Yes == yes",
              "linematch_context": "        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given(\n    fs=strategies.builds(constants.Filesystem),"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "assert hr.No == no",
              "linematch_context": "    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given(\n    fs=strategies.builds(constants.Filesystem),\n    hr=strategies.builds(constants.Humanreadable),"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"",
              "linematch_context": "    hr=strategies.builds(constants.Humanreadable),\n)\n@pytest.mark.fuzz\ndef test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "with pytest.raises(FrozenInstanceError):",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):\n        hr.No = \"NO\""
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "with pytest.raises(FrozenInstanceError):",
              "linematch_context": "def test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):\n        hr.No = \"NO\"\n\n"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "with pytest.raises(FrozenInstanceError):",
              "linematch_context": "    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):\n        hr.No = \"NO\"\n\n\n@given(\n    dir1=strategies.text(),"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"",
              "linematch_context": "    extra=strategies.text(),\n)\n@pytest.mark.fuzz\ndef test_fuzz_distinct(dir1, dir2, filename, extra):\n    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 64,
              "coloffset": 4,
              "linematch": "fs1 = constants.Filesystem(",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_distinct(dir1, dir2, filename, extra):\n    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "fs2 = constants.Filesystem(",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "if dir1 != dir2:",
              "linematch_context": "    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"",
              "linematch_context": "\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "dir1 = directory",
              "linematch_context": "@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )"
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "dir2 = directory",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem("
            },
            {
              "lineno": 82,
              "coloffset": 4,
              "linematch": "assert dir1 == dir2",
              "linematch_context": "def test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "fs1 = constants.Filesystem(",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "fs2 = constants.Filesystem(",
              "linematch_context": "    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    assert fs1 == fs2"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    assert fs1 == fs2"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/mutmut_config.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 4,
              "coloffset": 4,
              "linematch": "arithmetic_operators = ['+', '-', '*', '/']",
              "linematch_context": "from mutmut import context\n\ndef pre_mutation(context):\n    arithmetic_operators = ['+', '-', '*', '/']\n    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    \n    if context.mutation_id.operator == \"delete\":"
            },
            {
              "lineno": 7,
              "coloffset": 4,
              "linematch": "print(f\"Mutating: {context.mutation_id}\")",
              "linematch_context": "def pre_mutation(context):\n    arithmetic_operators = ['+', '-', '*', '/']\n    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    \n    if context.mutation_id.operator == \"delete\":\n        # Allow statement deletion mutations\n        return\n    elif any(op in context.source for op in arithmetic_operators):"
            },
            {
              "lineno": 9,
              "coloffset": 4,
              "linematch": "if context.mutation_id.operator == \"delete\":",
              "linematch_context": "    \n    # Debugging: Print statement to ensure this function is executed\n    print(f\"Mutating: {context.mutation_id}\")\n    \n    if context.mutation_id.operator == \"delete\":\n        # Allow statement deletion mutations\n        return\n    elif any(op in context.source for op in arithmetic_operators):\n        # Allow arithmetic operator mutations\n        return"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "context.pre_mutation = pre_mutation",
              "linematch_context": "        # Skip all other mutations\n        context.skip = True\n\ndef configure(context):\n    context.pre_mutation = pre_mutation"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configApp.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "\"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"",
              "linematch_context": "\n\n# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"",
              "linematch_context": "\n# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert configApp.write_checks(CSV_CHECK_LIST) == expected_check",
              "linematch_context": "# Test to check if the 'write_checks' function correctly converts CSV data to a formatted string\ndef test_write_checks():\n    \"\"\"Test the write_checks function by converting CSV data to a formatted string.\"\"\"\n    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\"\n    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check\n\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\""
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "\"\"\"Test the write_checks function when list is empty\"\"\"",
              "linematch_context": "\n\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\"\n    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"",
              "linematch_context": "\n# Test to check the handling of an empty input list by the 'write_checks' function\ndef test_write_checks_empty_file():\n    \"\"\"Test the write_checks function when list is empty\"\"\"\n    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\"\n\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\""
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "\"\"\"Test the split_file function by parsing check data from a file.\"\"\"",
              "linematch_context": "\n\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST"
            },
            {
              "lineno": 48,
              "coloffset": 4,
              "linematch": "tmp_dir = pathlib.Path(tmpdir)",
              "linematch_context": "\n# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"check_test.txt\"",
              "linematch_context": "# Test to check if the 'split_file' function correctly parses a file with check data\ndef test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "def test_split_file(tmpdir):\n    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "file.write_text(CHECK_TEST_DEFAULT)",
              "linematch_context": "    \"\"\"Test the split_file function by parsing check data from a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given("
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert configApp.split_file(file) == CSV_CHECK_LIST",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    file.write_text(CHECK_TEST_DEFAULT)\n    assert configApp.split_file(file) == CSV_CHECK_LIST\n\n\n# Property-based test to check if the 'store_in_file' function correctly stores generated data in a file\n@given(\n    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            },
            {
              "lineno": 64,
              "coloffset": 4,
              "linematch": "\"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"",
              "linematch_context": ")\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "tmp_dir = pathlib.Path(tmpdir)",
              "linematch_context": "@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"check_test.txt\"",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])\ndef test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "def test_store_in_file(Pattern, Matches, Exact, tmpdir):\n    \"\"\"Tests if the store_in_file function correctly stores data in a file.\"\"\"\n    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "configApp.store_in_file(file, Pattern, Matches, Exact)",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")",
              "linematch_context": "    file = tmp_dir / \"check_test.txt\"\n    file.touch()\n    # Call the 'store_in_file' function with generated data and check if it's stored in the file\n    configApp.store_in_file(file, Pattern, Matches, Exact)\n    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_database.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"",
              "linematch_context": "from chasten import database\n\n\ndef test_create_chasten_view():\n    \"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"\n    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)"
            },
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "chasten_database_name: str = \".example_database\"",
              "linematch_context": "\ndef test_create_chasten_view():\n    \"\"\"Confirm that the function creating and viewing an example database does not crash\"\"\"\n    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)\n    # remove the example variable made\n    os.remove(\".example_database\")"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "database.create_chasten_view(chasten_database_name)",
              "linematch_context": "    # define the variable name for the example database\n    chasten_database_name: str = \".example_database\"\n    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)\n    # remove the example variable made\n    os.remove(\".example_database\")"
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "os.remove(\".example_database\")",
              "linematch_context": "    # create the database with example name\n    # run the view command with a set SQL query\n    database.create_chasten_view(chasten_database_name)\n    # remove the example variable made\n    os.remove(\".example_database\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_debug.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 9,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the enumeration values are correct.\"\"\"",
              "linematch_context": "from chasten.debug import DebugDestination, DebugLevel\n\n\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\""
            },
            {
              "lineno": 10,
              "coloffset": 4,
              "linematch": "assert DebugLevel.DEBUG == \"DEBUG\"",
              "linematch_context": "\n\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n"
            },
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "assert DebugLevel.INFO == \"INFO\"",
              "linematch_context": "\ndef test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n"
            },
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "assert DebugLevel.WARNING == \"WARNING\"",
              "linematch_context": "def test_debug_level_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():"
            },
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "assert DebugLevel.ERROR == \"ERROR\"",
              "linematch_context": "    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\""
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert DebugLevel.CRITICAL == \"CRITICAL\"",
              "linematch_context": "    assert DebugLevel.DEBUG == \"DEBUG\"\n    assert DebugLevel.INFO == \"INFO\"\n    assert DebugLevel.WARNING == \"WARNING\"\n    assert DebugLevel.ERROR == \"ERROR\"\n    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"",
              "linematch_context": "    assert DebugLevel.CRITICAL == \"CRITICAL\"\n\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)"
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.DEBUG, DebugLevel)",
              "linematch_context": "\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.INFO, DebugLevel)",
              "linematch_context": "\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.WARNING, DebugLevel)",
              "linematch_context": "def test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.ERROR, DebugLevel)",
              "linematch_context": "    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\""
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.CRITICAL, DebugLevel)",
              "linematch_context": "    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to list all of the possible values.\"\"\"",
              "linematch_context": "    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\""
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]",
              "linematch_context": "\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\""
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the enumeration values are correct.\"\"\"",
              "linematch_context": "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "assert DebugDestination.CONSOLE == \"CONSOLE\"",
              "linematch_context": "\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\""
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert DebugDestination.SYSLOG == \"SYSLOG\"",
              "linematch_context": "\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\"\n    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)"
            },
            {
              "lineno": 38,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"",
              "linematch_context": "    assert DebugDestination.SYSLOG == \"SYSLOG\"\n\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.CONSOLE, DebugDestination)",
              "linematch_context": "\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.SYSLOG, DebugDestination)",
              "linematch_context": "\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"",
              "linematch_context": "    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\""
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that invalid values raise a ValueError.\"\"\"",
              "linematch_context": "    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "with pytest.raises(ValueError):",
              "linematch_context": "\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\""
            },
            {
              "lineno": 55,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that invalid values raise a ValueError.\"\"\"",
              "linematch_context": "        DebugLevel(\"INVALID\")\n\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugDestination(\"INVALID\")"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "with pytest.raises(ValueError):",
              "linematch_context": "\n\ndef test_debug_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):\n        DebugDestination(\"INVALID\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configuration.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_create_use_config_dir(\n    applicationname: str, applicationauthor: str\n) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "user_config_dir_str = configuration.user_config_dir(",
              "linematch_context": "def test_fuzz_create_use_config_dir(\n    applicationname: str, applicationauthor: str\n) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert user_config_dir_str",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and produces directory with the application name.\"\"\"\n    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n\n\n@given(\n    debug_level=strategies.sampled_from("
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert applicationname in user_config_dir_str",
              "linematch_context": "    user_config_dir_str = configuration.user_config_dir(\n        applicationname, applicationauthor\n    )\n    assert user_config_dir_str\n    assert applicationname in user_config_dir_str\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"",
              "linematch_context": "    debug_dest=strategies.sampled_from([\"CONSOLE\", \"SYSLOG\"]),\n)\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "logger, created = configuration.configure_logging(debug_level, debug_dest)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert logger",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given("
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert created",
              "linematch_context": "def test_fuzz_configure_logging(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from("
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"",
              "linematch_context": "    debug_dest=strategies.sampled_from([\"CONSOLE-WRONG\", \"SYSLOG-WRONG\"]),\n)\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 48,
              "coloffset": 4,
              "linematch": "logger, created = configuration.configure_logging(debug_level, debug_dest)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "assert logger",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "assert not created",
              "linematch_context": "def test_fuzz_configure_logging_incorrect_inputs(debug_level, debug_dest):\n    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_util.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"",
              "linematch_context": "from chasten import constants, util\n\n\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert util.get_human_readable_boolean(answer=True) == \"Yes\"",
              "linematch_context": "\n\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "assert util.get_human_readable_boolean(answer=False) == \"No\"",
              "linematch_context": "\ndef test_human_readable_boolean() -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    assert util.get_human_readable_boolean(answer=True) == \"Yes\"\n    assert util.get_human_readable_boolean(answer=False) == \"No\"\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"",
              "linematch_context": "\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    util.get_human_readable_boolean(answer=answer)\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "util.get_human_readable_boolean(answer=answer)",
              "linematch_context": "@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the function does not crash.\"\"\"\n    util.get_human_readable_boolean(answer=answer)\n\n\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:"
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"",
              "linematch_context": "\n@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\""
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "str_answer = util.get_human_readable_boolean(answer=answer)",
              "linematch_context": "@given(answer=st.booleans())\n@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_human_readable_boolean_correct_string(answer: bool) -> None:\n    \"\"\"Use Hypothesis to confirm that the conversion to human-readable works.\"\"\"\n    str_answer = util.get_human_readable_boolean(answer=answer)\n    if answer:\n        assert str_answer == \"Yes\"\n    else:\n        assert str_answer == \"No\"\n\n"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"",
              "linematch_context": "\n@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "result = util.is_url(url=url)",
              "linematch_context": "@given(url=provisional.urls())\n@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "assert result is True",
              "linematch_context": "@pytest.mark.fuzz\ndef test_is_url_correct(url: str) -> None:\n    \"\"\"Use Hypothesis to confirm that URLs are correctly recognized/unrecognized.\"\"\"\n    result = util.is_url(url=url)\n    assert result is True\n\n\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "stats = util.total_amount_passed(check_status_list)",
              "linematch_context": "\n@given(check_status_list=st.lists(st.booleans()))\n@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier",
              "linematch_context": "@pytest.mark.fuzz\ndef test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n\nOpSystem = util.get_OS()\ndatasette_exec = constants.datasette.Datasette_Executable"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "assert stats[0] <= stats[1]",
              "linematch_context": "def test_total_amount_passed(check_status_list: list[bool]):\n    stats = util.total_amount_passed(check_status_list)\n\n    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier\n    assert stats[0] <= stats[1]\n\n\nOpSystem = util.get_OS()\ndatasette_exec = constants.datasette.Datasette_Executable\n"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_createchecks.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 10,
              "coloffset": 4,
              "linematch": "\"\"\"Retrive and return api key from env variable\"\"\"",
              "linematch_context": "from chasten.createchecks import generate_yaml_config, is_valid_api_key\n\n\ndef get_valid_api_key():\n    \"\"\"Retrive and return api key from env variable\"\"\"\n    return os.getenv(\"API_KEY\")\n\n\n@pytest.mark.api\ndef test_valid_api_key():"
            },
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "return os.getenv(\"API_KEY\")",
              "linematch_context": "\n\ndef get_valid_api_key():\n    \"\"\"Retrive and return api key from env variable\"\"\"\n    return os.getenv(\"API_KEY\")\n\n\n@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\""
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "\"\"\"Test is_valid_api_key function with a valid api key.\"\"\"",
              "linematch_context": "\n\n@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "valid_api_key = get_valid_api_key()",
              "linematch_context": "\n@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "if not valid_api_key:",
              "linematch_context": "@pytest.mark.api\ndef test_valid_api_key():\n    \"\"\"Test is_valid_api_key function with a valid api key.\"\"\"\n    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "result = is_valid_api_key(valid_api_key)",
              "linematch_context": "    valid_api_key = get_valid_api_key()\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n\n\n# @pytest.mark.api\n# def test_invalid_api_key():"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert result is True",
              "linematch_context": "    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    result = is_valid_api_key(valid_api_key)\n    assert result is True\n\n\n# @pytest.mark.api\n# def test_invalid_api_key():\n#     \"\"\"Test is_valid_api_key function with an invalid api key.\"\"\""
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "valid_api_key = get_valid_api_key()",
              "linematch_context": "\n\n@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "test_genscript = \"Write: 'Hello, World'\"",
              "linematch_context": "\n@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "file_path = \"test_checks.yml\"",
              "linematch_context": "@pytest.mark.api\ndef test_generate_yaml_config():\n    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "if not valid_api_key:",
              "linematch_context": "    valid_api_key = get_valid_api_key()\n    test_genscript = \"Write: 'Hello, World'\"\n    file_path = \"test_checks.yml\"\n\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "file_path = Path(file_path)",
              "linematch_context": "\n    if not valid_api_key:\n        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "result = generate_yaml_config(file_path, valid_api_key, test_genscript)",
              "linematch_context": "        pytest.skip(\"No valid API key found in the environment variables\")\n\n    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "assert result is not None",
              "linematch_context": "    file_path = Path(file_path)\n\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "assert file_path.is_file()",
              "linematch_context": "\n    result = generate_yaml_config(file_path, valid_api_key, test_genscript)\n\n    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()\n        assert \"Hello, World\" in content"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "with open(file_path, \"r\") as f:",
              "linematch_context": "    assert result is not None\n    assert file_path.is_file()\n\n    # Check the content of the generated file\n    with open(file_path, \"r\") as f:\n        content = f.read()\n        assert \"Hello, World\" in content"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "from chasten import constants, filesystem\n\n\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n"
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "directory_str = str(Path(\"./tests/\"))",
              "linematch_context": "\n\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "directory = pathlib.Path(directory_str)",
              "linematch_context": "\ndef test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_directory(directory)",
              "linematch_context": "def test_valid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert confirmation is True",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./tests/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))"
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "    assert confirmation is True\n\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False"
            },
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "directory_str = str(Path(\"./testsNOT/\"))",
              "linematch_context": "\n\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n"
            },
            {
              "lineno": 25,
              "coloffset": 4,
              "linematch": "directory = pathlib.Path(directory_str)",
              "linematch_context": "\ndef test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n"
            },
            {
              "lineno": 26,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_directory(directory)",
              "linematch_context": "def test_invalid_directory() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "assert confirmation is False",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert filesystem.confirm_valid_directory(None) is False",
              "linematch_context": "    directory_str = str(Path(\"./testsNOT/\"))\n    directory = pathlib.Path(directory_str)\n    confirmation = filesystem.confirm_valid_directory(directory)\n    assert confirmation is False\n    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "    assert filesystem.confirm_valid_directory(None) is False\n\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))",
              "linematch_context": "\n\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "this_file = pathlib.Path(file_str)",
              "linematch_context": "\ndef test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_file(this_file)",
              "linematch_context": "def test_valid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\""
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert confirmation is True",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))\n    this_file = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file)\n    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that a valid directory is found.\"\"\"",
              "linematch_context": "    assert confirmation is True\n\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))",
              "linematch_context": "\n\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "this_file_not = pathlib.Path(file_str)",
              "linematch_context": "\ndef test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "confirmation = filesystem.confirm_valid_file(this_file_not)",
              "linematch_context": "def test_invalid_file() -> None:\n    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "assert confirmation is False",
              "linematch_context": "    \"\"\"Confirm that a valid directory is found.\"\"\"\n    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert filesystem.confirm_valid_file(None) is False",
              "linematch_context": "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))\n    this_file_not = pathlib.Path(file_str)\n    confirmation = filesystem.confirm_valid_file(this_file_not)\n    assert confirmation is False\n    assert filesystem.confirm_valid_file(None) is False\n\n\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function does not crash.\"\"\"",
              "linematch_context": "\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_directory(directory=directory)\n\n\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "filesystem.confirm_valid_directory(directory=directory)",
              "linematch_context": "@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_directory_using_builds(directory: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_directory(directory=directory)\n\n\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:"
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function does not crash.\"\"\"",
              "linematch_context": "\n@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\""
            },
            {
              "lineno": 59,
              "coloffset": 4,
              "linematch": "filesystem.confirm_valid_file(file=file)",
              "linematch_context": "@given(file=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_confirm_valid_file_using_builds(file: pathlib.Path) -> None:\n    \"\"\"Confirm that the function does not crash.\"\"\"\n    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that creation of the textual directory tree works.\"\"\"",
              "linematch_context": "    filesystem.confirm_valid_file(file=file)\n\n\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "tmp_dir = pathlib.Path(tmpdir)",
              "linematch_context": "\ndef test_create_directory_tree(tmpdir):\n    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"file1.txt\").touch()",
              "linematch_context": "    \"\"\"Confirm that creation of the textual directory tree works.\"\"\"\n    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)"
            },
            {
              "lineno": 68,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"subdir1\").mkdir()",
              "linematch_context": "    # create a temporary directory\n    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"subdir2\").mkdir()",
              "linematch_context": "    tmp_dir = pathlib.Path(tmpdir)\n    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "(tmp_dir / \"subdir2\" / \"file2.txt\").touch()",
              "linematch_context": "    # create some files and directories\n    (tmp_dir / \"file1.txt\").touch()\n    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node"
            },
            {
              "lineno": 72,
              "coloffset": 4,
              "linematch": "tree = filesystem.create_directory_tree_visualization(tmp_dir)",
              "linematch_context": "    (tmp_dir / \"subdir1\").mkdir()\n    (tmp_dir / \"subdir2\").mkdir()\n    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files"
            },
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            },
            {
              "lineno": 76,
              "coloffset": 4,
              "linematch": "assert tree.label == f\":open_file_folder: {tmp_dir.name}\"",
              "linematch_context": "    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore",
              "linematch_context": "    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore",
              "linematch_context": "    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "assert set(dirs) == {",
              "linematch_context": "    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "assert set(files) == {",
              "linematch_context": "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }\n\n\n@given(directory=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 91,
              "coloffset": 4,
              "linematch": "\"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"",
              "linematch_context": "\n@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\""
            },
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "tree = filesystem.create_directory_tree_visualization(directory)",
              "linematch_context": "@given(directory=strategies.builds(pathlib.Path))\n@pytest.mark.fuzz\ndef test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "def test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files"
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert tree.label == f\":open_file_folder: {directory.name}\"",
              "linematch_context": "    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore"
            },
            {
              "lineno": 97,
              "coloffset": 4,
              "linematch": "dirs = []",
              "linematch_context": "    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "files = []",
              "linematch_context": "    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore\n        else:"
            },
            {
              "lineno": 100,
              "coloffset": 4,
              "linematch": "for node in tree.children:",
              "linematch_context": "    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files\n    for node in tree.children:\n        if \":open_file_folder:\" in node.label:  # type: ignore\n            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names"
            },
            {
              "lineno": 106,
              "coloffset": 4,
              "linematch": "assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())",
              "linematch_context": "            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):"
            },
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())",
              "linematch_context": "        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\""
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"",
              "linematch_context": "\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 116,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n"
            },
            {
              "lineno": 117,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n"
            },
            {
              "lineno": 118,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 119,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception("
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 127,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_throw_exception(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 131,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm not possible to create the user configuration directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force"
            },
            {
              "lineno": 132,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):"
            },
            {
              "lineno": 133,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)"
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n"
            },
            {
              "lineno": 135,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n"
            },
            {
              "lineno": 137,
              "coloffset": 4,
              "linematch": "with pytest.raises(FileExistsError):",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_no_force("
            },
            {
              "lineno": 145,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_no_force(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 149,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force"
            },
            {
              "lineno": 150,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):"
            },
            {
              "lineno": 151,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)"
            },
            {
              "lineno": 152,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n"
            },
            {
              "lineno": 153,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n"
            },
            {
              "lineno": 155,
              "coloffset": 4,
              "linematch": "with pytest.raises(FileExistsError):",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it fails if called again without force\n    with pytest.raises(FileExistsError):\n        filesystem.create_configuration_directory(force=False)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_force("
            },
            {
              "lineno": 163,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_already_exist_no_exception_when_force(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 167,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force"
            },
            {
              "lineno": 168,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)"
            },
            {
              "lineno": 169,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n"
            },
            {
              "lineno": 170,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n"
            },
            {
              "lineno": 171,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):"
            },
            {
              "lineno": 173,
              "coloffset": 4,
              "linematch": "filesystem.create_configuration_directory(force=True)",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # confirm that it does not fail if called again with force\n    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with"
            },
            {
              "lineno": 177,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"",
              "linematch_context": "    filesystem.create_configuration_directory(force=True)\n\n\ndef test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)"
            },
            {
              "lineno": 180,
              "coloffset": 4,
              "linematch": "config = tmp_path / \"config\"",
              "linematch_context": "def test_detect_configuration_with_input_config_directory(tmp_path):\n    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 181,
              "coloffset": 4,
              "linematch": "config.mkdir()",
              "linematch_context": "    \"\"\"Confirm that it is possible to detect the configuration directory when it exists.\"\"\"\n    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default("
            },
            {
              "lineno": 182,
              "coloffset": 4,
              "linematch": "assert filesystem.detect_configuration(config) == str(config)",
              "linematch_context": "    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 189,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 193,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that it is possible to detect the configuration directory when none provided.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)"
            },
            {
              "lineno": 194,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)"
            },
            {
              "lineno": 195,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n"
            },
            {
              "lineno": 196,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n"
            },
            {
              "lineno": 197,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")"
            },
            {
              "lineno": 198,
              "coloffset": 4,
              "linematch": "detected_directory = filesystem.detect_configuration(None)",
              "linematch_context": "    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):"
            },
            {
              "lineno": 199,
              "coloffset": 4,
              "linematch": "assert detected_directory == str(dir_path)",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\""
            },
            {
              "lineno": 204,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"",
              "linematch_context": "\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 208,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file"
            },
            {
              "lineno": 209,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore"
            },
            {
              "lineno": 210,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file"
            },
            {
              "lineno": 211,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content"
            },
            {
              "lineno": 212,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\""
            },
            {
              "lineno": 214,
              "coloffset": 4,
              "linematch": "filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text"
            },
            {
              "lineno": 217,
              "coloffset": 4,
              "linematch": "main_configuation_file = dir_path / \"config.yml\"",
              "linematch_context": "    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 218,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.exists()",
              "linematch_context": "    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Configuration_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS\n    )"
            },
            {
              "lineno": 220,
              "coloffset": 4,
              "linematch": "assert (",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"config.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert (\n        main_configuation_file.read_text()\n        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS\n    )\n\n"
            },
            {
              "lineno": 228,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"",
              "linematch_context": "\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_checks_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\""
            },
            {
              "lineno": 232,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that it is possible to create the checks configuration file if it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file"
            },
            {
              "lineno": 233,
              "coloffset": 4,
              "linematch": "dir_path = tmp_path / \".chasten\"",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore"
            },
            {
              "lineno": 234,
              "coloffset": 4,
              "linematch": "result = filesystem.create_configuration_directory()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file"
            },
            {
              "lineno": 235,
              "coloffset": 4,
              "linematch": "assert result == dir_path",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content"
            },
            {
              "lineno": 236,
              "coloffset": 4,
              "linematch": "assert dir_path.exists()",
              "linematch_context": "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    dir_path = tmp_path / \".chasten\"\n    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\""
            },
            {
              "lineno": 238,
              "coloffset": 4,
              "linematch": "filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text"
            },
            {
              "lineno": 241,
              "coloffset": 4,
              "linematch": "main_configuation_file = dir_path / \"checks.yml\"",
              "linematch_context": "    # create the main configuration file\n    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 242,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.exists()",
              "linematch_context": "    filesystem.create_configuration_file(config=None, config_file_name=constants.filesystem.Main_Checks_File)  # type: ignore\n    # create the path to the main configuration file\n    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS",
              "linematch_context": "    # and then assert that it exists and has correct content\n    main_configuation_file = dir_path / \"checks.yml\"\n    assert main_configuation_file.exists()\n    # confirm that the configuration file has correct text\n    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"",
              "linematch_context": "    data_type=st.just(pyastgrepsearch.Match),\n)\n@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "filtered, _ = process.filter_matches(match_list, data_type)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert set(filtered) == set(",
              "linematch_context": "def test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n\n@given(match_list=st.lists(st.integers()))"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"",
              "linematch_context": "\n@given(match_list=st.lists(st.integers()))\n@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "data_type = pyastgrepsearch.Match",
              "linematch_context": "@given(match_list=st.lists(st.integers()))\n@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "filtered, _ = process.filter_matches(match_list, data_type)",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "assert filtered == []",
              "linematch_context": "def test_filter_matches_no_matches(match_list):\n    \"\"\"Use Hypothesis to confirm that filtering does not select a Match when there are none.\"\"\"\n    data_type = pyastgrepsearch.Match\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert filtered == []\n\n\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"",
              "linematch_context": "\n@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "filtered, _ = process.filter_matches(match_list, data_type)",
              "linematch_context": "@given(match_list=st.lists(st.integers()), data_type=st.just(int))\n@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            },
            {
              "lineno": 54,
              "coloffset": 4,
              "linematch": "if match_list == []:",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches_only_int_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering works for integers.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    if match_list == []:\n        assert filtered == []\n    else:\n        assert filtered != []"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_validate.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"",
              "linematch_context": "from chasten.validate import JSON_SCHEMA_CONFIG, validate_configuration\n\n\ndef test_validate_config_valid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }\n    }"
            },
            {
              "lineno": 12,
              "coloffset": 4,
              "linematch": "valid_config_correct_schema = {",
              "linematch_context": "\n\ndef test_validate_config_valid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(valid_config_correct_schema)",
              "linematch_context": "        \"chasten\": {\n            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():"
            },
            {
              "lineno": 18,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "            \"checks-file\": [\"checks.yml\"],\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\""
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert is_valid\n    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {"
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"",
              "linematch_context": "    assert not errors\n\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }\n    }"
            },
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "valid_config_correct_schema = {",
              "linematch_context": "\n\ndef test_validate_config_invalid_realistic():\n    \"\"\"Confirm that validation with built-in schema works for a realistic valid example.\"\"\"\n    valid_config_correct_schema = {\n        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(valid_config_correct_schema)",
              "linematch_context": "        \"chasten\": {\n            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "assert not is_valid",
              "linematch_context": "            \"checks-file\": \"checks.yml\",\n        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given("
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "assert errors",
              "linematch_context": "        }\n    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "assert \"is not of type\" in errors",
              "linematch_context": "    }\n    is_valid, errors = validate_configuration(valid_config_correct_schema)\n    assert not is_valid\n    assert errors\n    assert \"is not of type\" in errors\n\n\n@given(\n    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})\n)"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"",
              "linematch_context": "    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})\n)\n@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(config)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "@pytest.mark.fuzz\ndef test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "def test_validate_empty_config(config):\n    \"\"\"Use Hypothesis to confirm that an empty configuration will validate.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors\n\n\n@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"",
              "linematch_context": "@given(from_schema(JSON_SCHEMA_CONFIG))\n@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "is_valid, errors = validate_configuration(config)",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.too_slow])\n@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert is_valid",
              "linematch_context": "@pytest.mark.fuzz\ndef test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "assert not errors",
              "linematch_context": "def test_integers(config):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible valid instances.\"\"\"\n    is_valid, errors = validate_configuration(config)\n    assert is_valid\n    assert not errors"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"",
              "linematch_context": "}\n\n\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}",
              "linematch_context": "\n\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "\ndef test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():"
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "assert min_count == 1",
              "linematch_context": "def test_extract_min_max():\n    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\""
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "assert max_count == 10  # noqa",
              "linematch_context": "    \"\"\"Confirm that it is possible to extract both values from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"",
              "linematch_context": "    assert max_count == 10  # noqa\n\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "check = {\"name\": \"test\", \"count\": {\"max\": 10}}",
              "linematch_context": "\n\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n"
            },
            {
              "lineno": 38,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "\ndef test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():"
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert min_count is None",
              "linematch_context": "def test_extract_max():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert max_count == 10  # noqa",
              "linematch_context": "    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\"name\": \"test\", \"count\": {\"max\": 10}}\n    min_count, max_count = extract_min_max(check)\n    assert min_count is None\n    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"",
              "linematch_context": "    assert max_count == 10  # noqa\n\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "check = {",
              "linematch_context": "\n\ndef test_extract_min():\n    \"\"\"Confirm that it is possible to extract one value from the count parmeter when it exists.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },\n    }"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "assert min_count == 1",
              "linematch_context": "            \"min\": 1,\n        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\""
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "assert max_count is None",
              "linematch_context": "        },\n    }\n    min_count, max_count = extract_min_max(check)\n    assert min_count == 1\n    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}"
            },
            {
              "lineno": 57,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"",
              "linematch_context": "    assert max_count is None\n\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n"
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "check = {\"name\": \"test\"}",
              "linematch_context": "\n\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n"
            },
            {
              "lineno": 59,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)  # type: ignore",
              "linematch_context": "\ndef test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():"
            },
            {
              "lineno": 60,
              "coloffset": 4,
              "linematch": "assert min_count is None",
              "linematch_context": "def test_extract_min_max_missing():\n    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\""
            },
            {
              "lineno": 61,
              "coloffset": 4,
              "linematch": "assert max_count is None",
              "linematch_context": "    \"\"\"Confirm that it is not possible to extract both values when they do not exist.\"\"\"\n    check = {\"name\": \"test\"}\n    min_count, max_count = extract_min_max(check)  # type: ignore\n    assert min_count is None\n    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"",
              "linematch_context": "    assert max_count is None\n\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"description\": \"described test\",\n        \"count\": {\n            \"min\": 1,"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "check = {",
              "linematch_context": "\n\ndef test_extract_description():\n    \"\"\"Confirm that if a description exists, it is properly retrieved.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"description\": \"described test\",\n        \"count\": {\n            \"min\": 1,\n        },"
            },
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "assert \"described test\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {"
            },
            {
              "lineno": 77,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"",
              "linematch_context": "    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "check = {",
              "linematch_context": "\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {\n        \"name\": \"test\",\n        \"count\": {\n            \"min\": 1,\n        },\n    }"
            },
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "assert \"\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"\" == extract_description(check)\n\n\n@pytest.mark.parametrize(\n    \"bool_status,expected\",\n    ["
            },
            {
              "lineno": 95,
              "coloffset": 4,
              "linematch": "\"\"\"Confirms the output matches the expected message.\"\"\"",
              "linematch_context": "        (False, \":worried: Did the check pass? No\"),\n    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert make_checks_status_message(bool_status) == expected",
              "linematch_context": "    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):"
            },
            {
              "lineno": 102,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"",
              "linematch_context": "\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n"
            },
            {
              "lineno": 103,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))"
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 105,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"",
              "linematch_context": "@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n"
            },
            {
              "lineno": 113,
              "coloffset": 4,
              "linematch": "min_count, max_count = extract_min_max(check)",
              "linematch_context": "@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize("
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\","
            },
            {
              "lineno": 115,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the check of the match count works for simple examples.\"\"\"",
              "linematch_context": "        (3, None, 2, False),\n    ],\n)\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given("
            },
            {
              "lineno": 135,
              "coloffset": 4,
              "linematch": "result = check_match_count(count, min_value, max_value)",
              "linematch_context": "    ],\n)\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),"
            },
            {
              "lineno": 136,
              "coloffset": 4,
              "linematch": "assert result == expected",
              "linematch_context": ")\ndef test_check_match_count_expected(count, min_value, max_value, expected):\n    \"\"\"Confirm that the check of the match count works for simple examples.\"\"\"\n    result = check_match_count(count, min_value, max_value)\n    assert result == expected\n\n\n@given(\n    st.integers(),\n    st.integers(min_value=0, max_value=25),"
            },
            {
              "lineno": 146,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"",
              "linematch_context": "    st.integers(min_value=0, max_value=25),\n)\n@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            },
            {
              "lineno": 147,
              "coloffset": 4,
              "linematch": "confirmation = check_match_count(count, min, max)",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            },
            {
              "lineno": 148,
              "coloffset": 4,
              "linematch": "if is_in_closed_interval(count, min, max):",
              "linematch_context": "@pytest.mark.fuzz\ndef test_check_match_count(count, min, max):\n    \"\"\"Use Hypothesis to confirm that the count check works correctly.\"\"\"\n    confirmation = check_match_count(count, min, max)\n    if is_in_closed_interval(count, min, max):\n        assert confirmation"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_main.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "\"\"\"Define a test fixture for the current working directory.\"\"\"",
              "linematch_context": "\n\n@pytest.fixture\ndef cwd():\n    \"\"\"Define a test fixture for the current working directory.\"\"\"\n    return os.getcwd()\n\n\ndef test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\""
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "return os.getcwd()",
              "linematch_context": "\n@pytest.fixture\ndef cwd():\n    \"\"\"Define a test fixture for the current working directory.\"\"\"\n    return os.getcwd()\n\n\ndef test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # create some temporary directories;"
            },
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"",
              "linematch_context": "    return os.getcwd()\n\n\ndef test_cli_analyze_correct_arguments_nothing_to_analyze_not_looking(tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # create some temporary directories;\n    # note that there is no code inside of this directory\n    # and thus chasten does not actually have any\n    # Python source code that it can analyze\n    test_one = tmpdir.mkdir(\"test_one\")"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "    # create some temporary directories;\n    # note that there is no code inside of this directory\n    # and thus chasten does not actually have any\n    # Python source code that it can analyze\n    test_one = tmpdir.mkdir(\"test_one\")\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")"
            },
            {
              "lineno": 91,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "    # and thus chasten does not actually have any\n    # Python source code that it can analyze\n    test_one = tmpdir.mkdir(\"test_one\")\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "configuration_directory = test_one / Path(\".chasten\")",
              "linematch_context": "    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)"
            },
            {
              "lineno": 95,
              "coloffset": 4,
              "linematch": "configuration_directory_path = Path(configuration_directory)",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\""
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "configuration_directory_path.mkdir()",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()"
            },
            {
              "lineno": 97,
              "coloffset": 4,
              "linematch": "configuration_file = configuration_directory_path / \"config.yml\"",
              "linematch_context": "    # .chasten directory that supports testing\n    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "configuration_file.touch()",
              "linematch_context": "    configuration_directory = test_one / Path(\".chasten\")\n    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)",
              "linematch_context": "    configuration_directory_path = Path(configuration_directory)\n    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke("
            },
            {
              "lineno": 100,
              "coloffset": 4,
              "linematch": "checks_file = configuration_directory_path / \"checks.yml\"",
              "linematch_context": "    configuration_directory_path.mkdir()\n    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 101,
              "coloffset": 4,
              "linematch": "checks_file.touch()",
              "linematch_context": "    configuration_file = configuration_directory_path / \"config.yml\"\n    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,\n        ["
            },
            {
              "lineno": 102,
              "coloffset": 4,
              "linematch": "checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)",
              "linematch_context": "    configuration_file.touch()\n    configuration_file.write_text(CONFIGURATION_FILE_DEFAULT_CONTENTS)\n    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    checks_file = configuration_directory_path / \"checks.yml\"\n    checks_file.touch()\n    checks_file.write_text(CHECKS_FILE_DEFAULT_CONTENTS)\n    # filesystem.create_configuration_directory(configuration_directory_path, force=True)\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 116,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            configuration_directory,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 0\n\n\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command"
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"",
              "linematch_context": "    assert result.exit_code == 0\n\n\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")"
            },
            {
              "lineno": 122,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "\ndef test_cli_analyze_correct_arguments_analyze_chasten_codebase(cwd):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command with correct arguments.\"\"\"\n    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 125,
              "coloffset": 4,
              "linematch": "configuration_directory = cwd / Path(\".chasten\")",
              "linematch_context": "    # call the analyze command\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\","
            },
            {
              "lineno": 126,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "assert result.exit_code in [0, 1]",
              "linematch_context": "            configuration_directory,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code in [0, 1]\n\n\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 142,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"",
              "linematch_context": "    assert result.exit_code in [0, 1]\n\n\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")"
            },
            {
              "lineno": 144,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_no_project(cwd, tmpdir):\n    \"\"\"Confirm that using the command-line interface does not crash: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 147,
              "coloffset": 4,
              "linematch": "configuration_directory = cwd / Path(\".chasten\")",
              "linematch_context": "    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 149,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            test_one,"
            },
            {
              "lineno": 161,
              "coloffset": 4,
              "linematch": "assert result.exit_code != 0",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    # crashes because the command-line arguments are wrong\n    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\""
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "assert \"Missing argument\" in result.output",
              "linematch_context": "        ],\n    )\n    # crashes because the command-line arguments are wrong\n    assert result.exit_code != 0\n    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 166,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"",
              "linematch_context": "    assert \"Missing argument\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist"
            },
            {
              "lineno": 168,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command"
            },
            {
              "lineno": 169,
              "coloffset": 4,
              "linematch": "project_name = \"test\"",
              "linematch_context": "def test_cli_analyze_incorrect_arguments_wrong_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 172,
              "coloffset": 4,
              "linematch": "wrong_config_dir = \"config\"",
              "linematch_context": "    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 174,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 186,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            wrong_config_dir,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\""
            },
            {
              "lineno": 187,
              "coloffset": 4,
              "linematch": "assert \"Cannot perform analysis due to configuration\" in result.output",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 191,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"",
              "linematch_context": "    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory"
            },
            {
              "lineno": 193,
              "coloffset": 4,
              "linematch": "_ = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\""
            },
            {
              "lineno": 194,
              "coloffset": 4,
              "linematch": "test_one_incorrect_name = \"test_oneFF\"",
              "linematch_context": "def test_cli_analyze_incorrect_arguments_wrong_source_directory(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command"
            },
            {
              "lineno": 195,
              "coloffset": 4,
              "linematch": "project_name = \"test\"",
              "linematch_context": "    \"\"\"Confirm that using the command-line interface does return non-zero: analyze command incorrect arguments.\"\"\"\n    # create some temporary directories\n    _ = tmpdir.mkdir(\"test_one\")\n    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 198,
              "coloffset": 4,
              "linematch": "wrong_config_dir = \"config\"",
              "linematch_context": "    test_one_incorrect_name = \"test_oneFF\"\n    project_name = \"test\"\n    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 200,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a configuration directory\n    # that does not currently exist\n    wrong_config_dir = \"config\"\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 214,
              "coloffset": 4,
              "linematch": "assert result.exit_code != 0",
              "linematch_context": "        ],\n    )\n    # running the program with an invalid --search-path\n    # should not work and thus a zero exit code is wrong\n    assert result.exit_code != 0\n    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output"
            },
            {
              "lineno": 218,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 2  # noqa",
              "linematch_context": "    assert result.exit_code != 0\n    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\""
            },
            {
              "lineno": 219,
              "coloffset": 4,
              "linematch": "assert \"Usage:\" in result.output",
              "linematch_context": "    # note the error code of 2 indicates that it was\n    # an error arising from the fact that typer could\n    # not validate that test_oneFF is a existing directory\n    assert result.exit_code == 2  # noqa\n    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories"
            },
            {
              "lineno": 223,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"",
              "linematch_context": "    assert \"Usage:\" in result.output\n\n\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist"
            },
            {
              "lineno": 225,
              "coloffset": 4,
              "linematch": "test_one = tmpdir.mkdir(\"test_one\")",
              "linematch_context": "\ndef test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command"
            },
            {
              "lineno": 226,
              "coloffset": 4,
              "linematch": "project_name = \"test\"",
              "linematch_context": "def test_cli_analyze_incorrect_arguments_correct_config(tmpdir):\n    \"\"\"Confirm that using the command-line interface does return non-zero due to no config files: analyze command correct arguments.\"\"\"\n    # create some temporary directories\n    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command\n    result = runner.invoke("
            },
            {
              "lineno": 229,
              "coloffset": 4,
              "linematch": "correct_config_dir = tmpdir.mkdir(\"config\")",
              "linematch_context": "    test_one = tmpdir.mkdir(\"test_one\")\n    project_name = \"test\"\n    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 231,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a configuration directory\n    # that does currently exist\n    correct_config_dir = tmpdir.mkdir(\"config\")\n    # call the analyze command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--search-path\","
            },
            {
              "lineno": 243,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            correct_config_dir,\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\n# def test_cli_analyze_url_config(cwd):\n#     \"\"\"Confirm that using the command-line interface correctly handles a valid URL configuration.\"\"\""
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "assert \"Cannot perform analysis due to configuration\" in result.output",
              "linematch_context": "            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n    assert \"Cannot perform analysis due to configuration\" in result.output\n\n\n# def test_cli_analyze_url_config(cwd):\n#     \"\"\"Confirm that using the command-line interface correctly handles a valid URL configuration.\"\"\"\n#     # use config files found in chasten-configuration remotely"
            },
            {
              "lineno": 357,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_create_config_when_does_not_exist(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    # call the configure command"
            },
            {
              "lineno": 361,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that using the command-line interface does create .config directory when it does not exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\","
            },
            {
              "lineno": 363,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\",\n            \"create\",\n            \"--verbose\","
            },
            {
              "lineno": 371,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"create\",\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 0\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_cannot_create_config_when_does_exist(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 378,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"",
              "linematch_context": "@patch(\"chasten.configuration.user_config_dir\")\ndef test_cli_configure_cannot_create_config_when_does_exist(\n    mock_user_config_dir, tmp_path\n):\n    \"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")"
            },
            {
              "lineno": 382,
              "coloffset": 4,
              "linematch": "mock_user_config_dir.return_value = str(tmp_path / \".chasten\")",
              "linematch_context": "    \"\"\"Confirm that using the command-line interface does create .config directory when it does exist.\"\"\"\n    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke("
            },
            {
              "lineno": 383,
              "coloffset": 4,
              "linematch": "config_directory = Path(tmp_path / \".chasten\")",
              "linematch_context": "    # monkeypatch the platformdirs user_config_dir to always return\n    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 384,
              "coloffset": 4,
              "linematch": "config_directory.mkdir()",
              "linematch_context": "    # the tmpdir test fixture that is controlled by Pytest; the\n    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        ["
            },
            {
              "lineno": 385,
              "coloffset": 4,
              "linematch": "assert config_directory.exists()",
              "linematch_context": "    # directory inside of that will be \".chasten\" by default\n    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")\n    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\","
            },
            {
              "lineno": 387,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    config_directory = Path(tmp_path / \".chasten\")\n    config_directory.mkdir()\n    assert config_directory.exists()\n    # call the configure command\n    result = runner.invoke(\n        main.cli,\n        [\n            \"configure\",\n            \"create\",\n            \"--verbose\","
            },
            {
              "lineno": 395,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            \"create\",\n            \"--verbose\",\n        ],\n    )\n    assert result.exit_code == 1\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 402,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"",
              "linematch_context": "@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_fuzz_cli_analyze_single_directory(cwd, directory):\n    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke("
            },
            {
              "lineno": 403,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_fuzz_cli_analyze_single_directory(cwd, directory):\n    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 406,
              "coloffset": 4,
              "linematch": "configuration_directory = cwd / Path(\".chasten\")",
              "linematch_context": "    \"\"\"Confirm that the function does not crash when called through the command-line interface.\"\"\"\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,"
            },
            {
              "lineno": 407,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = cwd / Path(\".chasten\")\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            project_name,\n            \"--config\","
            },
            {
              "lineno": 418,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--search-path\",\n            str(directory),\n        ],\n    )\n    assert result.exit_code == 0\n\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)"
            },
            {
              "lineno": 422,
              "coloffset": 4,
              "linematch": "\"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"",
              "linematch_context": "    assert result.exit_code == 0\n\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\""
            },
            {
              "lineno": 423,
              "coloffset": 4,
              "linematch": "tmp_dir = Path(tmpdir)",
              "linematch_context": "\n\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke("
            },
            {
              "lineno": 424,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "\ndef test_analyze_store_results_file_does_not_exist(cwd, tmpdir):\n    \"\"\"Makes sure analyze doesn't crash when using markdown storage.\"\"\"\n    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 427,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "    tmp_dir = Path(tmpdir)\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\","
            },
            {
              "lineno": 428,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 441,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--markdown-storage\",\n            tmp_dir,\n        ],\n    )\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\""
            },
            {
              "lineno": 442,
              "coloffset": 4,
              "linematch": "assert \"\u2728 Results saved in:\" in result.output",
              "linematch_context": "            tmp_dir,\n        ],\n    )\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)"
            },
            {
              "lineno": 446,
              "coloffset": 4,
              "linematch": "\"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"",
              "linematch_context": "    assert \"\u2728 Results saved in:\" in result.output\n\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()"
            },
            {
              "lineno": 447,
              "coloffset": 4,
              "linematch": "tmp_dir = Path(tmpdir)",
              "linematch_context": "\n\ndef test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists"
            },
            {
              "lineno": 449,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"analysis.md\"",
              "linematch_context": "def test_analyze_store_results_file_exists_no_force(cwd, tmpdir):\n    \"\"\"Make sure Analyze acts accordingly when file exists and their is no force\"\"\"\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\""
            },
            {
              "lineno": 451,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 453,
              "coloffset": 4,
              "linematch": "assert file.exists()",
              "linematch_context": "    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands"
            },
            {
              "lineno": 454,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke("
            },
            {
              "lineno": 457,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 459,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 473,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 1",
              "linematch_context": "            tmp_dir,\n        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 1\n    assert (\n        \"File already exists: use --force to recreate markdown directory.\"\n        in result.output\n    )\n"
            },
            {
              "lineno": 474,
              "coloffset": 4,
              "linematch": "assert (",
              "linematch_context": "        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 1\n    assert (\n        \"File already exists: use --force to recreate markdown directory.\"\n        in result.output\n    )\n\n"
            },
            {
              "lineno": 481,
              "coloffset": 4,
              "linematch": "tmp_dir = Path(tmpdir)",
              "linematch_context": "    )\n\n\ndef test_analyze_store_results_file_exists_force(cwd, tmpdir):\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists"
            },
            {
              "lineno": 483,
              "coloffset": 4,
              "linematch": "file = tmp_dir / \"analysis.md\"",
              "linematch_context": "\ndef test_analyze_store_results_file_exists_force(cwd, tmpdir):\n    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\""
            },
            {
              "lineno": 485,
              "coloffset": 4,
              "linematch": "file.touch()",
              "linematch_context": "    tmp_dir = Path(tmpdir)\n    # creates a temporary directory to store markdown file\n    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing"
            },
            {
              "lineno": 487,
              "coloffset": 4,
              "linematch": "assert file.exists()",
              "linematch_context": "    file = tmp_dir / \"analysis.md\"\n    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands"
            },
            {
              "lineno": 488,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "    # creates file if does not exist\n    file.touch()\n    # makes sure the file exists\n    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke("
            },
            {
              "lineno": 491,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "    assert file.exists()\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\","
            },
            {
              "lineno": 493,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    # runs the CLI with the specified commands\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 508,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            \"--force\",\n        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])"
            },
            {
              "lineno": 509,
              "coloffset": 4,
              "linematch": "assert \"\u2728 Results saved in:\" in result.output",
              "linematch_context": "        ],\n    )\n    # assert that the code crashes and that the proper message is displayed\n    assert result.exit_code == 0\n    assert \"\u2728 Results saved in:\" in result.output\n\n\n@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz"
            },
            {
              "lineno": 516,
              "coloffset": 4,
              "linematch": "project_name = \"testing\"",
              "linematch_context": "@given(directory=strategies.builds(Path))\n@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])\n@pytest.mark.fuzz\ndef test_analyze_store_results_valid_path(directory, cwd):\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,"
            },
            {
              "lineno": 519,
              "coloffset": 4,
              "linematch": "configuration_directory = str(cwd) + \"/.chasten\"",
              "linematch_context": "def test_analyze_store_results_valid_path(directory, cwd):\n    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\","
            },
            {
              "lineno": 520,
              "coloffset": 4,
              "linematch": "result = runner.invoke(",
              "linematch_context": "    project_name = \"testing\"\n    # create a reference to the internal\n    # .chasten directory that supports testing\n    configuration_directory = str(cwd) + \"/.chasten\"\n    result = runner.invoke(\n        main.cli,\n        [\n            \"analyze\",\n            \"--search-path\",\n            cwd,"
            },
            {
              "lineno": 534,
              "coloffset": 4,
              "linematch": "assert result.exit_code == 0",
              "linematch_context": "            directory,\n            \"--force\",\n        ],\n    )\n    assert result.exit_code == 0"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_constants.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 13,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm default values of constants.\"\"\"",
              "linematch_context": "from chasten import constants\n\n\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "assert constants.filesystem.Current_Directory == \".\"",
              "linematch_context": "\n\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "assert constants.filesystem.Main_Configuration_File == \"config.yml\"",
              "linematch_context": "\ndef test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given("
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "assert constants.humanreadable.Yes == \"Yes\"",
              "linematch_context": "def test_filesystem_constants():\n    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given(\n    directory=strategies.text(),"
            },
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "assert constants.humanreadable.No == \"No\"",
              "linematch_context": "    \"\"\"Confirm default values of constants.\"\"\"\n    assert constants.filesystem.Current_Directory == \".\"\n    assert constants.filesystem.Main_Configuration_File == \"config.yml\"\n    assert constants.humanreadable.Yes == \"Yes\"\n    assert constants.humanreadable.No == \"No\"\n\n\n@given(\n    directory=strategies.text(),\n    configfile=strategies.text(),"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"",
              "linematch_context": "    no=strategies.text(),\n)\n@pytest.mark.fuzz\ndef test_fuzz_init(directory, configfile, checksfile, extra, yes, no):  # noqa: PLR0913\n    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)"
            },
            {
              "lineno": 31,
              "coloffset": 4,
              "linematch": "fs = constants.Filesystem(",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_init(directory, configfile, checksfile, extra, yes, no):  # noqa: PLR0913\n    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes"
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert fs.Current_Directory == directory",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that initial value is set correctly.\"\"\"\n    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "hr = constants.Humanreadable(yes, no)",
              "linematch_context": "    fs = constants.Filesystem(\n        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given("
            },
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert hr.Yes == yes",
              "linematch_context": "        directory, configfile, checksfile, extra, extra, extra, extra, extra, extra\n    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given(\n    fs=strategies.builds(constants.Filesystem),"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "assert hr.No == no",
              "linematch_context": "    )\n    assert fs.Current_Directory == directory\n    hr = constants.Humanreadable(yes, no)\n    assert hr.Yes == yes\n    assert hr.No == no\n\n\n@given(\n    fs=strategies.builds(constants.Filesystem),\n    hr=strategies.builds(constants.Humanreadable),"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"",
              "linematch_context": "    hr=strategies.builds(constants.Humanreadable),\n)\n@pytest.mark.fuzz\ndef test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):"
            },
            {
              "lineno": 47,
              "coloffset": 4,
              "linematch": "with pytest.raises(FrozenInstanceError):",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):\n        hr.No = \"NO\""
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "with pytest.raises(FrozenInstanceError):",
              "linematch_context": "def test_fuzz_immutable(fs, hr):\n    \"\"\"Use Hypothesis to confirm that attribute's value cannot be re-assigned.\"\"\"\n    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):\n        hr.No = \"NO\"\n\n"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "with pytest.raises(FrozenInstanceError):",
              "linematch_context": "    with pytest.raises(FrozenInstanceError):\n        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))\n    with pytest.raises(FrozenInstanceError):\n        hr.Yes = \"YES\"\n    with pytest.raises(FrozenInstanceError):\n        hr.No = \"NO\"\n\n\n@given(\n    dir1=strategies.text(),"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"",
              "linematch_context": "    extra=strategies.text(),\n)\n@pytest.mark.fuzz\ndef test_fuzz_distinct(dir1, dir2, filename, extra):\n    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 64,
              "coloffset": 4,
              "linematch": "fs1 = constants.Filesystem(",
              "linematch_context": ")\n@pytest.mark.fuzz\ndef test_fuzz_distinct(dir1, dir2, filename, extra):\n    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "fs2 = constants.Filesystem(",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm equality when the inputs names are the same.\"\"\"\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "if dir1 != dir2:",
              "linematch_context": "    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    if dir1 != dir2:\n        assert fs1 != fs2\n    else:\n        assert fs1 == fs2\n\n"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "\"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"",
              "linematch_context": "\n@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "dir1 = directory",
              "linematch_context": "@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())\n@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )"
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "dir2 = directory",
              "linematch_context": "@pytest.mark.fuzz\ndef test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem("
            },
            {
              "lineno": 82,
              "coloffset": 4,
              "linematch": "assert dir1 == dir2",
              "linematch_context": "def test_fuzz_dataclass_equality(directory, filename, extra):\n    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "fs1 = constants.Filesystem(",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the same directory makes the same constant.\"\"\"\n    dir1 = directory\n    dir2 = directory\n    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "fs2 = constants.Filesystem(",
              "linematch_context": "    assert dir1 == dir2\n    fs1 = constants.Filesystem(\n        dir1, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    assert fs1 == fs2"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "assert fs1 == fs2",
              "linematch_context": "    )\n    fs2 = constants.Filesystem(\n        dir2, filename, filename, extra, extra, extra, extra, extra, extra\n    )\n    assert fs1 == fs2"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "\"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"",
              "linematch_context": "from chasten import constants, filesystem, output, util, validate\n\n\ndef configure_tracebacks() -> None:\n    \"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"\n    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:\n    \"\"\"Return the user's configuration directory using platformdirs.\"\"\""
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "install()",
              "linematch_context": "\n\ndef configure_tracebacks() -> None:\n    \"\"\"Configure stack tracebacks arising from a crash to use rich.\"\"\"\n    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:\n    \"\"\"Return the user's configuration directory using platformdirs.\"\"\"\n    # access the directory and then return it based on the"
            },
            {
              "lineno": 26,
              "coloffset": 4,
              "linematch": "\"\"\"Return the user's configuration directory using platformdirs.\"\"\"",
              "linematch_context": "    install()\n\n\ndef user_config_dir(application_name: str, application_author: str) -> str:\n    \"\"\"Return the user's configuration directory using platformdirs.\"\"\"\n    # access the directory and then return it based on the\n    # provided name of the application and the application's author\n    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str\n"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_str = None",
              "linematch_context": "def user_config_dir(application_name: str, application_author: str) -> str:\n    \"\"\"Return the user's configuration directory using platformdirs.\"\"\"\n    # access the directory and then return it based on the\n    # provided name of the application and the application's author\n    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str\n\n\ndef configure_logging(\n    debug_level: str = constants.logging.Default_Logging_Level,"
            },
            {
              "lineno": 30,
              "coloffset": 4,
              "linematch": "return chasten_user_config_dir_str",
              "linematch_context": "    \"\"\"Return the user's configuration directory using platformdirs.\"\"\"\n    # access the directory and then return it based on the\n    # provided name of the application and the application's author\n    chasten_user_config_dir_str = None\n    return chasten_user_config_dir_str\n\n\ndef configure_logging(\n    debug_level: str = constants.logging.Default_Logging_Level,\n    debug_dest: str = constants.logging.Default_Logging_Destination,"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "\"\"\"Configure standard Python logging package.\"\"\"",
              "linematch_context": "def configure_logging(\n    debug_level: str = constants.logging.Default_Logging_Level,\n    debug_dest: str = constants.logging.Default_Logging_Destination,\n) -> Tuple[logging.Logger, bool]:\n    \"\"\"Configure standard Python logging package.\"\"\"\n    # use the specified logger with the specified destination\n    # by dynamically constructing the function to call and then\n    # invoking it with the provided debug_dest parameter\n    debug_dest = debug_dest.lower()\n    function_name = constants.logger.Function_Prefix + debug_dest"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "debug_dest = debug_dest.lower()",
              "linematch_context": "    \"\"\"Configure standard Python logging package.\"\"\"\n    # use the specified logger with the specified destination\n    # by dynamically constructing the function to call and then\n    # invoking it with the provided debug_dest parameter\n    debug_dest = debug_dest.lower()\n    function_name = constants.logger.Function_Prefix + debug_dest\n    configure_module = sys.modules[__name__]\n    # it was possible to create the requested logger, so return it\n    try:\n        return (getattr(configure_module, function_name)(debug_level), True)"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "function_name = constants.logger.Function_Prefix + debug_dest",
              "linematch_context": "    # use the specified logger with the specified destination\n    # by dynamically constructing the function to call and then\n    # invoking it with the provided debug_dest parameter\n    debug_dest = debug_dest.lower()\n    function_name = constants.logger.Function_Prefix + debug_dest\n    configure_module = sys.modules[__name__]\n    # it was possible to create the requested logger, so return it\n    try:\n        return (getattr(configure_module, function_name)(debug_level), True)\n    # it was not possible to create the requested logger, so"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "configure_module = sys.modules[__name__]",
              "linematch_context": "    # by dynamically constructing the function to call and then\n    # invoking it with the provided debug_dest parameter\n    debug_dest = debug_dest.lower()\n    function_name = constants.logger.Function_Prefix + debug_dest\n    configure_module = sys.modules[__name__]\n    # it was possible to create the requested logger, so return it\n    try:\n        return (getattr(configure_module, function_name)(debug_level), True)\n    # it was not possible to create the requested logger, so\n    # return the default console logger as a safe alternative"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "    debug_dest = debug_dest.lower()\n    function_name = constants.logger.Function_Prefix + debug_dest\n    configure_module = sys.modules[__name__]\n    # it was possible to create the requested logger, so return it\n    try:\n        return (getattr(configure_module, function_name)(debug_level), True)\n    # it was not possible to create the requested logger, so\n    # return the default console logger as a safe alternative\n    except AttributeError:\n        return (configure_logging_console(debug_level), False)"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "\"\"\"Configure standard Python logging package to use rich.\"\"\"",
              "linematch_context": "\ndef configure_logging_console(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use rich.\"\"\"\n    # use the RichHandler to provide formatted\n    # debugging output in the console\n    logging.basicConfig(\n        level=debug_level,\n        format=constants.logging.Format,"
            },
            {
              "lineno": 59,
              "coloffset": 4,
              "linematch": "logging.basicConfig(",
              "linematch_context": ") -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use rich.\"\"\"\n    # use the RichHandler to provide formatted\n    # debugging output in the console\n    logging.basicConfig(\n        level=debug_level,\n        format=constants.logging.Format,\n        datefmt=\"[%X]\",\n        handlers=[RichHandler()],\n    )"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "logger = logging.getLogger()",
              "linematch_context": "        datefmt=\"[%X]\",\n        handlers=[RichHandler()],\n    )\n    # create a logger and then return it\n    logger = logging.getLogger()\n    return logger\n\n\ndef configure_logging_syslog(\n    debug_level: str = constants.logging.Default_Logging_Level,"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "return logger",
              "linematch_context": "        handlers=[RichHandler()],\n    )\n    # create a logger and then return it\n    logger = logging.getLogger()\n    return logger\n\n\ndef configure_logging_syslog(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:"
            },
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "\"\"\"Configure standard Python logging package to use syslog.\"\"\"",
              "linematch_context": "\ndef configure_logging_syslog(\n    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use syslog.\"\"\"\n    # use the SysLogHandler to send output to a localhost on a port\n    syslog_handler = logging.handlers.SysLogHandler(\n        address=(constants.server.Localhost, constants.server.Port)\n    )\n    logging.basicConfig("
            },
            {
              "lineno": 75,
              "coloffset": 4,
              "linematch": "syslog_handler = logging.handlers.SysLogHandler(",
              "linematch_context": "    debug_level: str = constants.logging.Default_Logging_Level,\n) -> logging.Logger:\n    \"\"\"Configure standard Python logging package to use syslog.\"\"\"\n    # use the SysLogHandler to send output to a localhost on a port\n    syslog_handler = logging.handlers.SysLogHandler(\n        address=(constants.server.Localhost, constants.server.Port)\n    )\n    logging.basicConfig(\n        level=debug_level,\n        format=constants.logging.Format,"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "logging.basicConfig(",
              "linematch_context": "    # use the SysLogHandler to send output to a localhost on a port\n    syslog_handler = logging.handlers.SysLogHandler(\n        address=(constants.server.Localhost, constants.server.Port)\n    )\n    logging.basicConfig(\n        level=debug_level,\n        format=constants.logging.Format,\n        datefmt=\"[%X]\",\n        handlers=[syslog_handler],\n    )"
            },
            {
              "lineno": 85,
              "coloffset": 4,
              "linematch": "logger = logging.getLogger()",
              "linematch_context": "        datefmt=\"[%X]\",\n        handlers=[syslog_handler],\n    )\n    # create a logger and then return it\n    logger = logging.getLogger()\n    return logger\n\n\ndef display_configuration_directory(\n    chasten_user_config_dir_str: str, verbose: bool = False"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "return logger",
              "linematch_context": "        handlers=[syslog_handler],\n    )\n    # create a logger and then return it\n    logger = logging.getLogger()\n    return logger\n\n\ndef display_configuration_directory(\n    chasten_user_config_dir_str: str, verbose: bool = False\n) -> None:"
            },
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "\"\"\"Display information about the configuration in the console.\"\"\"",
              "linematch_context": "\ndef display_configuration_directory(\n    chasten_user_config_dir_str: str, verbose: bool = False\n) -> None:\n    \"\"\"Display information about the configuration in the console.\"\"\"\n    # create a visualization of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    rich_path_tree = filesystem.create_directory_tree_visualization(\n        chasten_user_config_dir_path\n    )"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_path = Path(chasten_user_config_dir_str)",
              "linematch_context": "    chasten_user_config_dir_str: str, verbose: bool = False\n) -> None:\n    \"\"\"Display information about the configuration in the console.\"\"\"\n    # create a visualization of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    rich_path_tree = filesystem.create_directory_tree_visualization(\n        chasten_user_config_dir_path\n    )\n    # display the visualization of the configuration directory\n    output.opt_print_log(verbose, tree=rich_path_tree)"
            },
            {
              "lineno": 95,
              "coloffset": 4,
              "linematch": "rich_path_tree = filesystem.create_directory_tree_visualization(",
              "linematch_context": ") -> None:\n    \"\"\"Display information about the configuration in the console.\"\"\"\n    # create a visualization of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    rich_path_tree = filesystem.create_directory_tree_visualization(\n        chasten_user_config_dir_path\n    )\n    # display the visualization of the configuration directory\n    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "output.opt_print_log(verbose, tree=rich_path_tree)",
              "linematch_context": "    rich_path_tree = filesystem.create_directory_tree_visualization(\n        chasten_user_config_dir_path\n    )\n    # display the visualization of the configuration directory\n    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,"
            },
            {
              "lineno": 100,
              "coloffset": 4,
              "linematch": "output.opt_print_log(verbose, empty=\"\")",
              "linematch_context": "        chasten_user_config_dir_path\n    )\n    # display the visualization of the configuration directory\n    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,\n    checks_file_name: str,"
            },
            {
              "lineno": 110,
              "coloffset": 4,
              "linematch": "\"\"\"Validate a checks file.\"\"\"",
              "linematch_context": "    chasten_user_config_url_str: str,\n    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,\n) -> Tuple[bool, bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Validate a checks file.\"\"\"\n    checks_file_validated = False\n    checks_file_invalidates_entire_config = False\n    # specified check file is URL\n    if util.is_url(checks_file_name):\n        # extract the configuration details"
            },
            {
              "lineno": 111,
              "coloffset": 4,
              "linematch": "checks_file_validated = False",
              "linematch_context": "    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,\n) -> Tuple[bool, bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Validate a checks file.\"\"\"\n    checks_file_validated = False\n    checks_file_invalidates_entire_config = False\n    # specified check file is URL\n    if util.is_url(checks_file_name):\n        # extract the configuration details\n        ("
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "checks_file_invalidates_entire_config = False",
              "linematch_context": "    chasten_user_config_file_str: str,\n) -> Tuple[bool, bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Validate a checks file.\"\"\"\n    checks_file_validated = False\n    checks_file_invalidates_entire_config = False\n    # specified check file is URL\n    if util.is_url(checks_file_name):\n        # extract the configuration details\n        (\n            checks_file_extracted_valid,"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "if util.is_url(checks_file_name):",
              "linematch_context": "    \"\"\"Validate a checks file.\"\"\"\n    checks_file_validated = False\n    checks_file_invalidates_entire_config = False\n    # specified check file is URL\n    if util.is_url(checks_file_name):\n        # extract the configuration details\n        (\n            checks_file_extracted_valid,\n            configuration_file_yaml_str,\n            yaml_data_dict,"
            },
            {
              "lineno": 157,
              "coloffset": 4,
              "linematch": "if not checks_file_extracted_valid:",
              "linematch_context": "        return (checks_file_validated, checks_file_invalidates_entire_config, {})\n    # the checks file could not be extracted in a valid\n    # fashion and thus there is no need to continue the\n    # validation of this file or any of the other check file\n    if not checks_file_extracted_valid:\n        checks_file_validated = False\n    # the checks file could be extract and thus the\n    # function should proceed to validate a checks configuration file\n    else:\n        # validate checks file"
            },
            {
              "lineno": 170,
              "coloffset": 4,
              "linematch": "return (",
              "linematch_context": "            yaml_data_dict,\n            validate.JSON_SCHEMA_CHECKS,\n            verbose,\n        )\n    return (\n        checks_file_validated,\n        checks_file_invalidates_entire_config,\n        yaml_data_dict,\n    )\n"
            },
            {
              "lineno": 183,
              "coloffset": 4,
              "linematch": "\"\"\"Validate the configuration.\"\"\"",
              "linematch_context": "    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:\n    \"\"\"Validate the configuration.\"\"\"\n    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":"
            },
            {
              "lineno": 184,
              "coloffset": 4,
              "linematch": "chasten_user_config_url_str = \"\"",
              "linematch_context": ") -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:\n    \"\"\"Validate the configuration.\"\"\"\n    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":\n        # there is no configuration file specified and thus"
            },
            {
              "lineno": 185,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_str = \"\"",
              "linematch_context": "    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:\n    \"\"\"Validate the configuration.\"\"\"\n    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":\n        # there is no configuration file specified and thus\n        # this function should access the platform-specific"
            },
            {
              "lineno": 186,
              "coloffset": 4,
              "linematch": "chasten_user_config_file_str = \"\"",
              "linematch_context": "]:\n    \"\"\"Validate the configuration.\"\"\"\n    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":\n        # there is no configuration file specified and thus\n        # this function should access the platform-specific\n        # configuration directory detected by platformdirs"
            },
            {
              "lineno": 188,
              "coloffset": 4,
              "linematch": "if config == \"\":",
              "linematch_context": "    chasten_user_config_url_str = \"\"\n    chasten_user_config_dir_str = \"\"\n    chasten_user_config_file_str = \"\"\n\n    if config == \"\":\n        # there is no configuration file specified and thus\n        # this function should access the platform-specific\n        # configuration directory detected by platformdirs\n        # detect and store the platform-specific user\n        # configuration directory by default"
            },
            {
              "lineno": 285,
              "coloffset": 4,
              "linematch": "config_file_validated = validate.validate_file(",
              "linematch_context": "    # --> Step 2: Validate the one or more checks files\n    # --> Step 3: If all files are valid, return overall validity\n    # --> Step 3: Otherwise, return an invalid configuration\n    # validate the user's configuration and display the results\n    config_file_validated = validate.validate_file(\n        configuration_file_source,\n        configuration_file_yaml_str,\n        yaml_data_dict,\n        validate.JSON_SCHEMA_CONFIG,\n        verbose,"
            },
            {
              "lineno": 294,
              "coloffset": 4,
              "linematch": "(_, checks_file_name_list) = validate.extract_checks_file_name(yaml_data_dict)",
              "linematch_context": "        verbose,\n    )\n\n    # if one or more exist, retrieve the name of the checks files\n    (_, checks_file_name_list) = validate.extract_checks_file_name(yaml_data_dict)\n    # iteratively extract the contents of each checks file\n    # and then validate the contents of that checks file\n    checks_files_validated_list = []\n    check_files_validated = False\n    # create an empty dictionary that will store the list of checks"
            },
            {
              "lineno": 297,
              "coloffset": 4,
              "linematch": "checks_files_validated_list = []",
              "linematch_context": "    # if one or more exist, retrieve the name of the checks files\n    (_, checks_file_name_list) = validate.extract_checks_file_name(yaml_data_dict)\n    # iteratively extract the contents of each checks file\n    # and then validate the contents of that checks file\n    checks_files_validated_list = []\n    check_files_validated = False\n    # create an empty dictionary that will store the list of checks\n    overall_checks_dict: Union[\n        Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]\n    ] = {}"
            },
            {
              "lineno": 298,
              "coloffset": 4,
              "linematch": "check_files_validated = False",
              "linematch_context": "    (_, checks_file_name_list) = validate.extract_checks_file_name(yaml_data_dict)\n    # iteratively extract the contents of each checks file\n    # and then validate the contents of that checks file\n    checks_files_validated_list = []\n    check_files_validated = False\n    # create an empty dictionary that will store the list of checks\n    overall_checks_dict: Union[\n        Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]\n    ] = {}\n    # create an empty list that will store the dicts of checks"
            },
            {
              "lineno": 300,
              "coloffset": 4,
              "linematch": "overall_checks_dict: Union[",
              "linematch_context": "    # and then validate the contents of that checks file\n    checks_files_validated_list = []\n    check_files_validated = False\n    # create an empty dictionary that will store the list of checks\n    overall_checks_dict: Union[\n        Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]\n    ] = {}\n    # create an empty list that will store the dicts of checks\n    overall_checks_list: List[Dict[str, Union[str, Dict[str, int]]]] = []\n    # initialize the dictionary to contain the empty list"
            },
            {
              "lineno": 304,
              "coloffset": 4,
              "linematch": "overall_checks_list: List[Dict[str, Union[str, Dict[str, int]]]] = []",
              "linematch_context": "    overall_checks_dict: Union[\n        Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]\n    ] = {}\n    # create an empty list that will store the dicts of checks\n    overall_checks_list: List[Dict[str, Union[str, Dict[str, int]]]] = []\n    # initialize the dictionary to contain the empty list\n    overall_checks_dict[constants.checks.Checks_Label] = overall_checks_list\n    for checks_file_name in checks_file_name_list:\n        (\n            checks_file_validated,"
            },
            {
              "lineno": 306,
              "coloffset": 4,
              "linematch": "overall_checks_dict[constants.checks.Checks_Label] = overall_checks_list",
              "linematch_context": "    ] = {}\n    # create an empty list that will store the dicts of checks\n    overall_checks_list: List[Dict[str, Union[str, Dict[str, int]]]] = []\n    # initialize the dictionary to contain the empty list\n    overall_checks_dict[constants.checks.Checks_Label] = overall_checks_list\n    for checks_file_name in checks_file_name_list:\n        (\n            checks_file_validated,\n            checks_file_invalidates_entire_config,\n            checks_file_yaml_data_dict,"
            },
            {
              "lineno": 307,
              "coloffset": 4,
              "linematch": "for checks_file_name in checks_file_name_list:",
              "linematch_context": "    # create an empty list that will store the dicts of checks\n    overall_checks_list: List[Dict[str, Union[str, Dict[str, int]]]] = []\n    # initialize the dictionary to contain the empty list\n    overall_checks_dict[constants.checks.Checks_Label] = overall_checks_list\n    for checks_file_name in checks_file_name_list:\n        (\n            checks_file_validated,\n            checks_file_invalidates_entire_config,\n            checks_file_yaml_data_dict,\n        ) = validate_checks_file("
            },
            {
              "lineno": 330,
              "coloffset": 4,
              "linematch": "check_files_validated = all(checks_files_validated_list)",
              "linematch_context": "        # add the listing of checks from the current yaml_data_dict to\n        # the overall listing of checks in the main dictionary\n        overall_checks_dict[constants.checks.Checks_Label].extend(checks_file_yaml_data_dict[constants.checks.Checks_Label])  # type: ignore\n    # the check files are only validated if all of them are valid\n    check_files_validated = all(checks_files_validated_list)\n    # the files validated correctly; return an indicator to\n    # show that validation worked and then return the overall\n    # dictionary that contains the listing of valid checks\n    if config_file_validated and check_files_validated:\n        return (True, overall_checks_dict)"
            },
            {
              "lineno": 334,
              "coloffset": 4,
              "linematch": "if config_file_validated and check_files_validated:",
              "linematch_context": "    check_files_validated = all(checks_files_validated_list)\n    # the files validated correctly; return an indicator to\n    # show that validation worked and then return the overall\n    # dictionary that contains the listing of valid checks\n    if config_file_validated and check_files_validated:\n        return (True, overall_checks_dict)\n    # there was at least one validation error\n    return (False, {})\n\n"
            },
            {
              "lineno": 337,
              "coloffset": 4,
              "linematch": "return (False, {})",
              "linematch_context": "    # dictionary that contains the listing of valid checks\n    if config_file_validated and check_files_validated:\n        return (True, overall_checks_dict)\n    # there was at least one validation error\n    return (False, {})\n\n\ndef extract_configuration_details_from_config_dir(\n    chasten_user_config_dir_str: Path,\n    configuration_file: str = constants.filesystem.Main_Configuration_File,"
            },
            {
              "lineno": 344,
              "coloffset": 4,
              "linematch": "\"\"\"Extract details from the configuration given a config directory.",
              "linematch_context": "def extract_configuration_details_from_config_dir(\n    chasten_user_config_dir_str: Path,\n    configuration_file: str = constants.filesystem.Main_Configuration_File,\n) -> Tuple[bool, str, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config directory.\n\n    chasten_user_config_dir_str -- directory to search for config file\n    configuration_file -- optional configuration file to specify. If not supplied, a default location will be searched\n    \"\"\"\n    # create the name of the main configuration file"
            },
            {
              "lineno": 351,
              "coloffset": 4,
              "linematch": "configuration_file_path = chasten_user_config_dir_str / configuration_file",
              "linematch_context": "    configuration_file -- optional configuration file to specify. If not supplied, a default location will be searched\n    \"\"\"\n    # create the name of the main configuration file\n    # load the text of the main configuration file\n    configuration_file_path = chasten_user_config_dir_str / configuration_file\n    # the configuration file does not exist and thus\n    # the extraction process cannot continue, the use of\n    # these return values indicates that the extraction\n    # failed and any future steps cannot continue\n    if not configuration_file_path.exists():"
            },
            {
              "lineno": 356,
              "coloffset": 4,
              "linematch": "if not configuration_file_path.exists():",
              "linematch_context": "    # the configuration file does not exist and thus\n    # the extraction process cannot continue, the use of\n    # these return values indicates that the extraction\n    # failed and any future steps cannot continue\n    if not configuration_file_path.exists():\n        output.logger.error(\n            f\"\\nFinding config or check file Path failed for {configuration_file_path}.\\n\"\n        )\n        return (False, None, None, None)  # type: ignore\n    configuration_file_yaml_str = configuration_file_path.read_text()"
            },
            {
              "lineno": 361,
              "coloffset": 4,
              "linematch": "configuration_file_yaml_str = configuration_file_path.read_text()",
              "linematch_context": "        output.logger.error(\n            f\"\\nFinding config or check file Path failed for {configuration_file_path}.\\n\"\n        )\n        return (False, None, None, None)  # type: ignore\n    configuration_file_yaml_str = configuration_file_path.read_text()\n    # load the contents of the main configuration file\n    with open(str(configuration_file_path)) as user_configuration_file_text:\n        (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n            user_configuration_file_text.read()\n        )"
            },
            {
              "lineno": 363,
              "coloffset": 4,
              "linematch": "with open(str(configuration_file_path)) as user_configuration_file_text:",
              "linematch_context": "        )\n        return (False, None, None, None)  # type: ignore\n    configuration_file_yaml_str = configuration_file_path.read_text()\n    # load the contents of the main configuration file\n    with open(str(configuration_file_path)) as user_configuration_file_text:\n        (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n            user_configuration_file_text.read()\n        )\n        # return success status, filename, file contents, and yaml parsed data upon success\n        if yaml_success:"
            },
            {
              "lineno": 386,
              "coloffset": 4,
              "linematch": "\"\"\"Extract details from the configuration given a config URL.",
              "linematch_context": "\ndef extract_configuration_details_from_config_url(\n    chasten_user_config_url: Url,\n) -> Tuple[bool, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config URL.\n\n    chasten_user_config_url -- URL to config or checks yaml file.\n    \"\"\"\n    # create request with given URL as source\n    response = requests.get(str(chasten_user_config_url))"
            },
            {
              "lineno": 391,
              "coloffset": 4,
              "linematch": "response = requests.get(str(chasten_user_config_url))",
              "linematch_context": "\n    chasten_user_config_url -- URL to config or checks yaml file.\n    \"\"\"\n    # create request with given URL as source\n    response = requests.get(str(chasten_user_config_url))\n    # the URL response is OK\n    if response.ok:\n        # assume URL endpoint returns raw text\n        configuration_file_yaml_str = response.text\n    # the URL indicates a problem with the response"
            },
            {
              "lineno": 393,
              "coloffset": 4,
              "linematch": "if response.ok:",
              "linematch_context": "    \"\"\"\n    # create request with given URL as source\n    response = requests.get(str(chasten_user_config_url))\n    # the URL response is OK\n    if response.ok:\n        # assume URL endpoint returns raw text\n        configuration_file_yaml_str = response.text\n    # the URL indicates a problem with the response\n    else:\n        output.logger.error("
            },
            {
              "lineno": 402,
              "coloffset": 4,
              "linematch": "(yaml_success, yaml_data) = convert_configuration_text_to_yaml(",
              "linematch_context": "        output.logger.error(\n            f\"\\nLoading config or check file URL failed for {chasten_user_config_url}.\\n\"\n        )\n        return (False, None, None)  # type: ignore\n    (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n        configuration_file_yaml_str\n    )\n    # return success status, filename, file contents, and yaml parsed data upon success\n    if yaml_success:\n        return (True, configuration_file_yaml_str, yaml_data)"
            },
            {
              "lineno": 406,
              "coloffset": 4,
              "linematch": "if yaml_success:",
              "linematch_context": "    (yaml_success, yaml_data) = convert_configuration_text_to_yaml(\n        configuration_file_yaml_str\n    )\n    # return success status, filename, file contents, and yaml parsed data upon success\n    if yaml_success:\n        return (True, configuration_file_yaml_str, yaml_data)\n    else:\n        output.logger.error(\n            f\"\\nParsing YAML from config or check file URL failed for {chasten_user_config_url}.\\n\"\n        )"
            },
            {
              "lineno": 418,
              "coloffset": 4,
              "linematch": "\"\"\"Return details about the configuration.\"\"\"",
              "linematch_context": "\ndef convert_configuration_text_to_yaml(\n    configuration_file_contents_str: str,\n) -> Tuple[bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Return details about the configuration.\"\"\"\n    yaml_data = None\n    try:\n        yaml_data = yaml.safe_load(configuration_file_contents_str)\n    except Exception:\n        # yaml parsing has failed and we will indicate the input is invalid"
            },
            {
              "lineno": 419,
              "coloffset": 4,
              "linematch": "yaml_data = None",
              "linematch_context": "def convert_configuration_text_to_yaml(\n    configuration_file_contents_str: str,\n) -> Tuple[bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Return details about the configuration.\"\"\"\n    yaml_data = None\n    try:\n        yaml_data = yaml.safe_load(configuration_file_contents_str)\n    except Exception:\n        # yaml parsing has failed and we will indicate the input is invalid\n        return (False, None)  # type: ignore"
            },
            {
              "lineno": 420,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "    configuration_file_contents_str: str,\n) -> Tuple[bool, Dict[str, Dict[str, Any]]]:\n    \"\"\"Return details about the configuration.\"\"\"\n    yaml_data = None\n    try:\n        yaml_data = yaml.safe_load(configuration_file_contents_str)\n    except Exception:\n        # yaml parsing has failed and we will indicate the input is invalid\n        return (False, None)  # type: ignore\n    # return the file name, the textual contents of the configuration file, and"
            },
            {
              "lineno": 427,
              "coloffset": 4,
              "linematch": "return (True, yaml_data)",
              "linematch_context": "        # yaml parsing has failed and we will indicate the input is invalid\n        return (False, None)  # type: ignore\n    # return the file name, the textual contents of the configuration file, and\n    # a dict-based representation of the configuration file\n    return (True, yaml_data)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/server.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 20,
              "coloffset": 8,
              "linematch": "\"\"\"Receive a message and then display it in output and log it to a file.\"\"\"",
              "linematch_context": "class SyslogUDPHandler(socketserver.BaseRequestHandler):\n    \"\"\"Syslog UDP handler for receiving debugging messages.\"\"\"\n\n    def handle(self):\n        \"\"\"Receive a message and then display it in output and log it to a file.\"\"\"\n        global logger  # noqa: PLW0602\n        # receive the message from the syslog logging client\n        message = bytes.decode(\n            self.request[0].strip(), encoding=constants.server.Utf8_Encoding\n        )"
            },
            {
              "lineno": 21,
              "coloffset": 8,
              "linematch": "global logger  # noqa: PLW0602",
              "linematch_context": "    \"\"\"Syslog UDP handler for receiving debugging messages.\"\"\"\n\n    def handle(self):\n        \"\"\"Receive a message and then display it in output and log it to a file.\"\"\"\n        global logger  # noqa: PLW0602\n        # receive the message from the syslog logging client\n        message = bytes.decode(\n            self.request[0].strip(), encoding=constants.server.Utf8_Encoding\n        )\n        # remove not-printable characters that can appear in message"
            },
            {
              "lineno": 23,
              "coloffset": 8,
              "linematch": "message = bytes.decode(",
              "linematch_context": "    def handle(self):\n        \"\"\"Receive a message and then display it in output and log it to a file.\"\"\"\n        global logger  # noqa: PLW0602\n        # receive the message from the syslog logging client\n        message = bytes.decode(\n            self.request[0].strip(), encoding=constants.server.Utf8_Encoding\n        )\n        # remove not-printable characters that can appear in message\n        enhanced_message = str(message).replace(\n            constants.markers.Bad_Fifteen, constants.markers.Empty_String"
            },
            {
              "lineno": 27,
              "coloffset": 8,
              "linematch": "enhanced_message = str(message).replace(",
              "linematch_context": "        message = bytes.decode(\n            self.request[0].strip(), encoding=constants.server.Utf8_Encoding\n        )\n        # remove not-printable characters that can appear in message\n        enhanced_message = str(message).replace(\n            constants.markers.Bad_Fifteen, constants.markers.Empty_String\n        )\n        enhanced_message = enhanced_message.replace(\n            constants.markers.Bad_Zero_Zero, constants.markers.Empty_String\n        )"
            },
            {
              "lineno": 30,
              "coloffset": 8,
              "linematch": "enhanced_message = enhanced_message.replace(",
              "linematch_context": "        # remove not-printable characters that can appear in message\n        enhanced_message = str(message).replace(\n            constants.markers.Bad_Fifteen, constants.markers.Empty_String\n        )\n        enhanced_message = enhanced_message.replace(\n            constants.markers.Bad_Zero_Zero, constants.markers.Empty_String\n        )\n        # display the message inside of the syslog's console\n        output.console.print(enhanced_message)\n        # write the logging message to a file using a rotating file handler"
            },
            {
              "lineno": 34,
              "coloffset": 8,
              "linematch": "output.console.print(enhanced_message)",
              "linematch_context": "        enhanced_message = enhanced_message.replace(\n            constants.markers.Bad_Zero_Zero, constants.markers.Empty_String\n        )\n        # display the message inside of the syslog's console\n        output.console.print(enhanced_message)\n        # write the logging message to a file using a rotating file handler\n        logger.debug(enhanced_message)\n\n\ndef start_syslog_server():"
            },
            {
              "lineno": 36,
              "coloffset": 8,
              "linematch": "logger.debug(enhanced_message)",
              "linematch_context": "        )\n        # display the message inside of the syslog's console\n        output.console.print(enhanced_message)\n        # write the logging message to a file using a rotating file handler\n        logger.debug(enhanced_message)\n\n\ndef start_syslog_server():\n    \"\"\"Start a syslog server.\"\"\"\n    global logger  # noqa: PLW0602"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "\"\"\"Start a syslog server.\"\"\"",
              "linematch_context": "        logger.debug(enhanced_message)\n\n\ndef start_syslog_server():\n    \"\"\"Start a syslog server.\"\"\"\n    global logger  # noqa: PLW0602\n    # always log all of the messages to a file\n    logger.setLevel(logging.DEBUG)\n    # create a RotatingFileHandler such that:\n    # -- it is stored in a file"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "global logger  # noqa: PLW0602",
              "linematch_context": "\n\ndef start_syslog_server():\n    \"\"\"Start a syslog server.\"\"\"\n    global logger  # noqa: PLW0602\n    # always log all of the messages to a file\n    logger.setLevel(logging.DEBUG)\n    # create a RotatingFileHandler such that:\n    # -- it is stored in a file\n    # -- it can never be bigger than 1 MB"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "logger.setLevel(logging.DEBUG)",
              "linematch_context": "def start_syslog_server():\n    \"\"\"Start a syslog server.\"\"\"\n    global logger  # noqa: PLW0602\n    # always log all of the messages to a file\n    logger.setLevel(logging.DEBUG)\n    # create a RotatingFileHandler such that:\n    # -- it is stored in a file\n    # -- it can never be bigger than 1 MB\n    # -- one backup is created when log file gets too big\n    rotating_file_handler = logging.handlers.RotatingFileHandler("
            },
            {
              "lineno": 48,
              "coloffset": 4,
              "linematch": "rotating_file_handler = logging.handlers.RotatingFileHandler(",
              "linematch_context": "    # create a RotatingFileHandler such that:\n    # -- it is stored in a file\n    # -- it can never be bigger than 1 MB\n    # -- one backup is created when log file gets too big\n    rotating_file_handler = logging.handlers.RotatingFileHandler(\n        LOG_FILE,\n        maxBytes=constants.server.Max_Log_Size,\n        backupCount=constants.server.Backup_Count,\n    )\n    # add the rotating file handler to the logger"
            },
            {
              "lineno": 54,
              "coloffset": 4,
              "linematch": "logger.addHandler(rotating_file_handler)",
              "linematch_context": "        maxBytes=constants.server.Max_Log_Size,\n        backupCount=constants.server.Backup_Count,\n    )\n    # add the rotating file handler to the logger\n    logger.addHandler(rotating_file_handler)\n    # startup the server and then let it run forever\n    try:\n        server = socketserver.UDPServer((HOST, PORT), SyslogUDPHandler)\n        server.serve_forever(poll_interval=constants.server.Poll_Interval)\n    # let the server crash and raise an error on SystemExit and IOError"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "    )\n    # add the rotating file handler to the logger\n    logger.addHandler(rotating_file_handler)\n    # startup the server and then let it run forever\n    try:\n        server = socketserver.UDPServer((HOST, PORT), SyslogUDPHandler)\n        server.serve_forever(poll_interval=constants.server.Poll_Interval)\n    # let the server crash and raise an error on SystemExit and IOError\n    except SystemExit:\n        raise"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/util.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 17,
              "coloffset": 4,
              "linematch": "\"\"\"Produce a human-readable Yes or No for a boolean value of True or False.\"\"\"",
              "linematch_context": "default_chasten_semver = \"0.0.0\"\n\n\ndef get_human_readable_boolean(answer: bool) -> str:\n    \"\"\"Produce a human-readable Yes or No for a boolean value of True or False.\"\"\"\n    # the provided answer is true\n    if answer:\n        return constants.humanreadable.Yes\n    # the provided answer is false\n    return constants.humanreadable.No"
            },
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "\ndef get_human_readable_boolean(answer: bool) -> str:\n    \"\"\"Produce a human-readable Yes or No for a boolean value of True or False.\"\"\"\n    # the provided answer is true\n    if answer:\n        return constants.humanreadable.Yes\n    # the provided answer is false\n    return constants.humanreadable.No\n\n"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "return constants.humanreadable.No",
              "linematch_context": "    # the provided answer is true\n    if answer:\n        return constants.humanreadable.Yes\n    # the provided answer is false\n    return constants.humanreadable.No\n\n\ndef get_OS() -> str:\n    \"\"\"Gets the Operating system of the user.\"\"\"\n    OpSystem = platform.system()"
            },
            {
              "lineno": 26,
              "coloffset": 4,
              "linematch": "\"\"\"Gets the Operating system of the user.\"\"\"",
              "linematch_context": "    return constants.humanreadable.No\n\n\ndef get_OS() -> str:\n    \"\"\"Gets the Operating system of the user.\"\"\"\n    OpSystem = platform.system()\n    return OpSystem\n\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "OpSystem = platform.system()",
              "linematch_context": "\n\ndef get_OS() -> str:\n    \"\"\"Gets the Operating system of the user.\"\"\"\n    OpSystem = platform.system()\n    return OpSystem\n\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\""
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "return OpSystem",
              "linematch_context": "\ndef get_OS() -> str:\n    \"\"\"Gets the Operating system of the user.\"\"\"\n    OpSystem = platform.system()\n    return OpSystem\n\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\""
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "\"\"\"Get the executable directory depending on OS\"\"\"",
              "linematch_context": "    return OpSystem\n\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\"\n    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\"\n        executable_name += \".exe\""
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "exe_directory = \"/bin/\"",
              "linematch_context": "\n\ndef executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\"\n    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\"\n        executable_name += \".exe\"\n    virtual_env_location = sys.prefix"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "if OpSystem == \"Windows\":",
              "linematch_context": "def executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:\n    \"\"\"Get the executable directory depending on OS\"\"\"\n    exe_directory = \"/bin/\"\n    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\"\n        executable_name += \".exe\"\n    virtual_env_location = sys.prefix\n    return virtual_env_location + exe_directory + executable_name\n"
            },
            {
              "lineno": 38,
              "coloffset": 4,
              "linematch": "virtual_env_location = sys.prefix",
              "linematch_context": "    # Checks if the OS is windows and changed where to search if true\n    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\"\n        executable_name += \".exe\"\n    virtual_env_location = sys.prefix\n    return virtual_env_location + exe_directory + executable_name\n\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\""
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "return virtual_env_location + exe_directory + executable_name",
              "linematch_context": "    if OpSystem == \"Windows\":\n        exe_directory = \"/Scripts/\"\n        executable_name += \".exe\"\n    virtual_env_location = sys.prefix\n    return virtual_env_location + exe_directory + executable_name\n\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "\"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"",
              "linematch_context": "    return virtual_env_location + exe_directory + executable_name\n\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:\n        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n\n"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "if answer:",
              "linematch_context": "\n\ndef get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:\n        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n\n\ndef get_chasten_version() -> str:"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "return f\"[red]{xmark_unicode}[/red]\"",
              "linematch_context": "def get_symbol_boolean(answer: bool) -> str:\n    \"\"\"Produce a symbol-formatted version of a boolean value of True or False.\"\"\"\n    if answer:\n        return f\"[green]{checkmark_unicode}[/green]\"\n    return f\"[red]{xmark_unicode}[/red]\"\n\n\ndef get_chasten_version() -> str:\n    \"\"\"Use importlib to extract the version of the package.\"\"\"\n    # attempt to determine the current version of the entire package,"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "\"\"\"Use importlib to extract the version of the package.\"\"\"",
              "linematch_context": "    return f\"[red]{xmark_unicode}[/red]\"\n\n\ndef get_chasten_version() -> str:\n    \"\"\"Use importlib to extract the version of the package.\"\"\"\n    # attempt to determine the current version of the entire package,\n    # bearing in mind that this program appears on PyPI with the name \"chasten\";\n    # this will then return the version string specified with the version attribute\n    # in the [tool.poetry] section of the pyproject.toml file\n    try:"
            },
            {
              "lineno": 55,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "    # attempt to determine the current version of the entire package,\n    # bearing in mind that this program appears on PyPI with the name \"chasten\";\n    # this will then return the version string specified with the version attribute\n    # in the [tool.poetry] section of the pyproject.toml file\n    try:\n        version_string_of_foo = importlib.metadata.version(\n            constants.chasten.Application_Name\n        )\n    # note that using the version function does not work when chasten is run\n    # through a 'poetry shell' and/or a 'poetry run' command because at that stage"
            },
            {
              "lineno": 65,
              "coloffset": 4,
              "linematch": "return version_string_of_foo",
              "linematch_context": "    # there is not a working package that importlib.metadata can access with a version;\n    # in this situation the function should return the default value of 0.0.0\n    except importlib.metadata.PackageNotFoundError:\n        version_string_of_foo = default_chasten_semver\n    return version_string_of_foo\n\n\ndef join_and_preserve(data, start, end):\n    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "\"\"\"Join and preserve lines inside of a list.\"\"\"",
              "linematch_context": "    return version_string_of_foo\n\n\ndef join_and_preserve(data, start, end):\n    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:\n    \"\"\"Determine if string is valid URL.\"\"\""
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "return constants.markers.Newline.join(data[start:end])",
              "linematch_context": "\n\ndef join_and_preserve(data, start, end):\n    \"\"\"Join and preserve lines inside of a list.\"\"\"\n    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:\n    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url"
            },
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "\"\"\"Determine if string is valid URL.\"\"\"",
              "linematch_context": "    return constants.markers.Newline.join(data[start:end])\n\n\ndef is_url(url: str) -> bool:\n    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url\n    url_parsed = parse_url(url)\n    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:\n        return False"
            },
            {
              "lineno": 76,
              "coloffset": 4,
              "linematch": "url_parsed = parse_url(url)",
              "linematch_context": "\ndef is_url(url: str) -> bool:\n    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url\n    url_parsed = parse_url(url)\n    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:\n        return False\n    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\""
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "if url_parsed.scheme not in [\"http\", \"https\"]:",
              "linematch_context": "    \"\"\"Determine if string is valid URL.\"\"\"\n    # parse input url\n    url_parsed = parse_url(url)\n    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:\n        return False\n    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\"\n    query_character = \"?\" if url_parsed.query is not None else \"\"\n    fragment_character = \"#\" if url_parsed.fragment is not None else \"\""
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "port_character = \":\" if url_parsed.port is not None else \"\"",
              "linematch_context": "    # only allow http and https\n    if url_parsed.scheme not in [\"http\", \"https\"]:\n        return False\n    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\"\n    query_character = \"?\" if url_parsed.query is not None else \"\"\n    fragment_character = \"#\" if url_parsed.fragment is not None else \"\"\n    url_pieces = [\n        url_parsed.scheme,\n        \"://\","
            },
            {
              "lineno": 82,
              "coloffset": 4,
              "linematch": "query_character = \"?\" if url_parsed.query is not None else \"\"",
              "linematch_context": "    if url_parsed.scheme not in [\"http\", \"https\"]:\n        return False\n    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\"\n    query_character = \"?\" if url_parsed.query is not None else \"\"\n    fragment_character = \"#\" if url_parsed.fragment is not None else \"\"\n    url_pieces = [\n        url_parsed.scheme,\n        \"://\",\n        url_parsed.host,"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "fragment_character = \"#\" if url_parsed.fragment is not None else \"\"",
              "linematch_context": "        return False\n    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\"\n    query_character = \"?\" if url_parsed.query is not None else \"\"\n    fragment_character = \"#\" if url_parsed.fragment is not None else \"\"\n    url_pieces = [\n        url_parsed.scheme,\n        \"://\",\n        url_parsed.host,\n        port_character,"
            },
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "url_pieces = [",
              "linematch_context": "    # only input characters for initiatig query and/or fragments if necessary\n    port_character = \":\" if url_parsed.port is not None else \"\"\n    query_character = \"?\" if url_parsed.query is not None else \"\"\n    fragment_character = \"#\" if url_parsed.fragment is not None else \"\"\n    url_pieces = [\n        url_parsed.scheme,\n        \"://\",\n        url_parsed.host,\n        port_character,\n        url_parsed.port,"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "url_reassembled = \"\"",
              "linematch_context": "        url_parsed.fragment,\n    ]\n    # convert every item to a string and piece the url back together\n    # to make sure it matches what was given\n    url_reassembled = \"\"\n    for url_piece in url_pieces:\n        if url_piece is not None:\n            url_reassembled += str(url_piece)\n    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "for url_piece in url_pieces:",
              "linematch_context": "    ]\n    # convert every item to a string and piece the url back together\n    # to make sure it matches what was given\n    url_reassembled = \"\"\n    for url_piece in url_pieces:\n        if url_piece is not None:\n            url_reassembled += str(url_piece)\n    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n"
            },
            {
              "lineno": 103,
              "coloffset": 4,
              "linematch": "return str(parse_url(url)).lower() == url_reassembled.lower()",
              "linematch_context": "    for url_piece in url_pieces:\n        if url_piece is not None:\n            url_reassembled += str(url_piece)\n    # determine if parsed and reconstructed url matches original\n    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed"
            },
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "\"\"\"Calculate amount of checks passed in analyze\"\"\"",
              "linematch_context": "    return str(parse_url(url)).lower() == url_reassembled.lower()\n\n\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed\n    try:\n        # calculate total amount of checks in list\n        count_total = len(check_status_list)\n        # count total amount of checks counted as true"
            },
            {
              "lineno": 109,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "\ndef total_amount_passed(check_status_list: list[bool]) -> tuple[int, int, float]:\n    \"\"\"Calculate amount of checks passed in analyze\"\"\"\n    # attempt calculations for percentage of checks passed\n    try:\n        # calculate total amount of checks in list\n        count_total = len(check_status_list)\n        # count total amount of checks counted as true\n        count_passed = check_status_list.count(True)\n        # return tuple of checks passed, total checks, percentage of checks passed"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 11,
              "coloffset": 4,
              "linematch": "\"\"\"Extract the minimum and maximum values from the checks dictionary.\"\"\"",
              "linematch_context": "\ndef extract_min_max(\n    check: Dict[str, Union[str, Dict[str, int]]]\n) -> Tuple[Union[int, None], Union[int, None]]:\n    \"\"\"Extract the minimum and maximum values from the checks dictionary.\"\"\"\n    # extract information about the count attribute\n    # and the min and max values if they exist\n    min_count = check.get(constants.checks.Check_Count, {}).get(constants.checks.Check_Min)  # type: ignore\n    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore\n    return (min_count, max_count)"
            },
            {
              "lineno": 14,
              "coloffset": 4,
              "linematch": "min_count = check.get(constants.checks.Check_Count, {}).get(constants.checks.Check_Min)  # type: ignore",
              "linematch_context": ") -> Tuple[Union[int, None], Union[int, None]]:\n    \"\"\"Extract the minimum and maximum values from the checks dictionary.\"\"\"\n    # extract information about the count attribute\n    # and the min and max values if they exist\n    min_count = check.get(constants.checks.Check_Count, {}).get(constants.checks.Check_Min)  # type: ignore\n    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore\n    return (min_count, max_count)\n\n\ndef extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:"
            },
            {
              "lineno": 15,
              "coloffset": 4,
              "linematch": "max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore",
              "linematch_context": "    \"\"\"Extract the minimum and maximum values from the checks dictionary.\"\"\"\n    # extract information about the count attribute\n    # and the min and max values if they exist\n    min_count = check.get(constants.checks.Check_Count, {}).get(constants.checks.Check_Min)  # type: ignore\n    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore\n    return (min_count, max_count)\n\n\ndef extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:\n    \"\"\"Extract the description that may optionally be stored in a check.\"\"\""
            },
            {
              "lineno": 16,
              "coloffset": 4,
              "linematch": "return (min_count, max_count)",
              "linematch_context": "    # extract information about the count attribute\n    # and the min and max values if they exist\n    min_count = check.get(constants.checks.Check_Count, {}).get(constants.checks.Check_Min)  # type: ignore\n    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore\n    return (min_count, max_count)\n\n\ndef extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:\n    \"\"\"Extract the description that may optionally be stored in a check.\"\"\"\n    # the attribute is not None and thus the function"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "\"\"\"Extract the description that may optionally be stored in a check.\"\"\"",
              "linematch_context": "    return (min_count, max_count)\n\n\ndef extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:\n    \"\"\"Extract the description that may optionally be stored in a check.\"\"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if \"description\" in check:\n        return str(check[\"description\"])\n    return \"\""
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "if \"description\" in check:",
              "linematch_context": "def extract_description(check: Dict[str, Union[str, Dict[str, int]]]) -> str:\n    \"\"\"Extract the description that may optionally be stored in a check.\"\"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if \"description\" in check:\n        return str(check[\"description\"])\n    return \"\"\n\n\ndef create_attribute_label(attribute: Union[str, int, None], label: str) -> str:"
            },
            {
              "lineno": 25,
              "coloffset": 4,
              "linematch": "return \"\"",
              "linematch_context": "    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if \"description\" in check:\n        return str(check[\"description\"])\n    return \"\"\n\n\ndef create_attribute_label(attribute: Union[str, int, None], label: str) -> str:\n    \"\"\"Create an attribute label string for display as long as it is not null.\"\"\"\n    # define an empty attribute string, which is"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "\"\"\"Create an attribute label string for display as long as it is not null.\"\"\"",
              "linematch_context": "    return \"\"\n\n\ndef create_attribute_label(attribute: Union[str, int, None], label: str) -> str:\n    \"\"\"Create an attribute label string for display as long as it is not null.\"\"\"\n    # define an empty attribute string, which is\n    # the default in the case when attribute is None\n    labeled_attribute = \"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "labeled_attribute = \"\"",
              "linematch_context": "def create_attribute_label(attribute: Union[str, int, None], label: str) -> str:\n    \"\"\"Create an attribute label string for display as long as it is not null.\"\"\"\n    # define an empty attribute string, which is\n    # the default in the case when attribute is None\n    labeled_attribute = \"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if attribute:\n        labeled_attribute = f\"{label} = {attribute}\"\n    return labeled_attribute"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "if attribute:",
              "linematch_context": "    # the default in the case when attribute is None\n    labeled_attribute = \"\"\n    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if attribute:\n        labeled_attribute = f\"{label} = {attribute}\"\n    return labeled_attribute\n\n\ndef join_attribute_labels(attribute_labels: List[str]) -> str:"
            },
            {
              "lineno": 37,
              "coloffset": 4,
              "linematch": "return labeled_attribute",
              "linematch_context": "    # the attribute is not None and thus the function\n    # should create the labelled attribute out of it\n    if attribute:\n        labeled_attribute = f\"{label} = {attribute}\"\n    return labeled_attribute\n\n\ndef join_attribute_labels(attribute_labels: List[str]) -> str:\n    \"\"\"Join all of the attribute labels in a comma-separated list.\"\"\"\n    # start the joined attribute labels with the empty string,"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "\"\"\"Join all of the attribute labels in a comma-separated list.\"\"\"",
              "linematch_context": "    return labeled_attribute\n\n\ndef join_attribute_labels(attribute_labels: List[str]) -> str:\n    \"\"\"Join all of the attribute labels in a comma-separated list.\"\"\"\n    # start the joined attribute labels with the empty string,\n    # which is what it will be by default as well\n    joined_attribute_labels = constants.markers.Empty_String\n    # incrementally create the list of labelled attributes,\n    # separating each one with a comma and a space and"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "joined_attribute_labels = constants.markers.Empty_String",
              "linematch_context": "def join_attribute_labels(attribute_labels: List[str]) -> str:\n    \"\"\"Join all of the attribute labels in a comma-separated list.\"\"\"\n    # start the joined attribute labels with the empty string,\n    # which is what it will be by default as well\n    joined_attribute_labels = constants.markers.Empty_String\n    # incrementally create the list of labelled attributes,\n    # separating each one with a comma and a space and\n    # ensuring that the last one does not have a trailing\n    # comma and space after it\n    for i, attribute_label in enumerate(attribute_labels):"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "for i, attribute_label in enumerate(attribute_labels):",
              "linematch_context": "    # incrementally create the list of labelled attributes,\n    # separating each one with a comma and a space and\n    # ensuring that the last one does not have a trailing\n    # comma and space after it\n    for i, attribute_label in enumerate(attribute_labels):\n        # only add the comma and the space when the for loop\n        # is not dealing with the final value in the list of labels\n        if i > 0:\n            joined_attribute_labels += constants.markers.Comma_Space\n        # append the new attribute label to the running list"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "return joined_attribute_labels",
              "linematch_context": "        if i > 0:\n            joined_attribute_labels += constants.markers.Comma_Space\n        # append the new attribute label to the running list\n        joined_attribute_labels += attribute_label  # type: ignore\n    return joined_attribute_labels\n\n\ndef is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    if min_value is None and max_value is None:"
            },
            {
              "lineno": 60,
              "coloffset": 4,
              "linematch": "\"\"\"Help to see if the value is in the closed interval.\"\"\"",
              "linematch_context": "    return joined_attribute_labels\n\n\ndef is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    if min_value is None and max_value is None:\n        return False\n    return True\n\n"
            },
            {
              "lineno": 61,
              "coloffset": 4,
              "linematch": "if min_value is None and max_value is None:",
              "linematch_context": "\n\ndef is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    if min_value is None and max_value is None:\n        return False\n    return True\n\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "return True",
              "linematch_context": "def is_checkable(min_value: Union[int, None], max_value: Union[int, None]) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    if min_value is None and max_value is None:\n        return False\n    return True\n\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value"
            },
            {
              "lineno": 67,
              "coloffset": 4,
              "linematch": "\"\"\"Help to see if the value is in the closed interval.\"\"\"",
              "linematch_context": "    return True\n\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None"
            },
            {
              "lineno": 68,
              "coloffset": 4,
              "linematch": "return min(max_value, value) == value and max(min_value, value) == value",
              "linematch_context": "\n\ndef is_in_closed_interval(value: int, min_value: int, max_value: int) -> bool:\n    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:"
            },
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the count is between min_value and max_value.\"\"\"",
              "linematch_context": "\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:\n    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value\n    # both of the values are None and thus the comparision is vacuously true\n    if min_value is None and max_value is None:\n        return True"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "if min_value is None and max_value is None:",
              "linematch_context": "    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value\n    # both of the values are None and thus the comparision is vacuously true\n    if min_value is None and max_value is None:\n        return True\n    # both are not None and thus the count must be in the closed interval\n    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None"
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "if min_value is not None and max_value is not None:",
              "linematch_context": "    # both of the values are None and thus the comparision is vacuously true\n    if min_value is None and max_value is None:\n        return True\n    # both are not None and thus the count must be in the closed interval\n    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:"
            },
            {
              "lineno": 85,
              "coloffset": 4,
              "linematch": "if min_value is not None:",
              "linematch_context": "    if min_value is not None and max_value is not None:\n        return is_in_closed_interval(count, min_value, max_value)\n    # at this point, only one of the values might not be None\n    # if min_value is not None, then confirm that it is greater than or equal\n    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:"
            },
            {
              "lineno": 89,
              "coloffset": 4,
              "linematch": "if max_value is not None:",
              "linematch_context": "    if min_value is not None:\n        if count >= min_value:\n            return True\n    # if max_value is not None, then confirm that it is less than or equal\n    if max_value is not None:\n        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "return False",
              "linematch_context": "        if count <= max_value:\n            return True\n    # if none of those conditions were true, then the count is not\n    # between the minimum and the maximum value, inclusively\n    return False\n\n\ndef make_checks_status_message(check_status: bool) -> str:\n    \"\"\"Make a check status message in human readable format.\"\"\"\n    if check_status:"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "\"\"\"Make a check status message in human readable format.\"\"\"",
              "linematch_context": "    return False\n\n\ndef make_checks_status_message(check_status: bool) -> str:\n    \"\"\"Make a check status message in human readable format.\"\"\"\n    if check_status:\n        return f\":smiley: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    return (\n        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    )"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "if check_status:",
              "linematch_context": "\n\ndef make_checks_status_message(check_status: bool) -> str:\n    \"\"\"Make a check status message in human readable format.\"\"\"\n    if check_status:\n        return f\":smiley: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    return (\n        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    )\n"
            },
            {
              "lineno": 101,
              "coloffset": 4,
              "linematch": "return (",
              "linematch_context": "def make_checks_status_message(check_status: bool) -> str:\n    \"\"\"Make a check status message in human readable format.\"\"\"\n    if check_status:\n        return f\":smiley: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    return (\n        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\"\n    )\n\n\ndef fix_check_criterion("
            },
            {
              "lineno": 109,
              "coloffset": 4,
              "linematch": "\"\"\"Remove null values from a criterion.\"\"\"",
              "linematch_context": "\ndef fix_check_criterion(\n    criterion: Union[enumerations.FilterableAttribute, str, int]\n) -> Union[str, int]:\n    \"\"\"Remove null values from a criterion.\"\"\"\n    # the converted criterion's default is an empty string\n    new_criterion: Union[str, int] = \"\"\n    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:"
            },
            {
              "lineno": 111,
              "coloffset": 4,
              "linematch": "new_criterion: Union[str, int] = \"\"",
              "linematch_context": "    criterion: Union[enumerations.FilterableAttribute, str, int]\n) -> Union[str, int]:\n    \"\"\"Remove null values from a criterion.\"\"\"\n    # the converted criterion's default is an empty string\n    new_criterion: Union[str, int] = \"\"\n    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "if criterion is not None:",
              "linematch_context": "    # the converted criterion's default is an empty string\n    new_criterion: Union[str, int] = \"\"\n    # if the criterion is not None, then it should either be\n    # the value in the enumeration or the value of a string or int\n    if criterion is not None:\n        # the criterion is an enum and thus the value must be extracted\n        if type(criterion) is enumerations.FilterableAttribute:\n            new_criterion = criterion.value\n        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly"
            },
            {
              "lineno": 122,
              "coloffset": 4,
              "linematch": "return new_criterion",
              "linematch_context": "        # the criterion is not an enum and thus it must be\n        # an int or a string that can be stored directly\n        else:\n            new_criterion = criterion  # type: ignore\n    return new_criterion"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "\"\"\"Create a view that combines results in the database tables.\"\"\"",
              "linematch_context": "small_bullet_unicode = constants.markers.Small_Bullet_Unicode\n\n\ndef create_chasten_view(chasten_database_name: str) -> None:\n    \"\"\"Create a view that combines results in the database tables.\"\"\"\n    database = Database(chasten_database_name)\n    # create a \"virtual table\" (i.e., a view) that is the result\n    # of running the pre-defined query; note that this query\n    # organizes all of chasten's results into a single table.\n    # When using datasette each of the columns in this view"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "database = Database(chasten_database_name)",
              "linematch_context": "\n\ndef create_chasten_view(chasten_database_name: str) -> None:\n    \"\"\"Create a view that combines results in the database tables.\"\"\"\n    database = Database(chasten_database_name)\n    # create a \"virtual table\" (i.e., a view) that is the result\n    # of running the pre-defined query; note that this query\n    # organizes all of chasten's results into a single table.\n    # When using datasette each of the columns in this view\n    # are \"facetable\" which means that they can be enabled or disabled"
            },
            {
              "lineno": 49,
              "coloffset": 4,
              "linematch": "database.create_view(",
              "linematch_context": "    # organizes all of chasten's results into a single table.\n    # When using datasette each of the columns in this view\n    # are \"facetable\" which means that they can be enabled or disabled\n    # inside of the web-based user interface\n    database.create_view(\n        constants.chasten.Chasten_Database_View, CHASTEN_SQL_SELECT_QUERY\n    )\n\n\ndef enable_full_text_search(chasten_database_name: str) -> None:"
            },
            {
              "lineno": 55,
              "coloffset": 4,
              "linematch": "\"\"\"Enable full-text search in the specific SQLite3 database.\"\"\"",
              "linematch_context": "    )\n\n\ndef enable_full_text_search(chasten_database_name: str) -> None:\n    \"\"\"Enable full-text search in the specific SQLite3 database.\"\"\"\n    database = Database(chasten_database_name)\n    # enable full-text search on the main database table\n    database[\"main\"].enable_fts(\n        [\n            \"configuration_chastenversion\","
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "database = Database(chasten_database_name)",
              "linematch_context": "\n\ndef enable_full_text_search(chasten_database_name: str) -> None:\n    \"\"\"Enable full-text search in the specific SQLite3 database.\"\"\"\n    database = Database(chasten_database_name)\n    # enable full-text search on the main database table\n    database[\"main\"].enable_fts(\n        [\n            \"configuration_chastenversion\",\n            \"configuration_projectname\","
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "database[\"main\"].enable_fts(",
              "linematch_context": "def enable_full_text_search(chasten_database_name: str) -> None:\n    \"\"\"Enable full-text search in the specific SQLite3 database.\"\"\"\n    database = Database(chasten_database_name)\n    # enable full-text search on the main database table\n    database[\"main\"].enable_fts(\n        [\n            \"configuration_chastenversion\",\n            \"configuration_projectname\",\n            \"configuration_datetime\",\n        ]"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "database[\"sources\"].enable_fts(",
              "linematch_context": "            \"configuration_datetime\",\n        ]\n    )\n    # enable full-text search on the sources database table\n    database[\"sources\"].enable_fts(\n        [\n            \"filename\",\n            \"check_id\",\n            \"check_name\",\n            \"check_description\","
            },
            {
              "lineno": 76,
              "coloffset": 4,
              "linematch": "database[\"sources_check_matches\"].enable_fts(",
              "linematch_context": "            \"check_pattern\",\n        ]\n    )\n    # enable full-text search on the sources database table\n    database[\"sources_check_matches\"].enable_fts(\n        [\n            \"lineno\",\n            \"coloffset\",\n            \"linematch\",\n        ]"
            },
            {
              "lineno": 88,
              "coloffset": 4,
              "linematch": "\"\"\"Output the final diagnostic message before control is given to a different tool.\"\"\"",
              "linematch_context": "    # full-text search on the view called chasten_complete\n\n\ndef display_final_diagnostic_message(datasette_platform: str, publish: bool):\n    \"\"\"Output the final diagnostic message before control is given to a different tool.\"\"\"\n    # output a \"final\" prompt about either the publication platform of a reminder\n    # that the remainder of the output comes from running a local datasette instance\n    # the database will be published to an external platform\n    if publish:\n        output.console.print("
            },
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "if publish:",
              "linematch_context": "    \"\"\"Output the final diagnostic message before control is given to a different tool.\"\"\"\n    # output a \"final\" prompt about either the publication platform of a reminder\n    # that the remainder of the output comes from running a local datasette instance\n    # the database will be published to an external platform\n    if publish:\n        output.console.print(\n            f\":sparkles: Debugging output from publishing datasette to '{datasette_platform}':\"\n        )\n    # the database will be displayed through a localhost-based server\n    else:"
            },
            {
              "lineno": 101,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    else:\n        output.console.print(\n            \":sparkles: Debugging output from the local datasette server:\"\n        )\n    output.console.print()\n\n\ndef display_datasette_details(\n    label: str,\n    virtual_env_location: str,"
            },
            {
              "lineno": 110,
              "coloffset": 4,
              "linematch": "\"\"\"Display details about the current datasette configuration.\"\"\"",
              "linematch_context": "    virtual_env_location: str,\n    executable_path: str,\n    full_executable_name: str,\n) -> None:\n    \"\"\"Display details about the current datasette configuration.\"\"\"\n    # output diagnostic information about the datasette instance; note\n    # that the output must appear here and not from the calling function\n    # because once the datasette instance starts the chasten tool can\n    # no longer produce output in the console\n    output.console.print()"
            },
            {
              "lineno": 115,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    # output diagnostic information about the datasette instance; note\n    # that the output must appear here and not from the calling function\n    # because once the datasette instance starts the chasten tool can\n    # no longer produce output in the console\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\"\n    )\n    if executable_path:"
            },
            {
              "lineno": 116,
              "coloffset": 4,
              "linematch": "output.console.print(label)",
              "linematch_context": "    # that the output must appear here and not from the calling function\n    # because once the datasette instance starts the chasten tool can\n    # no longer produce output in the console\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\"\n    )\n    if executable_path:\n        output.console.print("
            },
            {
              "lineno": 117,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": "    # because once the datasette instance starts the chasten tool can\n    # no longer produce output in the console\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\"\n    )\n    if executable_path:\n        output.console.print(\n            f\"{constants.markers.Indent}{small_bullet_unicode} Program: '{output.shorten_file_name(executable_path, 120)}'\""
            },
            {
              "lineno": 120,
              "coloffset": 4,
              "linematch": "if executable_path:",
              "linematch_context": "    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\"\n    )\n    if executable_path:\n        output.console.print(\n            f\"{constants.markers.Indent}{small_bullet_unicode} Program: '{output.shorten_file_name(executable_path, 120)}'\"\n        )\n    else:\n        output.console.print("
            },
            {
              "lineno": 128,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    else:\n        output.console.print(\n            f\"{constants.markers.Indent}{small_bullet_unicode} Cannot find: '{output.shorten_file_name(full_executable_name, 120)}'\"\n        )\n    output.console.print()\n\n\ndef start_datasette_server(  # noqa: PLR0912, PLR0913\n    database_path: Path,\n    datasette_metadata: Path,"
            },
            {
              "lineno": 139,
              "coloffset": 4,
              "linematch": "\"\"\"Start a local datasette server.\"\"\"",
              "linematch_context": "    datasette_port: int = 8001,\n    publish: bool = False,\n    OpSystem: str = \"Linux\",\n) -> None:\n    \"\"\"Start a local datasette server.\"\"\"\n    # define the name of the executable needed to run the server\n    # define the name of the file that contains datasette metadata;\n    # note that by default the metadata could be None and thus it\n    # will not be passed as a -m argument to the datasette program\n    metadata = datasette_metadata"
            },
            {
              "lineno": 144,
              "coloffset": 4,
              "linematch": "metadata = datasette_metadata",
              "linematch_context": "    # define the name of the executable needed to run the server\n    # define the name of the file that contains datasette metadata;\n    # note that by default the metadata could be None and thus it\n    # will not be passed as a -m argument to the datasette program\n    metadata = datasette_metadata\n    # identify the location at which the virtual environment exists;\n    # note that this is the location where executable dependencies of\n    # chasten will exist in a bin directory. For instance, the \"datasette\"\n    # executable that is a dependency of chasten can be found by starting\n    # the search from this location for the virtual environment."
            },
            {
              "lineno": 150,
              "coloffset": 4,
              "linematch": "full_executable_name = util.executable_name(",
              "linematch_context": "    # note that this is the location where executable dependencies of\n    # chasten will exist in a bin directory. For instance, the \"datasette\"\n    # executable that is a dependency of chasten can be found by starting\n    # the search from this location for the virtual environment.\n    full_executable_name = util.executable_name(\n        constants.datasette.Datasette_Executable, OpSystem\n    )\n    (found_executable, executable_path) = filesystem.can_find_executable(\n        full_executable_name\n    )"
            },
            {
              "lineno": 153,
              "coloffset": 4,
              "linematch": "(found_executable, executable_path) = filesystem.can_find_executable(",
              "linematch_context": "    # the search from this location for the virtual environment.\n    full_executable_name = util.executable_name(\n        constants.datasette.Datasette_Executable, OpSystem\n    )\n    (found_executable, executable_path) = filesystem.can_find_executable(\n        full_executable_name\n    )\n    # output diagnostic information about the datasette instance; note\n    # that the output must appear here and not from the calling function\n    # because once the datasette instance starts the chasten tool can"
            },
            {
              "lineno": 160,
              "coloffset": 4,
              "linematch": "if publish:",
              "linematch_context": "    # output diagnostic information about the datasette instance; note\n    # that the output must appear here and not from the calling function\n    # because once the datasette instance starts the chasten tool can\n    # no longer produce output in the console\n    if publish:\n        label = \":sparkles: Details for datasette publishing:\"\n    else:\n        label = \":sparkles: Details for datasette startup:\"\n    display_datasette_details(\n        label,"
            },
            {
              "lineno": 164,
              "coloffset": 4,
              "linematch": "display_datasette_details(",
              "linematch_context": "    if publish:\n        label = \":sparkles: Details for datasette publishing:\"\n    else:\n        label = \":sparkles: Details for datasette startup:\"\n    display_datasette_details(\n        label,\n        sys.prefix,\n        str(executable_path),\n        full_executable_name,\n    )"
            },
            {
              "lineno": 172,
              "coloffset": 4,
              "linematch": "if not found_executable:",
              "linematch_context": "        full_executable_name,\n    )\n    # since it was not possible to find the executable for datasette, display and\n    # error message and then exit this function since no further steps are possible\n    if not found_executable:\n        output.console.print(\n            f\":person_shrugging: Was not able to find {constants.datasette.Datasette_Executable}\"\n        )\n        return None\n    # run the localhost server because the"
            },
            {
              "lineno": 179,
              "coloffset": 4,
              "linematch": "if not publish:",
              "linematch_context": "        )\n        return None\n    # run the localhost server because the\n    # function was not asked to publish a database\n    if not publish:\n        # the metadata parameter should not be passed to the datasette\n        # program if it was not specified as an option\n        if metadata is not None:\n            cmd = [\n                str(full_executable_name),"
            },
            {
              "lineno": 271,
              "coloffset": 4,
              "linematch": "\"\"\"Run frogmouth as a subprocess of chasten\"\"\"",
              "linematch_context": "        proc.wait()\n\n\ndef display_results_frog_mouth(result_file, OpSystem) -> None:\n    \"\"\"Run frogmouth as a subprocess of chasten\"\"\"\n    cmd = [\n        \"frogmouth\",\n        result_file,\n    ]\n    executable = util.executable_name(\"frogmouth\", OpSystem)"
            },
            {
              "lineno": 272,
              "coloffset": 4,
              "linematch": "cmd = [",
              "linematch_context": "\n\ndef display_results_frog_mouth(result_file, OpSystem) -> None:\n    \"\"\"Run frogmouth as a subprocess of chasten\"\"\"\n    cmd = [\n        \"frogmouth\",\n        result_file,\n    ]\n    executable = util.executable_name(\"frogmouth\", OpSystem)\n    exec_found, executable_path = filesystem.can_find_executable(executable)"
            },
            {
              "lineno": 276,
              "coloffset": 4,
              "linematch": "executable = util.executable_name(\"frogmouth\", OpSystem)",
              "linematch_context": "    cmd = [\n        \"frogmouth\",\n        result_file,\n    ]\n    executable = util.executable_name(\"frogmouth\", OpSystem)\n    exec_found, executable_path = filesystem.can_find_executable(executable)\n    if exec_found:\n        # run frogmouth with specified path\n        output.console.print(\"\\n\ud83d\udc38 Frogmouth Information\\n\")\n        output.console.print(f\" {small_bullet_unicode} Venv: {sys.prefix}\")"
            },
            {
              "lineno": 277,
              "coloffset": 4,
              "linematch": "exec_found, executable_path = filesystem.can_find_executable(executable)",
              "linematch_context": "        \"frogmouth\",\n        result_file,\n    ]\n    executable = util.executable_name(\"frogmouth\", OpSystem)\n    exec_found, executable_path = filesystem.can_find_executable(executable)\n    if exec_found:\n        # run frogmouth with specified path\n        output.console.print(\"\\n\ud83d\udc38 Frogmouth Information\\n\")\n        output.console.print(f\" {small_bullet_unicode} Venv: {sys.prefix}\")\n        output.console.print(f\" {small_bullet_unicode} Program: {executable_path}\")"
            },
            {
              "lineno": 278,
              "coloffset": 4,
              "linematch": "if exec_found:",
              "linematch_context": "        result_file,\n    ]\n    executable = util.executable_name(\"frogmouth\", OpSystem)\n    exec_found, executable_path = filesystem.can_find_executable(executable)\n    if exec_found:\n        # run frogmouth with specified path\n        output.console.print(\"\\n\ud83d\udc38 Frogmouth Information\\n\")\n        output.console.print(f\" {small_bullet_unicode} Venv: {sys.prefix}\")\n        output.console.print(f\" {small_bullet_unicode} Program: {executable_path}\")\n        proc = subprocess.Popen(cmd)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "\"\"\"Detect the configuration.\"\"\"",
              "linematch_context": "}\n\n\ndef detect_configuration(config: Optional[Path]) -> str:\n    \"\"\"Detect the configuration.\"\"\"\n    # there is a specified configuration directory path and thus\n    # this overrides the use of the platform-specific configuration\n    if config is not None:\n        chasten_user_config_dir_str = str(config)\n    # there is no configuration directory specified and thus"
            },
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "if config is not None:",
              "linematch_context": "def detect_configuration(config: Optional[Path]) -> str:\n    \"\"\"Detect the configuration.\"\"\"\n    # there is a specified configuration directory path and thus\n    # this overrides the use of the platform-specific configuration\n    if config is not None:\n        chasten_user_config_dir_str = str(config)\n    # there is no configuration directory specified and thus\n    # this function should access the platform-specific\n    # configuration directory detected by platformdirs\n    else:"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "return chasten_user_config_dir_str",
              "linematch_context": "            application_name=constants.chasten.Application_Name,\n            application_author=constants.chasten.Application_Author,\n        )\n    # return in string form the detected configuration directory\n    return chasten_user_config_dir_str\n\n\ndef create_configuration_directory(\n    config: Optional[Path] = None, force: bool = False\n) -> Union[Path, NoReturn]:"
            },
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "\"\"\"Create the configuration directory.\"\"\"",
              "linematch_context": "\ndef create_configuration_directory(\n    config: Optional[Path] = None, force: bool = False\n) -> Union[Path, NoReturn]:\n    \"\"\"Create the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)\n    # create a path out of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # recursively delete the configuration directory and all of its"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_str = detect_configuration(config)",
              "linematch_context": "    config: Optional[Path] = None, force: bool = False\n) -> Union[Path, NoReturn]:\n    \"\"\"Create the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)\n    # create a path out of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # recursively delete the configuration directory and all of its\n    # contents because the force parameter permits deletion\n    if force:"
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_path = Path(chasten_user_config_dir_str)",
              "linematch_context": "    \"\"\"Create the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)\n    # create a path out of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # recursively delete the configuration directory and all of its\n    # contents because the force parameter permits deletion\n    if force:\n        shutil.rmtree(chasten_user_config_dir_path)\n    # create the configuration directory, a step that"
            },
            {
              "lineno": 99,
              "coloffset": 4,
              "linematch": "if force:",
              "linematch_context": "    # create a path out of the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # recursively delete the configuration directory and all of its\n    # contents because the force parameter permits deletion\n    if force:\n        shutil.rmtree(chasten_user_config_dir_path)\n    # create the configuration directory, a step that\n    # may fail if the directory already exists; in this\n    # case the FileExistsError will be passed to caller\n    chasten_user_config_dir_path.mkdir(parents=True)"
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_path.mkdir(parents=True)",
              "linematch_context": "        shutil.rmtree(chasten_user_config_dir_path)\n    # create the configuration directory, a step that\n    # may fail if the directory already exists; in this\n    # case the FileExistsError will be passed to caller\n    chasten_user_config_dir_path.mkdir(parents=True)\n    return chasten_user_config_dir_path\n\n\ndef create_configuration_file(\n    config: Path, config_file_name: str = constants.filesystem.Main_Configuration_File"
            },
            {
              "lineno": 105,
              "coloffset": 4,
              "linematch": "return chasten_user_config_dir_path",
              "linematch_context": "    # create the configuration directory, a step that\n    # may fail if the directory already exists; in this\n    # case the FileExistsError will be passed to caller\n    chasten_user_config_dir_path.mkdir(parents=True)\n    return chasten_user_config_dir_path\n\n\ndef create_configuration_file(\n    config: Path, config_file_name: str = constants.filesystem.Main_Configuration_File\n) -> None:"
            },
            {
              "lineno": 111,
              "coloffset": 4,
              "linematch": "\"\"\"Create the main configuration file in the configuration directory.\"\"\"",
              "linematch_context": "\ndef create_configuration_file(\n    config: Path, config_file_name: str = constants.filesystem.Main_Configuration_File\n) -> None:\n    \"\"\"Create the main configuration file in the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)\n    # create the final path to the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # create a path to the configuration file"
            },
            {
              "lineno": 113,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_str = detect_configuration(config)",
              "linematch_context": "    config: Path, config_file_name: str = constants.filesystem.Main_Configuration_File\n) -> None:\n    \"\"\"Create the main configuration file in the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)\n    # create the final path to the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # create a path to the configuration file\n    chasten_user_config_main_file = chasten_user_config_dir_path / Path(\n        config_file_name"
            },
            {
              "lineno": 115,
              "coloffset": 4,
              "linematch": "chasten_user_config_dir_path = Path(chasten_user_config_dir_str)",
              "linematch_context": "    \"\"\"Create the main configuration file in the configuration directory.\"\"\"\n    # detect the configuration directory\n    chasten_user_config_dir_str = detect_configuration(config)\n    # create the final path to the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # create a path to the configuration file\n    chasten_user_config_main_file = chasten_user_config_dir_path / Path(\n        config_file_name\n    )\n    # create the file (if it does not exist)"
            },
            {
              "lineno": 117,
              "coloffset": 4,
              "linematch": "chasten_user_config_main_file = chasten_user_config_dir_path / Path(",
              "linematch_context": "    chasten_user_config_dir_str = detect_configuration(config)\n    # create the final path to the configuration directory\n    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)\n    # create a path to the configuration file\n    chasten_user_config_main_file = chasten_user_config_dir_path / Path(\n        config_file_name\n    )\n    # create the file (if it does not exist)\n    chasten_user_config_main_file.touch()\n    # write the default contents of the file"
            },
            {
              "lineno": 121,
              "coloffset": 4,
              "linematch": "chasten_user_config_main_file.touch()",
              "linematch_context": "    chasten_user_config_main_file = chasten_user_config_dir_path / Path(\n        config_file_name\n    )\n    # create the file (if it does not exist)\n    chasten_user_config_main_file.touch()\n    # write the default contents of the file\n    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]\n    chasten_user_config_main_file.write_text(file_contents)\n\n"
            },
            {
              "lineno": 123,
              "coloffset": 4,
              "linematch": "file_contents = FILE_CONTENTS_LOOKUP[config_file_name]",
              "linematch_context": "    )\n    # create the file (if it does not exist)\n    chasten_user_config_main_file.touch()\n    # write the default contents of the file\n    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]\n    chasten_user_config_main_file.write_text(file_contents)\n\n\ndef create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\""
            },
            {
              "lineno": 124,
              "coloffset": 4,
              "linematch": "chasten_user_config_main_file.write_text(file_contents)",
              "linematch_context": "    # create the file (if it does not exist)\n    chasten_user_config_main_file.touch()\n    # write the default contents of the file\n    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]\n    chasten_user_config_main_file.write_text(file_contents)\n\n\ndef create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it"
            },
            {
              "lineno": 128,
              "coloffset": 4,
              "linematch": "\"\"\"Create a directory tree visualization using the Rich tree.\"\"\"",
              "linematch_context": "    chasten_user_config_main_file.write_text(file_contents)\n\n\ndef create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")\n    # add the new file node to the tree since"
            },
            {
              "lineno": 131,
              "coloffset": 4,
              "linematch": "if tree is None:",
              "linematch_context": "def create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")\n    # add the new file node to the tree since\n    # the tree has already been created\n    else:\n        tree = tree.add(f\":open_file_folder: {path.name}\")"
            },
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "if path.is_dir():",
              "linematch_context": "    # the tree has already been created\n    else:\n        tree = tree.add(f\":open_file_folder: {path.name}\")\n    # recursively process the directory\n    if path.is_dir():\n        for item in path.iterdir():\n            if item.is_dir():\n                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")"
            },
            {
              "lineno": 145,
              "coloffset": 4,
              "linematch": "return tree",
              "linematch_context": "                create_directory_tree_visualization(item, tree)\n            else:\n                tree.add(f\":page_facing_up: {item.name}\")\n    # return the tree now containing all nodes\n    return tree\n\n\ndef confirm_valid_file(file: Path) -> bool:\n    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file"
            },
            {
              "lineno": 149,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"",
              "linematch_context": "    return tree\n\n\ndef confirm_valid_file(file: Path) -> bool:\n    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():\n            return True"
            },
            {
              "lineno": 151,
              "coloffset": 4,
              "linematch": "if file is not None:",
              "linematch_context": "\ndef confirm_valid_file(file: Path) -> bool:\n    \"\"\"Confirm that the provided file is a valid path that is a file.\"\"\"\n    # determine if the file is not None and if it is a file\n    if file is not None:\n        # the file is valid\n        if file.is_file() and file.exists():\n            return True\n    # the file was either none or not valid\n    return False"
            },
            {
              "lineno": 156,
              "coloffset": 4,
              "linematch": "return False",
              "linematch_context": "        # the file is valid\n        if file.is_file() and file.exists():\n            return True\n    # the file was either none or not valid\n    return False\n\n\ndef confirm_valid_directory(directory: Path) -> bool:\n    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file"
            },
            {
              "lineno": 160,
              "coloffset": 4,
              "linematch": "\"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"",
              "linematch_context": "    return False\n\n\ndef confirm_valid_directory(directory: Path) -> bool:\n    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True"
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "if directory is not None:",
              "linematch_context": "\ndef confirm_valid_directory(directory: Path) -> bool:\n    \"\"\"Confirm that the provided directory is a valid path that is a directory.\"\"\"\n    # determine if the file is not None and if it is a file\n    if directory is not None:\n        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True\n    # the directory was either none or not valid\n    return False"
            },
            {
              "lineno": 167,
              "coloffset": 4,
              "linematch": "return False",
              "linematch_context": "        # the file is valid\n        if directory.is_dir() and directory.exists():\n            return True\n    # the directory was either none or not valid\n    return False\n\n\ndef get_default_directory_list() -> List[Path]:\n    \"\"\"Return the default directory list that is the current working directory by itself.\"\"\"\n    default_directory_list = [Path(constants.filesystem.Current_Directory)]"
            },
            {
              "lineno": 171,
              "coloffset": 4,
              "linematch": "\"\"\"Return the default directory list that is the current working directory by itself.\"\"\"",
              "linematch_context": "    return False\n\n\ndef get_default_directory_list() -> List[Path]:\n    \"\"\"Return the default directory list that is the current working directory by itself.\"\"\"\n    default_directory_list = [Path(constants.filesystem.Current_Directory)]\n    return default_directory_list\n\n\ndef write_chasten_results("
            },
            {
              "lineno": 172,
              "coloffset": 4,
              "linematch": "default_directory_list = [Path(constants.filesystem.Current_Directory)]",
              "linematch_context": "\n\ndef get_default_directory_list() -> List[Path]:\n    \"\"\"Return the default directory list that is the current working directory by itself.\"\"\"\n    default_directory_list = [Path(constants.filesystem.Current_Directory)]\n    return default_directory_list\n\n\ndef write_chasten_results(\n    results_path: Path,"
            },
            {
              "lineno": 173,
              "coloffset": 4,
              "linematch": "return default_directory_list",
              "linematch_context": "\ndef get_default_directory_list() -> List[Path]:\n    \"\"\"Return the default directory list that is the current working directory by itself.\"\"\"\n    default_directory_list = [Path(constants.filesystem.Current_Directory)]\n    return default_directory_list\n\n\ndef write_chasten_results(\n    results_path: Path,\n    projectname: str,"
            },
            {
              "lineno": 182,
              "coloffset": 4,
              "linematch": "\"\"\"Write the results of a Chasten subclass of Pydantic BaseModel to the specified directory.\"\"\"",
              "linematch_context": "    projectname: str,\n    results_content: results.Chasten,\n    save: bool = False,\n) -> str:\n    \"\"\"Write the results of a Chasten subclass of Pydantic BaseModel to the specified directory.\"\"\"\n    if save:\n        # extract the unique hexadecimal code that will ensure that\n        # this file name is unique when it is being saved\n        results_file_uuid = results_content.configuration.fileuuid\n        # extract the current date and time when results were created"
            },
            {
              "lineno": 183,
              "coloffset": 4,
              "linematch": "if save:",
              "linematch_context": "    results_content: results.Chasten,\n    save: bool = False,\n) -> str:\n    \"\"\"Write the results of a Chasten subclass of Pydantic BaseModel to the specified directory.\"\"\"\n    if save:\n        # extract the unique hexadecimal code that will ensure that\n        # this file name is unique when it is being saved\n        results_file_uuid = results_content.configuration.fileuuid\n        # extract the current date and time when results were created\n        formatted_datetime = results_content.configuration._datetime"
            },
            {
              "lineno": 209,
              "coloffset": 4,
              "linematch": "return constants.markers.Empty_String",
              "linematch_context": "        # return the name of the created file for diagnostic purposes\n        return complete_results_file_name\n    # saving was not enabled and thus this function cannot\n    # return the name of the file that was created during saving\n    return constants.markers.Empty_String\n\n\ndef write_dict_results(\n    results_json: str,\n    results_path: Path,"
            },
            {
              "lineno": 217,
              "coloffset": 4,
              "linematch": "\"\"\"Write a JSON file with results to the specified directory.\"\"\"",
              "linematch_context": "    results_json: str,\n    results_path: Path,\n    projectname: str,\n) -> str:\n    \"\"\"Write a JSON file with results to the specified directory.\"\"\"\n    # generate a unique hexadecimal code that will ensure that\n    # this file name is unique when it is being saved\n    results_file_uuid = uuid.uuid4().hex\n    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            },
            {
              "lineno": 220,
              "coloffset": 4,
              "linematch": "results_file_uuid = uuid.uuid4().hex",
              "linematch_context": ") -> str:\n    \"\"\"Write a JSON file with results to the specified directory.\"\"\"\n    # generate a unique hexadecimal code that will ensure that\n    # this file name is unique when it is being saved\n    results_file_uuid = uuid.uuid4().hex\n    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n    # create a file name so that it includes:\n    # a) the name of the project\n    # b) the date on which analysis was completed"
            },
            {
              "lineno": 222,
              "coloffset": 4,
              "linematch": "formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))",
              "linematch_context": "    # generate a unique hexadecimal code that will ensure that\n    # this file name is unique when it is being saved\n    results_file_uuid = uuid.uuid4().hex\n    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n    # create a file name so that it includes:\n    # a) the name of the project\n    # b) the date on which analysis was completed\n    # c) a unique identifier to handle cased when\n    #    two result files are created at \"same time\""
            },
            {
              "lineno": 229,
              "coloffset": 4,
              "linematch": "complete_results_file_name = f\"{constants.filesystem.Main_Results_Combined_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\"",
              "linematch_context": "    # b) the date on which analysis was completed\n    # c) a unique identifier to handle cased when\n    #    two result files are created at \"same time\"\n    # d) Clear indiciator in the name that this is a combined result\n    complete_results_file_name = f\"{constants.filesystem.Main_Results_Combined_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\"\n    # create the file and then write the text,\n    # using indentation to ensure that JSON file is readable\n    results_path_with_file = results_path / complete_results_file_name\n    # use the built-in method from pathlib Path to write the JSON contents\n    results_path_with_file.write_text(results_json, \"utf-8\")"
            },
            {
              "lineno": 232,
              "coloffset": 4,
              "linematch": "results_path_with_file = results_path / complete_results_file_name",
              "linematch_context": "    # d) Clear indiciator in the name that this is a combined result\n    complete_results_file_name = f\"{constants.filesystem.Main_Results_Combined_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\"\n    # create the file and then write the text,\n    # using indentation to ensure that JSON file is readable\n    results_path_with_file = results_path / complete_results_file_name\n    # use the built-in method from pathlib Path to write the JSON contents\n    results_path_with_file.write_text(results_json, \"utf-8\")\n    # return the name of the file that contains the JSON dictionary contents\n    return complete_results_file_name\n"
            },
            {
              "lineno": 234,
              "coloffset": 4,
              "linematch": "results_path_with_file.write_text(results_json, \"utf-8\")",
              "linematch_context": "    # create the file and then write the text,\n    # using indentation to ensure that JSON file is readable\n    results_path_with_file = results_path / complete_results_file_name\n    # use the built-in method from pathlib Path to write the JSON contents\n    results_path_with_file.write_text(results_json, \"utf-8\")\n    # return the name of the file that contains the JSON dictionary contents\n    return complete_results_file_name\n\n\ndef write_flattened_csv_and_database("
            },
            {
              "lineno": 236,
              "coloffset": 4,
              "linematch": "return complete_results_file_name",
              "linematch_context": "    results_path_with_file = results_path / complete_results_file_name\n    # use the built-in method from pathlib Path to write the JSON contents\n    results_path_with_file.write_text(results_json, \"utf-8\")\n    # return the name of the file that contains the JSON dictionary contents\n    return complete_results_file_name\n\n\ndef write_flattened_csv_and_database(\n    combined_results_json: str,\n    results_path: Path,"
            },
            {
              "lineno": 244,
              "coloffset": 4,
              "linematch": "\"\"\"Write flattened CSV files with results to the specified directory and create the database.\"\"\"",
              "linematch_context": "    combined_results_json: str,\n    results_path: Path,\n    projectname: str,\n) -> str:\n    \"\"\"Write flattened CSV files with results to the specified directory and create the database.\"\"\"\n    # generate a unique hexadecimal code that will ensure that\n    # this file name is unique when it is being saved\n    results_file_uuid = uuid.uuid4().hex\n    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            },
            {
              "lineno": 247,
              "coloffset": 4,
              "linematch": "results_file_uuid = uuid.uuid4().hex",
              "linematch_context": ") -> str:\n    \"\"\"Write flattened CSV files with results to the specified directory and create the database.\"\"\"\n    # generate a unique hexadecimal code that will ensure that\n    # this file name is unique when it is being saved\n    results_file_uuid = uuid.uuid4().hex\n    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n    # create a string-based name for the JSON file that contains\n    # the combined results, suitable for input to the flatten function\n    combined_results_json_file = results_path / Path(combined_results_json)"
            },
            {
              "lineno": 249,
              "coloffset": 4,
              "linematch": "formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))",
              "linematch_context": "    # generate a unique hexadecimal code that will ensure that\n    # this file name is unique when it is being saved\n    results_file_uuid = uuid.uuid4().hex\n    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n    # create a string-based name for the JSON file that contains\n    # the combined results, suitable for input to the flatten function\n    combined_results_json_file = results_path / Path(combined_results_json)\n    combined_results_json_file_str = str(combined_results_json_file)\n    # create a final part of the directory name so that it includes:"
            },
            {
              "lineno": 252,
              "coloffset": 4,
              "linematch": "combined_results_json_file = results_path / Path(combined_results_json)",
              "linematch_context": "    # create a formatted datetime\n    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n    # create a string-based name for the JSON file that contains\n    # the combined results, suitable for input to the flatten function\n    combined_results_json_file = results_path / Path(combined_results_json)\n    combined_results_json_file_str = str(combined_results_json_file)\n    # create a final part of the directory name so that it includes:\n    # a) the name of the project\n    # b) the date on which analysis was completed\n    # c) a unique identifier to handle cased when"
            },
            {
              "lineno": 253,
              "coloffset": 4,
              "linematch": "combined_results_json_file_str = str(combined_results_json_file)",
              "linematch_context": "    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))\n    # create a string-based name for the JSON file that contains\n    # the combined results, suitable for input to the flatten function\n    combined_results_json_file = results_path / Path(combined_results_json)\n    combined_results_json_file_str = str(combined_results_json_file)\n    # create a final part of the directory name so that it includes:\n    # a) the name of the project\n    # b) the date on which analysis was completed\n    # c) a unique identifier to handle cased when\n    #    two directories are created at \"same time\""
            },
            {
              "lineno": 259,
              "coloffset": 4,
              "linematch": "complete_flattened_results_directory_name = f\"{constants.filesystem.Main_Results_Flattened_Directory_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}\"",
              "linematch_context": "    # a) the name of the project\n    # b) the date on which analysis was completed\n    # c) a unique identifier to handle cased when\n    #    two directories are created at \"same time\"\n    complete_flattened_results_directory_name = f\"{constants.filesystem.Main_Results_Flattened_Directory_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}\"\n    # the output directory is contained inside of the results_path\n    flattened_output_directory = (\n        results_path / complete_flattened_results_directory_name\n    )\n    # the flatten function expects a string-based directory name"
            },
            {
              "lineno": 261,
              "coloffset": 4,
              "linematch": "flattened_output_directory = (",
              "linematch_context": "    # c) a unique identifier to handle cased when\n    #    two directories are created at \"same time\"\n    complete_flattened_results_directory_name = f\"{constants.filesystem.Main_Results_Flattened_Directory_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}\"\n    # the output directory is contained inside of the results_path\n    flattened_output_directory = (\n        results_path / complete_flattened_results_directory_name\n    )\n    # the flatten function expects a string-based directory name\n    flattened_output_directory_str = str(flattened_output_directory)\n    # the SQLite3 database file exists in the directory that will"
            },
            {
              "lineno": 265,
              "coloffset": 4,
              "linematch": "flattened_output_directory_str = str(flattened_output_directory)",
              "linematch_context": "    flattened_output_directory = (\n        results_path / complete_flattened_results_directory_name\n    )\n    # the flatten function expects a string-based directory name\n    flattened_output_directory_str = str(flattened_output_directory)\n    # the SQLite3 database file exists in the directory that will\n    # store all of the flattened results in the csv/ directory\n    database_file_name = (\n        flattened_output_directory / constants.datasette.Chasten_Database\n    )"
            },
            {
              "lineno": 268,
              "coloffset": 4,
              "linematch": "database_file_name = (",
              "linematch_context": "    # the flatten function expects a string-based directory name\n    flattened_output_directory_str = str(flattened_output_directory)\n    # the SQLite3 database file exists in the directory that will\n    # store all of the flattened results in the csv/ directory\n    database_file_name = (\n        flattened_output_directory / constants.datasette.Chasten_Database\n    )\n    database_file_name_str = str(database_file_name)\n    # perform the flattening, creating a directory called csv/ that\n    # contains all of the CSV files and a SQLite3 database called chasten.db"
            },
            {
              "lineno": 271,
              "coloffset": 4,
              "linematch": "database_file_name_str = str(database_file_name)",
              "linematch_context": "    # store all of the flattened results in the csv/ directory\n    database_file_name = (\n        flattened_output_directory / constants.datasette.Chasten_Database\n    )\n    database_file_name_str = str(database_file_name)\n    # perform the flattening, creating a directory called csv/ that\n    # contains all of the CSV files and a SQLite3 database called chasten.db\n    # that contains all of the contents of the CSV files; this chasten.db\n    # file is ready for browsing through the use of a tool like datasette\n    flatterer.flatten("
            },
            {
              "lineno": 276,
              "coloffset": 4,
              "linematch": "flatterer.flatten(",
              "linematch_context": "    # perform the flattening, creating a directory called csv/ that\n    # contains all of the CSV files and a SQLite3 database called chasten.db\n    # that contains all of the contents of the CSV files; this chasten.db\n    # file is ready for browsing through the use of a tool like datasette\n    flatterer.flatten(\n        combined_results_json_file_str,\n        flattened_output_directory_str,\n        csv=True,\n        sqlite=True,\n        sqlite_path=database_file_name_str,"
            },
            {
              "lineno": 284,
              "coloffset": 4,
              "linematch": "database.create_chasten_view(database_file_name_str)",
              "linematch_context": "        sqlite=True,\n        sqlite_path=database_file_name_str,\n    )\n    # create a view that combines all of the data\n    database.create_chasten_view(database_file_name_str)\n    # enable full-text search in the SQLite3 database\n    database.enable_full_text_search(database_file_name_str)\n    # return the name of the directory that contains the flattened CSV files\n    return flattened_output_directory_str\n"
            },
            {
              "lineno": 286,
              "coloffset": 4,
              "linematch": "database.enable_full_text_search(database_file_name_str)",
              "linematch_context": "    )\n    # create a view that combines all of the data\n    database.create_chasten_view(database_file_name_str)\n    # enable full-text search in the SQLite3 database\n    database.enable_full_text_search(database_file_name_str)\n    # return the name of the directory that contains the flattened CSV files\n    return flattened_output_directory_str\n\n\ndef get_json_results(json_paths: List[Path]) -> List[Dict[Any, Any]]:"
            },
            {
              "lineno": 288,
              "coloffset": 4,
              "linematch": "return flattened_output_directory_str",
              "linematch_context": "    database.create_chasten_view(database_file_name_str)\n    # enable full-text search in the SQLite3 database\n    database.enable_full_text_search(database_file_name_str)\n    # return the name of the directory that contains the flattened CSV files\n    return flattened_output_directory_str\n\n\ndef get_json_results(json_paths: List[Path]) -> List[Dict[Any, Any]]:\n    \"\"\"Get a list of dictionaries, one the contents of each JSON file path.\"\"\"\n    # create an empty list of dictionaries"
            },
            {
              "lineno": 292,
              "coloffset": 4,
              "linematch": "\"\"\"Get a list of dictionaries, one the contents of each JSON file path.\"\"\"",
              "linematch_context": "    return flattened_output_directory_str\n\n\ndef get_json_results(json_paths: List[Path]) -> List[Dict[Any, Any]]:\n    \"\"\"Get a list of dictionaries, one the contents of each JSON file path.\"\"\"\n    # create an empty list of dictionaries\n    json_dicts_list: List[Dict[Any, Any]] = []\n    # iterate through each of the provided paths to a JSON file\n    for json_path in json_paths:\n        # turn the contents of the current JSON file into a dictionary"
            },
            {
              "lineno": 294,
              "coloffset": 4,
              "linematch": "json_dicts_list: List[Dict[Any, Any]] = []",
              "linematch_context": "\ndef get_json_results(json_paths: List[Path]) -> List[Dict[Any, Any]]:\n    \"\"\"Get a list of dictionaries, one the contents of each JSON file path.\"\"\"\n    # create an empty list of dictionaries\n    json_dicts_list: List[Dict[Any, Any]] = []\n    # iterate through each of the provided paths to a JSON file\n    for json_path in json_paths:\n        # turn the contents of the current JSON file into a dictionary\n        json_dict = json.loads(json_path.read_text(\"utf-8\"))\n        # add the current dictionary to the list of dictionaries"
            },
            {
              "lineno": 296,
              "coloffset": 4,
              "linematch": "for json_path in json_paths:",
              "linematch_context": "    \"\"\"Get a list of dictionaries, one the contents of each JSON file path.\"\"\"\n    # create an empty list of dictionaries\n    json_dicts_list: List[Dict[Any, Any]] = []\n    # iterate through each of the provided paths to a JSON file\n    for json_path in json_paths:\n        # turn the contents of the current JSON file into a dictionary\n        json_dict = json.loads(json_path.read_text(\"utf-8\"))\n        # add the current dictionary to the list of dictionaries\n        json_dicts_list.append(json_dict)\n    # return the list of JSON dictionaries"
            },
            {
              "lineno": 302,
              "coloffset": 4,
              "linematch": "return json_dicts_list",
              "linematch_context": "        json_dict = json.loads(json_path.read_text(\"utf-8\"))\n        # add the current dictionary to the list of dictionaries\n        json_dicts_list.append(json_dict)\n    # return the list of JSON dictionaries\n    return json_dicts_list\n\n\ndef can_find_executable(executable_name: str) -> Tuple[bool, str]:\n    \"\"\"Determine whether or not it is possible to find an executable.\"\"\"\n    # use the shutil.which function to find the path of the executable"
            },
            {
              "lineno": 306,
              "coloffset": 4,
              "linematch": "\"\"\"Determine whether or not it is possible to find an executable.\"\"\"",
              "linematch_context": "    return json_dicts_list\n\n\ndef can_find_executable(executable_name: str) -> Tuple[bool, str]:\n    \"\"\"Determine whether or not it is possible to find an executable.\"\"\"\n    # use the shutil.which function to find the path of the executable\n    executable_path = shutil.which(executable_name)\n    # the executable is available in the path, so\n    # signal that it is found and return the full path\n    if executable_path is not None:"
            },
            {
              "lineno": 308,
              "coloffset": 4,
              "linematch": "executable_path = shutil.which(executable_name)",
              "linematch_context": "\ndef can_find_executable(executable_name: str) -> Tuple[bool, str]:\n    \"\"\"Determine whether or not it is possible to find an executable.\"\"\"\n    # use the shutil.which function to find the path of the executable\n    executable_path = shutil.which(executable_name)\n    # the executable is available in the path, so\n    # signal that it is found and return the full path\n    if executable_path is not None:\n        return (True, executable_path)\n    # the executable is not available, so signal its"
            },
            {
              "lineno": 311,
              "coloffset": 4,
              "linematch": "if executable_path is not None:",
              "linematch_context": "    # use the shutil.which function to find the path of the executable\n    executable_path = shutil.which(executable_name)\n    # the executable is available in the path, so\n    # signal that it is found and return the full path\n    if executable_path is not None:\n        return (True, executable_path)\n    # the executable is not available, so signal its\n    # absence and then return an emptry string instead of a path\n    return (False, constants.markers.Nothing)"
            },
            {
              "lineno": 315,
              "coloffset": 4,
              "linematch": "return (False, constants.markers.Nothing)",
              "linematch_context": "    if executable_path is not None:\n        return (True, executable_path)\n    # the executable is not available, so signal its\n    # absence and then return an emptry string instead of a path\n    return (False, constants.markers.Nothing)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/createchecks.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 60,
              "coloffset": 4,
              "linematch": "key = Fernet.generate_key()",
              "linematch_context": "API_KEY_FILE = \"userapikey.txt\"\n\n\ndef save_user_api_key(user_api_key):\n    key = Fernet.generate_key()\n    fernet = Fernet(key)\n    encrypted_key = fernet.encrypt(user_api_key.encode()).decode()\n    with open(API_KEY_FILE, \"w\") as f:\n        f.write(key.decode() + \"\\n\" + encrypted_key)\n"
            },
            {
              "lineno": 61,
              "coloffset": 4,
              "linematch": "fernet = Fernet(key)",
              "linematch_context": "\n\ndef save_user_api_key(user_api_key):\n    key = Fernet.generate_key()\n    fernet = Fernet(key)\n    encrypted_key = fernet.encrypt(user_api_key.encode()).decode()\n    with open(API_KEY_FILE, \"w\") as f:\n        f.write(key.decode() + \"\\n\" + encrypted_key)\n\n"
            },
            {
              "lineno": 62,
              "coloffset": 4,
              "linematch": "encrypted_key = fernet.encrypt(user_api_key.encode()).decode()",
              "linematch_context": "\ndef save_user_api_key(user_api_key):\n    key = Fernet.generate_key()\n    fernet = Fernet(key)\n    encrypted_key = fernet.encrypt(user_api_key.encode()).decode()\n    with open(API_KEY_FILE, \"w\") as f:\n        f.write(key.decode() + \"\\n\" + encrypted_key)\n\n\ndef load_user_api_key(file):"
            },
            {
              "lineno": 63,
              "coloffset": 4,
              "linematch": "with open(API_KEY_FILE, \"w\") as f:",
              "linematch_context": "def save_user_api_key(user_api_key):\n    key = Fernet.generate_key()\n    fernet = Fernet(key)\n    encrypted_key = fernet.encrypt(user_api_key.encode()).decode()\n    with open(API_KEY_FILE, \"w\") as f:\n        f.write(key.decode() + \"\\n\" + encrypted_key)\n\n\ndef load_user_api_key(file):\n    with open(file, \"r\") as f:"
            },
            {
              "lineno": 68,
              "coloffset": 4,
              "linematch": "with open(file, \"r\") as f:",
              "linematch_context": "        f.write(key.decode() + \"\\n\" + encrypted_key)\n\n\ndef load_user_api_key(file):\n    with open(file, \"r\") as f:\n        lines = f.read().strip().split(\"\\n\")\n        if len(lines) == 2:  # noqa: PLR2004\n            key = lines[0].encode()\n            encrypted_key = lines[1]\n        fernet = Fernet(key)"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "        return fernet.decrypt(encrypted_key.encode()).decode()\n\n\ndef is_valid_api_key(api_key):\n    try:\n        openai.api_key = api_key\n        openai.ChatCompletion.create(\n            model=\"gpt-3.5-turbo\",\n            messages=[{\"role\": \"system\", \"content\": \"Test message\"}],\n        )"
            },
            {
              "lineno": 90,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": "        return False\n\n\ndef generate_yaml_config(file: Path, user_api_key, user_input: str) -> str:\n    try:\n        openai.api_key = user_api_key\n\n        prompts = [\n            genscript\n            + \"in the same format as what is shown above(do not just generate the example use it as a framework nothing else): \""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/validate.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 105,
              "coloffset": 4,
              "linematch": "\"\"\"Validate the checks configuration.\"\"\"",
              "linematch_context": "\ndef extract_checks_file_name(\n    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files"
            },
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "if constants.checks.Check_Chasten in configuration.keys():",
              "linematch_context": "    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, List[str]]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    # there is a main \"chasten\" key\n    if constants.checks.Check_Chasten in configuration.keys():\n        # there is a \"checks-file\" key\n        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:\n            # extract the name of the checks-files\n            # and return them in a list with a boolean\n            # indicate to show that checks files were found"
            },
            {
              "lineno": 118,
              "coloffset": 4,
              "linematch": "return (False, [constants.markers.Empty_String])",
              "linematch_context": "                constants.checks.Check_File\n            ]\n            return (True, checks_file_name_list)\n    # contents were not found and thus returen no filenames\n    return (False, [constants.markers.Empty_String])\n\n\ndef validate_configuration(\n    configuration: Dict[str, Dict[str, Any]],\n    schema: Dict[str, Any] = JSON_SCHEMA_CONFIG,"
            },
            {
              "lineno": 125,
              "coloffset": 4,
              "linematch": "\"\"\"Validate the main configuration.\"\"\"",
              "linematch_context": "def validate_configuration(\n    configuration: Dict[str, Dict[str, Any]],\n    schema: Dict[str, Any] = JSON_SCHEMA_CONFIG,\n) -> Tuple[bool, str]:\n    \"\"\"Validate the main configuration.\"\"\"\n    # indicate that validation passed; since there\n    # were no validation errors, return an empty string\n    try:\n        jsonschema.validate(configuration, schema)\n        return (True, constants.markers.Empty_String)"
            },
            {
              "lineno": 128,
              "coloffset": 4,
              "linematch": "try:",
              "linematch_context": ") -> Tuple[bool, str]:\n    \"\"\"Validate the main configuration.\"\"\"\n    # indicate that validation passed; since there\n    # were no validation errors, return an empty string\n    try:\n        jsonschema.validate(configuration, schema)\n        return (True, constants.markers.Empty_String)\n    # indicate that validation failed;\n    # since validation errors exist, package them up\n    # and return them along with the indication"
            },
            {
              "lineno": 143,
              "coloffset": 4,
              "linematch": "\"\"\"Validate the checks configuration.\"\"\"",
              "linematch_context": "\ndef validate_checks_configuration(\n    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, str]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    return validate_configuration(configuration, JSON_SCHEMA_CHECKS)\n\n\ndef validate_file(\n    file_name: str,"
            },
            {
              "lineno": 144,
              "coloffset": 4,
              "linematch": "return validate_configuration(configuration, JSON_SCHEMA_CHECKS)",
              "linematch_context": "def validate_checks_configuration(\n    configuration: Dict[str, Dict[str, Any]]\n) -> Tuple[bool, str]:\n    \"\"\"Validate the checks configuration.\"\"\"\n    return validate_configuration(configuration, JSON_SCHEMA_CHECKS)\n\n\ndef validate_file(\n    file_name: str,\n    configuration_file_yaml_str: str,"
            },
            {
              "lineno": 154,
              "coloffset": 4,
              "linematch": "\"\"\"Validate the provided file according to the provided JSON schema.\"\"\"",
              "linematch_context": "    yaml_data_dict: Dict[str, Dict[str, Any]],\n    json_schema: Dict[str, Any] = JSON_SCHEMA_CONFIG,\n    verbose: bool = False,\n) -> bool:\n    \"\"\"Validate the provided file according to the provided JSON schema.\"\"\"\n    # perform the validation of the configuration file\n    (validated, errors) = validate_configuration(yaml_data_dict, json_schema)\n    output.console.print(\n        f\":sparkles: Validated {file_name}? {util.get_human_readable_boolean(validated)}\"\n    )"
            },
            {
              "lineno": 156,
              "coloffset": 4,
              "linematch": "(validated, errors) = validate_configuration(yaml_data_dict, json_schema)",
              "linematch_context": "    verbose: bool = False,\n) -> bool:\n    \"\"\"Validate the provided file according to the provided JSON schema.\"\"\"\n    # perform the validation of the configuration file\n    (validated, errors) = validate_configuration(yaml_data_dict, json_schema)\n    output.console.print(\n        f\":sparkles: Validated {file_name}? {util.get_human_readable_boolean(validated)}\"\n    )\n    # there was a validation error, so display the error report\n    if not validated:"
            },
            {
              "lineno": 157,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": ") -> bool:\n    \"\"\"Validate the provided file according to the provided JSON schema.\"\"\"\n    # perform the validation of the configuration file\n    (validated, errors) = validate_configuration(yaml_data_dict, json_schema)\n    output.console.print(\n        f\":sparkles: Validated {file_name}? {util.get_human_readable_boolean(validated)}\"\n    )\n    # there was a validation error, so display the error report\n    if not validated:\n        output.console.print(f\":person_shrugging: Validation errors:\\n\\n{errors}\")"
            },
            {
              "lineno": 161,
              "coloffset": 4,
              "linematch": "if not validated:",
              "linematch_context": "    output.console.print(\n        f\":sparkles: Validated {file_name}? {util.get_human_readable_boolean(validated)}\"\n    )\n    # there was a validation error, so display the error report\n    if not validated:\n        output.console.print(f\":person_shrugging: Validation errors:\\n\\n{errors}\")\n    # validation worked correctly, so display the configuration file\n    else:\n        output.opt_print_log(verbose, newline=\"\")\n        output.opt_print_log(verbose, label=f\":sparkles: Contents of {file_name}:\\n\")"
            },
            {
              "lineno": 168,
              "coloffset": 4,
              "linematch": "return validated",
              "linematch_context": "    else:\n        output.opt_print_log(verbose, newline=\"\")\n        output.opt_print_log(verbose, label=f\":sparkles: Contents of {file_name}:\\n\")\n        output.opt_print_log(verbose, config_file=configuration_file_yaml_str)\n    return validated"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "\"\"\"Split a csv file into a list of lists.\"\"\"",
              "linematch_context": "CHECK_DEFAULT = [\"\", \"1\", False]\n\n\ndef split_file(file_name: Path) -> List[List[str]]:\n    \"\"\"Split a csv file into a list of lists.\"\"\"\n    check_list = []\n    with open(file_name) as file:\n        for row in file:\n            strip_row = row.strip()  # Remove leading/trailing white spaces\n            if strip_row:"
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "check_list = []",
              "linematch_context": "\n\ndef split_file(file_name: Path) -> List[List[str]]:\n    \"\"\"Split a csv file into a list of lists.\"\"\"\n    check_list = []\n    with open(file_name) as file:\n        for row in file:\n            strip_row = row.strip()  # Remove leading/trailing white spaces\n            if strip_row:\n                check_list.append(strip_row.split(\",\"))"
            },
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "with open(file_name) as file:",
              "linematch_context": "\ndef split_file(file_name: Path) -> List[List[str]]:\n    \"\"\"Split a csv file into a list of lists.\"\"\"\n    check_list = []\n    with open(file_name) as file:\n        for row in file:\n            strip_row = row.strip()  # Remove leading/trailing white spaces\n            if strip_row:\n                check_list.append(strip_row.split(\",\"))\n    return check_list"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "return check_list",
              "linematch_context": "        for row in file:\n            strip_row = row.strip()  # Remove leading/trailing white spaces\n            if strip_row:\n                check_list.append(strip_row.split(\",\"))\n    return check_list\n\n\ndef write_checks(check_list: List[List[str]]) -> str:\n    \"\"\"Generate structured output based on the contents of the file.\"\"\"\n    if len(check_list) != 0:"
            },
            {
              "lineno": 33,
              "coloffset": 4,
              "linematch": "\"\"\"Generate structured output based on the contents of the file.\"\"\"",
              "linematch_context": "    return check_list\n\n\ndef write_checks(check_list: List[List[str]]) -> str:\n    \"\"\"Generate structured output based on the contents of the file.\"\"\"\n    if len(check_list) != 0:\n        result = \"Make a YAML file that checks for:\"\n        for checks in check_list:\n            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\"\n            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\""
            },
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "if len(check_list) != 0:",
              "linematch_context": "\n\ndef write_checks(check_list: List[List[str]]) -> str:\n    \"\"\"Generate structured output based on the contents of the file.\"\"\"\n    if len(check_list) != 0:\n        result = \"Make a YAML file that checks for:\"\n        for checks in check_list:\n            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\"\n            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\"\n        return result"
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "return \"[red][ERROR][/red] No checks were supplied\"",
              "linematch_context": "        for checks in check_list:\n            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\"\n            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\"\n        return result\n    return \"[red][ERROR][/red] No checks were supplied\"\n\n\ndef store_in_file(File: Path, Pattern, Matches, Exact):\n    \"\"\"Store inputed values into a text file\"\"\"\n    File.touch()"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "\"\"\"Store inputed values into a text file\"\"\"",
              "linematch_context": "    return \"[red][ERROR][/red] No checks were supplied\"\n\n\ndef store_in_file(File: Path, Pattern, Matches, Exact):\n    \"\"\"Store inputed values into a text file\"\"\"\n    File.touch()\n    with open(File, \"a\") as file:\n        file.write(f\"\\n{Pattern},{Matches},{Exact}\")  # Append input data to the file\n\n"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "File.touch()",
              "linematch_context": "\n\ndef store_in_file(File: Path, Pattern, Matches, Exact):\n    \"\"\"Store inputed values into a text file\"\"\"\n    File.touch()\n    with open(File, \"a\") as file:\n        file.write(f\"\\n{Pattern},{Matches},{Exact}\")  # Append input data to the file\n\n\n# Define input fields and buttons for the user interface"
            },
            {
              "lineno": 46,
              "coloffset": 4,
              "linematch": "with open(File, \"a\") as file:",
              "linematch_context": "\ndef store_in_file(File: Path, Pattern, Matches, Exact):\n    \"\"\"Store inputed values into a text file\"\"\"\n    File.touch()\n    with open(File, \"a\") as file:\n        file.write(f\"\\n{Pattern},{Matches},{Exact}\")  # Append input data to the file\n\n\n# Define input fields and buttons for the user interface\nCheck_Input = Input(placeholder=\"Check For:\", id=\"Check\", name=\"Check\")"
            },
            {
              "lineno": 64,
              "coloffset": 8,
              "linematch": "\"\"\"For displaying the user interface\"\"\"",
              "linematch_context": "\n# Static widget to display user input and validation results\nclass answers(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Check_Input\n        yield Match_Input\n\n\n# Static widget to display buttons for user interactions"
            },
            {
              "lineno": 65,
              "coloffset": 8,
              "linematch": "yield Check_Input",
              "linematch_context": "# Static widget to display user input and validation results\nclass answers(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Check_Input\n        yield Match_Input\n\n\n# Static widget to display buttons for user interactions\nclass button_prompts(Static):"
            },
            {
              "lineno": 66,
              "coloffset": 8,
              "linematch": "yield Match_Input",
              "linematch_context": "class answers(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Check_Input\n        yield Match_Input\n\n\n# Static widget to display buttons for user interactions\nclass button_prompts(Static):\n    def compose(self) -> ComposeResult:"
            },
            {
              "lineno": 72,
              "coloffset": 8,
              "linematch": "\"\"\"For displaying the user interface\"\"\"",
              "linematch_context": "\n# Static widget to display buttons for user interactions\nclass button_prompts(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")\n        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")"
            },
            {
              "lineno": 73,
              "coloffset": 8,
              "linematch": "yield Pretty([])  # Widget to display validation messages",
              "linematch_context": "# Static widget to display buttons for user interactions\nclass button_prompts(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")\n        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")\n"
            },
            {
              "lineno": 74,
              "coloffset": 8,
              "linematch": "yield Exact_button  # Display the \"Exact\" button",
              "linematch_context": "class button_prompts(Static):\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")\n        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")\n\n"
            },
            {
              "lineno": 75,
              "coloffset": 8,
              "linematch": "yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button",
              "linematch_context": "    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")\n        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")\n\n\n# Custom App class for the Textual application"
            },
            {
              "lineno": 76,
              "coloffset": 8,
              "linematch": "yield Button(\"Done\", id=\"done\")",
              "linematch_context": "        \"\"\"For displaying the user interface\"\"\"\n        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")\n        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")\n\n\n# Custom App class for the Textual application\nclass config_App(App):"
            },
            {
              "lineno": 77,
              "coloffset": 8,
              "linematch": "yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")",
              "linematch_context": "        yield Pretty([])  # Widget to display validation messages\n        yield Exact_button  # Display the \"Exact\" button\n        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button\n        yield Button(\"Done\", id=\"done\")\n        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")\n\n\n# Custom App class for the Textual application\nclass config_App(App):\n    CSS = \"\"\""
            },
            {
              "lineno": 118,
              "coloffset": 8,
              "linematch": "\"\"\"When inputs change this updates the values of Check\"\"\"",
              "linematch_context": "    Check: ClassVar[list] = [\"\", \"1\", False]\n    Valid: bool = False\n\n    def on_input_changed(self, event: Input.Changed) -> None:\n        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:"
            },
            {
              "lineno": 119,
              "coloffset": 8,
              "linematch": "self.Valid = False",
              "linematch_context": "    Valid: bool = False\n\n    def on_input_changed(self, event: Input.Changed) -> None:\n        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value"
            },
            {
              "lineno": 120,
              "coloffset": 8,
              "linematch": "if event.input.id == \"Check\":",
              "linematch_context": "\n    def on_input_changed(self, event: Input.Changed) -> None:\n        \"\"\"When inputs change this updates the values of Check\"\"\"\n        self.Valid = False\n        if event.input.id == \"Check\":\n            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n        elif event.validation_result is not None:\n            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True"
            },
            {
              "lineno": 128,
              "coloffset": 8,
              "linematch": "if event.button.id == \"Exact\":",
              "linematch_context": "                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit(\n                self"
            },
            {
              "lineno": 159,
              "coloffset": 8,
              "linematch": "\"\"\"For displaying the user interface\"\"\"",
              "linematch_context": "            self.query_one(Pretty).update([\"Invalid Input Please enter a Integer\"])\n            Match_Input.value = \"\"  # Clear the \"Matches\" input field\n\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield answers()  # Display the input fields for user input\n        yield button_prompts()  # Display the buttons for user interaction"
            },
            {
              "lineno": 160,
              "coloffset": 8,
              "linematch": "yield answers()  # Display the input fields for user input",
              "linematch_context": "            Match_Input.value = \"\"  # Clear the \"Matches\" input field\n\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield answers()  # Display the input fields for user input\n        yield button_prompts()  # Display the buttons for user interaction"
            },
            {
              "lineno": 161,
              "coloffset": 8,
              "linematch": "yield button_prompts()  # Display the buttons for user interaction",
              "linematch_context": "\n    def compose(self) -> ComposeResult:\n        \"\"\"For displaying the user interface\"\"\"\n        yield answers()  # Display the input fields for user input\n        yield button_prompts()  # Display the buttons for user interaction"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "\"\"\"Perform all of the includes and excludes for the list of checks.\"\"\"",
              "linematch_context": "    check_match: str,\n    check_confidence: int = constants.checks.Check_Confidence,\n    include: bool = True,\n) -> List[Dict[str, Union[str, Dict[str, int]]]]:\n    \"\"\"Perform all of the includes and excludes for the list of checks.\"\"\"\n    filtered_checks = []\n    # at least one aspect of the inputs was not specified (likely due to\n    # the fact that the command-line argument(s) were not used) and thus\n    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "filtered_checks = []",
              "linematch_context": "    check_confidence: int = constants.checks.Check_Confidence,\n    include: bool = True,\n) -> List[Dict[str, Union[str, Dict[str, int]]]]:\n    \"\"\"Perform all of the includes and excludes for the list of checks.\"\"\"\n    filtered_checks = []\n    # at least one aspect of the inputs was not specified (likely due to\n    # the fact that the command-line argument(s) were not used) and thus\n    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:\n        return checks"
            },
            {
              "lineno": 24,
              "coloffset": 4,
              "linematch": "if check_attribute is None or check_match is None:",
              "linematch_context": "    filtered_checks = []\n    # at least one aspect of the inputs was not specified (likely due to\n    # the fact that the command-line argument(s) were not used) and thus\n    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:\n        return checks\n    # the function's inputs are valid and so perform the filtering\n    for check in checks:\n        # extract the contents of the requested attribute for inclusion\n        check_requested_include_attribute = check[check_attribute]"
            },
            {
              "lineno": 27,
              "coloffset": 4,
              "linematch": "for check in checks:",
              "linematch_context": "    # there is no filtering that should take place; return the input\n    if check_attribute is None or check_match is None:\n        return checks\n    # the function's inputs are valid and so perform the filtering\n    for check in checks:\n        # extract the contents of the requested attribute for inclusion\n        check_requested_include_attribute = check[check_attribute]\n        # compute the fuzzy match value for the specific:\n        # --> requested include attribute\n        # --> specified match string"
            },
            {
              "lineno": 43,
              "coloffset": 4,
              "linematch": "return filtered_checks",
              "linematch_context": "        # and the purpose of the function call is to exclude values;\n        # note that not including a value means that it excludes\n        elif (fuzzy_value < check_confidence) and not include:\n            filtered_checks.append(check)\n    return filtered_checks\n\n\ndef filter_matches(\n    match_list: List[Union[pyastgrepsearch.Match, Any]],\n    data_type,"
            },
            {
              "lineno": 50,
              "coloffset": 4,
              "linematch": "\"\"\"Filter the list of matches based on the provided data type.\"\"\"",
              "linematch_context": "def filter_matches(\n    match_list: List[Union[pyastgrepsearch.Match, Any]],\n    data_type,\n) -> Tuple[List[pyastgrepsearch.Match], List[Any]]:\n    \"\"\"Filter the list of matches based on the provided data type.\"\"\"\n    subset_match_list = []\n    did_not_match_list = []\n    # iterate through all of the matches\n    for match in match_list:\n        # if the current match is of the"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "subset_match_list = []",
              "linematch_context": "    match_list: List[Union[pyastgrepsearch.Match, Any]],\n    data_type,\n) -> Tuple[List[pyastgrepsearch.Match], List[Any]]:\n    \"\"\"Filter the list of matches based on the provided data type.\"\"\"\n    subset_match_list = []\n    did_not_match_list = []\n    # iterate through all of the matches\n    for match in match_list:\n        # if the current match is of the\n        # specified type, then keep it in"
            },
            {
              "lineno": 52,
              "coloffset": 4,
              "linematch": "did_not_match_list = []",
              "linematch_context": "    data_type,\n) -> Tuple[List[pyastgrepsearch.Match], List[Any]]:\n    \"\"\"Filter the list of matches based on the provided data type.\"\"\"\n    subset_match_list = []\n    did_not_match_list = []\n    # iterate through all of the matches\n    for match in match_list:\n        # if the current match is of the\n        # specified type, then keep it in\n        # the list of the matching matches"
            },
            {
              "lineno": 54,
              "coloffset": 4,
              "linematch": "for match in match_list:",
              "linematch_context": "    \"\"\"Filter the list of matches based on the provided data type.\"\"\"\n    subset_match_list = []\n    did_not_match_list = []\n    # iterate through all of the matches\n    for match in match_list:\n        # if the current match is of the\n        # specified type, then keep it in\n        # the list of the matching matches\n        if isinstance(match, data_type):\n            subset_match_list.append(match)"
            },
            {
              "lineno": 66,
              "coloffset": 4,
              "linematch": "return (subset_match_list, did_not_match_list)",
              "linematch_context": "        # the list of non-matching matches\n        else:\n            did_not_match_list.append(match)\n    # return both of the created lists\n    return (subset_match_list, did_not_match_list)\n\n\ndef organize_matches(\n    match_list: List[pyastgrepsearch.Match],\n) -> Dict[str, List[pyastgrepsearch.Match]]:"
            },
            {
              "lineno": 72,
              "coloffset": 4,
              "linematch": "\"\"\"Organize the matches on a per-file basis to support simplified processing.\"\"\"",
              "linematch_context": "\ndef organize_matches(\n    match_list: List[pyastgrepsearch.Match],\n) -> Dict[str, List[pyastgrepsearch.Match]]:\n    \"\"\"Organize the matches on a per-file basis to support simplified processing.\"\"\"\n    match_dict: Dict[str, List[pyastgrepsearch.Match]] = {}\n    # iterate through each of the matches in the list, with\n    # the goal of creating a dictionary organized so that\n    # --> the key is the name of a file under analysis\n    # --> the value is a list of all of the matches for that file"
            },
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "match_dict: Dict[str, List[pyastgrepsearch.Match]] = {}",
              "linematch_context": "def organize_matches(\n    match_list: List[pyastgrepsearch.Match],\n) -> Dict[str, List[pyastgrepsearch.Match]]:\n    \"\"\"Organize the matches on a per-file basis to support simplified processing.\"\"\"\n    match_dict: Dict[str, List[pyastgrepsearch.Match]] = {}\n    # iterate through each of the matches in the list, with\n    # the goal of creating a dictionary organized so that\n    # --> the key is the name of a file under analysis\n    # --> the value is a list of all of the matches for that file\n    for current_match in match_list:"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "for current_match in match_list:",
              "linematch_context": "    # iterate through each of the matches in the list, with\n    # the goal of creating a dictionary organized so that\n    # --> the key is the name of a file under analysis\n    # --> the value is a list of all of the matches for that file\n    for current_match in match_list:\n        # extract the name of the file for the current match\n        current_match_file_name = str(current_match.path)\n        # already storing matches for this file\n        if current_match_file_name in match_dict:\n            # extract the existing list of matches for this file"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "return match_dict",
              "linematch_context": "            # add the current match to the list\n            current_match_list.append(current_match)\n            # associate this new list with the current file name\n            match_dict[current_match_file_name] = current_match_list\n    return match_dict\n\n\ndef combine_dicts(dict_list: List[Dict[Any, Any]]) -> str:\n    \"\"\"Combine all dictionaries in the list into a single list of dictionaries as a string.\"\"\"\n    # combine all of the dictionaries in the list into"
            },
            {
              "lineno": 98,
              "coloffset": 4,
              "linematch": "\"\"\"Combine all dictionaries in the list into a single list of dictionaries as a string.\"\"\"",
              "linematch_context": "    return match_dict\n\n\ndef combine_dicts(dict_list: List[Dict[Any, Any]]) -> str:\n    \"\"\"Combine all dictionaries in the list into a single list of dictionaries as a string.\"\"\"\n    # combine all of the dictionaries in the list into\n    # a single string that is a list of each JSON-based\n    # dictionary represented as a string; this leads to:\n    # [\n    #   { nested JSON for file 1 },"
            },
            {
              "lineno": 109,
              "coloffset": 4,
              "linematch": "return json.dumps(dict_list, indent=2)",
              "linematch_context": "    #   ...\n    #   { nested JSON for file n }\n    # ]\n    # which is a list of valid JSON objects\n    return json.dumps(dict_list, indent=2)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "\"\"\"Output all of the preamble content.\"\"\"",
              "linematch_context": "    debug_level: debug.DebugLevel = debug.DebugLevel.ERROR,\n    debug_destination: debug.DebugDestination = debug.DebugDestination.CONSOLE,\n    **kwargs,\n) -> None:\n    \"\"\"Output all of the preamble content.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            },
            {
              "lineno": 53,
              "coloffset": 4,
              "linematch": "output.setup(debug_level, debug_destination)",
              "linematch_context": "    **kwargs,\n) -> None:\n    \"\"\"Output all of the preamble content.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the header\n    output.print_header()"
            },
            {
              "lineno": 54,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Display verbose output? {verbose}\")",
              "linematch_context": ") -> None:\n    \"\"\"Output all of the preamble content.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the header\n    output.print_header()\n    # display details about configuration as"
            },
            {
              "lineno": 55,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug level? {debug_level.value}\")",
              "linematch_context": "    \"\"\"Output all of the preamble content.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the header\n    output.print_header()\n    # display details about configuration as\n    # long as verbose output was requested;"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug destination? {debug_destination.value}\")",
              "linematch_context": "    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the header\n    output.print_header()\n    # display details about configuration as\n    # long as verbose output was requested;\n    # note that passing **kwargs to this function"
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "output.print_header()",
              "linematch_context": "    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the header\n    output.print_header()\n    # display details about configuration as\n    # long as verbose output was requested;\n    # note that passing **kwargs to this function\n    # will pass along all of the extra keyword\n    # arguments that were input to the function"
            },
            {
              "lineno": 64,
              "coloffset": 4,
              "linematch": "output.print_diagnostics(",
              "linematch_context": "    # long as verbose output was requested;\n    # note that passing **kwargs to this function\n    # will pass along all of the extra keyword\n    # arguments that were input to the function\n    output.print_diagnostics(\n        verbose,\n        debug_level=debug_level.value,\n        debug_destination=debug_destination.value,\n        **kwargs,\n    )"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "\"\"\"Display diagnostic details at startup of serve or publish commands.\"\"\"",
              "linematch_context": "    metadata: Path,\n    port: int = 8001,\n    publish: bool = False,\n) -> None:\n    \"\"\"Display diagnostic details at startup of serve or publish commands.\"\"\"\n    # output diagnostic information about the datasette instance\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\""
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    publish: bool = False,\n) -> None:\n    \"\"\"Display diagnostic details at startup of serve or publish commands.\"\"\"\n    # output diagnostic information about the datasette instance\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\"\n    )\n    output.console.print("
            },
            {
              "lineno": 82,
              "coloffset": 4,
              "linematch": "output.console.print(label)",
              "linematch_context": ") -> None:\n    \"\"\"Display diagnostic details at startup of serve or publish commands.\"\"\"\n    # output diagnostic information about the datasette instance\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\"\n    )\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\""
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": "    \"\"\"Display diagnostic details at startup of serve or publish commands.\"\"\"\n    # output diagnostic information about the datasette instance\n    output.console.print()\n    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\"\n    )\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\"\n    )"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": "    output.console.print(label)\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\"\n    )\n    output.console.print(\n        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\"\n    )\n    # do not display a port if the task is publishing to fly.io\n    # because that step does not support port specification\n    if not publish:"
            },
            {
              "lineno": 91,
              "coloffset": 4,
              "linematch": "if not publish:",
              "linematch_context": "        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\"\n    )\n    # do not display a port if the task is publishing to fly.io\n    # because that step does not support port specification\n    if not publish:\n        output.console.print(\n            f\"{constants.markers.Indent}{small_bullet_unicode} Port: {port}\"\n        )\n\n"
            },
            {
              "lineno": 110,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"",
              "linematch_context": "@cli.command()\ndef create_checks(\n    filename: Path = typer.Option(\"checks.yml\", help=\"YAML file name\")\n) -> None:\n    \"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"\n    # creates a textual object for better user interface\n    app.run()\n    # Checks if the file storing the wanted checks exists and is valid\n    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks"
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "app.run()",
              "linematch_context": "    filename: Path = typer.Option(\"checks.yml\", help=\"YAML file name\")\n) -> None:\n    \"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"\n    # creates a textual object for better user interface\n    app.run()\n    # Checks if the file storing the wanted checks exists and is valid\n    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks\n        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))\n        # Checks if API key storage file exists"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "if filesystem.confirm_valid_file(CHECK_STORAGE):",
              "linematch_context": "    \"\"\"\ud83d\udd27 Interactively specify for checks and have a checks.yml file created(Requires API key)\"\"\"\n    # creates a textual object for better user interface\n    app.run()\n    # Checks if the file storing the wanted checks exists and is valid\n    if filesystem.confirm_valid_file(CHECK_STORAGE):\n        # stores the human readable version of the checks\n        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))\n        # Checks if API key storage file exists\n        if filesystem.confirm_valid_file(API_KEY_STORAGE):\n            # prints the human readable checks to the terminal"
            },
            {
              "lineno": 182,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83e\ude82 Manage chasten's configuration.\"\"\"",
              "linematch_context": "        help=\"Create configuration directory and files even if they exist\",\n    ),\n    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83e\ude82 Manage chasten's configuration.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,"
            },
            {
              "lineno": 184,
              "coloffset": 4,
              "linematch": "output_preamble(",
              "linematch_context": "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83e\ude82 Manage chasten's configuration.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,\n        task=task.value,\n        config=config,"
            },
            {
              "lineno": 193,
              "coloffset": 4,
              "linematch": "output.setup(debug_level, debug_destination)",
              "linematch_context": "        config=config,\n        force=force,\n    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the configuration directory and its contents\n    if task == enumerations.ConfigureTask.VALIDATE:"
            },
            {
              "lineno": 194,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Display verbose output? {verbose}\")",
              "linematch_context": "        force=force,\n    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the configuration directory and its contents\n    if task == enumerations.ConfigureTask.VALIDATE:\n        # validate the configuration files:"
            },
            {
              "lineno": 195,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug level? {debug_level.value}\")",
              "linematch_context": "    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the configuration directory and its contents\n    if task == enumerations.ConfigureTask.VALIDATE:\n        # validate the configuration files:\n        # --> config.yml (or url pointing to one)"
            },
            {
              "lineno": 196,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug destination? {debug_destination.value}\")",
              "linematch_context": "    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the configuration directory and its contents\n    if task == enumerations.ConfigureTask.VALIDATE:\n        # validate the configuration files:\n        # --> config.yml (or url pointing to one)\n        # --> checks.yml (or whatever file/url is reference in config.yml)"
            },
            {
              "lineno": 198,
              "coloffset": 4,
              "linematch": "if task == enumerations.ConfigureTask.VALIDATE:",
              "linematch_context": "    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display the configuration directory and its contents\n    if task == enumerations.ConfigureTask.VALIDATE:\n        # validate the configuration files:\n        # --> config.yml (or url pointing to one)\n        # --> checks.yml (or whatever file/url is reference in config.yml)\n        (validated, _) = configuration.validate_configuration_files(config, verbose)\n        # some aspect of the configuration was not"
            },
            {
              "lineno": 211,
              "coloffset": 4,
              "linematch": "if task == enumerations.ConfigureTask.CREATE:",
              "linematch_context": "                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n            )\n            sys.exit(constants.markers.Non_Zero_Exit)\n    # create the configuration directory and a starting version of the configuration file\n    if task == enumerations.ConfigureTask.CREATE:\n        # attempt to create the configuration directory\n        try:\n            # create the configuration directory, which will either be the one\n            # specified by the config parameter (if it exists) or it will be\n            # the one in the platform-specific directory given by platformdirs"
            },
            {
              "lineno": 342,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83d\udcab Analyze the AST of Python source code.\"\"\"",
              "linematch_context": "    verbose: bool = typer.Option(False, help=\"Enable verbose mode output.\"),\n    save: bool = typer.Option(False, help=\"Enable saving of output file(s).\"),\n    force: bool = typer.Option(False, help=\"Force creation of new markdown file\"),\n) -> None:\n    \"\"\"\ud83d\udcab Analyze the AST of Python source code.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            },
            {
              "lineno": 344,
              "coloffset": 4,
              "linematch": "output.setup(debug_level, debug_destination)",
              "linematch_context": "    force: bool = typer.Option(False, help=\"Force creation of new markdown file\"),\n) -> None:\n    \"\"\"\ud83d\udcab Analyze the AST of Python source code.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")"
            },
            {
              "lineno": 345,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Display verbose output? {verbose}\")",
              "linematch_context": ") -> None:\n    \"\"\"\ud83d\udcab Analyze the AST of Python source code.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")\n    # output the preamble, including extra parameters specific to this function"
            },
            {
              "lineno": 346,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug level? {debug_level.value}\")",
              "linematch_context": "    \"\"\"\ud83d\udcab Analyze the AST of Python source code.\"\"\"\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")\n    # output the preamble, including extra parameters specific to this function\n    output_preamble("
            },
            {
              "lineno": 347,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug destination? {debug_destination.value}\")",
              "linematch_context": "    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,"
            },
            {
              "lineno": 348,
              "coloffset": 4,
              "linematch": "start_time = time.time()",
              "linematch_context": "    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,"
            },
            {
              "lineno": 349,
              "coloffset": 4,
              "linematch": "output.logger.debug(\"Analysis Started.\")",
              "linematch_context": "    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,"
            },
            {
              "lineno": 351,
              "coloffset": 4,
              "linematch": "output_preamble(",
              "linematch_context": "    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    start_time = time.time()\n    output.logger.debug(\"Analysis Started.\")\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,\n        project=project,\n        directory=input_path,"
            },
            {
              "lineno": 359,
              "coloffset": 4,
              "linematch": "chasten_version = util.get_chasten_version()",
              "linematch_context": "        project=project,\n        directory=input_path,\n    )\n    # extract the current version of the program\n    chasten_version = util.get_chasten_version()\n    # display current chasten version\n    output.logger.debug(f\"Current version of chasten: {chasten_version}\")\n    # create the include and exclude criteria\n    include = results.CheckCriterion(\n        attribute=str(checks.fix_check_criterion(check_include[0])),"
            },
            {
              "lineno": 361,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Current version of chasten: {chasten_version}\")",
              "linematch_context": "    )\n    # extract the current version of the program\n    chasten_version = util.get_chasten_version()\n    # display current chasten version\n    output.logger.debug(f\"Current version of chasten: {chasten_version}\")\n    # create the include and exclude criteria\n    include = results.CheckCriterion(\n        attribute=str(checks.fix_check_criterion(check_include[0])),\n        value=str(checks.fix_check_criterion(check_include[1])),\n        confidence=int(checks.fix_check_criterion(check_include[2])),"
            },
            {
              "lineno": 363,
              "coloffset": 4,
              "linematch": "include = results.CheckCriterion(",
              "linematch_context": "    chasten_version = util.get_chasten_version()\n    # display current chasten version\n    output.logger.debug(f\"Current version of chasten: {chasten_version}\")\n    # create the include and exclude criteria\n    include = results.CheckCriterion(\n        attribute=str(checks.fix_check_criterion(check_include[0])),\n        value=str(checks.fix_check_criterion(check_include[1])),\n        confidence=int(checks.fix_check_criterion(check_include[2])),\n    )\n    exclude = results.CheckCriterion("
            },
            {
              "lineno": 368,
              "coloffset": 4,
              "linematch": "exclude = results.CheckCriterion(",
              "linematch_context": "        attribute=str(checks.fix_check_criterion(check_include[0])),\n        value=str(checks.fix_check_criterion(check_include[1])),\n        confidence=int(checks.fix_check_criterion(check_include[2])),\n    )\n    exclude = results.CheckCriterion(\n        attribute=str(checks.fix_check_criterion(check_exclude[0])),\n        value=str(checks.fix_check_criterion(check_exclude[1])),\n        confidence=int(checks.fix_check_criterion(check_exclude[2])),\n    )\n    # create a configuration that is the same for all results"
            },
            {
              "lineno": 374,
              "coloffset": 4,
              "linematch": "chasten_configuration = results.Configuration(",
              "linematch_context": "        value=str(checks.fix_check_criterion(check_exclude[1])),\n        confidence=int(checks.fix_check_criterion(check_exclude[2])),\n    )\n    # create a configuration that is the same for all results\n    chasten_configuration = results.Configuration(\n        chastenversion=chasten_version,\n        projectname=project,\n        configdirectory=Path(config),\n        searchpath=input_path,\n        debuglevel=debug_level,"
            },
            {
              "lineno": 386,
              "coloffset": 4,
              "linematch": "chasten_results_save = results.Chasten(configuration=chasten_configuration)",
              "linematch_context": "        checkexclude=exclude,\n    )\n    # connect the configuration to the top-level chasten object for results saving\n    # note: this is the final object that contains all of the data\n    chasten_results_save = results.Chasten(configuration=chasten_configuration)\n    # add extra space after the command to run the program\n    output.console.print()\n    # validate the configuration\n    (validated, checks_dict) = configuration.validate_configuration_files(\n        config, verbose"
            },
            {
              "lineno": 388,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    # connect the configuration to the top-level chasten object for results saving\n    # note: this is the final object that contains all of the data\n    chasten_results_save = results.Chasten(configuration=chasten_configuration)\n    # add extra space after the command to run the program\n    output.console.print()\n    # validate the configuration\n    (validated, checks_dict) = configuration.validate_configuration_files(\n        config, verbose\n    )\n    # some aspect of the configuration was not"
            },
            {
              "lineno": 390,
              "coloffset": 4,
              "linematch": "(validated, checks_dict) = configuration.validate_configuration_files(",
              "linematch_context": "    chasten_results_save = results.Chasten(configuration=chasten_configuration)\n    # add extra space after the command to run the program\n    output.console.print()\n    # validate the configuration\n    (validated, checks_dict) = configuration.validate_configuration_files(\n        config, verbose\n    )\n    # some aspect of the configuration was not\n    # valid, so exit early and signal an error\n    if not validated:"
            },
            {
              "lineno": 395,
              "coloffset": 4,
              "linematch": "if not validated:",
              "linematch_context": "        config, verbose\n    )\n    # some aspect of the configuration was not\n    # valid, so exit early and signal an error\n    if not validated:\n        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\"\n        )\n        output.logger.debug(\"Cannot perform analysis due to configuration error(s)\")\n        sys.exit(constants.markers.Non_Zero_Exit)"
            },
            {
              "lineno": 404,
              "coloffset": 4,
              "linematch": "check_list: List[Dict[str, Union[str, Dict[str, int]]]] = checks_dict[",
              "linematch_context": "        sys.exit(constants.markers.Non_Zero_Exit)\n    # extract the list of the specific patterns (i.e., the XPATH expressions)\n    # that will be used to analyze all of the XML-based representations of\n    # the Python source code found in the valid directories\n    check_list: List[Dict[str, Union[str, Dict[str, int]]]] = checks_dict[\n        constants.checks.Checks_Label\n    ]\n    # filter the list of checks based on the include and exclude parameters\n    # --> only run those checks that were included\n    check_list = process.include_or_exclude_checks(  # type: ignore"
            },
            {
              "lineno": 409,
              "coloffset": 4,
              "linematch": "check_list = process.include_or_exclude_checks(  # type: ignore",
              "linematch_context": "        constants.checks.Checks_Label\n    ]\n    # filter the list of checks based on the include and exclude parameters\n    # --> only run those checks that were included\n    check_list = process.include_or_exclude_checks(  # type: ignore\n        check_list, include=True, *check_include\n    )\n    # --> remove those checks that were excluded\n    check_list = process.include_or_exclude_checks(  # type: ignore\n        check_list, include=False, *check_exclude"
            },
            {
              "lineno": 413,
              "coloffset": 4,
              "linematch": "check_list = process.include_or_exclude_checks(  # type: ignore",
              "linematch_context": "    check_list = process.include_or_exclude_checks(  # type: ignore\n        check_list, include=True, *check_include\n    )\n    # --> remove those checks that were excluded\n    check_list = process.include_or_exclude_checks(  # type: ignore\n        check_list, include=False, *check_exclude\n    )\n    # the specified search path is not valid and thus it is\n    # not possible to analyze the Python source files in this directory\n    # OR"
            },
            {
              "lineno": 421,
              "coloffset": 4,
              "linematch": "if not filesystem.confirm_valid_directory(",
              "linematch_context": "    # not possible to analyze the Python source files in this directory\n    # OR\n    # the specified search path is not valid and thus it is\n    # not possible to analyze the specific Python source code file\n    if not filesystem.confirm_valid_directory(\n        input_path\n    ) and not filesystem.confirm_valid_file(input_path):\n        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\"\n        )"
            },
            {
              "lineno": 428,
              "coloffset": 4,
              "linematch": "if store_result:",
              "linematch_context": "        output.console.print(\n            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\"\n        )\n        sys.exit(constants.markers.Non_Zero_Exit)\n    if store_result:\n        # creates an empty string for storing results temporarily\n        analysis_result = \"\"\n        analysis_file_dir = store_result / ANALYSIS_FILE\n        # clears markdown file of results if it exists and new results are to be store\n        if filesystem.confirm_valid_file(analysis_file_dir):"
            },
            {
              "lineno": 450,
              "coloffset": 4,
              "linematch": "valid_directories = [input_path]",
              "linematch_context": "                analysis_file_dir.write_text(\"\")\n        # creates file if doesn't exist already\n        analysis_file_dir.touch()\n    # create the list of directories\n    valid_directories = [input_path]\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")\n    # output the number of checks that will be performed\n    output.console.print()"
            },
            {
              "lineno": 452,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "        analysis_file_dir.touch()\n    # create the list of directories\n    valid_directories = [input_path]\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")\n    # output the number of checks that will be performed\n    output.console.print()\n    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")\n    output.console.print()"
            },
            {
              "lineno": 453,
              "coloffset": 4,
              "linematch": "output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")",
              "linematch_context": "    # create the list of directories\n    valid_directories = [input_path]\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")\n    # output the number of checks that will be performed\n    output.console.print()\n    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")\n    output.console.print()\n    # create a check_status list for all of the checks"
            },
            {
              "lineno": 455,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")\n    # output the number of checks that will be performed\n    output.console.print()\n    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")\n    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version"
            },
            {
              "lineno": 456,
              "coloffset": 4,
              "linematch": "output.console.print(f\":tada: Performing {len(check_list)} check(s):\")",
              "linematch_context": "    output.console.print()\n    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")\n    # output the number of checks that will be performed\n    output.console.print()\n    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")\n    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version\n    if xpath == \"1.0\":"
            },
            {
              "lineno": 457,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")\n    # output the number of checks that will be performed\n    output.console.print()\n    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")\n    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version\n    if xpath == \"1.0\":\n        output.logger.debug(\"Using XPath version 1.0\")"
            },
            {
              "lineno": 459,
              "coloffset": 4,
              "linematch": "check_status_list: List[bool] = []",
              "linematch_context": "    output.console.print()\n    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")\n    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version\n    if xpath == \"1.0\":\n        output.logger.debug(\"Using XPath version 1.0\")\n    else:\n        output.logger.debug(\"Using XPath version 2.0\")"
            },
            {
              "lineno": 461,
              "coloffset": 4,
              "linematch": "if xpath == \"1.0\":",
              "linematch_context": "    output.console.print()\n    # create a check_status list for all of the checks\n    check_status_list: List[bool] = []\n    # check XPATH version\n    if xpath == \"1.0\":\n        output.logger.debug(\"Using XPath version 1.0\")\n    else:\n        output.logger.debug(\"Using XPath version 2.0\")\n    # iterate through and perform each of the checks\n    for current_check in check_list:"
            },
            {
              "lineno": 466,
              "coloffset": 4,
              "linematch": "for current_check in check_list:",
              "linematch_context": "        output.logger.debug(\"Using XPath version 1.0\")\n    else:\n        output.logger.debug(\"Using XPath version 2.0\")\n    # iterate through and perform each of the checks\n    for current_check in check_list:\n        # extract the pattern for the current check\n        current_xpath_pattern = str(\n            current_check[constants.checks.Check_Pattern]\n        )  # type: ignore\n        # extract the minimum and maximum values for the checks, if they exist"
            },
            {
              "lineno": 631,
              "coloffset": 4,
              "linematch": "total_result = util.total_amount_passed(check_status_list)",
              "linematch_context": "            chasten_results_save.sources.append(current_result_source)\n        # add the amount of total matches in each check to the end of each checks output\n        output.console.print(f\"   = {len(match_generator_list)} total matches\\n\")\n    # calculate the final count of matches found\n    total_result = util.total_amount_passed(check_status_list)\n    # display checks passed, total amount of checks, and percentage of checks passed\n    output.console.print(\n        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\"\n    )\n    # display all of the analysis results if verbose output is requested"
            },
            {
              "lineno": 633,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": "        output.console.print(f\"   = {len(match_generator_list)} total matches\\n\")\n    # calculate the final count of matches found\n    total_result = util.total_amount_passed(check_status_list)\n    # display checks passed, total amount of checks, and percentage of checks passed\n    output.console.print(\n        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\"\n    )\n    # display all of the analysis results if verbose output is requested\n    output.print_analysis_details(chasten_results_save, verbose=verbose)\n    # save all of the results from this analysis"
            },
            {
              "lineno": 637,
              "coloffset": 4,
              "linematch": "output.print_analysis_details(chasten_results_save, verbose=verbose)",
              "linematch_context": "    output.console.print(\n        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\"\n    )\n    # display all of the analysis results if verbose output is requested\n    output.print_analysis_details(chasten_results_save, verbose=verbose)\n    # save all of the results from this analysis\n    saved_file_name = filesystem.write_chasten_results(\n        output_directory, project, chasten_results_save, save\n    )\n    # output the name of the saved file if saving successfully took place"
            },
            {
              "lineno": 639,
              "coloffset": 4,
              "linematch": "saved_file_name = filesystem.write_chasten_results(",
              "linematch_context": "    )\n    # display all of the analysis results if verbose output is requested\n    output.print_analysis_details(chasten_results_save, verbose=verbose)\n    # save all of the results from this analysis\n    saved_file_name = filesystem.write_chasten_results(\n        output_directory, project, chasten_results_save, save\n    )\n    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")"
            },
            {
              "lineno": 643,
              "coloffset": 4,
              "linematch": "if saved_file_name:",
              "linematch_context": "    saved_file_name = filesystem.write_chasten_results(\n        output_directory, project, chasten_results_save, save\n    )\n    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")\n    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:"
            },
            {
              "lineno": 646,
              "coloffset": 4,
              "linematch": "if save_XML is not None or view_XML is not None:",
              "linematch_context": "    # output the name of the saved file if saving successfully took place\n    if saved_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")\n    # --save-xml and --view-xml\n    if save_XML is not None or view_XML is not None:\n        output.console.print(\":memo: Saving XML...\")\n        try:\n            if os.path.isdir(input_path):\n                for each_file in os.listdir(input_path):\n                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901"
            },
            {
              "lineno": 705,
              "coloffset": 4,
              "linematch": "all_checks_passed = all(check_status_list)",
              "linematch_context": "        except FileNotFoundError:\n            output.console.print(\":sweat: Sorry, could not convert to xml.\")\n    # confirm whether or not all of the checks passed\n    # and then display the appropriate diagnostic message\n    all_checks_passed = all(check_status_list)\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")"
            },
            {
              "lineno": 706,
              "coloffset": 4,
              "linematch": "end_time = time.time()",
              "linematch_context": "            output.console.print(\":sweat: Sorry, could not convert to xml.\")\n    # confirm whether or not all of the checks passed\n    # and then display the appropriate diagnostic message\n    all_checks_passed = all(check_status_list)\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:"
            },
            {
              "lineno": 707,
              "coloffset": 4,
              "linematch": "elapsed_time = end_time - start_time",
              "linematch_context": "    # confirm whether or not all of the checks passed\n    # and then display the appropriate diagnostic message\n    all_checks_passed = all(check_status_list)\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file"
            },
            {
              "lineno": 709,
              "coloffset": 4,
              "linematch": "if not all_checks_passed:",
              "linematch_context": "    all_checks_passed = all(check_status_list)\n    end_time = time.time()\n    elapsed_time = end_time - start_time\n\n    if not all_checks_passed:\n        output.console.print(\":sweat: At least one check did not pass.\")\n        if store_result:\n            # writes results of analyze into a markdown file\n            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n            output.console.print("
            },
            {
              "lineno": 718,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": "            output.console.print(\n                f\"\\n:sparkles: Results saved in: {os.path.abspath(analysis_file_dir)}\\n\"\n            )\n        sys.exit(constants.markers.Non_Zero_Exit)\n    output.console.print(\n        f\"\\n:joy: All checks passed. Elapsed Time: {elapsed_time} seconds\"\n    )\n    output.logger.debug(\"Analysis complete.\")\n    if store_result:\n        # writes results of analyze into a markdown file"
            },
            {
              "lineno": 721,
              "coloffset": 4,
              "linematch": "output.logger.debug(\"Analysis complete.\")",
              "linematch_context": "        sys.exit(constants.markers.Non_Zero_Exit)\n    output.console.print(\n        f\"\\n:joy: All checks passed. Elapsed Time: {elapsed_time} seconds\"\n    )\n    output.logger.debug(\"Analysis complete.\")\n    if store_result:\n        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")"
            },
            {
              "lineno": 722,
              "coloffset": 4,
              "linematch": "if store_result:",
              "linematch_context": "    output.console.print(\n        f\"\\n:joy: All checks passed. Elapsed Time: {elapsed_time} seconds\"\n    )\n    output.logger.debug(\"Analysis complete.\")\n    if store_result:\n        # writes results of analyze into a markdown file\n        result_path = os.path.abspath(analysis_file_dir)\n        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")\n        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")\n        if display:"
            },
            {
              "lineno": 767,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83d\udea7 Integrate files and make a database.\"\"\"",
              "linematch_context": "        help=\"Create converted results files even if they exist\",\n    ),\n    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83d\udea7 Integrate files and make a database.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,"
            },
            {
              "lineno": 769,
              "coloffset": 4,
              "linematch": "output_preamble(",
              "linematch_context": "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83d\udea7 Integrate files and make a database.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,\n        project=project,\n        output_directory=output_directory,"
            },
            {
              "lineno": 778,
              "coloffset": 4,
              "linematch": "output.logger.debug(\"Integrate function started.\")",
              "linematch_context": "        output_directory=output_directory,\n        json_path=json_path,\n        force=force,\n    )\n    output.logger.debug(\"Integrate function started.\")\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(\":sparkles: Combining data file(s) in:\")\n    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()"
            },
            {
              "lineno": 780,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "        force=force,\n    )\n    output.logger.debug(\"Integrate function started.\")\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(\":sparkles: Combining data file(s) in:\")\n    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files"
            },
            {
              "lineno": 781,
              "coloffset": 4,
              "linematch": "output.console.print(\":sparkles: Combining data file(s) in:\")",
              "linematch_context": "    )\n    output.logger.debug(\"Integrate function started.\")\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(\":sparkles: Combining data file(s) in:\")\n    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)"
            },
            {
              "lineno": 782,
              "coloffset": 4,
              "linematch": "output.logger.debug(\":sparkles: Combining data file(s) in:\")",
              "linematch_context": "    output.logger.debug(\"Integrate function started.\")\n    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(\":sparkles: Combining data file(s) in:\")\n    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)"
            },
            {
              "lineno": 783,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    # output the list of directories subject to checking\n    output.console.print()\n    output.console.print(\":sparkles: Combining data file(s) in:\")\n    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)\n    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")"
            },
            {
              "lineno": 784,
              "coloffset": 4,
              "linematch": "output.print_list_contents(json_path)",
              "linematch_context": "    output.console.print()\n    output.console.print(\":sparkles: Combining data file(s) in:\")\n    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)\n    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")\n    # combine all of the dictionaries into a single string"
            },
            {
              "lineno": 786,
              "coloffset": 4,
              "linematch": "json_dicts = filesystem.get_json_results(json_path)",
              "linematch_context": "    output.logger.debug(\":sparkles: Combining data file(s) in:\")\n    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)\n    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")\n    # combine all of the dictionaries into a single string\n    combined_json_dict = process.combine_dicts(json_dicts)\n    # write the combined JSON file string to the filesystem"
            },
            {
              "lineno": 787,
              "coloffset": 4,
              "linematch": "count = len(json_path)",
              "linematch_context": "    output.console.print()\n    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)\n    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")\n    # combine all of the dictionaries into a single string\n    combined_json_dict = process.combine_dicts(json_dicts)\n    # write the combined JSON file string to the filesystem\n    combined_json_file_name = filesystem.write_dict_results("
            },
            {
              "lineno": 788,
              "coloffset": 4,
              "linematch": "output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")",
              "linematch_context": "    output.print_list_contents(json_path)\n    # extract all of the JSON dictionaries from the specified files\n    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)\n    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")\n    # combine all of the dictionaries into a single string\n    combined_json_dict = process.combine_dicts(json_dicts)\n    # write the combined JSON file string to the filesystem\n    combined_json_file_name = filesystem.write_dict_results(\n        combined_json_dict, output_directory, project"
            },
            {
              "lineno": 790,
              "coloffset": 4,
              "linematch": "combined_json_dict = process.combine_dicts(json_dicts)",
              "linematch_context": "    json_dicts = filesystem.get_json_results(json_path)\n    count = len(json_path)\n    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")\n    # combine all of the dictionaries into a single string\n    combined_json_dict = process.combine_dicts(json_dicts)\n    # write the combined JSON file string to the filesystem\n    combined_json_file_name = filesystem.write_dict_results(\n        combined_json_dict, output_directory, project\n    )\n    # output the name of the saved file if saving successfully took place"
            },
            {
              "lineno": 792,
              "coloffset": 4,
              "linematch": "combined_json_file_name = filesystem.write_dict_results(",
              "linematch_context": "    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")\n    # combine all of the dictionaries into a single string\n    combined_json_dict = process.combine_dicts(json_dicts)\n    # write the combined JSON file string to the filesystem\n    combined_json_file_name = filesystem.write_dict_results(\n        combined_json_dict, output_directory, project\n    )\n    # output the name of the saved file if saving successfully took place\n    if combined_json_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{combined_json_file_name}'\")"
            },
            {
              "lineno": 796,
              "coloffset": 4,
              "linematch": "if combined_json_file_name:",
              "linematch_context": "    combined_json_file_name = filesystem.write_dict_results(\n        combined_json_dict, output_directory, project\n    )\n    # output the name of the saved file if saving successfully took place\n    if combined_json_file_name:\n        output.console.print(f\"\\n:sparkles: Saved the file '{combined_json_file_name}'\")\n        output.logger.debug(f\"Saved the file '{combined_json_file_name}'.\")\n    # \"flatten\" (i.e., \"un-nest\") the now-saved combined JSON file using flatterer\n    # create the SQLite3 database and then configure the database for use in datasette\n    combined_flattened_directory = filesystem.write_flattened_csv_and_database("
            },
            {
              "lineno": 801,
              "coloffset": 4,
              "linematch": "combined_flattened_directory = filesystem.write_flattened_csv_and_database(",
              "linematch_context": "        output.console.print(f\"\\n:sparkles: Saved the file '{combined_json_file_name}'\")\n        output.logger.debug(f\"Saved the file '{combined_json_file_name}'.\")\n    # \"flatten\" (i.e., \"un-nest\") the now-saved combined JSON file using flatterer\n    # create the SQLite3 database and then configure the database for use in datasette\n    combined_flattened_directory = filesystem.write_flattened_csv_and_database(\n        combined_json_file_name,\n        output_directory,\n        project,\n    )\n    output.logger.debug(\"Flattened JSON and created SQLite database.\")"
            },
            {
              "lineno": 806,
              "coloffset": 4,
              "linematch": "output.logger.debug(\"Flattened JSON and created SQLite database.\")",
              "linematch_context": "        combined_json_file_name,\n        output_directory,\n        project,\n    )\n    output.logger.debug(\"Flattened JSON and created SQLite database.\")\n    # output the name of the saved file if saving successfully took place\n    if combined_flattened_directory:\n        output.console.print(\n            f\"\\n:sparkles: Created this directory structure in {Path(combined_flattened_directory).parent}:\"\n        )"
            },
            {
              "lineno": 808,
              "coloffset": 4,
              "linematch": "if combined_flattened_directory:",
              "linematch_context": "        project,\n    )\n    output.logger.debug(\"Flattened JSON and created SQLite database.\")\n    # output the name of the saved file if saving successfully took place\n    if combined_flattened_directory:\n        output.console.print(\n            f\"\\n:sparkles: Created this directory structure in {Path(combined_flattened_directory).parent}:\"\n        )\n        combined_directory_tree = filesystem.create_directory_tree_visualization(\n            Path(combined_flattened_directory)"
            },
            {
              "lineno": 863,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83c\udfc3 Start a local datasette server.\"\"\"",
              "linematch_context": "        help=\"Specify the destination for debugging output.\",\n    ),\n    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83c\udfc3 Start a local datasette server.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,"
            },
            {
              "lineno": 865,
              "coloffset": 4,
              "linematch": "output_preamble(",
              "linematch_context": "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83c\udfc3 Start a local datasette server.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,\n        database=database_path,\n        datasette_port=port,"
            },
            {
              "lineno": 874,
              "coloffset": 4,
              "linematch": "output.setup(debug_level, debug_destination)",
              "linematch_context": "        datasette_port=port,\n        metadata=metadata,\n    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display diagnostic information about the datasette instance\n    label = \":sparkles: Starting a local datasette instance:\""
            },
            {
              "lineno": 875,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Display verbose output? {verbose}\")",
              "linematch_context": "        metadata=metadata,\n    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display diagnostic information about the datasette instance\n    label = \":sparkles: Starting a local datasette instance:\"\n    display_serve_or_publish_details("
            },
            {
              "lineno": 876,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug level? {debug_level.value}\")",
              "linematch_context": "    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display diagnostic information about the datasette instance\n    label = \":sparkles: Starting a local datasette instance:\"\n    display_serve_or_publish_details(\n        label, database_path, metadata, port, publish=False"
            },
            {
              "lineno": 877,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug destination? {debug_destination.value}\")",
              "linematch_context": "    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display diagnostic information about the datasette instance\n    label = \":sparkles: Starting a local datasette instance:\"\n    display_serve_or_publish_details(\n        label, database_path, metadata, port, publish=False\n    )"
            },
            {
              "lineno": 879,
              "coloffset": 4,
              "linematch": "label = \":sparkles: Starting a local datasette instance:\"",
              "linematch_context": "    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display diagnostic information about the datasette instance\n    label = \":sparkles: Starting a local datasette instance:\"\n    display_serve_or_publish_details(\n        label, database_path, metadata, port, publish=False\n    )\n    # start the datasette server that will run indefinitely;\n    # shutting down the datasette server with a CTRL-C will"
            },
            {
              "lineno": 880,
              "coloffset": 4,
              "linematch": "display_serve_or_publish_details(",
              "linematch_context": "    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    # display diagnostic information about the datasette instance\n    label = \":sparkles: Starting a local datasette instance:\"\n    display_serve_or_publish_details(\n        label, database_path, metadata, port, publish=False\n    )\n    # start the datasette server that will run indefinitely;\n    # shutting down the datasette server with a CTRL-C will\n    # also shut down this command in chasten"
            },
            {
              "lineno": 886,
              "coloffset": 4,
              "linematch": "database.start_datasette_server(",
              "linematch_context": "    )\n    # start the datasette server that will run indefinitely;\n    # shutting down the datasette server with a CTRL-C will\n    # also shut down this command in chasten\n    database.start_datasette_server(\n        database_path=database_path,\n        datasette_port=port,\n        datasette_metadata=metadata,\n        publish=False,\n        OpSystem=util.get_OS(),"
            },
            {
              "lineno": 938,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83c\udf0e Publish a datasette to Fly or Vercel.\"\"\"",
              "linematch_context": "        help=\"Specify the destination for debugging output.\",\n    ),\n    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83c\udf0e Publish a datasette to Fly or Vercel.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,"
            },
            {
              "lineno": 940,
              "coloffset": 4,
              "linematch": "output_preamble(",
              "linematch_context": "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),\n) -> None:\n    \"\"\"\ud83c\udf0e Publish a datasette to Fly or Vercel.\"\"\"\n    # output the preamble, including extra parameters specific to this function\n    output_preamble(\n        verbose,\n        debug_level,\n        debug_destination,\n        database=database_path,\n        metadata=metadata,"
            },
            {
              "lineno": 948,
              "coloffset": 4,
              "linematch": "output.setup(debug_level, debug_destination)",
              "linematch_context": "        database=database_path,\n        metadata=metadata,\n    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    output.console.print()\n    output.console.print("
            },
            {
              "lineno": 949,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Display verbose output? {verbose}\")",
              "linematch_context": "        metadata=metadata,\n    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    output.console.print()\n    output.console.print(\n        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\""
            },
            {
              "lineno": 950,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug level? {debug_level.value}\")",
              "linematch_context": "    )\n    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    output.console.print()\n    output.console.print(\n        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\"\n    )"
            },
            {
              "lineno": 951,
              "coloffset": 4,
              "linematch": "output.logger.debug(f\"Debug destination? {debug_destination.value}\")",
              "linematch_context": "    # setup the console and the logger through the output module\n    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    output.console.print()\n    output.console.print(\n        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\"\n    )\n    # display details about the publishing step"
            },
            {
              "lineno": 952,
              "coloffset": 4,
              "linematch": "output.console.print()",
              "linematch_context": "    output.setup(debug_level, debug_destination)\n    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    output.console.print()\n    output.console.print(\n        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\"\n    )\n    # display details about the publishing step\n    label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\""
            },
            {
              "lineno": 953,
              "coloffset": 4,
              "linematch": "output.console.print(",
              "linematch_context": "    output.logger.debug(f\"Display verbose output? {verbose}\")\n    output.logger.debug(f\"Debug level? {debug_level.value}\")\n    output.logger.debug(f\"Debug destination? {debug_destination.value}\")\n    output.console.print()\n    output.console.print(\n        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\"\n    )\n    # display details about the publishing step\n    label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\"\n    display_serve_or_publish_details(label, database_path, metadata, publish=True)"
            },
            {
              "lineno": 957,
              "coloffset": 4,
              "linematch": "label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\"",
              "linematch_context": "    output.console.print(\n        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\"\n    )\n    # display details about the publishing step\n    label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\"\n    display_serve_or_publish_details(label, database_path, metadata, publish=True)\n    # publish the datasette instance using fly.io;\n    # this passes control to datasette and then to\n    # the fly program that must be installed\n    database.start_datasette_server("
            },
            {
              "lineno": 958,
              "coloffset": 4,
              "linematch": "display_serve_or_publish_details(label, database_path, metadata, publish=True)",
              "linematch_context": "        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\"\n    )\n    # display details about the publishing step\n    label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\"\n    display_serve_or_publish_details(label, database_path, metadata, publish=True)\n    # publish the datasette instance using fly.io;\n    # this passes control to datasette and then to\n    # the fly program that must be installed\n    database.start_datasette_server(\n        database_path=database_path,"
            },
            {
              "lineno": 962,
              "coloffset": 4,
              "linematch": "database.start_datasette_server(",
              "linematch_context": "    display_serve_or_publish_details(label, database_path, metadata, publish=True)\n    # publish the datasette instance using fly.io;\n    # this passes control to datasette and then to\n    # the fly program that must be installed\n    database.start_datasette_server(\n        database_path=database_path,\n        datasette_metadata=metadata,\n        datasette_platform=datasette_platform.value,\n        publish=True,\n        OpSystem=util.get_OS(),"
            },
            {
              "lineno": 973,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83e\udd9a Start the logging server.\"\"\"",
              "linematch_context": "\n\n@cli.command()\ndef log() -> None:\n    \"\"\"\ud83e\udd9a Start the logging server.\"\"\"\n    # display the header\n    output.print_header()\n    # display details about the server\n    output.print_server()\n    # run the server; note that this"
            },
            {
              "lineno": 975,
              "coloffset": 4,
              "linematch": "output.print_header()",
              "linematch_context": "@cli.command()\ndef log() -> None:\n    \"\"\"\ud83e\udd9a Start the logging server.\"\"\"\n    # display the header\n    output.print_header()\n    # display details about the server\n    output.print_server()\n    # run the server; note that this\n    # syslog server receives debugging\n    # information from chasten."
            },
            {
              "lineno": 977,
              "coloffset": 4,
              "linematch": "output.print_server()",
              "linematch_context": "    \"\"\"\ud83e\udd9a Start the logging server.\"\"\"\n    # display the header\n    output.print_header()\n    # display details about the server\n    output.print_server()\n    # run the server; note that this\n    # syslog server receives debugging\n    # information from chasten.\n    # It must be started in a separate process\n    # before running any sub-command"
            },
            {
              "lineno": 984,
              "coloffset": 4,
              "linematch": "server.start_syslog_server()",
              "linematch_context": "    # information from chasten.\n    # It must be started in a separate process\n    # before running any sub-command\n    # of the chasten tool\n    server.start_syslog_server()\n\n\n@cli.command()\ndef version():\n    \"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\""
            },
            {
              "lineno": 989,
              "coloffset": 4,
              "linematch": "\"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\"",
              "linematch_context": "\n\n@cli.command()\ndef version():\n    \"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\"\n    # Get Chasten version from util file\n    version_string = util.get_chasten_version()\n    # output chasten version\n    typer.echo(f\"chasten {version_string}\")\n"
            },
            {
              "lineno": 991,
              "coloffset": 4,
              "linematch": "version_string = util.get_chasten_version()",
              "linematch_context": "@cli.command()\ndef version():\n    \"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\"\n    # Get Chasten version from util file\n    version_string = util.get_chasten_version()\n    # output chasten version\n    typer.echo(f\"chasten {version_string}\")\n\n\n# ---"
            },
            {
              "lineno": 993,
              "coloffset": 4,
              "linematch": "typer.echo(f\"chasten {version_string}\")",
              "linematch_context": "    \"\"\"\ud83d\udda5\ufe0f  Display the version of Chasten.\"\"\"\n    # Get Chasten version from util file\n    version_string = util.get_chasten_version()\n    # output chasten version\n    typer.echo(f\"chasten {version_string}\")\n\n\n# ---\n# End region: Command-line interface functions }}}\n# ---"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "CML001",
          "name": "count-method-lines",
          "description": "Count the lines within methods.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef/body/* | .//FunctionDef/body/Return",
          "passed": false,
          "matches": [
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "\"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"",
              "linematch_context": "\ndef setup(\n    debug_level: debug.DebugLevel, debug_destination: debug.DebugDestination\n) -> None:\n    \"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"\n    global logger\n    # configure the use of rich for improved terminal output:\n    # --> rich-based tracebacks to enable better debugging on program crash\n    configuration.configure_tracebacks()\n    # --> logging to keep track of key events during program execution;"
            },
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "global logger",
              "linematch_context": "def setup(\n    debug_level: debug.DebugLevel, debug_destination: debug.DebugDestination\n) -> None:\n    \"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"\n    global logger\n    # configure the use of rich for improved terminal output:\n    # --> rich-based tracebacks to enable better debugging on program crash\n    configuration.configure_tracebacks()\n    # --> logging to keep track of key events during program execution;\n    # pass in the actual values as strings instead of using class enums"
            },
            {
              "lineno": 32,
              "coloffset": 4,
              "linematch": "configuration.configure_tracebacks()",
              "linematch_context": "    \"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"\n    global logger\n    # configure the use of rich for improved terminal output:\n    # --> rich-based tracebacks to enable better debugging on program crash\n    configuration.configure_tracebacks()\n    # --> logging to keep track of key events during program execution;\n    # pass in the actual values as strings instead of using class enums\n    logger, _ = configuration.configure_logging(\n        debug_level.value, debug_destination.value\n    )"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "logger, _ = configuration.configure_logging(",
              "linematch_context": "    # --> rich-based tracebacks to enable better debugging on program crash\n    configuration.configure_tracebacks()\n    # --> logging to keep track of key events during program execution;\n    # pass in the actual values as strings instead of using class enums\n    logger, _ = configuration.configure_logging(\n        debug_level.value, debug_destination.value\n    )\n\n\ndef print_diagnostics(verbose: bool, **configurations: Any) -> None:"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "\"\"\"Display all variables input to the function.\"\"\"",
              "linematch_context": "    )\n\n\ndef print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")\n        # iterate through each of the configuration keyword arguments"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")\n        # iterate through each of the configuration keyword arguments\n        for configuration_current in configurations:"
            },
            {
              "lineno": 44,
              "coloffset": 4,
              "linematch": "if verbose:",
              "linematch_context": "def print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")\n        # iterate through each of the configuration keyword arguments\n        for configuration_current in configurations:\n            # print the name and the value of the keyword argument\n            console.print("
            },
            {
              "lineno": 55,
              "coloffset": 4,
              "linematch": "\"\"\"Produce logging information and only print when not verbose.\"\"\"",
              "linematch_context": "            )\n\n\ndef opt_print_log(verbose: bool, **contents: Any) -> None:\n    \"\"\"Produce logging information and only print when not verbose.\"\"\"\n    global console  # noqa: PLW0602\n    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument\n        # to the console if verbose mode is enabled"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef opt_print_log(verbose: bool, **contents: Any) -> None:\n    \"\"\"Produce logging information and only print when not verbose.\"\"\"\n    global console  # noqa: PLW0602\n    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument\n        # to the console if verbose mode is enabled\n        if verbose:"
            },
            {
              "lineno": 58,
              "coloffset": 4,
              "linematch": "for current in contents:",
              "linematch_context": "def opt_print_log(verbose: bool, **contents: Any) -> None:\n    \"\"\"Produce logging information and only print when not verbose.\"\"\"\n    global console  # noqa: PLW0602\n    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument\n        # to the console if verbose mode is enabled\n        if verbose:\n            console.print(contents[current])\n        # always log the information to the configured logger"
            },
            {
              "lineno": 68,
              "coloffset": 4,
              "linematch": "\"\"\"Display tool details in the header.\"\"\"",
              "linematch_context": "        logger.debug(contents[current])\n\n\ndef print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline\n    )"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline\n    )\n    console.print(constants.chasten.Website)"
            },
            {
              "lineno": 70,
              "coloffset": 4,
              "linematch": "console.print()",
              "linematch_context": "\ndef print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline\n    )\n    console.print(constants.chasten.Website)\n"
            },
            {
              "lineno": 71,
              "coloffset": 4,
              "linematch": "console.print(",
              "linematch_context": "def print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline\n    )\n    console.print(constants.chasten.Website)\n\n"
            },
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "console.print(constants.chasten.Website)",
              "linematch_context": "    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline\n    )\n    console.print(constants.chasten.Website)\n\n\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602"
            },
            {
              "lineno": 78,
              "coloffset": 4,
              "linematch": "\"\"\"Display server details in the header.\"\"\"",
              "linematch_context": "    console.print(constants.chasten.Website)\n\n\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n\n"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n\n\ndef print_test_start() -> None:"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "console.print(constants.output.Syslog)",
              "linematch_context": "\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\""
            },
            {
              "lineno": 81,
              "coloffset": 4,
              "linematch": "console.print()",
              "linematch_context": "def print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602"
            },
            {
              "lineno": 85,
              "coloffset": 4,
              "linematch": "\"\"\"Display details about the test run.\"\"\"",
              "linematch_context": "    console.print()\n\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n\n"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n\n\ndef print_test_finish() -> None:"
            },
            {
              "lineno": 87,
              "coloffset": 4,
              "linematch": "console.print(constants.output.Test_Start)",
              "linematch_context": "\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\""
            },
            {
              "lineno": 88,
              "coloffset": 4,
              "linematch": "console.print()",
              "linematch_context": "def print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602"
            },
            {
              "lineno": 92,
              "coloffset": 4,
              "linematch": "\"\"\"Display details about the test run.\"\"\"",
              "linematch_context": "    console.print()\n\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n"
            },
            {
              "lineno": 93,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "console.print()",
              "linematch_context": "\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n\ndef print_footer() -> None:"
            },
            {
              "lineno": 95,
              "coloffset": 4,
              "linematch": "console.print(\":sparkles: Finished running test suite for the specified program\")",
              "linematch_context": "def print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\""
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "console.print()",
              "linematch_context": "    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602"
            },
            {
              "lineno": 100,
              "coloffset": 4,
              "linematch": "\"\"\"Display concluding details in the footer.\"\"\"",
              "linematch_context": "    console.print()\n\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:"
            },
            {
              "lineno": 101,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\""
            },
            {
              "lineno": 102,
              "coloffset": 4,
              "linematch": "console.print()",
              "linematch_context": "\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\"\n    # create an empty dictionary"
            },
            {
              "lineno": 106,
              "coloffset": 4,
              "linematch": "\"\"\"Organize the files in a list according to their base directory.\"\"\"",
              "linematch_context": "    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\"\n    # create an empty dictionary\n    grouped_files: Dict[Path, List[str]] = {}\n    # iterate through each of the full paths\n    # and extract the containing directory\n    # from the name of the file that is contained"
            },
            {
              "lineno": 108,
              "coloffset": 4,
              "linematch": "grouped_files: Dict[Path, List[str]] = {}",
              "linematch_context": "\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\"\n    # create an empty dictionary\n    grouped_files: Dict[Path, List[str]] = {}\n    # iterate through each of the full paths\n    # and extract the containing directory\n    # from the name of the file that is contained\n    for file_path in file_paths:\n        # extract the parent (i.e., containing)"
            },
            {
              "lineno": 112,
              "coloffset": 4,
              "linematch": "for file_path in file_paths:",
              "linematch_context": "    grouped_files: Dict[Path, List[str]] = {}\n    # iterate through each of the full paths\n    # and extract the containing directory\n    # from the name of the file that is contained\n    for file_path in file_paths:\n        # extract the parent (i.e., containing)\n        # directory for the current file path\n        directory = file_path.parent\n        # extract the name of the file, excluding\n        # the containing directory"
            },
            {
              "lineno": 126,
              "coloffset": 4,
              "linematch": "return grouped_files",
              "linematch_context": "        if directory not in grouped_files:\n            grouped_files[directory] = []\n        grouped_files[directory].append(file_name)\n    # return the dictionary of files organized by directory\n    return grouped_files\n\n\ndef shorten_file_name(file_name: str, max_length: int) -> str:\n    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long"
            },
            {
              "lineno": 130,
              "coloffset": 4,
              "linematch": "\"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"",
              "linematch_context": "    return grouped_files\n\n\ndef shorten_file_name(file_name: str, max_length: int) -> str:\n    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long\n    if len(file_name) > max_length:\n        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name\n"
            },
            {
              "lineno": 132,
              "coloffset": 4,
              "linematch": "if len(file_name) > max_length:",
              "linematch_context": "\ndef shorten_file_name(file_name: str, max_length: int) -> str:\n    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long\n    if len(file_name) > max_length:\n        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name\n\n\ndef print_list_contents(container: List[Path]) -> None:"
            },
            {
              "lineno": 134,
              "coloffset": 4,
              "linematch": "return file_name",
              "linematch_context": "    \"\"\"Elide part of a file name if it is longer than the maximum length.\"\"\"\n    # remove content from the start of the filename if it is too long\n    if len(file_name) > max_length:\n        return \"... \" + file_name[-(max_length - 3) :]\n    return file_name\n\n\ndef print_list_contents(container: List[Path]) -> None:\n    \"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"\n    global console  # noqa: PLW0602"
            },
            {
              "lineno": 138,
              "coloffset": 4,
              "linematch": "\"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"",
              "linematch_context": "    return file_name\n\n\ndef print_list_contents(container: List[Path]) -> None:\n    \"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"\n    global console  # noqa: PLW0602\n    # group all of the files by the directory that contains them;\n    # note that this is important because the contain can contain\n    # paths that specify files in different directories\n    grouped_files = group_files_by_directory(container)"
            },
            {
              "lineno": 139,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_list_contents(container: List[Path]) -> None:\n    \"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"\n    global console  # noqa: PLW0602\n    # group all of the files by the directory that contains them;\n    # note that this is important because the contain can contain\n    # paths that specify files in different directories\n    grouped_files = group_files_by_directory(container)\n    # iterate through each of the directories and"
            },
            {
              "lineno": 143,
              "coloffset": 4,
              "linematch": "grouped_files = group_files_by_directory(container)",
              "linematch_context": "    global console  # noqa: PLW0602\n    # group all of the files by the directory that contains them;\n    # note that this is important because the contain can contain\n    # paths that specify files in different directories\n    grouped_files = group_files_by_directory(container)\n    # iterate through each of the directories and\n    # --> display the name of the directory\n    # --> display the name of each file stored in this directory\n    for directory, files in grouped_files.items():\n        console.print(f\"{small_bullet_unicode} Directory: {directory}\")"
            },
            {
              "lineno": 147,
              "coloffset": 4,
              "linematch": "for directory, files in grouped_files.items():",
              "linematch_context": "    grouped_files = group_files_by_directory(container)\n    # iterate through each of the directories and\n    # --> display the name of the directory\n    # --> display the name of each file stored in this directory\n    for directory, files in grouped_files.items():\n        console.print(f\"{small_bullet_unicode} Directory: {directory}\")\n        filecount = 0\n        for file_name in files:\n            filecount = +1\n            console.print("
            },
            {
              "lineno": 161,
              "coloffset": 4,
              "linematch": "\"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"",
              "linematch_context": "            )\n\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass\n    # is an instance of pyastgrepsearch.Match and contains the entire details"
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass\n    # is an instance of pyastgrepsearch.Match and contains the entire details\n    # about the specific match, including the entire source code. This object"
            },
            {
              "lineno": 169,
              "coloffset": 4,
              "linematch": "if not verbose:",
              "linematch_context": "    # 2) Note: the _match object that is inside of a Match BaseModel subclass\n    # is an instance of pyastgrepsearch.Match and contains the entire details\n    # about the specific match, including the entire source code. This object\n    # is not saved to the JSON file by default, as evidenced by the underscore\n    if not verbose:\n        return None\n    opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")\n    # iterate through the the list of sources inside of the resulting analysis\n    for current_source in chasten.sources:\n        # extract the current check from this source"
            },
            {
              "lineno": 171,
              "coloffset": 4,
              "linematch": "opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")",
              "linematch_context": "    # about the specific match, including the entire source code. This object\n    # is not saved to the JSON file by default, as evidenced by the underscore\n    if not verbose:\n        return None\n    opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")\n    # iterate through the the list of sources inside of the resulting analysis\n    for current_source in chasten.sources:\n        # extract the current check from this source\n        current_check: results.Check = current_source.check  # type: ignore\n        current_xpath_pattern = current_check.pattern"
            },
            {
              "lineno": 173,
              "coloffset": 4,
              "linematch": "for current_source in chasten.sources:",
              "linematch_context": "    if not verbose:\n        return None\n    opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")\n    # iterate through the the list of sources inside of the resulting analysis\n    for current_source in chasten.sources:\n        # extract the current check from this source\n        current_check: results.Check = current_source.check  # type: ignore\n        current_xpath_pattern = current_check.pattern\n        console.print(\"\\n:tada: Check:\")\n        xpath_syntax = Syntax("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "MRET001",
          "name": "multiple-returns-in-function",
          "description": "Detect functions with multiple return statements.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[count(body//Return) > 2]",
          "passed": true,
          "matches": [
            {
              "lineno": 103,
              "coloffset": 0,
              "linematch": "def validate_checks_file(",
              "linematch_context": "    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,\n    checks_file_name: str,\n    chasten_user_config_url_str: str,\n    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,"
            },
            {
              "lineno": 177,
              "coloffset": 0,
              "linematch": "def validate_configuration_files(",
              "linematch_context": "        yaml_data_dict,\n    )\n\n\ndef validate_configuration_files(\n    config: str,\n    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:"
            },
            {
              "lineno": 340,
              "coloffset": 0,
              "linematch": "def extract_configuration_details_from_config_dir(",
              "linematch_context": "    # there was at least one validation error\n    return (False, {})\n\n\ndef extract_configuration_details_from_config_dir(\n    chasten_user_config_dir_str: Path,\n    configuration_file: str = constants.filesystem.Main_Configuration_File,\n) -> Tuple[bool, str, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config directory.\n"
            },
            {
              "lineno": 383,
              "coloffset": 0,
              "linematch": "def extract_configuration_details_from_config_url(",
              "linematch_context": "            )\n            return (False, None, None, None)  # type: ignore\n\n\ndef extract_configuration_details_from_config_url(\n    chasten_user_config_url: Url,\n) -> Tuple[bool, str, Dict[str, Dict[str, Any]]]:\n    \"\"\"Extract details from the configuration given a config URL.\n\n    chasten_user_config_url -- URL to config or checks yaml file."
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "MRET001",
          "name": "multiple-returns-in-function",
          "description": "Detect functions with multiple return statements.",
          "min": 1,
          "max": 10,
          "pattern": ".//FunctionDef[count(body//Return) > 2]",
          "passed": true,
          "matches": [
            {
              "lineno": 71,
              "coloffset": 0,
              "linematch": "def check_match_count(",
              "linematch_context": "    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:\n    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_debug.py",
        "check": {
          "id": "UNUSED001",
          "name": "unused-variables",
          "description": "Detect variables that are defined but not used.",
          "min": null,
          "max": null,
          "pattern": "//FunctionDef[starts-with(@name, \"test_\")]//Assert[count(.//Call[func/Name]) > 0]",
          "passed": true,
          "matches": [
            {
              "lineno": 19,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.DEBUG, DebugLevel)",
              "linematch_context": "\n\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n"
            },
            {
              "lineno": 20,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.INFO, DebugLevel)",
              "linematch_context": "\ndef test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n"
            },
            {
              "lineno": 21,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.WARNING, DebugLevel)",
              "linematch_context": "def test_debug_level_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():"
            },
            {
              "lineno": 22,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.ERROR, DebugLevel)",
              "linematch_context": "    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\""
            },
            {
              "lineno": 23,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugLevel.CRITICAL, DebugLevel)",
              "linematch_context": "    assert isinstance(DebugLevel.DEBUG, DebugLevel)\n    assert isinstance(DebugLevel.INFO, DebugLevel)\n    assert isinstance(DebugLevel.WARNING, DebugLevel)\n    assert isinstance(DebugLevel.ERROR, DebugLevel)\n    assert isinstance(DebugLevel.CRITICAL, DebugLevel)\n\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 28,
              "coloffset": 4,
              "linematch": "assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]",
              "linematch_context": "\n\ndef test_debug_level_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible values.\"\"\"\n    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n\n\ndef test_debug_destination_values():\n    \"\"\"Confirm that all of the enumeration values are correct.\"\"\"\n    assert DebugDestination.CONSOLE == \"CONSOLE\""
            },
            {
              "lineno": 39,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.CONSOLE, DebugDestination)",
              "linematch_context": "\n\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\""
            },
            {
              "lineno": 40,
              "coloffset": 4,
              "linematch": "assert isinstance(DebugDestination.SYSLOG, DebugDestination)",
              "linematch_context": "\ndef test_debug_destination_isinstance():\n    \"\"\"Confirm that all of the individual levels are of the correct type.\"\"\"\n    assert isinstance(DebugDestination.CONSOLE, DebugDestination)\n    assert isinstance(DebugDestination.SYSLOG, DebugDestination)\n\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            },
            {
              "lineno": 45,
              "coloffset": 4,
              "linematch": "assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]",
              "linematch_context": "\n\ndef test_debug_destination_iteration():\n    \"\"\"Confirm that it is possible to list all of the possible valuers.\"\"\"\n    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]\n\n\ndef test_level_destination_invalid():\n    \"\"\"Confirm that invalid values raise a ValueError.\"\"\"\n    with pytest.raises(ValueError):"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_configuration.py",
        "check": {
          "id": "UNUSED001",
          "name": "unused-variables",
          "description": "Detect variables that are defined but not used.",
          "min": null,
          "max": null,
          "pattern": "//FunctionDef[starts-with(@name, \"test_\")]//Assert[count(.//Call[func/Name]) > 0]",
          "passed": true,
          "matches": [
            {
              "lineno": 36,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert created\n    assert isinstance(logger, logging.Logger)\n\n\n@given(\n    debug_level=strategies.sampled_from(\n        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            },
            {
              "lineno": 51,
              "coloffset": 4,
              "linematch": "assert isinstance(logger, logging.Logger)",
              "linematch_context": "    \"\"\"Use Hypothesis to confirm that the function does not crash and always produces logger with valid data.\"\"\"\n    logger, created = configuration.configure_logging(debug_level, debug_dest)\n    assert logger\n    assert not created\n    assert isinstance(logger, logging.Logger)"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_filesystem.py",
        "check": {
          "id": "UNUSED001",
          "name": "unused-variables",
          "description": "Detect variables that are defined but not used.",
          "min": null,
          "max": null,
          "pattern": "//FunctionDef[starts-with(@name, \"test_\")]//Assert[count(.//Call[func/Name]) > 0]",
          "passed": true,
          "matches": [
            {
              "lineno": 74,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()\n    # call the function under test\n    tree = filesystem.create_directory_tree_visualization(tmp_dir)\n    # confirm that the output is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm the directory name in root node\n    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            },
            {
              "lineno": 80,
              "coloffset": 4,
              "linematch": "assert set(dirs) == {",
              "linematch_context": "    assert tree.label == f\":open_file_folder: {tmp_dir.name}\"\n    # confirm that the child nodes contain the expected dirs and files\n    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore\n    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }"
            },
            {
              "lineno": 83,
              "coloffset": 4,
              "linematch": "assert set(files) == {",
              "linematch_context": "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore\n    assert set(dirs) == {\n        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()\n    }\n    assert set(files) == {\n        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()\n    }\n\n\n@given(directory=strategies.builds(pathlib.Path))"
            },
            {
              "lineno": 94,
              "coloffset": 4,
              "linematch": "assert isinstance(tree, Tree)",
              "linematch_context": "def test_fuzz_create_directory_tree(directory):\n    \"\"\"Using Hypothesis to confirm that the file system directory tree creation works.\"\"\"\n    tree = filesystem.create_directory_tree_visualization(directory)\n    # confirm that it is a rich tree object\n    assert isinstance(tree, Tree)\n    # confirm that it has the fully-qualified name as the main label\n    assert tree.label == f\":open_file_folder: {directory.name}\"\n    dirs = []\n    files = []\n    # build up a list of all of the directories and files"
            },
            {
              "lineno": 106,
              "coloffset": 4,
              "linematch": "assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())",
              "linematch_context": "            dirs.append(node.label[19:])  # type: ignore\n        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):"
            },
            {
              "lineno": 107,
              "coloffset": 4,
              "linematch": "assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())",
              "linematch_context": "        else:\n            files.append(node.label[17:])  # type: ignore\n    # confirm that it contains all of the directory and file names\n    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())\n    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_config_dir_does_not_exist(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm possible to create the user configuration directory when it does not exist.\"\"\""
            },
            {
              "lineno": 182,
              "coloffset": 4,
              "linematch": "assert filesystem.detect_configuration(config) == str(config)",
              "linematch_context": "    # detecting a configuration directory should happen with\n    # the provided configuration directory over the platform-specific one\n    config = tmp_path / \"config\"\n    config.mkdir()\n    assert filesystem.detect_configuration(config) == str(config)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_detect_configuration_with_input_config_directory_use_default(\n    mock_user_config_dir, tmp_path"
            },
            {
              "lineno": 199,
              "coloffset": 4,
              "linematch": "assert detected_directory == str(dir_path)",
              "linematch_context": "    result = filesystem.create_configuration_directory()\n    assert result == dir_path\n    assert dir_path.exists()\n    detected_directory = filesystem.detect_configuration(None)\n    assert detected_directory == str(dir_path)\n\n\n@patch(\"chasten.configuration.user_config_dir\")\ndef test_create_main_configuration_file(mock_user_config_dir, tmp_path):\n    \"\"\"Confirm that it is possible to create the main configuration file if it does not exist.\"\"\""
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_process.py",
        "check": {
          "id": "UNUSED001",
          "name": "unused-variables",
          "description": "Detect variables that are defined but not used.",
          "min": null,
          "max": null,
          "pattern": "//FunctionDef[starts-with(@name, \"test_\")]//Assert[count(.//Call[func/Name]) > 0]",
          "passed": true,
          "matches": [
            {
              "lineno": 34,
              "coloffset": 4,
              "linematch": "assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)",
              "linematch_context": "@pytest.mark.fuzz\ndef test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n"
            },
            {
              "lineno": 35,
              "coloffset": 4,
              "linematch": "assert set(filtered) == set(",
              "linematch_context": "def test_filter_matches(match_list, data_type):\n    \"\"\"Use Hypothesis to confirm that filtering always gets the Match objects.\"\"\"\n    filtered, _ = process.filter_matches(match_list, data_type)\n    assert all(isinstance(m, pyastgrepsearch.Match) for m in filtered)\n    assert set(filtered) == set(\n        m for m in match_list if isinstance(m, pyastgrepsearch.Match)\n    )\n\n\n@given(match_list=st.lists(st.integers()))"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/tests/test_checks.py",
        "check": {
          "id": "UNUSED001",
          "name": "unused-variables",
          "description": "Detect variables that are defined but not used.",
          "min": null,
          "max": null,
          "pattern": "//FunctionDef[starts-with(@name, \"test_\")]//Assert[count(.//Call[func/Name]) > 0]",
          "passed": true,
          "matches": [
            {
              "lineno": 73,
              "coloffset": 4,
              "linematch": "assert \"described test\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"described test\" == extract_description(check)\n\n\ndef test_extract_desription_none():\n    \"\"\"Confirm that if a description does not exist, an empty string is returned.\"\"\"\n    check = {"
            },
            {
              "lineno": 84,
              "coloffset": 4,
              "linematch": "assert \"\" == extract_description(check)",
              "linematch_context": "        \"count\": {\n            \"min\": 1,\n        },\n    }\n    assert \"\" == extract_description(check)\n\n\n@pytest.mark.parametrize(\n    \"bool_status,expected\",\n    ["
            },
            {
              "lineno": 96,
              "coloffset": 4,
              "linematch": "assert make_checks_status_message(bool_status) == expected",
              "linematch_context": "    ],\n)\ndef test_make_checks_status_message(bool_status: bool, expected: str):\n    \"\"\"Confirms the output matches the expected message.\"\"\"\n    assert make_checks_status_message(bool_status) == expected\n\n\n@given(st.dictionaries(st.text(), st.integers()))\n@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):"
            },
            {
              "lineno": 104,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@pytest.mark.fuzz\ndef test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz"
            },
            {
              "lineno": 105,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_extract_min_max_hypothesis(check):\n    \"\"\"Use Hypothesis to confirm that extract works correctly.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@given(from_schema(JSON_SCHEMA_COUNT))\n@pytest.mark.fuzz\n@settings(suppress_health_check=[HealthCheck.too_slow])"
            },
            {
              "lineno": 114,
              "coloffset": 4,
              "linematch": "assert isinstance(min_count, int) or min_count is None",
              "linematch_context": "@settings(suppress_health_check=[HealthCheck.too_slow])\ndef test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\","
            },
            {
              "lineno": 115,
              "coloffset": 4,
              "linematch": "assert isinstance(max_count, int) or max_count is None",
              "linematch_context": "def test_integers(check):\n    \"\"\"Use Hypothesis and the JSON schema plugin to confirm validation works for all possible check configurations.\"\"\"\n    min_count, max_count = extract_min_max(check)\n    assert isinstance(min_count, int) or min_count is None\n    assert isinstance(max_count, int) or max_count is None\n\n\n@pytest.mark.parametrize(\n    \"count,min_value,max_value,expected\",\n    ["
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "F027",
          "name": "high-cyclomatic-complexity",
          "description": "Methods with high cyclomatic complexity are hard to test and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//And | .//Or) > 10]",
          "passed": true,
          "matches": [
            {
              "lineno": 177,
              "coloffset": 0,
              "linematch": "def validate_configuration_files(",
              "linematch_context": "        yaml_data_dict,\n    )\n\n\ndef validate_configuration_files(\n    config: str,\n    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "F027",
          "name": "high-cyclomatic-complexity",
          "description": "Methods with high cyclomatic complexity are hard to test and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//And | .//Or) > 10]",
          "passed": true,
          "matches": [
            {
              "lineno": 252,
              "coloffset": 0,
              "linematch": "def analyze(  # noqa: PLR0912, PLR0913, PLR0915",
              "linematch_context": "            sys.exit(constants.markers.Non_Zero_Exit)\n\n\n@cli.command()\ndef analyze(  # noqa: PLR0912, PLR0913, PLR0915\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    xpath: Path = typer.Option(\n        str,\n        \"--xpath-version\",\n        \"-xp\","
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 103,
              "coloffset": 0,
              "linematch": "def validate_checks_file(",
              "linematch_context": "    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,\n    checks_file_name: str,\n    chasten_user_config_url_str: str,\n    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,"
            },
            {
              "lineno": 177,
              "coloffset": 0,
              "linematch": "def validate_configuration_files(",
              "linematch_context": "        yaml_data_dict,\n    )\n\n\ndef validate_configuration_files(\n    config: str,\n    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 71,
              "coloffset": 0,
              "linematch": "def check_match_count(",
              "linematch_context": "    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:\n    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 131,
              "coloffset": 0,
              "linematch": "def start_datasette_server(  # noqa: PLR0912, PLR0913",
              "linematch_context": "        )\n    output.console.print()\n\n\ndef start_datasette_server(  # noqa: PLR0912, PLR0913\n    database_path: Path,\n    datasette_metadata: Path,\n    datasette_platform: str = enumerations.DatasettePublicationPlatform.FLY.value,\n    datasette_port: int = 8001,\n    publish: bool = False,"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 127,
              "coloffset": 0,
              "linematch": "def create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore",
              "linematch_context": "    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]\n    chasten_user_config_main_file.write_text(file_contents)\n\n\ndef create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 127,
              "coloffset": 4,
              "linematch": "def on_button_pressed(self, event: Button.Pressed) -> None:",
              "linematch_context": "            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 0,
              "linematch": "def include_or_exclude_checks(",
              "linematch_context": "\nfrom chasten import constants, enumerations\n\n\ndef include_or_exclude_checks(\n    checks: List[Dict[str, Union[str, Dict[str, int]]]],\n    check_attribute: enumerations.FilterableAttribute,\n    check_match: str,\n    check_confidence: int = constants.checks.Check_Confidence,\n    include: bool = True,"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 154,
              "coloffset": 0,
              "linematch": "def configure(  # noqa: PLR0913",
              "linematch_context": "        )\n\n\n@cli.command()\ndef configure(  # noqa: PLR0913\n    task: enumerations.ConfigureTask = typer.Argument(\n        enumerations.ConfigureTask.VALIDATE.value\n    ),\n    config: str = typer.Option(\n        None,"
            },
            {
              "lineno": 252,
              "coloffset": 0,
              "linematch": "def analyze(  # noqa: PLR0912, PLR0913, PLR0915",
              "linematch_context": "            sys.exit(constants.markers.Non_Zero_Exit)\n\n\n@cli.command()\ndef analyze(  # noqa: PLR0912, PLR0913, PLR0915\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    xpath: Path = typer.Option(\n        str,\n        \"--xpath-version\",\n        \"-xp\","
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "F030",
          "name": "deeply-nested-control-structures",
          "description": "Deeply nested control structures make the code hard to read and understand.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 160,
              "coloffset": 0,
              "linematch": "def print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:",
              "linematch_context": "                f\"  {small_bullet_unicode} file(s) {int(filecount)} in this directory\"\n            )\n\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/server.py",
        "check": {
          "id": "F035",
          "name": "use-of-global-variables",
          "description": "Use of global variables can lead to code that is hard to debug and maintain.",
          "min": null,
          "max": null,
          "pattern": ".//Global",
          "passed": true,
          "matches": [
            {
              "lineno": 21,
              "coloffset": 8,
              "linematch": "global logger  # noqa: PLW0602",
              "linematch_context": "    \"\"\"Syslog UDP handler for receiving debugging messages.\"\"\"\n\n    def handle(self):\n        \"\"\"Receive a message and then display it in output and log it to a file.\"\"\"\n        global logger  # noqa: PLW0602\n        # receive the message from the syslog logging client\n        message = bytes.decode(\n            self.request[0].strip(), encoding=constants.server.Utf8_Encoding\n        )\n        # remove not-printable characters that can appear in message"
            },
            {
              "lineno": 41,
              "coloffset": 4,
              "linematch": "global logger  # noqa: PLW0602",
              "linematch_context": "\n\ndef start_syslog_server():\n    \"\"\"Start a syslog server.\"\"\"\n    global logger  # noqa: PLW0602\n    # always log all of the messages to a file\n    logger.setLevel(logging.DEBUG)\n    # create a RotatingFileHandler such that:\n    # -- it is stored in a file\n    # -- it can never be bigger than 1 MB"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "F035",
          "name": "use-of-global-variables",
          "description": "Use of global variables can lead to code that is hard to debug and maintain.",
          "min": null,
          "max": null,
          "pattern": ".//Global",
          "passed": true,
          "matches": [
            {
              "lineno": 29,
              "coloffset": 4,
              "linematch": "global logger",
              "linematch_context": "def setup(\n    debug_level: debug.DebugLevel, debug_destination: debug.DebugDestination\n) -> None:\n    \"\"\"Perform the setup steps and return a Console for terminal-based display.\"\"\"\n    global logger\n    # configure the use of rich for improved terminal output:\n    # --> rich-based tracebacks to enable better debugging on program crash\n    configuration.configure_tracebacks()\n    # --> logging to keep track of key events during program execution;\n    # pass in the actual values as strings instead of using class enums"
            },
            {
              "lineno": 42,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_diagnostics(verbose: bool, **configurations: Any) -> None:\n    \"\"\"Display all variables input to the function.\"\"\"\n    global console  # noqa: PLW0602\n    # display diagnostic information for each configuration keyword argument\n    if verbose:\n        console.print(\":sparkles: Configured with these parameters:\")\n        # iterate through each of the configuration keyword arguments\n        for configuration_current in configurations:"
            },
            {
              "lineno": 56,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef opt_print_log(verbose: bool, **contents: Any) -> None:\n    \"\"\"Produce logging information and only print when not verbose.\"\"\"\n    global console  # noqa: PLW0602\n    # iterate through each of the configuration keyword arguments\n    for current in contents:\n        # print the name and the value of the keyword argument\n        # to the console if verbose mode is enabled\n        if verbose:"
            },
            {
              "lineno": 69,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_header() -> None:\n    \"\"\"Display tool details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\n        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline\n    )\n    console.print(constants.chasten.Website)"
            },
            {
              "lineno": 79,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_server() -> None:\n    \"\"\"Display server details in the header.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Syslog)\n    console.print()\n\n\ndef print_test_start() -> None:"
            },
            {
              "lineno": 86,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_test_start() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print(constants.output.Test_Start)\n    console.print()\n\n\ndef print_test_finish() -> None:"
            },
            {
              "lineno": 93,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_test_finish() -> None:\n    \"\"\"Display details about the test run.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n    console.print(\":sparkles: Finished running test suite for the specified program\")\n    console.print()\n\n"
            },
            {
              "lineno": 101,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_footer() -> None:\n    \"\"\"Display concluding details in the footer.\"\"\"\n    global console  # noqa: PLW0602\n    console.print()\n\n\ndef group_files_by_directory(file_paths: List[Path]) -> Dict[Path, List[str]]:\n    \"\"\"Organize the files in a list according to their base directory.\"\"\""
            },
            {
              "lineno": 139,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_list_contents(container: List[Path]) -> None:\n    \"\"\"Display the contents of the list in an easy-to-read fashion.\"\"\"\n    global console  # noqa: PLW0602\n    # group all of the files by the directory that contains them;\n    # note that this is important because the contain can contain\n    # paths that specify files in different directories\n    grouped_files = group_files_by_directory(container)\n    # iterate through each of the directories and"
            },
            {
              "lineno": 162,
              "coloffset": 4,
              "linematch": "global console  # noqa: PLW0602",
              "linematch_context": "\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass\n    # is an instance of pyastgrepsearch.Match and contains the entire details\n    # about the specific match, including the entire source code. This object"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configuration.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 103,
              "coloffset": 0,
              "linematch": "def validate_checks_file(",
              "linematch_context": "    output.opt_print_log(verbose, tree=rich_path_tree)\n    output.opt_print_log(verbose, empty=\"\")\n\n\ndef validate_checks_file(\n    verbose: bool,\n    checks_file_name: str,\n    chasten_user_config_url_str: str,\n    chasten_user_config_dir_str: str,\n    chasten_user_config_file_str: str,"
            },
            {
              "lineno": 177,
              "coloffset": 0,
              "linematch": "def validate_configuration_files(",
              "linematch_context": "        yaml_data_dict,\n    )\n\n\ndef validate_configuration_files(\n    config: str,\n    verbose: bool = False,\n) -> Tuple[\n    bool, Union[Dict[str, List[Dict[str, Union[str, Dict[str, int]]]]], Dict[Any, Any]]\n]:"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/checks.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 71,
              "coloffset": 0,
              "linematch": "def check_match_count(",
              "linematch_context": "    \"\"\"Help to see if the value is in the closed interval.\"\"\"\n    return min(max_value, value) == value and max(min_value, value) == value\n\n\ndef check_match_count(\n    count: int, min_value: Union[int, None] = None, max_value: Union[int, None] = None\n) -> bool:\n    \"\"\"Confirm that the count is between min_value and max_value.\"\"\"\n    # Overall description: if min_value is not None then count must be >= min_value.\n    # If max_value is not None then count must be <= max_value"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/database.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 131,
              "coloffset": 0,
              "linematch": "def start_datasette_server(  # noqa: PLR0912, PLR0913",
              "linematch_context": "        )\n    output.console.print()\n\n\ndef start_datasette_server(  # noqa: PLR0912, PLR0913\n    database_path: Path,\n    datasette_metadata: Path,\n    datasette_platform: str = enumerations.DatasettePublicationPlatform.FLY.value,\n    datasette_port: int = 8001,\n    publish: bool = False,"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/filesystem.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 127,
              "coloffset": 0,
              "linematch": "def create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore",
              "linematch_context": "    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]\n    chasten_user_config_main_file.write_text(file_contents)\n\n\ndef create_directory_tree_visualization(path: Path, tree: Tree = None) -> Tree:  # type: ignore\n    \"\"\"Create a directory tree visualization using the Rich tree.\"\"\"\n    # create the root of the tree if it\n    # has not already been created\n    if tree is None:\n        tree = Tree(f\":open_file_folder: {path.name}\")"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/configApp.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 127,
              "coloffset": 4,
              "linematch": "def on_button_pressed(self, event: Button.Pressed) -> None:",
              "linematch_context": "            if event.validation_result.is_valid:\n                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value\n                self.Valid = True\n\n    def on_button_pressed(self, event: Button.Pressed) -> None:\n        if event.button.id == \"Exact\":\n            self.Check[2] = True  # Mark the \"Exact\" button as clicked\n            event.button.disabled = True  # Disable the \"Exact\" button after clicking\n        elif event.button.id == \"done\":\n            config_App.exit("
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/process.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 12,
              "coloffset": 0,
              "linematch": "def include_or_exclude_checks(",
              "linematch_context": "\nfrom chasten import constants, enumerations\n\n\ndef include_or_exclude_checks(\n    checks: List[Dict[str, Union[str, Dict[str, int]]]],\n    check_attribute: enumerations.FilterableAttribute,\n    check_match: str,\n    check_confidence: int = constants.checks.Check_Confidence,\n    include: bool = True,"
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/main.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 154,
              "coloffset": 0,
              "linematch": "def configure(  # noqa: PLR0913",
              "linematch_context": "        )\n\n\n@cli.command()\ndef configure(  # noqa: PLR0913\n    task: enumerations.ConfigureTask = typer.Argument(\n        enumerations.ConfigureTask.VALIDATE.value\n    ),\n    config: str = typer.Option(\n        None,"
            },
            {
              "lineno": 252,
              "coloffset": 0,
              "linematch": "def analyze(  # noqa: PLR0912, PLR0913, PLR0915",
              "linematch_context": "            sys.exit(constants.markers.Non_Zero_Exit)\n\n\n@cli.command()\ndef analyze(  # noqa: PLR0912, PLR0913, PLR0915\n    project: str = typer.Argument(help=\"Name of the project.\"),\n    xpath: Path = typer.Option(\n        str,\n        \"--xpath-version\",\n        \"-xp\","
            }
          ]
        }
      },
      {
        "filename": "/Users/danielbekele/jsem/SEERS/scripts/analyzer/demo/chasten/chasten/output.py",
        "check": {
          "id": "P005",
          "name": "long-scope-chaining",
          "description": "A multiply-nested method or function.",
          "min": null,
          "max": null,
          "pattern": ".//FunctionDef[count(.//If | .//For | .//While | .//Try) > 3]",
          "passed": true,
          "matches": [
            {
              "lineno": 160,
              "coloffset": 0,
              "linematch": "def print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:",
              "linematch_context": "                f\"  {small_bullet_unicode} file(s) {int(filecount)} in this directory\"\n            )\n\n\ndef print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:\n    \"\"\"Print all of the verbose debugging details for the results of an analysis.\"\"\"\n    global console  # noqa: PLW0602\n    # 1) Note: see the BaseModel definitions in results.py for more details\n    # about the objects and their relationships\n    # 2) Note: the _match object that is inside of a Match BaseModel subclass"
            }
          ]
        }
      }
    ]
  },
  "mutmut_result": {
    "disabled": 0,
    "errors": 0,
    "failures": 32,
    "tests": 2043,
    "time": 0,
    "testsuite": [
      {
        "disabled": 0,
        "errors": 0,
        "failures": 32,
        "name": "mutmut",
        "skipped": 0,
        "tests": 2043,
        "time": 0,
        "testcase": [
          {
            "name": "Mutant #2",
            "file": "chasten/configuration.py",
            "line": 41,
            "system-out": [
              "    debug_dest = debug_dest.lower()"
            ]
          },
          {
            "name": "Mutant #3",
            "file": "chasten/configuration.py",
            "line": 42,
            "system-out": [
              "    function_name = constants.logger.Function_Prefix + debug_dest"
            ]
          },
          {
            "name": "Mutant #4",
            "file": "chasten/configuration.py",
            "line": 43,
            "system-out": [
              "    configure_module = sys.modules[__name__]"
            ]
          },
          {
            "name": "Mutant #5",
            "file": "chasten/configuration.py",
            "line": 66,
            "system-out": [
              "    logger = logging.getLogger()"
            ]
          },
          {
            "name": "Mutant #6",
            "file": "chasten/configuration.py",
            "line": 77,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #7",
            "file": "chasten/configuration.py",
            "line": 85,
            "system-out": [
              "    logger = logging.getLogger()"
            ]
          },
          {
            "name": "Mutant #8",
            "file": "chasten/configuration.py",
            "line": 94,
            "system-out": [
              "    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)"
            ]
          },
          {
            "name": "Mutant #9",
            "file": "chasten/configuration.py",
            "line": 97,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #10",
            "file": "chasten/configuration.py",
            "line": 111,
            "system-out": [
              "    checks_file_validated = False"
            ]
          },
          {
            "name": "Mutant #11",
            "file": "chasten/configuration.py",
            "line": 112,
            "system-out": [
              "    checks_file_invalidates_entire_config = False"
            ]
          },
          {
            "name": "Mutant #12",
            "file": "chasten/configuration.py",
            "line": 120,
            "system-out": [
              "        ) = extract_configuration_details_from_config_url(parse_url(checks_file_name))"
            ]
          },
          {
            "name": "Mutant #13",
            "file": "chasten/configuration.py",
            "line": 122,
            "system-out": [
              "        checks_file_source = checks_file_name"
            ]
          },
          {
            "name": "Mutant #14",
            "file": "chasten/configuration.py",
            "line": 130,
            "system-out": [
              "        checks_file_validated = False"
            ]
          },
          {
            "name": "Mutant #15",
            "file": "chasten/configuration.py",
            "line": 131,
            "system-out": [
              "        checks_file_invalidates_entire_config = True"
            ]
          },
          {
            "name": "Mutant #16",
            "file": "chasten/configuration.py",
            "line": 143,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #17",
            "file": "chasten/configuration.py",
            "line": 145,
            "system-out": [
              "        checks_file_source = configuration_file_path_str"
            ]
          },
          {
            "name": "Mutant #18",
            "file": "chasten/configuration.py",
            "line": 151,
            "system-out": [
              "        checks_file_validated = False"
            ]
          },
          {
            "name": "Mutant #19",
            "file": "chasten/configuration.py",
            "line": 152,
            "system-out": [
              "        checks_file_invalidates_entire_config = True"
            ]
          },
          {
            "name": "Mutant #20",
            "file": "chasten/configuration.py",
            "line": 158,
            "system-out": [
              "        checks_file_validated = False"
            ]
          },
          {
            "name": "Mutant #21",
            "file": "chasten/configuration.py",
            "line": 169,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #22",
            "file": "chasten/configuration.py",
            "line": 184,
            "system-out": [
              "    chasten_user_config_url_str = \"\""
            ]
          },
          {
            "name": "Mutant #23",
            "file": "chasten/configuration.py",
            "line": 185,
            "system-out": [
              "    chasten_user_config_dir_str = \"\""
            ]
          },
          {
            "name": "Mutant #24",
            "file": "chasten/configuration.py",
            "line": 186,
            "system-out": [
              "    chasten_user_config_file_str = \"\""
            ]
          },
          {
            "name": "Mutant #25",
            "file": "chasten/configuration.py",
            "line": 197,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #26",
            "file": "chasten/configuration.py",
            "line": 204,
            "system-out": [
              "        chasten_user_config_url_str = str(parse_url(config))"
            ]
          },
          {
            "name": "Mutant #27",
            "file": "chasten/configuration.py",
            "line": 218,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #28",
            "file": "chasten/configuration.py",
            "line": 219,
            "system-out": [
              "        configuration_file_source = chasten_user_config_url_str"
            ]
          },
          {
            "name": "Mutant #29",
            "file": "chasten/configuration.py",
            "line": 225,
            "system-out": [
              "            chasten_user_config_dir_str = str(Path(config))"
            ]
          },
          {
            "name": "Mutant #30",
            "file": "chasten/configuration.py",
            "line": 229,
            "system-out": [
              "            config_as_path = Path(config)"
            ]
          },
          {
            "name": "Mutant #31",
            "file": "chasten/configuration.py",
            "line": 233,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #32",
            "file": "chasten/configuration.py",
            "line": 235,
            "system-out": [
              "            chasten_user_config_file_str = str(config_as_path.parts[-1])"
            ]
          },
          {
            "name": "Mutant #33",
            "file": "chasten/configuration.py",
            "line": 249,
            "system-out": [
              "        chasten_user_config_file_str_argument = {}"
            ]
          },
          {
            "name": "Mutant #34",
            "file": "chasten/configuration.py",
            "line": 253,
            "system-out": [
              "            ] = chasten_user_config_file_str"
            ]
          },
          {
            "name": "Mutant #35",
            "file": "chasten/configuration.py",
            "line": 262,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #36",
            "file": "chasten/configuration.py",
            "line": 271,
            "system-out": [
              "        configuration_file_source = chasten_user_config_dir_str"
            ]
          },
          {
            "name": "Mutant #37",
            "file": "chasten/configuration.py",
            "line": 291,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #38",
            "file": "chasten/configuration.py",
            "line": 294,
            "system-out": [
              "    (_, checks_file_name_list) = validate.extract_checks_file_name(yaml_data_dict)"
            ]
          },
          {
            "name": "Mutant #39",
            "file": "chasten/configuration.py",
            "line": 297,
            "system-out": [
              "    checks_files_validated_list = []"
            ]
          },
          {
            "name": "Mutant #40",
            "file": "chasten/configuration.py",
            "line": 298,
            "system-out": [
              "    check_files_validated = False"
            ]
          },
          {
            "name": "Mutant #41",
            "file": "chasten/configuration.py",
            "line": 306,
            "system-out": [
              "    overall_checks_dict[constants.checks.Checks_Label] = overall_checks_list"
            ]
          },
          {
            "name": "Mutant #42",
            "file": "chasten/configuration.py",
            "line": 318,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #43",
            "file": "chasten/configuration.py",
            "line": 330,
            "system-out": [
              "    check_files_validated = all(checks_files_validated_list)"
            ]
          },
          {
            "name": "Mutant #44",
            "file": "chasten/configuration.py",
            "line": 351,
            "system-out": [
              "    configuration_file_path = chasten_user_config_dir_str / configuration_file"
            ]
          },
          {
            "name": "Mutant #45",
            "file": "chasten/configuration.py",
            "line": 361,
            "system-out": [
              "    configuration_file_yaml_str = configuration_file_path.read_text()"
            ]
          },
          {
            "name": "Mutant #46",
            "file": "chasten/configuration.py",
            "line": 366,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #47",
            "file": "chasten/configuration.py",
            "line": 391,
            "system-out": [
              "    response = requests.get(str(chasten_user_config_url))"
            ]
          },
          {
            "name": "Mutant #48",
            "file": "chasten/configuration.py",
            "line": 395,
            "system-out": [
              "        configuration_file_yaml_str = response.text"
            ]
          },
          {
            "name": "Mutant #49",
            "file": "chasten/configuration.py",
            "line": 404,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #50",
            "file": "chasten/configuration.py",
            "line": 419,
            "system-out": [
              "    yaml_data = None"
            ]
          },
          {
            "name": "Mutant #51",
            "file": "chasten/configuration.py",
            "line": 421,
            "system-out": [
              "        yaml_data = yaml.safe_load(configuration_file_contents_str)"
            ]
          },
          {
            "name": "Mutant #52",
            "file": "chasten/server.py",
            "line": 9,
            "system-out": [
              "LOG_FILE = constants.server.Log_File"
            ]
          },
          {
            "name": "Mutant #53",
            "file": "chasten/server.py",
            "line": 10,
            "system-out": [
              "HOST = constants.server.Localhost"
            ]
          },
          {
            "name": "Mutant #54",
            "file": "chasten/server.py",
            "line": 11,
            "system-out": [
              "PORT = constants.server.Port"
            ]
          },
          {
            "name": "Mutant #55",
            "file": "chasten/server.py",
            "line": 13,
            "system-out": [
              "logger = logging.getLogger(constants.logger.Syslog)"
            ]
          },
          {
            "name": "Mutant #56",
            "file": "chasten/server.py",
            "line": 25,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #57",
            "file": "chasten/server.py",
            "line": 29,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #58",
            "file": "chasten/server.py",
            "line": 32,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #59",
            "file": "chasten/server.py",
            "line": 52,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #60",
            "file": "chasten/server.py",
            "line": 57,
            "system-out": [
              "        server = socketserver.UDPServer((HOST, PORT), SyslogUDPHandler)"
            ]
          },
          {
            "name": "Mutant #61",
            "file": "chasten/util.py",
            "line": 11,
            "system-out": [
              "checkmark_unicode = \"\\u2713\""
            ]
          },
          {
            "name": "Mutant #62",
            "file": "chasten/util.py",
            "line": 12,
            "system-out": [
              "xmark_unicode = \"\\u2717\""
            ]
          },
          {
            "name": "Mutant #63",
            "file": "chasten/util.py",
            "line": 13,
            "system-out": [
              "default_chasten_semver = \"0.0.0\""
            ]
          },
          {
            "name": "Mutant #64",
            "file": "chasten/util.py",
            "line": 27,
            "system-out": [
              "    OpSystem = platform.system()"
            ]
          },
          {
            "name": "Mutant #65",
            "file": "chasten/util.py",
            "line": 33,
            "system-out": [
              "    exe_directory = \"/bin/\""
            ]
          },
          {
            "name": "Mutant #66",
            "file": "chasten/util.py",
            "line": 36,
            "system-out": [
              "        exe_directory = \"/Scripts/\""
            ]
          },
          {
            "name": "Mutant #67",
            "file": "chasten/util.py",
            "line": 38,
            "system-out": [
              "    virtual_env_location = sys.prefix"
            ]
          },
          {
            "name": "Mutant #68",
            "file": "chasten/util.py",
            "line": 58,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #69",
            "file": "chasten/util.py",
            "line": 64,
            "system-out": [
              "        version_string_of_foo = default_chasten_semver"
            ]
          },
          {
            "name": "Mutant #70",
            "file": "chasten/util.py",
            "line": 76,
            "system-out": [
              "    url_parsed = parse_url(url)"
            ]
          },
          {
            "name": "Mutant #71",
            "file": "chasten/util.py",
            "line": 81,
            "system-out": [
              "    port_character = \":\" if url_parsed.port is not None else \"\""
            ]
          },
          {
            "name": "Mutant #72",
            "file": "chasten/util.py",
            "line": 82,
            "system-out": [
              "    query_character = \"?\" if url_parsed.query is not None else \"\""
            ]
          },
          {
            "name": "Mutant #73",
            "file": "chasten/util.py",
            "line": 83,
            "system-out": [
              "    fragment_character = \"#\" if url_parsed.fragment is not None else \"\""
            ]
          },
          {
            "name": "Mutant #74",
            "file": "chasten/util.py",
            "line": 95,
            "system-out": [
              "    ]"
            ]
          },
          {
            "name": "Mutant #75",
            "file": "chasten/util.py",
            "line": 98,
            "system-out": [
              "    url_reassembled = \"\""
            ]
          },
          {
            "name": "Mutant #76",
            "file": "chasten/util.py",
            "line": 111,
            "system-out": [
              "        count_total = len(check_status_list)"
            ]
          },
          {
            "name": "Mutant #77",
            "file": "chasten/util.py",
            "line": 113,
            "system-out": [
              "        count_passed = check_status_list.count(True)"
            ]
          },
          {
            "name": "Mutant #78",
            "file": "chasten/checks.py",
            "line": 14,
            "system-out": [
              "    min_count = check.get(constants.checks.Check_Count, {}).get(constants.checks.Check_Min)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #79",
            "file": "chasten/checks.py",
            "line": 15,
            "system-out": [
              "    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore"
            ]
          },
          {
            "name": "Mutant #80",
            "file": "chasten/checks.py",
            "line": 32,
            "system-out": [
              "    labeled_attribute = \"\""
            ]
          },
          {
            "name": "Mutant #81",
            "file": "chasten/checks.py",
            "line": 36,
            "system-out": [
              "        labeled_attribute = f\"{label} = {attribute}\""
            ]
          },
          {
            "name": "Mutant #82",
            "file": "chasten/checks.py",
            "line": 44,
            "system-out": [
              "    joined_attribute_labels = constants.markers.Empty_String"
            ]
          },
          {
            "name": "Mutant #83",
            "file": "chasten/checks.py",
            "line": 117,
            "system-out": [
              "            new_criterion = criterion.value"
            ]
          },
          {
            "name": "Mutant #84",
            "file": "chasten/checks.py",
            "line": 121,
            "system-out": [
              "            new_criterion = criterion  # type: ignore"
            ]
          },
          {
            "name": "Mutant #85",
            "file": "chasten/database.py",
            "line": 11,
            "system-out": [
              "CHASTEN_SQL_SELECT_QUERY = \"\"\""
            ]
          },
          {
            "name": "Mutant #86",
            "file": "chasten/database.py",
            "line": 37,
            "system-out": [
              "small_bullet_unicode = constants.markers.Small_Bullet_Unicode"
            ]
          },
          {
            "name": "Mutant #87",
            "file": "chasten/database.py",
            "line": 42,
            "system-out": [
              "    database = Database(chasten_database_name)"
            ]
          },
          {
            "name": "Mutant #88",
            "file": "chasten/database.py",
            "line": 56,
            "system-out": [
              "    database = Database(chasten_database_name)"
            ]
          },
          {
            "name": "Mutant #89",
            "file": "chasten/database.py",
            "line": 144,
            "system-out": [
              "    metadata = datasette_metadata"
            ]
          },
          {
            "name": "Mutant #90",
            "file": "chasten/database.py",
            "line": 152,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #91",
            "file": "chasten/database.py",
            "line": 155,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #92",
            "file": "chasten/database.py",
            "line": 161,
            "system-out": [
              "        label = \":sparkles: Details for datasette publishing:\""
            ]
          },
          {
            "name": "Mutant #93",
            "file": "chasten/database.py",
            "line": 163,
            "system-out": [
              "        label = \":sparkles: Details for datasette startup:\""
            ]
          },
          {
            "name": "Mutant #94",
            "file": "chasten/database.py",
            "line": 190,
            "system-out": [
              "            ]"
            ]
          },
          {
            "name": "Mutant #95",
            "file": "chasten/database.py",
            "line": 197,
            "system-out": [
              "            ]"
            ]
          },
          {
            "name": "Mutant #96",
            "file": "chasten/database.py",
            "line": 201,
            "system-out": [
              "        proc = subprocess.Popen(cmd)"
            ]
          },
          {
            "name": "Mutant #97",
            "file": "chasten/database.py",
            "line": 210,
            "system-out": [
              "        ) = filesystem.can_find_executable(util.executable_name(datasette_platform))"
            ]
          },
          {
            "name": "Mutant #98",
            "file": "chasten/database.py",
            "line": 230,
            "system-out": [
              "        running_argument = \"\""
            ]
          },
          {
            "name": "Mutant #99",
            "file": "chasten/database.py",
            "line": 232,
            "system-out": [
              "            running_argument = \"--app=chasten\""
            ]
          },
          {
            "name": "Mutant #100",
            "file": "chasten/database.py",
            "line": 234,
            "system-out": [
              "            running_argument = \"--project=chasten\""
            ]
          },
          {
            "name": "Mutant #101",
            "file": "chasten/database.py",
            "line": 250,
            "system-out": [
              "            ]"
            ]
          },
          {
            "name": "Mutant #102",
            "file": "chasten/database.py",
            "line": 262,
            "system-out": [
              "            ]"
            ]
          },
          {
            "name": "Mutant #103",
            "file": "chasten/database.py",
            "line": 266,
            "system-out": [
              "        proc = subprocess.Popen(cmd)"
            ]
          },
          {
            "name": "Mutant #104",
            "file": "chasten/database.py",
            "line": 275,
            "system-out": [
              "    ]"
            ]
          },
          {
            "name": "Mutant #105",
            "file": "chasten/database.py",
            "line": 276,
            "system-out": [
              "    executable = util.executable_name(\"frogmouth\", OpSystem)"
            ]
          },
          {
            "name": "Mutant #106",
            "file": "chasten/database.py",
            "line": 277,
            "system-out": [
              "    exec_found, executable_path = filesystem.can_find_executable(executable)"
            ]
          },
          {
            "name": "Mutant #107",
            "file": "chasten/database.py",
            "line": 283,
            "system-out": [
              "        proc = subprocess.Popen(cmd)"
            ]
          },
          {
            "name": "Mutant #108",
            "file": "chasten/filesystem.py",
            "line": 15,
            "system-out": [
              "CONFIGURATION_FILE_DEFAULT_CONTENTS = \"\"\""
            ]
          },
          {
            "name": "Mutant #109",
            "file": "chasten/filesystem.py",
            "line": 24,
            "system-out": [
              "CHECKS_FILE_DEFAULT_CONTENTS = \"\"\""
            ]
          },
          {
            "name": "Mutant #110",
            "file": "chasten/filesystem.py",
            "line": 66,
            "system-out": [
              "}"
            ]
          },
          {
            "name": "Mutant #111",
            "file": "chasten/filesystem.py",
            "line": 74,
            "system-out": [
              "        chasten_user_config_dir_str = str(config)"
            ]
          },
          {
            "name": "Mutant #112",
            "file": "chasten/filesystem.py",
            "line": 84,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #113",
            "file": "chasten/filesystem.py",
            "line": 94,
            "system-out": [
              "    chasten_user_config_dir_str = detect_configuration(config)"
            ]
          },
          {
            "name": "Mutant #114",
            "file": "chasten/filesystem.py",
            "line": 96,
            "system-out": [
              "    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)"
            ]
          },
          {
            "name": "Mutant #115",
            "file": "chasten/filesystem.py",
            "line": 113,
            "system-out": [
              "    chasten_user_config_dir_str = detect_configuration(config)"
            ]
          },
          {
            "name": "Mutant #116",
            "file": "chasten/filesystem.py",
            "line": 115,
            "system-out": [
              "    chasten_user_config_dir_path = Path(chasten_user_config_dir_str)"
            ]
          },
          {
            "name": "Mutant #117",
            "file": "chasten/filesystem.py",
            "line": 119,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #118",
            "file": "chasten/filesystem.py",
            "line": 123,
            "system-out": [
              "    file_contents = FILE_CONTENTS_LOOKUP[config_file_name]"
            ]
          },
          {
            "name": "Mutant #119",
            "file": "chasten/filesystem.py",
            "line": 132,
            "system-out": [
              "        tree = Tree(f\":open_file_folder: {path.name}\")"
            ]
          },
          {
            "name": "Mutant #120",
            "file": "chasten/filesystem.py",
            "line": 136,
            "system-out": [
              "        tree = tree.add(f\":open_file_folder: {path.name}\")"
            ]
          },
          {
            "name": "Mutant #121",
            "file": "chasten/filesystem.py",
            "line": 172,
            "system-out": [
              "    default_directory_list = [Path(constants.filesystem.Current_Directory)]"
            ]
          },
          {
            "name": "Mutant #122",
            "file": "chasten/filesystem.py",
            "line": 186,
            "system-out": [
              "        results_file_uuid = results_content.configuration.fileuuid"
            ]
          },
          {
            "name": "Mutant #123",
            "file": "chasten/filesystem.py",
            "line": 188,
            "system-out": [
              "        formatted_datetime = results_content.configuration._datetime"
            ]
          },
          {
            "name": "Mutant #124",
            "file": "chasten/filesystem.py",
            "line": 194,
            "system-out": [
              "        complete_results_file_name = f\"{constants.filesystem.Main_Results_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\""
            ]
          },
          {
            "name": "Mutant #125",
            "file": "chasten/filesystem.py",
            "line": 197,
            "system-out": [
              "        results_path_with_file = results_path / complete_results_file_name"
            ]
          },
          {
            "name": "Mutant #126",
            "file": "chasten/filesystem.py",
            "line": 198,
            "system-out": [
              "        results_json = results_content.model_dump_json(indent=2)"
            ]
          },
          {
            "name": "Mutant #127",
            "file": "chasten/filesystem.py",
            "line": 220,
            "system-out": [
              "    results_file_uuid = uuid.uuid4().hex"
            ]
          },
          {
            "name": "Mutant #128",
            "file": "chasten/filesystem.py",
            "line": 222,
            "system-out": [
              "    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            ]
          },
          {
            "name": "Mutant #129",
            "file": "chasten/filesystem.py",
            "line": 229,
            "system-out": [
              "    complete_results_file_name = f\"{constants.filesystem.Main_Results_Combined_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\""
            ]
          },
          {
            "name": "Mutant #130",
            "file": "chasten/filesystem.py",
            "line": 232,
            "system-out": [
              "    results_path_with_file = results_path / complete_results_file_name"
            ]
          },
          {
            "name": "Mutant #131",
            "file": "chasten/filesystem.py",
            "line": 247,
            "system-out": [
              "    results_file_uuid = uuid.uuid4().hex"
            ]
          },
          {
            "name": "Mutant #132",
            "file": "chasten/filesystem.py",
            "line": 249,
            "system-out": [
              "    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            ]
          },
          {
            "name": "Mutant #133",
            "file": "chasten/filesystem.py",
            "line": 252,
            "system-out": [
              "    combined_results_json_file = results_path / Path(combined_results_json)"
            ]
          },
          {
            "name": "Mutant #134",
            "file": "chasten/filesystem.py",
            "line": 253,
            "system-out": [
              "    combined_results_json_file_str = str(combined_results_json_file)"
            ]
          },
          {
            "name": "Mutant #135",
            "file": "chasten/filesystem.py",
            "line": 259,
            "system-out": [
              "    complete_flattened_results_directory_name = f\"{constants.filesystem.Main_Results_Flattened_Directory_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}\""
            ]
          },
          {
            "name": "Mutant #136",
            "file": "chasten/filesystem.py",
            "line": 263,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #137",
            "file": "chasten/filesystem.py",
            "line": 265,
            "system-out": [
              "    flattened_output_directory_str = str(flattened_output_directory)"
            ]
          },
          {
            "name": "Mutant #138",
            "file": "chasten/filesystem.py",
            "line": 270,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #139",
            "file": "chasten/filesystem.py",
            "line": 271,
            "system-out": [
              "    database_file_name_str = str(database_file_name)"
            ]
          },
          {
            "name": "Mutant #140",
            "file": "chasten/filesystem.py",
            "line": 298,
            "system-out": [
              "        json_dict = json.loads(json_path.read_text(\"utf-8\"))"
            ]
          },
          {
            "name": "Mutant #141",
            "file": "chasten/filesystem.py",
            "line": 308,
            "system-out": [
              "    executable_path = shutil.which(executable_name)"
            ]
          },
          {
            "name": "Mutant #142",
            "file": "chasten/createchecks.py",
            "line": 6,
            "system-out": [
              "genscript = \"\"\""
            ]
          },
          {
            "name": "Mutant #143",
            "file": "chasten/createchecks.py",
            "line": 56,
            "system-out": [
              "API_KEY_FILE = \"userapikey.txt\""
            ]
          },
          {
            "name": "Mutant #144",
            "file": "chasten/createchecks.py",
            "line": 60,
            "system-out": [
              "    key = Fernet.generate_key()"
            ]
          },
          {
            "name": "Mutant #145",
            "file": "chasten/createchecks.py",
            "line": 61,
            "system-out": [
              "    fernet = Fernet(key)"
            ]
          },
          {
            "name": "Mutant #146",
            "file": "chasten/createchecks.py",
            "line": 62,
            "system-out": [
              "    encrypted_key = fernet.encrypt(user_api_key.encode()).decode()"
            ]
          },
          {
            "name": "Mutant #147",
            "file": "chasten/createchecks.py",
            "line": 69,
            "system-out": [
              "        lines = f.read().strip().split(\"\\n\")"
            ]
          },
          {
            "name": "Mutant #148",
            "file": "chasten/createchecks.py",
            "line": 71,
            "system-out": [
              "            key = lines[0].encode()"
            ]
          },
          {
            "name": "Mutant #149",
            "file": "chasten/createchecks.py",
            "line": 72,
            "system-out": [
              "            encrypted_key = lines[1]"
            ]
          },
          {
            "name": "Mutant #150",
            "file": "chasten/createchecks.py",
            "line": 73,
            "system-out": [
              "        fernet = Fernet(key)"
            ]
          },
          {
            "name": "Mutant #151",
            "file": "chasten/createchecks.py",
            "line": 79,
            "system-out": [
              "        openai.api_key = api_key"
            ]
          },
          {
            "name": "Mutant #152",
            "file": "chasten/createchecks.py",
            "line": 91,
            "system-out": [
              "        openai.api_key = user_api_key"
            ]
          },
          {
            "name": "Mutant #153",
            "file": "chasten/createchecks.py",
            "line": 97,
            "system-out": [
              "        ]"
            ]
          },
          {
            "name": "Mutant #154",
            "file": "chasten/createchecks.py",
            "line": 107,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #155",
            "file": "chasten/createchecks.py",
            "line": 109,
            "system-out": [
              "        generated_yaml = response.choices[0].message[\"content\"].strip()"
            ]
          },
          {
            "name": "Mutant #156",
            "file": "chasten/enumerations.py",
            "line": 9,
            "system-out": [
              "    CREATE = \"create\""
            ]
          },
          {
            "name": "Mutant #157",
            "file": "chasten/enumerations.py",
            "line": 10,
            "system-out": [
              "    VALIDATE = \"validate\""
            ]
          },
          {
            "name": "Mutant #158",
            "file": "chasten/enumerations.py",
            "line": 16,
            "system-out": [
              "    FLY = \"fly\""
            ]
          },
          {
            "name": "Mutant #159",
            "file": "chasten/enumerations.py",
            "line": 17,
            "system-out": [
              "    VERCEL = \"vercel\""
            ]
          },
          {
            "name": "Mutant #160",
            "file": "chasten/enumerations.py",
            "line": 23,
            "system-out": [
              "    CODE = \"code\""
            ]
          },
          {
            "name": "Mutant #161",
            "file": "chasten/enumerations.py",
            "line": 24,
            "system-out": [
              "    ID = \"id\""
            ]
          },
          {
            "name": "Mutant #162",
            "file": "chasten/enumerations.py",
            "line": 25,
            "system-out": [
              "    NONE = \"\""
            ]
          },
          {
            "name": "Mutant #163",
            "file": "chasten/enumerations.py",
            "line": 26,
            "system-out": [
              "    NAME = \"name\""
            ]
          },
          {
            "name": "Mutant #164",
            "file": "chasten/enumerations.py",
            "line": 27,
            "system-out": [
              "    PATTERN = \"pattern\""
            ]
          },
          {
            "name": "Mutant #165",
            "file": "chasten/constants.py",
            "line": 51,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -29,26 +29,7 @@\n     Website: str\n \n \n-chasten = Chasten(\n-    Analyze_Storage=Path(\"analysis.md\"),\n-    Application_Name=\"chasten\",\n-    Application_Author=\"ChastenedTeam\",\n-    App_Storage=Path(\"check.txt\"),\n-    API_Key_Storage=Path(\"userapikey.txt\"),\n-    Chasten_Database_View=\"chasten_complete\",\n-    Emoji=\":dizzy:\",\n-    Executable_Fly=\"fly\",\n-    Executable_Vercel=\"vercel\",\n-    Https=\"https://\",\n-    Name=\"chasten\",\n-    Programming_Language=\"python\",\n-    Separator=\"/\",\n-    Server_Shutdown=\":person_shrugging: Shut down chasten's sylog server\",\n-    Tagline=\"chasten: Analyze the AST of Python Source Code\",\n-    Theme_Background=\"default\",\n-    Theme_Colors=\"ansi_dark\",\n-    Website=\":link: GitHub: https://github.com/gkapfham/chasten\",\n-)\n+chasten = None\n \n \n # checks constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #166",
            "file": "chasten/constants.py",
            "line": 84,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -69,19 +69,7 @@\n     Check_Pattern: str\n \n \n-checks = Checks(\n-    Check_Chasten=\"chasten\",\n-    Check_Code=\"code\",\n-    Check_Count=\"count\",\n-    Check_Confidence=80,\n-    Check_File=\"checks-file\",\n-    Check_Id=\"id\",\n-    Checks_Label=\"checks\",\n-    Check_Max=\"max\",\n-    Check_Min=\"min\",\n-    Check_Name=\"name\",\n-    Check_Pattern=\"pattern\",\n-)\n+checks = None\n \n \n # datasette constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #167",
            "file": "chasten/constants.py",
            "line": 105,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -96,13 +96,7 @@\n     Datasette_Search_All: str\n \n \n-datasette = Datasette(\n-    Chasten_Database=\"chasten.db\",\n-    Datasette_Executable=\"datasette\",\n-    Datasette_Copyable_Install=\"--install=datasette-copyable\",\n-    Datasette_Export_Notebook=\"--install=datasette-export-notebook\",\n-    Datasette_Search_All=\"--install=datasette-search-all\",\n-)\n+datasette = None\n \n \n # filesystem constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #168",
            "file": "chasten/constants.py",
            "line": 134,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -121,17 +121,7 @@\n     Results_Extension: str\n \n \n-filesystem = Filesystem(\n-    Current_Directory=\".\",\n-    Dash=\"-\",\n-    Dot=\".\",\n-    Main_Configuration_File=\"config.yml\",\n-    Main_Checks_File=\"checks.yml\",\n-    Main_Results_File_Name=\"chasten-results\",\n-    Main_Results_Combined_File_Name=\"chasten-integrated-results\",\n-    Main_Results_Flattened_Directory_Name=\"chasten-flattened-csvs-sqlite-db\",\n-    Results_Extension=\"json\",\n-)\n+filesystem = None\n \n \n # humanreadable constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #169",
            "file": "chasten/constants.py",
            "line": 146,
            "system-out": [
              "humanreadable = Humanreadable(Yes=\"Yes\", No=\"No\")"
            ]
          },
          {
            "name": "Mutant #170",
            "file": "chasten/constants.py",
            "line": 163,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -156,11 +156,7 @@\n     Syslog: str\n \n \n-logger = Logger(\n-    Function_Prefix=\"configure_logging_\",\n-    Richlog=\"chasten-richlog\",\n-    Syslog=\"chasten-syslog\",\n-)\n+logger = None\n \n \n # logging constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #171",
            "file": "chasten/constants.py",
            "line": 196,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -181,19 +181,7 @@\n     Rich: str\n \n \n-logging = Logging(\n-    Debug=\"DEBUG\",\n-    Info=\"INFO\",\n-    Warning=\"WARNING\",\n-    Error=\"ERROR\",\n-    Critical=\"CRITICAL\",\n-    Console_Logging_Destination=\"CONSOLE\",\n-    Syslog_Logging_Destination=\"syslog\",\n-    Default_Logging_Destination=\"console\",\n-    Default_Logging_Level=\"ERROR\",\n-    Format=\"%(message)s\",\n-    Rich=\"Rich\",\n-)\n+logging = None\n \n \n # markers constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #172",
            "file": "chasten/constants.py",
            "line": 255,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -227,32 +227,7 @@\n     Percent_Multiplier: int\n \n \n-markers = Markers(\n-    Bad_Fifteen=\"<15>\",\n-    Bad_Zero_Zero=\"\",\n-    Code_Context=5,\n-    Comma_Space=\", \",\n-    Empty_Bytes=b\"\",\n-    Empty_String=\"\",\n-    Ellipse=\"...\",\n-    Forward_Slash=\"/\",\n-    Dot=\".\",\n-    Hidden=\".\",\n-    Indent=\"   \",\n-    Newline=\"\\n\",\n-    Non_Zero_Exit=1,\n-    Nothing=\"\",\n-    Single_Quote=\"'\",\n-    Slice_One=1,\n-    Small_Bullet_Unicode=\"\\u2022\",\n-    Space=\" \",\n-    Tab=\"\\t\",\n-    Underscore=\"_\",\n-    Xml=\"xml\",\n-    Zero=0,\n-    Zero_Exit=0,\n-    Percent_Multiplier=100,\n-)\n+markers = None\n \n \n # output constant\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #173",
            "file": "chasten/constants.py",
            "line": 270,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #174",
            "file": "chasten/constants.py",
            "line": 295,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -284,13 +284,5 @@\n     Utf8_Encoding: str\n \n \n-server = Server(\n-    Backup_Count=1,\n-    Localhost=\"127.0.0.1\",\n-    Log_File=\".discover.log\",\n-    Max_Log_Size=1048576,\n-    Poll_Interval=0.5,\n-    Port=2525,\n-    Utf8_Encoding=\"utf-8\",\n-)\n-\n+server = None\n+\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #175",
            "file": "chasten/validate.py",
            "line": 29,
            "system-out": [
              "}"
            ]
          },
          {
            "name": "Mutant #176",
            "file": "chasten/validate.py",
            "line": 99,
            "failure": [
              {
                "inner": "--- chasten/validate.py\n+++ chasten/validate.py\n@@ -31,72 +31,7 @@\n # intutive description:\n # a checks file describes all of the details for one or more checks\n # see ./chasten in the root of the repository for the checks.yml file\n-JSON_SCHEMA_CHECKS = {\n-    \"type\": \"object\",\n-    \"properties\": {\n-        \"checks\": {\n-            \"type\": \"array\",\n-            \"items\": {\n-                \"type\": \"object\",\n-                \"properties\": {\n-                    \"name\": {\"type\": \"string\"},\n-                    \"id\": {\"type\": \"string\"},\n-                    \"description\": {\"type\": \"string\"},\n-                    \"pattern\": {\"type\": \"string\"},\n-                    \"code\": {\"type\": \"string\"},\n-                    \"count\": {\n-                        \"anyOf\": [\n-                            {\n-                                \"type\": \"object\",\n-                                \"properties\": {\n-                                    \"min\": {\n-                                        \"anyOf\": [\n-                                            {\"type\": \"integer\"},\n-                                            {\"type\": \"null\"},\n-                                        ]\n-                                    }\n-                                },\n-                                \"required\": [\"min\"],\n-                            },\n-                            {\n-                                \"type\": \"object\",\n-                                \"properties\": {\n-                                    \"max\": {\n-                                        \"anyOf\": [\n-                                            {\"type\": \"integer\"},\n-                                            {\"type\": \"null\"},\n-                                        ]\n-                                    }\n-                                },\n-                                \"required\": [\"max\"],\n-                            },\n-                            {\n-                                \"type\": \"object\",\n-                                \"properties\": {\n-                                    \"min\": {\n-                                        \"anyOf\": [\n-                                            {\"type\": \"integer\"},\n-                                            {\"type\": \"null\"},\n-                                        ]\n-                                    },\n-                                    \"max\": {\n-                                        \"anyOf\": [\n-                                            {\"type\": \"integer\"},\n-                                            {\"type\": \"null\"},\n-                                        ]\n-                                    },\n-                                },\n-                                \"required\": [\"min\", \"max\"],\n-                            },\n-                        ]\n-                    },\n-                },\n-                \"required\": [\"name\", \"id\", \"pattern\", \"code\"],\n-                \"additionalProperties\": False,\n-            },\n-        }\n-    },\n-}\n+JSON_SCHEMA_CHECKS = None\n \n \n def extract_checks_file_name(\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "}"
            ]
          },
          {
            "name": "Mutant #177",
            "file": "chasten/validate.py",
            "line": 115,
            "system-out": [
              "            ]"
            ]
          },
          {
            "name": "Mutant #178",
            "file": "chasten/validate.py",
            "line": 135,
            "system-out": [
              "        error_message = str(validation_error)"
            ]
          },
          {
            "name": "Mutant #179",
            "file": "chasten/validate.py",
            "line": 136,
            "system-out": [
              "        error_message = error_message.lstrip()"
            ]
          },
          {
            "name": "Mutant #180",
            "file": "chasten/validate.py",
            "line": 156,
            "system-out": [
              "    (validated, errors) = validate_configuration(yaml_data_dict, json_schema)"
            ]
          },
          {
            "name": "Mutant #181",
            "file": "chasten/debug.py",
            "line": 9,
            "system-out": [
              "    DEBUG = \"DEBUG\""
            ]
          },
          {
            "name": "Mutant #182",
            "file": "chasten/debug.py",
            "line": 10,
            "system-out": [
              "    INFO = \"INFO\""
            ]
          },
          {
            "name": "Mutant #183",
            "file": "chasten/debug.py",
            "line": 11,
            "system-out": [
              "    WARNING = \"WARNING\""
            ]
          },
          {
            "name": "Mutant #184",
            "file": "chasten/debug.py",
            "line": 12,
            "system-out": [
              "    ERROR = \"ERROR\""
            ]
          },
          {
            "name": "Mutant #185",
            "file": "chasten/debug.py",
            "line": 13,
            "system-out": [
              "    CRITICAL = \"CRITICAL\""
            ]
          },
          {
            "name": "Mutant #186",
            "file": "chasten/debug.py",
            "line": 19,
            "system-out": [
              "    CONSOLE = \"CONSOLE\""
            ]
          },
          {
            "name": "Mutant #187",
            "file": "chasten/debug.py",
            "line": 20,
            "system-out": [
              "    SYSLOG = \"SYSLOG\""
            ]
          },
          {
            "name": "Mutant #188",
            "file": "chasten/configApp.py",
            "line": 12,
            "system-out": [
              "CHECK_STORAGE = constants.chasten.App_Storage"
            ]
          },
          {
            "name": "Mutant #189",
            "file": "chasten/configApp.py",
            "line": 17,
            "system-out": [
              "}"
            ]
          },
          {
            "name": "Mutant #190",
            "file": "chasten/configApp.py",
            "line": 18,
            "system-out": [
              "CHECK_DEFAULT = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #191",
            "file": "chasten/configApp.py",
            "line": 23,
            "system-out": [
              "    check_list = []"
            ]
          },
          {
            "name": "Mutant #192",
            "file": "chasten/configApp.py",
            "line": 26,
            "system-out": [
              "            strip_row = row.strip()  # Remove leading/trailing white spaces"
            ]
          },
          {
            "name": "Mutant #193",
            "file": "chasten/configApp.py",
            "line": 35,
            "system-out": [
              "        result = \"Make a YAML file that checks for:\""
            ]
          },
          {
            "name": "Mutant #194",
            "file": "chasten/configApp.py",
            "line": 37,
            "system-out": [
              "            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            ]
          },
          {
            "name": "Mutant #195",
            "file": "chasten/configApp.py",
            "line": 51,
            "system-out": [
              "Check_Input = Input(placeholder=\"Check For:\", id=\"Check\", name=\"Check\")"
            ]
          },
          {
            "name": "Mutant #196",
            "file": "chasten/configApp.py",
            "line": 57,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #197",
            "file": "chasten/configApp.py",
            "line": 58,
            "system-out": [
              "Exact_button = Button(\"Exact\", id=\"Exact\")  # Button to trigger an action"
            ]
          },
          {
            "name": "Mutant #198",
            "file": "chasten/configApp.py",
            "line": 82,
            "system-out": [
              "    CSS = \"\"\""
            ]
          },
          {
            "name": "Mutant #199",
            "file": "chasten/configApp.py",
            "line": 119,
            "system-out": [
              "        self.Valid = False"
            ]
          },
          {
            "name": "Mutant #200",
            "file": "chasten/configApp.py",
            "line": 121,
            "system-out": [
              "            self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value"
            ]
          },
          {
            "name": "Mutant #201",
            "file": "chasten/configApp.py",
            "line": 124,
            "system-out": [
              "                self.Check[CHECK_VALUE[str(event.input.name)]] = event.input.value"
            ]
          },
          {
            "name": "Mutant #202",
            "file": "chasten/configApp.py",
            "line": 125,
            "system-out": [
              "                self.Valid = True"
            ]
          },
          {
            "name": "Mutant #203",
            "file": "chasten/configApp.py",
            "line": 129,
            "system-out": [
              "            self.Check[2] = True  # Mark the \"Exact\" button as clicked"
            ]
          },
          {
            "name": "Mutant #204",
            "file": "chasten/configApp.py",
            "line": 130,
            "system-out": [
              "            event.button.disabled = True  # Disable the \"Exact\" button after clicking"
            ]
          },
          {
            "name": "Mutant #205",
            "file": "chasten/configApp.py",
            "line": 146,
            "system-out": [
              "                self.Check[0] = \"\""
            ]
          },
          {
            "name": "Mutant #206",
            "file": "chasten/configApp.py",
            "line": 147,
            "system-out": [
              "                self.Check[1] = \"1\""
            ]
          },
          {
            "name": "Mutant #207",
            "file": "chasten/configApp.py",
            "line": 148,
            "system-out": [
              "                self.Check[2] = False"
            ]
          },
          {
            "name": "Mutant #208",
            "file": "chasten/configApp.py",
            "line": 151,
            "system-out": [
              "                Exact_button.disabled = False  # Re-enable the \"Exact\" button"
            ]
          },
          {
            "name": "Mutant #209",
            "file": "chasten/configApp.py",
            "line": 152,
            "system-out": [
              "                Check_Input.value = \"\""
            ]
          },
          {
            "name": "Mutant #210",
            "file": "chasten/configApp.py",
            "line": 153,
            "system-out": [
              "                Match_Input.value = \"\"  # Refresh the application UI"
            ]
          },
          {
            "name": "Mutant #211",
            "file": "chasten/configApp.py",
            "line": 156,
            "system-out": [
              "            Match_Input.value = \"\"  # Clear the \"Matches\" input field"
            ]
          },
          {
            "name": "Mutant #212",
            "file": "chasten/process.py",
            "line": 20,
            "system-out": [
              "    filtered_checks = []"
            ]
          },
          {
            "name": "Mutant #213",
            "file": "chasten/process.py",
            "line": 29,
            "system-out": [
              "        check_requested_include_attribute = check[check_attribute]"
            ]
          },
          {
            "name": "Mutant #214",
            "file": "chasten/process.py",
            "line": 33,
            "system-out": [
              "        fuzzy_value = fuzz.ratio(check_match, check_requested_include_attribute)"
            ]
          },
          {
            "name": "Mutant #215",
            "file": "chasten/process.py",
            "line": 51,
            "system-out": [
              "    subset_match_list = []"
            ]
          },
          {
            "name": "Mutant #216",
            "file": "chasten/process.py",
            "line": 52,
            "system-out": [
              "    did_not_match_list = []"
            ]
          },
          {
            "name": "Mutant #217",
            "file": "chasten/process.py",
            "line": 80,
            "system-out": [
              "        current_match_file_name = str(current_match.path)"
            ]
          },
          {
            "name": "Mutant #218",
            "file": "chasten/process.py",
            "line": 84,
            "system-out": [
              "            current_match_file_list = match_dict[current_match_file_name]"
            ]
          },
          {
            "name": "Mutant #219",
            "file": "chasten/process.py",
            "line": 93,
            "system-out": [
              "            match_dict[current_match_file_name] = current_match_list"
            ]
          },
          {
            "name": "Mutant #220",
            "file": "chasten/main.py",
            "line": 31,
            "failure": [
              {
                "inner": "--- chasten/main.py\n+++ chasten/main.py\n@@ -28,7 +28,7 @@\n )\n \n # create a Typer object to support the command-line interface\n-cli = typer.Typer(no_args_is_help=True)\n+cli = None\n app = configApp.config_App()\n # create a small bullet for display in the output\n small_bullet_unicode = constants.markers.Small_Bullet_Unicode\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "cli = typer.Typer(no_args_is_help=True)"
            ]
          },
          {
            "name": "Mutant #221",
            "file": "chasten/main.py",
            "line": 32,
            "system-out": [
              "app = configApp.config_App()"
            ]
          },
          {
            "name": "Mutant #222",
            "file": "chasten/main.py",
            "line": 34,
            "system-out": [
              "small_bullet_unicode = constants.markers.Small_Bullet_Unicode"
            ]
          },
          {
            "name": "Mutant #223",
            "file": "chasten/main.py",
            "line": 35,
            "system-out": [
              "CHECK_STORAGE = constants.chasten.App_Storage"
            ]
          },
          {
            "name": "Mutant #224",
            "file": "chasten/main.py",
            "line": 36,
            "system-out": [
              "API_KEY_STORAGE = constants.chasten.API_Key_Storage"
            ]
          },
          {
            "name": "Mutant #225",
            "file": "chasten/main.py",
            "line": 37,
            "system-out": [
              "ANALYSIS_FILE = constants.chasten.Analyze_Storage"
            ]
          },
          {
            "name": "Mutant #226",
            "file": "chasten/main.py",
            "line": 116,
            "system-out": [
              "        result = configApp.write_checks(configApp.split_file(CHECK_STORAGE))"
            ]
          },
          {
            "name": "Mutant #227",
            "file": "chasten/main.py",
            "line": 122,
            "system-out": [
              "            api_key = createchecks.load_user_api_key(API_KEY_STORAGE)"
            ]
          },
          {
            "name": "Mutant #228",
            "file": "chasten/main.py",
            "line": 129,
            "system-out": [
              "            api_key = input(\"Please Enter your openai API Key:\")"
            ]
          },
          {
            "name": "Mutant #229",
            "file": "chasten/main.py",
            "line": 135,
            "system-out": [
              "                api_key = input(\"Please Enter your openai API Key:\")"
            ]
          },
          {
            "name": "Mutant #230",
            "file": "chasten/main.py",
            "line": 141,
            "system-out": [
              "            api_key = createchecks.load_user_api_key(API_KEY_STORAGE)"
            ]
          },
          {
            "name": "Mutant #231",
            "file": "chasten/main.py",
            "line": 202,
            "system-out": [
              "        (validated, _) = configuration.validate_configuration_files(config, verbose)"
            ]
          },
          {
            "name": "Mutant #232",
            "file": "chasten/main.py",
            "line": 218,
            "system-out": [
              "                configuration_directory = None"
            ]
          },
          {
            "name": "Mutant #233",
            "file": "chasten/main.py",
            "line": 220,
            "system-out": [
              "                configuration_directory = Path(config)"
            ]
          },
          {
            "name": "Mutant #234",
            "file": "chasten/main.py",
            "line": 223,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #235",
            "file": "chasten/main.py",
            "line": 348,
            "system-out": [
              "    start_time = time.time()"
            ]
          },
          {
            "name": "Mutant #236",
            "file": "chasten/main.py",
            "line": 359,
            "system-out": [
              "    chasten_version = util.get_chasten_version()"
            ]
          },
          {
            "name": "Mutant #237",
            "file": "chasten/main.py",
            "line": 367,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #238",
            "file": "chasten/main.py",
            "line": 372,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #239",
            "file": "chasten/main.py",
            "line": 383,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #240",
            "file": "chasten/main.py",
            "line": 386,
            "system-out": [
              "    chasten_results_save = results.Chasten(configuration=chasten_configuration)"
            ]
          },
          {
            "name": "Mutant #241",
            "file": "chasten/main.py",
            "line": 392,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #242",
            "file": "chasten/main.py",
            "line": 411,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #243",
            "file": "chasten/main.py",
            "line": 415,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #244",
            "file": "chasten/main.py",
            "line": 430,
            "system-out": [
              "        analysis_result = \"\""
            ]
          },
          {
            "name": "Mutant #245",
            "file": "chasten/main.py",
            "line": 431,
            "system-out": [
              "        analysis_file_dir = store_result / ANALYSIS_FILE"
            ]
          },
          {
            "name": "Mutant #246",
            "file": "chasten/main.py",
            "line": 450,
            "system-out": [
              "    valid_directories = [input_path]"
            ]
          },
          {
            "name": "Mutant #247",
            "file": "chasten/main.py",
            "line": 470,
            "system-out": [
              "        )  # type: ignore"
            ]
          },
          {
            "name": "Mutant #248",
            "file": "chasten/main.py",
            "line": 475,
            "system-out": [
              "        (min_count, max_count) = checks.extract_min_max(current_check)"
            ]
          },
          {
            "name": "Mutant #249",
            "file": "chasten/main.py",
            "line": 478,
            "system-out": [
              "        check_id = current_check[constants.checks.Check_Id]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #250",
            "file": "chasten/main.py",
            "line": 480,
            "system-out": [
              "        check_name = current_check[constants.checks.Check_Name]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #251",
            "file": "chasten/main.py",
            "line": 481,
            "system-out": [
              "        check_description = checks.extract_description(current_check)"
            ]
          },
          {
            "name": "Mutant #252",
            "file": "chasten/main.py",
            "line": 491,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #253",
            "file": "chasten/main.py",
            "line": 495,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #254",
            "file": "chasten/main.py",
            "line": 499,
            "system-out": [
              "        match_generator_list = list(match_generator)"
            ]
          },
          {
            "name": "Mutant #255",
            "file": "chasten/main.py",
            "line": 504,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #256",
            "file": "chasten/main.py",
            "line": 507,
            "system-out": [
              "        match_dict = process.organize_matches(match_generator_list)"
            ]
          },
          {
            "name": "Mutant #257",
            "file": "chasten/main.py",
            "line": 509,
            "system-out": [
              "        current_check_save = None"
            ]
          },
          {
            "name": "Mutant #258",
            "file": "chasten/main.py",
            "line": 514,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #259",
            "file": "chasten/main.py",
            "line": 520,
            "system-out": [
              "            check_status = True"
            ]
          },
          {
            "name": "Mutant #260",
            "file": "chasten/main.py",
            "line": 522,
            "system-out": [
              "        check_status_symbol = util.get_symbol_boolean(check_status)"
            ]
          },
          {
            "name": "Mutant #261",
            "file": "chasten/main.py",
            "line": 525,
            "system-out": [
              "        current_xpath_pattern_escape = current_xpath_pattern.replace(\"[\", \"\\\\[\")"
            ]
          },
          {
            "name": "Mutant #262",
            "file": "chasten/main.py",
            "line": 537,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #263",
            "file": "chasten/main.py",
            "line": 548,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #264",
            "file": "chasten/main.py",
            "line": 552,
            "system-out": [
              "            current_result_source.check = current_check_save"
            ]
          },
          {
            "name": "Mutant #265",
            "file": "chasten/main.py",
            "line": 571,
            "system-out": [
              "            )"
            ]
          },
          {
            "name": "Mutant #266",
            "file": "chasten/main.py",
            "line": 573,
            "system-out": [
              "            current_result_source = results.Source(filename=file_name)"
            ]
          },
          {
            "name": "Mutant #267",
            "file": "chasten/main.py",
            "line": 575,
            "system-out": [
              "            current_result_source.check = current_check_save"
            ]
          },
          {
            "name": "Mutant #268",
            "file": "chasten/main.py",
            "line": 588,
            "system-out": [
              "                current_result_source._filelines = matches_list[0].file_lines"
            ]
          },
          {
            "name": "Mutant #269",
            "file": "chasten/main.py",
            "line": 593,
            "system-out": [
              "                    current_result_source._filelines = current_match.file_lines"
            ]
          },
          {
            "name": "Mutant #270",
            "file": "chasten/main.py",
            "line": 595,
            "system-out": [
              "                    position_end = current_match.position.lineno"
            ]
          },
          {
            "name": "Mutant #271",
            "file": "chasten/main.py",
            "line": 597,
            "system-out": [
              "                    column_offset = current_match.position.col_offset"
            ]
          },
          {
            "name": "Mutant #272",
            "file": "chasten/main.py",
            "line": 618,
            "system-out": [
              "                    )"
            ]
          },
          {
            "name": "Mutant #273",
            "file": "chasten/main.py",
            "line": 631,
            "system-out": [
              "    total_result = util.total_amount_passed(check_status_list)"
            ]
          },
          {
            "name": "Mutant #274",
            "file": "chasten/main.py",
            "line": 641,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #275",
            "file": "chasten/main.py",
            "line": 651,
            "system-out": [
              "                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901"
            ]
          },
          {
            "name": "Mutant #276",
            "file": "chasten/main.py",
            "line": 658,
            "system-out": [
              "                        contents = Path(each_file).read_bytes()"
            ]
          },
          {
            "name": "Mutant #277",
            "file": "chasten/main.py",
            "line": 662,
            "system-out": [
              "                        )"
            ]
          },
          {
            "name": "Mutant #278",
            "file": "chasten/main.py",
            "line": 664,
            "system-out": [
              "                        xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            ]
          },
          {
            "name": "Mutant #279",
            "file": "chasten/main.py",
            "line": 674,
            "system-out": [
              "                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901"
            ]
          },
          {
            "name": "Mutant #280",
            "file": "chasten/main.py",
            "line": 676,
            "system-out": [
              "                                contents = Path(sub_file).read_bytes()"
            ]
          },
          {
            "name": "Mutant #281",
            "file": "chasten/main.py",
            "line": 679,
            "system-out": [
              "                                )"
            ]
          },
          {
            "name": "Mutant #282",
            "file": "chasten/main.py",
            "line": 680,
            "system-out": [
              "                                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            ]
          },
          {
            "name": "Mutant #283",
            "file": "chasten/main.py",
            "line": 689,
            "system-out": [
              "                contents = Path(input_path).read_bytes()"
            ]
          },
          {
            "name": "Mutant #284",
            "file": "chasten/main.py",
            "line": 692,
            "system-out": [
              "                )"
            ]
          },
          {
            "name": "Mutant #285",
            "file": "chasten/main.py",
            "line": 693,
            "system-out": [
              "                xml_root = pyastgrep.asts.ast_to_xml(ast, {})"
            ]
          },
          {
            "name": "Mutant #286",
            "file": "chasten/main.py",
            "line": 705,
            "system-out": [
              "    all_checks_passed = all(check_status_list)"
            ]
          },
          {
            "name": "Mutant #287",
            "file": "chasten/main.py",
            "line": 706,
            "system-out": [
              "    end_time = time.time()"
            ]
          },
          {
            "name": "Mutant #288",
            "file": "chasten/main.py",
            "line": 707,
            "system-out": [
              "    elapsed_time = end_time - start_time"
            ]
          },
          {
            "name": "Mutant #289",
            "file": "chasten/main.py",
            "line": 724,
            "system-out": [
              "        result_path = os.path.abspath(analysis_file_dir)"
            ]
          },
          {
            "name": "Mutant #290",
            "file": "chasten/main.py",
            "line": 786,
            "system-out": [
              "    json_dicts = filesystem.get_json_results(json_path)"
            ]
          },
          {
            "name": "Mutant #291",
            "file": "chasten/main.py",
            "line": 787,
            "system-out": [
              "    count = len(json_path)"
            ]
          },
          {
            "name": "Mutant #292",
            "file": "chasten/main.py",
            "line": 790,
            "system-out": [
              "    combined_json_dict = process.combine_dicts(json_dicts)"
            ]
          },
          {
            "name": "Mutant #293",
            "file": "chasten/main.py",
            "line": 794,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #294",
            "file": "chasten/main.py",
            "line": 805,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #295",
            "file": "chasten/main.py",
            "line": 814,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #296",
            "file": "chasten/main.py",
            "line": 879,
            "system-out": [
              "    label = \":sparkles: Starting a local datasette instance:\""
            ]
          },
          {
            "name": "Mutant #297",
            "file": "chasten/main.py",
            "line": 957,
            "system-out": [
              "    label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\""
            ]
          },
          {
            "name": "Mutant #298",
            "file": "chasten/main.py",
            "line": 991,
            "system-out": [
              "    version_string = util.get_chasten_version()"
            ]
          },
          {
            "name": "Mutant #299",
            "file": "chasten/output.py",
            "line": 19,
            "system-out": [
              "console = Console()"
            ]
          },
          {
            "name": "Mutant #300",
            "file": "chasten/output.py",
            "line": 22,
            "system-out": [
              "small_bullet_unicode = constants.markers.Small_Bullet_Unicode"
            ]
          },
          {
            "name": "Mutant #301",
            "file": "chasten/output.py",
            "line": 37,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #302",
            "file": "chasten/output.py",
            "line": 115,
            "system-out": [
              "        directory = file_path.parent"
            ]
          },
          {
            "name": "Mutant #303",
            "file": "chasten/output.py",
            "line": 118,
            "system-out": [
              "        file_name = file_path.name"
            ]
          },
          {
            "name": "Mutant #304",
            "file": "chasten/output.py",
            "line": 123,
            "system-out": [
              "            grouped_files[directory] = []"
            ]
          },
          {
            "name": "Mutant #305",
            "file": "chasten/output.py",
            "line": 143,
            "system-out": [
              "    grouped_files = group_files_by_directory(container)"
            ]
          },
          {
            "name": "Mutant #306",
            "file": "chasten/output.py",
            "line": 149,
            "system-out": [
              "        filecount = 0"
            ]
          },
          {
            "name": "Mutant #307",
            "file": "chasten/output.py",
            "line": 151,
            "system-out": [
              "            filecount = +1"
            ]
          },
          {
            "name": "Mutant #308",
            "file": "chasten/output.py",
            "line": 176,
            "system-out": [
              "        current_xpath_pattern = current_check.pattern"
            ]
          },
          {
            "name": "Mutant #309",
            "file": "chasten/output.py",
            "line": 182,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #310",
            "file": "chasten/output.py",
            "line": 187,
            "system-out": [
              "        min_count = current_check.min"
            ]
          },
          {
            "name": "Mutant #311",
            "file": "chasten/output.py",
            "line": 188,
            "system-out": [
              "        max_count = current_check.max"
            ]
          },
          {
            "name": "Mutant #312",
            "file": "chasten/output.py",
            "line": 189,
            "system-out": [
              "        min_label = checks.create_attribute_label(min_count, constants.checks.Check_Min)"
            ]
          },
          {
            "name": "Mutant #313",
            "file": "chasten/output.py",
            "line": 190,
            "system-out": [
              "        max_label = checks.create_attribute_label(max_count, constants.checks.Check_Max)"
            ]
          },
          {
            "name": "Mutant #314",
            "file": "chasten/output.py",
            "line": 193,
            "system-out": [
              "        check_id = current_check.id"
            ]
          },
          {
            "name": "Mutant #315",
            "file": "chasten/output.py",
            "line": 194,
            "system-out": [
              "        check_id_label = checks.create_attribute_label(check_id, constants.checks.Check_Id)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #316",
            "file": "chasten/output.py",
            "line": 195,
            "system-out": [
              "        check_name = current_check.name"
            ]
          },
          {
            "name": "Mutant #317",
            "file": "chasten/output.py",
            "line": 196,
            "system-out": [
              "        check_name_label = checks.create_attribute_label(check_name, constants.checks.Check_Name)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #318",
            "file": "chasten/output.py",
            "line": 200,
            "system-out": [
              "        )"
            ]
          },
          {
            "name": "Mutant #319",
            "file": "chasten/output.py",
            "line": 223,
            "system-out": [
              "                    position_end = current_match.position.lineno"
            ]
          },
          {
            "name": "Mutant #320",
            "file": "chasten/output.py",
            "line": 225,
            "system-out": [
              "                    column_offset = current_match.position.col_offset"
            ]
          },
          {
            "name": "Mutant #321",
            "file": "chasten/output.py",
            "line": 230,
            "system-out": [
              "                    all_lines = current_match.file_lines"
            ]
          },
          {
            "name": "Mutant #322",
            "file": "chasten/output.py",
            "line": 234,
            "system-out": [
              "                    all_lines_for_marking = deepcopy(all_lines)"
            ]
          },
          {
            "name": "Mutant #323",
            "file": "chasten/output.py",
            "line": 240,
            "system-out": [
              "                    ]"
            ]
          },
          {
            "name": "Mutant #324",
            "file": "chasten/output.py",
            "line": 258,
            "system-out": [
              "                    )"
            ]
          },
          {
            "name": "Mutant #325",
            "file": "tests/test_configApp.py",
            "line": 10,
            "system-out": [
              "ALPHABET = \"0123456789!@#$%^&*()_+-=[]|:;'<>.?/~`AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz\""
            ]
          },
          {
            "name": "Mutant #326",
            "file": "tests/test_configApp.py",
            "line": 13,
            "system-out": [
              "CHECK_STORAGE = constants.chasten.App_Storage"
            ]
          },
          {
            "name": "Mutant #327",
            "file": "tests/test_configApp.py",
            "line": 21,
            "system-out": [
              "]"
            ]
          },
          {
            "name": "Mutant #328",
            "file": "tests/test_configApp.py",
            "line": 24,
            "system-out": [
              "CHECK_TEST_DEFAULT = \"\"\""
            ]
          },
          {
            "name": "Mutant #329",
            "file": "tests/test_configApp.py",
            "line": 35,
            "system-out": [
              "    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\""
            ]
          },
          {
            "name": "Mutant #330",
            "file": "tests/test_configApp.py",
            "line": 48,
            "system-out": [
              "    tmp_dir = pathlib.Path(tmpdir)"
            ]
          },
          {
            "name": "Mutant #331",
            "file": "tests/test_configApp.py",
            "line": 49,
            "system-out": [
              "    file = tmp_dir / \"check_test.txt\""
            ]
          },
          {
            "name": "Mutant #332",
            "file": "tests/test_configApp.py",
            "line": 65,
            "system-out": [
              "    tmp_dir = pathlib.Path(tmpdir)"
            ]
          },
          {
            "name": "Mutant #333",
            "file": "tests/test_configApp.py",
            "line": 66,
            "system-out": [
              "    file = tmp_dir / \"check_test.txt\""
            ]
          },
          {
            "name": "Mutant #334",
            "file": "tests/test_configuration.py",
            "line": 19,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #335",
            "file": "tests/test_configuration.py",
            "line": 33,
            "system-out": [
              "    logger, created = configuration.configure_logging(debug_level, debug_dest)"
            ]
          },
          {
            "name": "Mutant #336",
            "file": "tests/test_configuration.py",
            "line": 48,
            "system-out": [
              "    logger, created = configuration.configure_logging(debug_level, debug_dest)"
            ]
          },
          {
            "name": "Mutant #337",
            "file": "tests/test_util.py",
            "line": 29,
            "system-out": [
              "    str_answer = util.get_human_readable_boolean(answer=answer)"
            ]
          },
          {
            "name": "Mutant #338",
            "file": "tests/test_util.py",
            "line": 40,
            "system-out": [
              "    result = util.is_url(url=url)"
            ]
          },
          {
            "name": "Mutant #339",
            "file": "tests/test_util.py",
            "line": 47,
            "system-out": [
              "    stats = util.total_amount_passed(check_status_list)"
            ]
          },
          {
            "name": "Mutant #340",
            "file": "tests/test_util.py",
            "line": 53,
            "system-out": [
              "OpSystem = util.get_OS()"
            ]
          },
          {
            "name": "Mutant #341",
            "file": "tests/test_util.py",
            "line": 54,
            "system-out": [
              "datasette_exec = constants.datasette.Datasette_Executable"
            ]
          },
          {
            "name": "Mutant #342",
            "file": "tests/test_createchecks.py",
            "line": 17,
            "system-out": [
              "    valid_api_key = get_valid_api_key()"
            ]
          },
          {
            "name": "Mutant #343",
            "file": "tests/test_createchecks.py",
            "line": 21,
            "system-out": [
              "    result = is_valid_api_key(valid_api_key)"
            ]
          },
          {
            "name": "Mutant #344",
            "file": "tests/test_createchecks.py",
            "line": 35,
            "system-out": [
              "    valid_api_key = get_valid_api_key()"
            ]
          },
          {
            "name": "Mutant #345",
            "file": "tests/test_createchecks.py",
            "line": 36,
            "system-out": [
              "    test_genscript = \"Write: 'Hello, World'\""
            ]
          },
          {
            "name": "Mutant #346",
            "file": "tests/test_createchecks.py",
            "line": 37,
            "system-out": [
              "    file_path = \"test_checks.yml\""
            ]
          },
          {
            "name": "Mutant #347",
            "file": "tests/test_createchecks.py",
            "line": 42,
            "system-out": [
              "    file_path = Path(file_path)"
            ]
          },
          {
            "name": "Mutant #348",
            "file": "tests/test_createchecks.py",
            "line": 44,
            "system-out": [
              "    result = generate_yaml_config(file_path, valid_api_key, test_genscript)"
            ]
          },
          {
            "name": "Mutant #349",
            "file": "tests/test_createchecks.py",
            "line": 51,
            "system-out": [
              "        content = f.read()"
            ]
          },
          {
            "name": "Mutant #350",
            "file": "tests/test_filesystem.py",
            "line": 16,
            "system-out": [
              "    directory_str = str(Path(\"./tests/\"))"
            ]
          },
          {
            "name": "Mutant #351",
            "file": "tests/test_filesystem.py",
            "line": 17,
            "system-out": [
              "    directory = pathlib.Path(directory_str)"
            ]
          },
          {
            "name": "Mutant #352",
            "file": "tests/test_filesystem.py",
            "line": 18,
            "system-out": [
              "    confirmation = filesystem.confirm_valid_directory(directory)"
            ]
          },
          {
            "name": "Mutant #353",
            "file": "tests/test_filesystem.py",
            "line": 24,
            "system-out": [
              "    directory_str = str(Path(\"./testsNOT/\"))"
            ]
          },
          {
            "name": "Mutant #354",
            "file": "tests/test_filesystem.py",
            "line": 25,
            "system-out": [
              "    directory = pathlib.Path(directory_str)"
            ]
          },
          {
            "name": "Mutant #355",
            "file": "tests/test_filesystem.py",
            "line": 26,
            "system-out": [
              "    confirmation = filesystem.confirm_valid_directory(directory)"
            ]
          },
          {
            "name": "Mutant #356",
            "file": "tests/test_filesystem.py",
            "line": 33,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            ]
          },
          {
            "name": "Mutant #357",
            "file": "tests/test_filesystem.py",
            "line": 34,
            "system-out": [
              "    this_file = pathlib.Path(file_str)"
            ]
          },
          {
            "name": "Mutant #358",
            "file": "tests/test_filesystem.py",
            "line": 35,
            "system-out": [
              "    confirmation = filesystem.confirm_valid_file(this_file)"
            ]
          },
          {
            "name": "Mutant #359",
            "file": "tests/test_filesystem.py",
            "line": 41,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            ]
          },
          {
            "name": "Mutant #360",
            "file": "tests/test_filesystem.py",
            "line": 42,
            "system-out": [
              "    this_file_not = pathlib.Path(file_str)"
            ]
          },
          {
            "name": "Mutant #361",
            "file": "tests/test_filesystem.py",
            "line": 43,
            "system-out": [
              "    confirmation = filesystem.confirm_valid_file(this_file_not)"
            ]
          },
          {
            "name": "Mutant #362",
            "file": "tests/test_filesystem.py",
            "line": 65,
            "system-out": [
              "    tmp_dir = pathlib.Path(tmpdir)"
            ]
          },
          {
            "name": "Mutant #363",
            "file": "tests/test_filesystem.py",
            "line": 72,
            "system-out": [
              "    tree = filesystem.create_directory_tree_visualization(tmp_dir)"
            ]
          },
          {
            "name": "Mutant #364",
            "file": "tests/test_filesystem.py",
            "line": 78,
            "system-out": [
              "    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #365",
            "file": "tests/test_filesystem.py",
            "line": 79,
            "system-out": [
              "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #366",
            "file": "tests/test_filesystem.py",
            "line": 92,
            "system-out": [
              "    tree = filesystem.create_directory_tree_visualization(directory)"
            ]
          },
          {
            "name": "Mutant #367",
            "file": "tests/test_filesystem.py",
            "line": 97,
            "system-out": [
              "    dirs = []"
            ]
          },
          {
            "name": "Mutant #368",
            "file": "tests/test_filesystem.py",
            "line": 98,
            "system-out": [
              "    files = []"
            ]
          },
          {
            "name": "Mutant #369",
            "file": "tests/test_filesystem.py",
            "line": 116,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #370",
            "file": "tests/test_filesystem.py",
            "line": 117,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #371",
            "file": "tests/test_filesystem.py",
            "line": 118,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #372",
            "file": "tests/test_filesystem.py",
            "line": 131,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #373",
            "file": "tests/test_filesystem.py",
            "line": 132,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #374",
            "file": "tests/test_filesystem.py",
            "line": 133,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #375",
            "file": "tests/test_filesystem.py",
            "line": 149,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #376",
            "file": "tests/test_filesystem.py",
            "line": 150,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #377",
            "file": "tests/test_filesystem.py",
            "line": 151,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #378",
            "file": "tests/test_filesystem.py",
            "line": 167,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #379",
            "file": "tests/test_filesystem.py",
            "line": 168,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #380",
            "file": "tests/test_filesystem.py",
            "line": 169,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #381",
            "file": "tests/test_filesystem.py",
            "line": 180,
            "system-out": [
              "    config = tmp_path / \"config\""
            ]
          },
          {
            "name": "Mutant #382",
            "file": "tests/test_filesystem.py",
            "line": 193,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #383",
            "file": "tests/test_filesystem.py",
            "line": 194,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #384",
            "file": "tests/test_filesystem.py",
            "line": 195,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #385",
            "file": "tests/test_filesystem.py",
            "line": 198,
            "system-out": [
              "    detected_directory = filesystem.detect_configuration(None)"
            ]
          },
          {
            "name": "Mutant #386",
            "file": "tests/test_filesystem.py",
            "line": 208,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #387",
            "file": "tests/test_filesystem.py",
            "line": 209,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #388",
            "file": "tests/test_filesystem.py",
            "line": 210,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #389",
            "file": "tests/test_filesystem.py",
            "line": 217,
            "system-out": [
              "    main_configuation_file = dir_path / \"config.yml\""
            ]
          },
          {
            "name": "Mutant #390",
            "file": "tests/test_filesystem.py",
            "line": 232,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #391",
            "file": "tests/test_filesystem.py",
            "line": 233,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #392",
            "file": "tests/test_filesystem.py",
            "line": 234,
            "system-out": [
              "    result = filesystem.create_configuration_directory()"
            ]
          },
          {
            "name": "Mutant #393",
            "file": "tests/test_filesystem.py",
            "line": 241,
            "system-out": [
              "    main_configuation_file = dir_path / \"checks.yml\""
            ]
          },
          {
            "name": "Mutant #394",
            "file": "tests/test_process.py",
            "line": 33,
            "system-out": [
              "    filtered, _ = process.filter_matches(match_list, data_type)"
            ]
          },
          {
            "name": "Mutant #395",
            "file": "tests/test_process.py",
            "line": 44,
            "system-out": [
              "    data_type = pyastgrepsearch.Match"
            ]
          },
          {
            "name": "Mutant #396",
            "file": "tests/test_process.py",
            "line": 45,
            "system-out": [
              "    filtered, _ = process.filter_matches(match_list, data_type)"
            ]
          },
          {
            "name": "Mutant #397",
            "file": "tests/test_process.py",
            "line": 53,
            "system-out": [
              "    filtered, _ = process.filter_matches(match_list, data_type)"
            ]
          },
          {
            "name": "Mutant #398",
            "file": "tests/test_validate.py",
            "line": 16,
            "system-out": [
              "    }"
            ]
          },
          {
            "name": "Mutant #399",
            "file": "tests/test_validate.py",
            "line": 17,
            "system-out": [
              "    is_valid, errors = validate_configuration(valid_config_correct_schema)"
            ]
          },
          {
            "name": "Mutant #400",
            "file": "tests/test_validate.py",
            "line": 28,
            "system-out": [
              "    }"
            ]
          },
          {
            "name": "Mutant #401",
            "file": "tests/test_validate.py",
            "line": 29,
            "system-out": [
              "    is_valid, errors = validate_configuration(valid_config_correct_schema)"
            ]
          },
          {
            "name": "Mutant #402",
            "file": "tests/test_validate.py",
            "line": 41,
            "system-out": [
              "    is_valid, errors = validate_configuration(config)"
            ]
          },
          {
            "name": "Mutant #403",
            "file": "tests/test_validate.py",
            "line": 51,
            "system-out": [
              "    is_valid, errors = validate_configuration(config)"
            ]
          },
          {
            "name": "Mutant #404",
            "file": "tests/test_checks.py",
            "line": 24,
            "system-out": [
              "}"
            ]
          },
          {
            "name": "Mutant #405",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #406",
            "file": "tests/test_checks.py",
            "line": 30,
            "system-out": [
              "    min_count, max_count = extract_min_max(check)"
            ]
          },
          {
            "name": "Mutant #407",
            "file": "tests/test_checks.py",
            "line": 37,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #408",
            "file": "tests/test_checks.py",
            "line": 38,
            "system-out": [
              "    min_count, max_count = extract_min_max(check)"
            ]
          },
          {
            "name": "Mutant #409",
            "file": "tests/test_checks.py",
            "line": 50,
            "system-out": [
              "    }"
            ]
          },
          {
            "name": "Mutant #410",
            "file": "tests/test_checks.py",
            "line": 51,
            "system-out": [
              "    min_count, max_count = extract_min_max(check)"
            ]
          },
          {
            "name": "Mutant #411",
            "file": "tests/test_checks.py",
            "line": 58,
            "system-out": [
              "    check = {\"name\": \"test\"}"
            ]
          },
          {
            "name": "Mutant #412",
            "file": "tests/test_checks.py",
            "line": 59,
            "system-out": [
              "    min_count, max_count = extract_min_max(check)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #413",
            "file": "tests/test_checks.py",
            "line": 72,
            "system-out": [
              "    }"
            ]
          },
          {
            "name": "Mutant #414",
            "file": "tests/test_checks.py",
            "line": 83,
            "system-out": [
              "    }"
            ]
          },
          {
            "name": "Mutant #415",
            "file": "tests/test_checks.py",
            "line": 103,
            "system-out": [
              "    min_count, max_count = extract_min_max(check)"
            ]
          },
          {
            "name": "Mutant #416",
            "file": "tests/test_checks.py",
            "line": 113,
            "system-out": [
              "    min_count, max_count = extract_min_max(check)"
            ]
          },
          {
            "name": "Mutant #417",
            "file": "tests/test_checks.py",
            "line": 135,
            "system-out": [
              "    result = check_match_count(count, min_value, max_value)"
            ]
          },
          {
            "name": "Mutant #418",
            "file": "tests/test_checks.py",
            "line": 147,
            "system-out": [
              "    confirmation = check_match_count(count, min, max)"
            ]
          },
          {
            "name": "Mutant #419",
            "file": "tests/test_main.py",
            "line": 13,
            "system-out": [
              "runner = CliRunner()"
            ]
          },
          {
            "name": "Mutant #420",
            "file": "tests/test_main.py",
            "line": 16,
            "system-out": [
              "CONFIGURATION_FILE_DEFAULT_CONTENTS = \"\"\""
            ]
          },
          {
            "name": "Mutant #421",
            "file": "tests/test_main.py",
            "line": 25,
            "system-out": [
              "CHECKS_FILE_DEFAULT_CONTENTS = \"\"\""
            ]
          },
          {
            "name": "Mutant #422",
            "file": "tests/test_main.py",
            "line": 49,
            "system-out": [
              "CHECKS_FILE_DEFAULT_CONTENTS_GOTCHA = \"\"\""
            ]
          },
          {
            "name": "Mutant #423",
            "file": "tests/test_main.py",
            "line": 89,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #424",
            "file": "tests/test_main.py",
            "line": 91,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #425",
            "file": "tests/test_main.py",
            "line": 94,
            "system-out": [
              "    configuration_directory = test_one / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #426",
            "file": "tests/test_main.py",
            "line": 95,
            "system-out": [
              "    configuration_directory_path = Path(configuration_directory)"
            ]
          },
          {
            "name": "Mutant #427",
            "file": "tests/test_main.py",
            "line": 97,
            "system-out": [
              "    configuration_file = configuration_directory_path / \"config.yml\""
            ]
          },
          {
            "name": "Mutant #428",
            "file": "tests/test_main.py",
            "line": 100,
            "system-out": [
              "    checks_file = configuration_directory_path / \"checks.yml\""
            ]
          },
          {
            "name": "Mutant #429",
            "file": "tests/test_main.py",
            "line": 115,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #430",
            "file": "tests/test_main.py",
            "line": 122,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #431",
            "file": "tests/test_main.py",
            "line": 125,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #432",
            "file": "tests/test_main.py",
            "line": 137,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #433",
            "file": "tests/test_main.py",
            "line": 144,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #434",
            "file": "tests/test_main.py",
            "line": 147,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #435",
            "file": "tests/test_main.py",
            "line": 159,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #436",
            "file": "tests/test_main.py",
            "line": 168,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #437",
            "file": "tests/test_main.py",
            "line": 169,
            "system-out": [
              "    project_name = \"test\""
            ]
          },
          {
            "name": "Mutant #438",
            "file": "tests/test_main.py",
            "line": 172,
            "system-out": [
              "    wrong_config_dir = \"config\""
            ]
          },
          {
            "name": "Mutant #439",
            "file": "tests/test_main.py",
            "line": 185,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #440",
            "file": "tests/test_main.py",
            "line": 193,
            "system-out": [
              "    _ = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #441",
            "file": "tests/test_main.py",
            "line": 194,
            "system-out": [
              "    test_one_incorrect_name = \"test_oneFF\""
            ]
          },
          {
            "name": "Mutant #442",
            "file": "tests/test_main.py",
            "line": 195,
            "system-out": [
              "    project_name = \"test\""
            ]
          },
          {
            "name": "Mutant #443",
            "file": "tests/test_main.py",
            "line": 198,
            "system-out": [
              "    wrong_config_dir = \"config\""
            ]
          },
          {
            "name": "Mutant #444",
            "file": "tests/test_main.py",
            "line": 211,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #445",
            "file": "tests/test_main.py",
            "line": 225,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #446",
            "file": "tests/test_main.py",
            "line": 226,
            "system-out": [
              "    project_name = \"test\""
            ]
          },
          {
            "name": "Mutant #447",
            "file": "tests/test_main.py",
            "line": 229,
            "system-out": [
              "    correct_config_dir = tmpdir.mkdir(\"config\")"
            ]
          },
          {
            "name": "Mutant #448",
            "file": "tests/test_main.py",
            "line": 242,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #449",
            "file": "tests/test_main.py",
            "line": 361,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #450",
            "file": "tests/test_main.py",
            "line": 370,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #451",
            "file": "tests/test_main.py",
            "line": 382,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #452",
            "file": "tests/test_main.py",
            "line": 383,
            "system-out": [
              "    config_directory = Path(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #453",
            "file": "tests/test_main.py",
            "line": 394,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #454",
            "file": "tests/test_main.py",
            "line": 403,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #455",
            "file": "tests/test_main.py",
            "line": 406,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #456",
            "file": "tests/test_main.py",
            "line": 417,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #457",
            "file": "tests/test_main.py",
            "line": 423,
            "system-out": [
              "    tmp_dir = Path(tmpdir)"
            ]
          },
          {
            "name": "Mutant #458",
            "file": "tests/test_main.py",
            "line": 424,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #459",
            "file": "tests/test_main.py",
            "line": 427,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #460",
            "file": "tests/test_main.py",
            "line": 440,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #461",
            "file": "tests/test_main.py",
            "line": 447,
            "system-out": [
              "    tmp_dir = Path(tmpdir)"
            ]
          },
          {
            "name": "Mutant #462",
            "file": "tests/test_main.py",
            "line": 449,
            "system-out": [
              "    file = tmp_dir / \"analysis.md\""
            ]
          },
          {
            "name": "Mutant #463",
            "file": "tests/test_main.py",
            "line": 454,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #464",
            "file": "tests/test_main.py",
            "line": 457,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #465",
            "file": "tests/test_main.py",
            "line": 471,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #466",
            "file": "tests/test_main.py",
            "line": 481,
            "system-out": [
              "    tmp_dir = Path(tmpdir)"
            ]
          },
          {
            "name": "Mutant #467",
            "file": "tests/test_main.py",
            "line": 483,
            "system-out": [
              "    file = tmp_dir / \"analysis.md\""
            ]
          },
          {
            "name": "Mutant #468",
            "file": "tests/test_main.py",
            "line": 488,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #469",
            "file": "tests/test_main.py",
            "line": 491,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #470",
            "file": "tests/test_main.py",
            "line": 506,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #471",
            "file": "tests/test_main.py",
            "line": 516,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #472",
            "file": "tests/test_main.py",
            "line": 519,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #473",
            "file": "tests/test_main.py",
            "line": 533,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #474",
            "file": "tests/test_constants.py",
            "line": 33,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #475",
            "file": "tests/test_constants.py",
            "line": 35,
            "system-out": [
              "    hr = constants.Humanreadable(yes, no)"
            ]
          },
          {
            "name": "Mutant #476",
            "file": "tests/test_constants.py",
            "line": 48,
            "system-out": [
              "        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))"
            ]
          },
          {
            "name": "Mutant #477",
            "file": "tests/test_constants.py",
            "line": 50,
            "system-out": [
              "        hr.Yes = \"YES\""
            ]
          },
          {
            "name": "Mutant #478",
            "file": "tests/test_constants.py",
            "line": 52,
            "system-out": [
              "        hr.No = \"NO\""
            ]
          },
          {
            "name": "Mutant #479",
            "file": "tests/test_constants.py",
            "line": 66,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #480",
            "file": "tests/test_constants.py",
            "line": 69,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #481",
            "file": "tests/test_constants.py",
            "line": 80,
            "system-out": [
              "    dir1 = directory"
            ]
          },
          {
            "name": "Mutant #482",
            "file": "tests/test_constants.py",
            "line": 81,
            "system-out": [
              "    dir2 = directory"
            ]
          },
          {
            "name": "Mutant #483",
            "file": "tests/test_constants.py",
            "line": 85,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #484",
            "file": "tests/test_constants.py",
            "line": 88,
            "system-out": [
              "    )"
            ]
          },
          {
            "name": "Mutant #485",
            "file": "chasten/configuration.py",
            "line": 29,
            "system-out": [
              "    chasten_user_config_dir_str = None"
            ]
          },
          {
            "name": "Mutant #486",
            "file": "chasten/configuration.py",
            "line": 42,
            "system-out": [
              "    function_name = constants.logger.Function_Prefix + debug_dest"
            ]
          },
          {
            "name": "Mutant #487",
            "file": "chasten/configuration.py",
            "line": 46,
            "system-out": [
              "        return (getattr(configure_module, function_name)(debug_level), True)"
            ]
          },
          {
            "name": "Mutant #488",
            "file": "chasten/configuration.py",
            "line": 50,
            "system-out": [
              "        return (configure_logging_console(debug_level), False)"
            ]
          },
          {
            "name": "Mutant #489",
            "file": "chasten/configuration.py",
            "line": 62,
            "system-out": [
              "        datefmt=\"[%X]\","
            ]
          },
          {
            "name": "Mutant #490",
            "file": "chasten/configuration.py",
            "line": 90,
            "system-out": [
              "    chasten_user_config_dir_str: str, verbose: bool = False"
            ]
          },
          {
            "name": "Mutant #491",
            "file": "chasten/configuration.py",
            "line": 100,
            "system-out": [
              "    output.opt_print_log(verbose, empty=\"\")"
            ]
          },
          {
            "name": "Mutant #492",
            "file": "chasten/configuration.py",
            "line": 111,
            "system-out": [
              "    checks_file_validated = False"
            ]
          },
          {
            "name": "Mutant #493",
            "file": "chasten/configuration.py",
            "line": 112,
            "system-out": [
              "    checks_file_invalidates_entire_config = False"
            ]
          },
          {
            "name": "Mutant #494",
            "file": "chasten/configuration.py",
            "line": 126,
            "system-out": [
              "    elif chasten_user_config_url_str != \"\":"
            ]
          },
          {
            "name": "Mutant #495",
            "file": "chasten/configuration.py",
            "line": 126,
            "system-out": [
              "    elif chasten_user_config_url_str != \"\":"
            ]
          },
          {
            "name": "Mutant #496",
            "file": "chasten/configuration.py",
            "line": 128,
            "system-out": [
              "            f\"\\nChecks file directive was a Path when config was a URL (given: '{checks_file_name}')\\n\""
            ]
          },
          {
            "name": "Mutant #497",
            "file": "chasten/configuration.py",
            "line": 130,
            "system-out": [
              "        checks_file_validated = False"
            ]
          },
          {
            "name": "Mutant #498",
            "file": "chasten/configuration.py",
            "line": 131,
            "system-out": [
              "        checks_file_invalidates_entire_config = True"
            ]
          },
          {
            "name": "Mutant #499",
            "file": "chasten/configuration.py",
            "line": 134,
            "system-out": [
              "    elif (Path(chasten_user_config_dir_str) / Path(checks_file_name)).exists():"
            ]
          },
          {
            "name": "Mutant #500",
            "file": "chasten/configuration.py",
            "line": 149,
            "system-out": [
              "            f\"\\nChecks file directive was not a valid Path or URL (given: '{checks_file_name}')\\n\""
            ]
          },
          {
            "name": "Mutant #501",
            "file": "chasten/configuration.py",
            "line": 157,
            "system-out": [
              "    if not checks_file_extracted_valid:"
            ]
          },
          {
            "name": "Mutant #502",
            "file": "chasten/configuration.py",
            "line": 179,
            "system-out": [
              "    verbose: bool = False,"
            ]
          },
          {
            "name": "Mutant #503",
            "file": "chasten/configuration.py",
            "line": 184,
            "system-out": [
              "    chasten_user_config_url_str = \"\""
            ]
          },
          {
            "name": "Mutant #504",
            "file": "chasten/configuration.py",
            "line": 185,
            "system-out": [
              "    chasten_user_config_dir_str = \"\""
            ]
          },
          {
            "name": "Mutant #505",
            "file": "chasten/configuration.py",
            "line": 186,
            "system-out": [
              "    chasten_user_config_file_str = \"\""
            ]
          },
          {
            "name": "Mutant #506",
            "file": "chasten/configuration.py",
            "line": 188,
            "system-out": [
              "    if config == \"\":"
            ]
          },
          {
            "name": "Mutant #507",
            "file": "chasten/configuration.py",
            "line": 188,
            "system-out": [
              "    if config == \"\":"
            ]
          },
          {
            "name": "Mutant #508",
            "file": "chasten/configuration.py",
            "line": 206,
            "system-out": [
              "            \":sparkles: Configuration URL:\""
            ]
          },
          {
            "name": "Mutant #509",
            "file": "chasten/configuration.py",
            "line": 207,
            "system-out": [
              "            + constants.markers.Space"
            ]
          },
          {
            "name": "Mutant #510",
            "file": "chasten/configuration.py",
            "line": 208,
            "system-out": [
              "            + chasten_user_config_url_str"
            ]
          },
          {
            "name": "Mutant #511",
            "file": "chasten/configuration.py",
            "line": 209,
            "system-out": [
              "            + constants.markers.Newline"
            ]
          },
          {
            "name": "Mutant #512",
            "file": "chasten/configuration.py",
            "line": 232,
            "system-out": [
              "                Path(*config_as_path.parts[: len(config_as_path.parts) - 1])"
            ]
          },
          {
            "name": "Mutant #513",
            "file": "chasten/configuration.py",
            "line": 232,
            "system-out": [
              "                Path(*config_as_path.parts[: len(config_as_path.parts) - 1])"
            ]
          },
          {
            "name": "Mutant #514",
            "file": "chasten/configuration.py",
            "line": 235,
            "system-out": [
              "            chasten_user_config_file_str = str(config_as_path.parts[-1])"
            ]
          },
          {
            "name": "Mutant #515",
            "file": "chasten/configuration.py",
            "line": 235,
            "system-out": [
              "            chasten_user_config_file_str = str(config_as_path.parts[-1])"
            ]
          },
          {
            "name": "Mutant #516",
            "file": "chasten/configuration.py",
            "line": 238,
            "system-out": [
              "                \"\\nGiven configuration was a Path, but was the wrong file type.\\n\""
            ]
          },
          {
            "name": "Mutant #517",
            "file": "chasten/configuration.py",
            "line": 240,
            "system-out": [
              "            return (False, {})"
            ]
          },
          {
            "name": "Mutant #518",
            "file": "chasten/configuration.py",
            "line": 242,
            "system-out": [
              "            \":sparkles: Configuration directory:\""
            ]
          },
          {
            "name": "Mutant #519",
            "file": "chasten/configuration.py",
            "line": 244,
            "system-out": [
              "            + chasten_user_config_dir_str"
            ]
          },
          {
            "name": "Mutant #520",
            "file": "chasten/configuration.py",
            "line": 250,
            "system-out": [
              "        if chasten_user_config_file_str != \"\":"
            ]
          },
          {
            "name": "Mutant #521",
            "file": "chasten/configuration.py",
            "line": 250,
            "system-out": [
              "        if chasten_user_config_file_str != \"\":"
            ]
          },
          {
            "name": "Mutant #522",
            "file": "chasten/configuration.py",
            "line": 252,
            "system-out": [
              "                \"configuration_file\""
            ]
          },
          {
            "name": "Mutant #523",
            "file": "chasten/configuration.py",
            "line": 266,
            "system-out": [
              "        if not configuration_valid:"
            ]
          },
          {
            "name": "Mutant #524",
            "file": "chasten/configuration.py",
            "line": 276,
            "system-out": [
              "        output.logger.error(\"\\nGiven configuration was not a valid Path or URL.\\n\")"
            ]
          },
          {
            "name": "Mutant #525",
            "file": "chasten/configuration.py",
            "line": 277,
            "system-out": [
              "        return (False, {})"
            ]
          },
          {
            "name": "Mutant #526",
            "file": "chasten/configuration.py",
            "line": 298,
            "system-out": [
              "    check_files_validated = False"
            ]
          },
          {
            "name": "Mutant #527",
            "file": "chasten/configuration.py",
            "line": 302,
            "system-out": [
              "    ] = {}"
            ]
          },
          {
            "name": "Mutant #528",
            "file": "chasten/configuration.py",
            "line": 304,
            "system-out": [
              "    overall_checks_list: List[Dict[str, Union[str, Dict[str, int]]]] = []"
            ]
          },
          {
            "name": "Mutant #529",
            "file": "chasten/configuration.py",
            "line": 334,
            "system-out": [
              "    if config_file_validated and check_files_validated:"
            ]
          },
          {
            "name": "Mutant #530",
            "file": "chasten/configuration.py",
            "line": 335,
            "system-out": [
              "        return (True, overall_checks_dict)"
            ]
          },
          {
            "name": "Mutant #531",
            "file": "chasten/configuration.py",
            "line": 337,
            "system-out": [
              "    return (False, {})"
            ]
          },
          {
            "name": "Mutant #532",
            "file": "chasten/configuration.py",
            "line": 351,
            "system-out": [
              "    configuration_file_path = chasten_user_config_dir_str / configuration_file"
            ]
          },
          {
            "name": "Mutant #533",
            "file": "chasten/configuration.py",
            "line": 356,
            "system-out": [
              "    if not configuration_file_path.exists():"
            ]
          },
          {
            "name": "Mutant #534",
            "file": "chasten/configuration.py",
            "line": 358,
            "system-out": [
              "            f\"\\nFinding config or check file Path failed for {configuration_file_path}.\\n\""
            ]
          },
          {
            "name": "Mutant #535",
            "file": "chasten/configuration.py",
            "line": 360,
            "system-out": [
              "        return (False, None, None, None)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #536",
            "file": "chasten/configuration.py",
            "line": 370,
            "system-out": [
              "                True,"
            ]
          },
          {
            "name": "Mutant #537",
            "file": "chasten/configuration.py",
            "line": 378,
            "system-out": [
              "                f\"\\nParsing YAML from config or check file Path failed for {configuration_file_path}.\\n\""
            ]
          },
          {
            "name": "Mutant #538",
            "file": "chasten/configuration.py",
            "line": 380,
            "system-out": [
              "            return (False, None, None, None)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #539",
            "file": "chasten/configuration.py",
            "line": 399,
            "system-out": [
              "            f\"\\nLoading config or check file URL failed for {chasten_user_config_url}.\\n\""
            ]
          },
          {
            "name": "Mutant #540",
            "file": "chasten/configuration.py",
            "line": 401,
            "system-out": [
              "        return (False, None, None)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #541",
            "file": "chasten/configuration.py",
            "line": 407,
            "system-out": [
              "        return (True, configuration_file_yaml_str, yaml_data)"
            ]
          },
          {
            "name": "Mutant #542",
            "file": "chasten/configuration.py",
            "line": 410,
            "system-out": [
              "            f\"\\nParsing YAML from config or check file URL failed for {chasten_user_config_url}.\\n\""
            ]
          },
          {
            "name": "Mutant #543",
            "file": "chasten/configuration.py",
            "line": 424,
            "system-out": [
              "        return (False, None)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #544",
            "file": "chasten/configuration.py",
            "line": 427,
            "system-out": [
              "    return (True, yaml_data)"
            ]
          },
          {
            "name": "Mutant #545",
            "file": "chasten/server.py",
            "line": 24,
            "system-out": [
              "            self.request[0].strip(), encoding=constants.server.Utf8_Encoding"
            ]
          },
          {
            "name": "Mutant #546",
            "file": "chasten/results.py",
            "line": 61,
            "system-out": [
              "    linematch: str = \"\""
            ]
          },
          {
            "name": "Mutant #547",
            "file": "chasten/results.py",
            "line": 61,
            "system-out": [
              "    linematch: str = \"\""
            ]
          },
          {
            "name": "Mutant #548",
            "file": "chasten/results.py",
            "line": 62,
            "system-out": [
              "    linematch_context: str = \"\""
            ]
          },
          {
            "name": "Mutant #549",
            "file": "chasten/results.py",
            "line": 62,
            "system-out": [
              "    linematch_context: str = \"\""
            ]
          },
          {
            "name": "Mutant #550",
            "file": "chasten/results.py",
            "line": 70,
            "system-out": [
              "    description: str = \"\""
            ]
          },
          {
            "name": "Mutant #551",
            "file": "chasten/results.py",
            "line": 70,
            "system-out": [
              "    description: str = \"\""
            ]
          },
          {
            "name": "Mutant #552",
            "file": "chasten/results.py",
            "line": 71,
            "system-out": [
              "    min: Optional[conint(ge=0)] = 0  # type: ignore"
            ]
          },
          {
            "name": "Mutant #553",
            "file": "chasten/results.py",
            "line": 71,
            "system-out": [
              "    min: Optional[conint(ge=0)] = 0  # type: ignore"
            ]
          },
          {
            "name": "Mutant #554",
            "file": "chasten/results.py",
            "line": 71,
            "system-out": [
              "    min: Optional[conint(ge=0)] = 0  # type: ignore"
            ]
          },
          {
            "name": "Mutant #555",
            "file": "chasten/results.py",
            "line": 72,
            "system-out": [
              "    max: Optional[conint(ge=0)] = 0  # type: ignore"
            ]
          },
          {
            "name": "Mutant #556",
            "file": "chasten/results.py",
            "line": 72,
            "system-out": [
              "    max: Optional[conint(ge=0)] = 0  # type: ignore"
            ]
          },
          {
            "name": "Mutant #557",
            "file": "chasten/results.py",
            "line": 72,
            "system-out": [
              "    max: Optional[conint(ge=0)] = 0  # type: ignore"
            ]
          },
          {
            "name": "Mutant #558",
            "file": "chasten/results.py",
            "line": 75,
            "system-out": [
              "    matches: list[Match] = []"
            ]
          },
          {
            "name": "Mutant #559",
            "file": "chasten/results.py",
            "line": 76,
            "system-out": [
              "    _matches: list[pyastgrepsearch.Match] = []"
            ]
          },
          {
            "name": "Mutant #560",
            "file": "chasten/results.py",
            "line": 83,
            "system-out": [
              "    _filelines: List[str] = []"
            ]
          },
          {
            "name": "Mutant #561",
            "file": "chasten/results.py",
            "line": 84,
            "system-out": [
              "    check: Union[None, Check] = None"
            ]
          },
          {
            "name": "Mutant #562",
            "file": "chasten/results.py",
            "line": 90,
            "system-out": [
              "    attribute: Union[None, str] = \"\""
            ]
          },
          {
            "name": "Mutant #563",
            "file": "chasten/results.py",
            "line": 90,
            "system-out": [
              "    attribute: Union[None, str] = \"\""
            ]
          },
          {
            "name": "Mutant #564",
            "file": "chasten/results.py",
            "line": 91,
            "system-out": [
              "    value: Union[None, str] = \"\""
            ]
          },
          {
            "name": "Mutant #565",
            "file": "chasten/results.py",
            "line": 91,
            "system-out": [
              "    value: Union[None, str] = \"\""
            ]
          },
          {
            "name": "Mutant #566",
            "file": "chasten/results.py",
            "line": 92,
            "system-out": [
              "    confidence: int = 0"
            ]
          },
          {
            "name": "Mutant #567",
            "file": "chasten/results.py",
            "line": 92,
            "system-out": [
              "    confidence: int = 0"
            ]
          },
          {
            "name": "Mutant #568",
            "file": "chasten/results.py",
            "line": 104,
            "system-out": [
              "    fileuuid: str = str(uuid.uuid4().hex)"
            ]
          },
          {
            "name": "Mutant #569",
            "file": "chasten/results.py",
            "line": 105,
            "system-out": [
              "    _datetime: str = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            ]
          },
          {
            "name": "Mutant #570",
            "file": "chasten/results.py",
            "line": 105,
            "system-out": [
              "    _datetime: str = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            ]
          },
          {
            "name": "Mutant #571",
            "file": "chasten/results.py",
            "line": 106,
            "system-out": [
              "    datetime: str = str(datetime.now())"
            ]
          },
          {
            "name": "Mutant #572",
            "file": "chasten/results.py",
            "line": 107,
            "system-out": [
              "    checkinclude: Union[None, CheckCriterion] = None"
            ]
          },
          {
            "name": "Mutant #573",
            "file": "chasten/results.py",
            "line": 108,
            "system-out": [
              "    checkexclude: Union[None, CheckCriterion] = None"
            ]
          },
          {
            "name": "Mutant #574",
            "file": "chasten/results.py",
            "line": 115,
            "system-out": [
              "    sources: list[Source] = []"
            ]
          },
          {
            "name": "Mutant #575",
            "file": "chasten/util.py",
            "line": 11,
            "system-out": [
              "checkmark_unicode = \"\\u2713\""
            ]
          },
          {
            "name": "Mutant #576",
            "file": "chasten/util.py",
            "line": 12,
            "system-out": [
              "xmark_unicode = \"\\u2717\""
            ]
          },
          {
            "name": "Mutant #577",
            "file": "chasten/util.py",
            "line": 13,
            "system-out": [
              "default_chasten_semver = \"0.0.0\""
            ]
          },
          {
            "name": "Mutant #578",
            "file": "chasten/util.py",
            "line": 31,
            "system-out": [
              "def executable_name(executable_name: str, OpSystem: str = \"Linux\") -> str:"
            ]
          },
          {
            "name": "Mutant #579",
            "file": "chasten/util.py",
            "line": 33,
            "system-out": [
              "    exe_directory = \"/bin/\""
            ]
          },
          {
            "name": "Mutant #580",
            "file": "chasten/util.py",
            "line": 35,
            "system-out": [
              "    if OpSystem == \"Windows\":"
            ]
          },
          {
            "name": "Mutant #581",
            "file": "chasten/util.py",
            "line": 35,
            "system-out": [
              "    if OpSystem == \"Windows\":"
            ]
          },
          {
            "name": "Mutant #582",
            "file": "chasten/util.py",
            "line": 36,
            "system-out": [
              "        exe_directory = \"/Scripts/\""
            ]
          },
          {
            "name": "Mutant #583",
            "file": "chasten/util.py",
            "line": 37,
            "system-out": [
              "        executable_name += \".exe\""
            ]
          },
          {
            "name": "Mutant #584",
            "file": "chasten/util.py",
            "line": 37,
            "system-out": [
              "        executable_name += \".exe\""
            ]
          },
          {
            "name": "Mutant #585",
            "file": "chasten/util.py",
            "line": 37,
            "system-out": [
              "        executable_name += \".exe\""
            ]
          },
          {
            "name": "Mutant #586",
            "file": "chasten/util.py",
            "line": 39,
            "system-out": [
              "    return virtual_env_location + exe_directory + executable_name"
            ]
          },
          {
            "name": "Mutant #587",
            "file": "chasten/util.py",
            "line": 39,
            "system-out": [
              "    return virtual_env_location + exe_directory + executable_name"
            ]
          },
          {
            "name": "Mutant #588",
            "file": "chasten/util.py",
            "line": 45,
            "system-out": [
              "        return f\"[green]{checkmark_unicode}[/green]\""
            ]
          },
          {
            "name": "Mutant #589",
            "file": "chasten/util.py",
            "line": 46,
            "system-out": [
              "    return f\"[red]{xmark_unicode}[/red]\""
            ]
          },
          {
            "name": "Mutant #590",
            "file": "chasten/util.py",
            "line": 78,
            "system-out": [
              "    if url_parsed.scheme not in [\"http\", \"https\"]:"
            ]
          },
          {
            "name": "Mutant #591",
            "file": "chasten/util.py",
            "line": 78,
            "system-out": [
              "    if url_parsed.scheme not in [\"http\", \"https\"]:"
            ]
          },
          {
            "name": "Mutant #592",
            "file": "chasten/util.py",
            "line": 78,
            "system-out": [
              "    if url_parsed.scheme not in [\"http\", \"https\"]:"
            ]
          },
          {
            "name": "Mutant #593",
            "file": "chasten/util.py",
            "line": 79,
            "system-out": [
              "        return False"
            ]
          },
          {
            "name": "Mutant #594",
            "file": "chasten/util.py",
            "line": 81,
            "system-out": [
              "    port_character = \":\" if url_parsed.port is not None else \"\""
            ]
          },
          {
            "name": "Mutant #595",
            "file": "chasten/util.py",
            "line": 81,
            "system-out": [
              "    port_character = \":\" if url_parsed.port is not None else \"\""
            ]
          },
          {
            "name": "Mutant #596",
            "file": "chasten/util.py",
            "line": 81,
            "system-out": [
              "    port_character = \":\" if url_parsed.port is not None else \"\""
            ]
          },
          {
            "name": "Mutant #597",
            "file": "chasten/util.py",
            "line": 82,
            "system-out": [
              "    query_character = \"?\" if url_parsed.query is not None else \"\""
            ]
          },
          {
            "name": "Mutant #598",
            "file": "chasten/util.py",
            "line": 82,
            "system-out": [
              "    query_character = \"?\" if url_parsed.query is not None else \"\""
            ]
          },
          {
            "name": "Mutant #599",
            "file": "chasten/util.py",
            "line": 82,
            "system-out": [
              "    query_character = \"?\" if url_parsed.query is not None else \"\""
            ]
          },
          {
            "name": "Mutant #600",
            "file": "chasten/util.py",
            "line": 83,
            "system-out": [
              "    fragment_character = \"#\" if url_parsed.fragment is not None else \"\""
            ]
          },
          {
            "name": "Mutant #601",
            "file": "chasten/util.py",
            "line": 83,
            "system-out": [
              "    fragment_character = \"#\" if url_parsed.fragment is not None else \"\""
            ]
          },
          {
            "name": "Mutant #602",
            "file": "chasten/util.py",
            "line": 83,
            "system-out": [
              "    fragment_character = \"#\" if url_parsed.fragment is not None else \"\""
            ]
          },
          {
            "name": "Mutant #603",
            "file": "chasten/util.py",
            "line": 86,
            "system-out": [
              "        \"://\","
            ]
          },
          {
            "name": "Mutant #604",
            "file": "chasten/util.py",
            "line": 98,
            "system-out": [
              "    url_reassembled = \"\""
            ]
          },
          {
            "name": "Mutant #605",
            "file": "chasten/util.py",
            "line": 100,
            "system-out": [
              "        if url_piece is not None:"
            ]
          },
          {
            "name": "Mutant #606",
            "file": "chasten/util.py",
            "line": 101,
            "system-out": [
              "            url_reassembled += str(url_piece)"
            ]
          },
          {
            "name": "Mutant #607",
            "file": "chasten/util.py",
            "line": 101,
            "system-out": [
              "            url_reassembled += str(url_piece)"
            ]
          },
          {
            "name": "Mutant #608",
            "file": "chasten/util.py",
            "line": 103,
            "system-out": [
              "    return str(parse_url(url)).lower() == url_reassembled.lower()"
            ]
          },
          {
            "name": "Mutant #609",
            "file": "chasten/util.py",
            "line": 113,
            "system-out": [
              "        count_passed = check_status_list.count(True)"
            ]
          },
          {
            "name": "Mutant #610",
            "file": "chasten/util.py",
            "line": 118,
            "system-out": [
              "            (count_passed / count_total) * constants.markers.Percent_Multiplier,"
            ]
          },
          {
            "name": "Mutant #611",
            "file": "chasten/util.py",
            "line": 118,
            "system-out": [
              "            (count_passed / count_total) * constants.markers.Percent_Multiplier,"
            ]
          },
          {
            "name": "Mutant #612",
            "file": "chasten/util.py",
            "line": 122,
            "system-out": [
              "        return (0, 0, 0.0)"
            ]
          },
          {
            "name": "Mutant #613",
            "file": "chasten/util.py",
            "line": 122,
            "system-out": [
              "        return (0, 0, 0.0)"
            ]
          },
          {
            "name": "Mutant #614",
            "file": "chasten/util.py",
            "line": 122,
            "system-out": [
              "        return (0, 0, 0.0)"
            ]
          },
          {
            "name": "Mutant #615",
            "file": "chasten/configuration.py",
            "line": 81,
            "system-out": [
              "        datefmt=\"[%X]\","
            ]
          },
          {
            "name": "Mutant #616",
            "file": "chasten/configuration.py",
            "line": 152,
            "system-out": [
              "        checks_file_invalidates_entire_config = True"
            ]
          },
          {
            "name": "Mutant #617",
            "file": "chasten/configuration.py",
            "line": 243,
            "system-out": [
              "            + constants.markers.Space"
            ]
          },
          {
            "name": "Mutant #618",
            "file": "chasten/checks.py",
            "line": 15,
            "system-out": [
              "    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore"
            ]
          },
          {
            "name": "Mutant #619",
            "file": "chasten/checks.py",
            "line": 15,
            "system-out": [
              "    max_count = check.get(\"count\", {}).get(\"max\")  # type: ignore"
            ]
          },
          {
            "name": "Mutant #620",
            "file": "chasten/checks.py",
            "line": 23,
            "system-out": [
              "    if \"description\" in check:"
            ]
          },
          {
            "name": "Mutant #621",
            "file": "chasten/checks.py",
            "line": 23,
            "system-out": [
              "    if \"description\" in check:"
            ]
          },
          {
            "name": "Mutant #622",
            "file": "chasten/checks.py",
            "line": 24,
            "system-out": [
              "        return str(check[\"description\"])"
            ]
          },
          {
            "name": "Mutant #623",
            "file": "chasten/checks.py",
            "line": 25,
            "system-out": [
              "    return \"\""
            ]
          },
          {
            "name": "Mutant #624",
            "file": "chasten/checks.py",
            "line": 32,
            "system-out": [
              "    labeled_attribute = \"\""
            ]
          },
          {
            "name": "Mutant #625",
            "file": "chasten/checks.py",
            "line": 36,
            "system-out": [
              "        labeled_attribute = f\"{label} = {attribute}\""
            ]
          },
          {
            "name": "Mutant #626",
            "file": "chasten/checks.py",
            "line": 52,
            "system-out": [
              "        if i > 0:"
            ]
          },
          {
            "name": "Mutant #627",
            "file": "chasten/checks.py",
            "line": 52,
            "system-out": [
              "        if i > 0:"
            ]
          },
          {
            "name": "Mutant #628",
            "file": "chasten/checks.py",
            "line": 53,
            "system-out": [
              "            joined_attribute_labels += constants.markers.Comma_Space"
            ]
          },
          {
            "name": "Mutant #629",
            "file": "chasten/checks.py",
            "line": 53,
            "system-out": [
              "            joined_attribute_labels += constants.markers.Comma_Space"
            ]
          },
          {
            "name": "Mutant #630",
            "file": "chasten/checks.py",
            "line": 55,
            "system-out": [
              "        joined_attribute_labels += attribute_label  # type: ignore"
            ]
          },
          {
            "name": "Mutant #631",
            "file": "chasten/checks.py",
            "line": 55,
            "system-out": [
              "        joined_attribute_labels += attribute_label  # type: ignore"
            ]
          },
          {
            "name": "Mutant #632",
            "file": "chasten/checks.py",
            "line": 61,
            "system-out": [
              "    if min_value is None and max_value is None:"
            ]
          },
          {
            "name": "Mutant #633",
            "file": "chasten/checks.py",
            "line": 61,
            "system-out": [
              "    if min_value is None and max_value is None:"
            ]
          },
          {
            "name": "Mutant #634",
            "file": "chasten/checks.py",
            "line": 61,
            "system-out": [
              "    if min_value is None and max_value is None:"
            ]
          },
          {
            "name": "Mutant #635",
            "file": "chasten/checks.py",
            "line": 62,
            "system-out": [
              "        return False"
            ]
          },
          {
            "name": "Mutant #636",
            "file": "chasten/checks.py",
            "line": 63,
            "system-out": [
              "    return True"
            ]
          },
          {
            "name": "Mutant #637",
            "file": "chasten/checks.py",
            "line": 68,
            "system-out": [
              "    return min(max_value, value) == value and max(min_value, value) == value"
            ]
          },
          {
            "name": "Mutant #638",
            "file": "chasten/checks.py",
            "line": 68,
            "system-out": [
              "    return min(max_value, value) == value and max(min_value, value) == value"
            ]
          },
          {
            "name": "Mutant #639",
            "file": "chasten/checks.py",
            "line": 68,
            "system-out": [
              "    return min(max_value, value) == value and max(min_value, value) == value"
            ]
          },
          {
            "name": "Mutant #640",
            "file": "chasten/checks.py",
            "line": 79,
            "system-out": [
              "        return True"
            ]
          },
          {
            "name": "Mutant #641",
            "file": "chasten/checks.py",
            "line": 81,
            "system-out": [
              "    if min_value is not None and max_value is not None:"
            ]
          },
          {
            "name": "Mutant #642",
            "file": "chasten/checks.py",
            "line": 81,
            "system-out": [
              "    if min_value is not None and max_value is not None:"
            ]
          },
          {
            "name": "Mutant #643",
            "file": "chasten/checks.py",
            "line": 81,
            "system-out": [
              "    if min_value is not None and max_value is not None:"
            ]
          },
          {
            "name": "Mutant #644",
            "file": "chasten/checks.py",
            "line": 85,
            "system-out": [
              "    if min_value is not None:"
            ]
          },
          {
            "name": "Mutant #645",
            "file": "chasten/checks.py",
            "line": 86,
            "system-out": [
              "        if count >= min_value:"
            ]
          },
          {
            "name": "Mutant #646",
            "file": "chasten/checks.py",
            "line": 87,
            "system-out": [
              "            return True"
            ]
          },
          {
            "name": "Mutant #647",
            "file": "chasten/checks.py",
            "line": 89,
            "system-out": [
              "    if max_value is not None:"
            ]
          },
          {
            "name": "Mutant #648",
            "file": "chasten/checks.py",
            "line": 90,
            "system-out": [
              "        if count <= max_value:"
            ]
          },
          {
            "name": "Mutant #649",
            "file": "chasten/checks.py",
            "line": 94,
            "system-out": [
              "    return False"
            ]
          },
          {
            "name": "Mutant #650",
            "file": "chasten/checks.py",
            "line": 100,
            "system-out": [
              "        return f\":smiley: Did the check pass? {util.get_human_readable_boolean(check_status)}\""
            ]
          },
          {
            "name": "Mutant #651",
            "file": "chasten/checks.py",
            "line": 102,
            "system-out": [
              "        f\":worried: Did the check pass? {util.get_human_readable_boolean(check_status)}\""
            ]
          },
          {
            "name": "Mutant #652",
            "file": "chasten/checks.py",
            "line": 111,
            "system-out": [
              "    new_criterion: Union[str, int] = \"\""
            ]
          },
          {
            "name": "Mutant #653",
            "file": "chasten/checks.py",
            "line": 111,
            "system-out": [
              "    new_criterion: Union[str, int] = \"\""
            ]
          },
          {
            "name": "Mutant #654",
            "file": "chasten/checks.py",
            "line": 114,
            "system-out": [
              "    if criterion is not None:"
            ]
          },
          {
            "name": "Mutant #655",
            "file": "chasten/checks.py",
            "line": 116,
            "system-out": [
              "        if type(criterion) is enumerations.FilterableAttribute:"
            ]
          },
          {
            "name": "Mutant #656",
            "file": "chasten/configuration.py",
            "line": 245,
            "system-out": [
              "            + constants.markers.Newline"
            ]
          },
          {
            "name": "Mutant #657",
            "file": "chasten/configuration.py",
            "line": 267,
            "system-out": [
              "            return (False, {})"
            ]
          },
          {
            "name": "Mutant #658",
            "file": "chasten/configuration.py",
            "line": 322,
            "system-out": [
              "            return (False, {})"
            ]
          },
          {
            "name": "Mutant #659",
            "file": "chasten/configuration.py",
            "line": 412,
            "system-out": [
              "        return (False, None, None)  # type: ignore"
            ]
          },
          {
            "name": "Mutant #660",
            "file": "chasten/database.py",
            "line": 58,
            "system-out": [
              "    database[\"main\"].enable_fts("
            ]
          },
          {
            "name": "Mutant #661",
            "file": "chasten/database.py",
            "line": 60,
            "system-out": [
              "            \"configuration_chastenversion\","
            ]
          },
          {
            "name": "Mutant #662",
            "file": "chasten/database.py",
            "line": 61,
            "system-out": [
              "            \"configuration_projectname\","
            ]
          },
          {
            "name": "Mutant #663",
            "file": "chasten/database.py",
            "line": 62,
            "system-out": [
              "            \"configuration_datetime\","
            ]
          },
          {
            "name": "Mutant #664",
            "file": "chasten/database.py",
            "line": 66,
            "system-out": [
              "    database[\"sources\"].enable_fts("
            ]
          },
          {
            "name": "Mutant #665",
            "file": "chasten/database.py",
            "line": 68,
            "system-out": [
              "            \"filename\","
            ]
          },
          {
            "name": "Mutant #666",
            "file": "chasten/database.py",
            "line": 69,
            "system-out": [
              "            \"check_id\","
            ]
          },
          {
            "name": "Mutant #667",
            "file": "chasten/database.py",
            "line": 70,
            "system-out": [
              "            \"check_name\","
            ]
          },
          {
            "name": "Mutant #668",
            "file": "chasten/database.py",
            "line": 71,
            "system-out": [
              "            \"check_description\","
            ]
          },
          {
            "name": "Mutant #669",
            "file": "chasten/database.py",
            "line": 72,
            "system-out": [
              "            \"check_pattern\","
            ]
          },
          {
            "name": "Mutant #670",
            "file": "chasten/database.py",
            "line": 76,
            "system-out": [
              "    database[\"sources_check_matches\"].enable_fts("
            ]
          },
          {
            "name": "Mutant #671",
            "file": "chasten/database.py",
            "line": 78,
            "system-out": [
              "            \"lineno\","
            ]
          },
          {
            "name": "Mutant #672",
            "file": "chasten/database.py",
            "line": 79,
            "system-out": [
              "            \"coloffset\","
            ]
          },
          {
            "name": "Mutant #673",
            "file": "chasten/database.py",
            "line": 80,
            "system-out": [
              "            \"linematch\","
            ]
          },
          {
            "name": "Mutant #674",
            "file": "chasten/database.py",
            "line": 94,
            "system-out": [
              "            f\":sparkles: Debugging output from publishing datasette to '{datasette_platform}':\""
            ]
          },
          {
            "name": "Mutant #675",
            "file": "chasten/database.py",
            "line": 99,
            "system-out": [
              "            \":sparkles: Debugging output from the local datasette server:\""
            ]
          },
          {
            "name": "Mutant #676",
            "file": "chasten/database.py",
            "line": 118,
            "system-out": [
              "        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\""
            ]
          },
          {
            "name": "Mutant #677",
            "file": "chasten/database.py",
            "line": 118,
            "system-out": [
              "        f\"{constants.markers.Indent}{small_bullet_unicode} Venv: '{output.shorten_file_name(str(virtual_env_location), 120)}'\""
            ]
          },
          {
            "name": "Mutant #678",
            "file": "chasten/database.py",
            "line": 122,
            "system-out": [
              "            f\"{constants.markers.Indent}{small_bullet_unicode} Program: '{output.shorten_file_name(executable_path, 120)}'\""
            ]
          },
          {
            "name": "Mutant #679",
            "file": "chasten/database.py",
            "line": 122,
            "system-out": [
              "            f\"{constants.markers.Indent}{small_bullet_unicode} Program: '{output.shorten_file_name(executable_path, 120)}'\""
            ]
          },
          {
            "name": "Mutant #680",
            "file": "chasten/database.py",
            "line": 126,
            "system-out": [
              "            f\"{constants.markers.Indent}{small_bullet_unicode} Cannot find: '{output.shorten_file_name(full_executable_name, 120)}'\""
            ]
          },
          {
            "name": "Mutant #681",
            "file": "chasten/database.py",
            "line": 126,
            "system-out": [
              "            f\"{constants.markers.Indent}{small_bullet_unicode} Cannot find: '{output.shorten_file_name(full_executable_name, 120)}'\""
            ]
          },
          {
            "name": "Mutant #682",
            "file": "chasten/database.py",
            "line": 135,
            "system-out": [
              "    datasette_port: int = 8001,"
            ]
          },
          {
            "name": "Mutant #683",
            "file": "chasten/database.py",
            "line": 136,
            "system-out": [
              "    publish: bool = False,"
            ]
          },
          {
            "name": "Mutant #684",
            "file": "chasten/database.py",
            "line": 137,
            "system-out": [
              "    OpSystem: str = \"Linux\","
            ]
          },
          {
            "name": "Mutant #685",
            "file": "chasten/database.py",
            "line": 161,
            "system-out": [
              "        label = \":sparkles: Details for datasette publishing:\""
            ]
          },
          {
            "name": "Mutant #686",
            "file": "chasten/database.py",
            "line": 163,
            "system-out": [
              "        label = \":sparkles: Details for datasette startup:\""
            ]
          },
          {
            "name": "Mutant #687",
            "file": "chasten/database.py",
            "line": 172,
            "system-out": [
              "    if not found_executable:"
            ]
          },
          {
            "name": "Mutant #688",
            "file": "chasten/database.py",
            "line": 174,
            "system-out": [
              "            f\":person_shrugging: Was not able to find {constants.datasette.Datasette_Executable}\""
            ]
          },
          {
            "name": "Mutant #689",
            "file": "chasten/database.py",
            "line": 179,
            "system-out": [
              "    if not publish:"
            ]
          },
          {
            "name": "Mutant #690",
            "file": "chasten/database.py",
            "line": 182,
            "system-out": [
              "        if metadata is not None:"
            ]
          },
          {
            "name": "Mutant #691",
            "file": "chasten/database.py",
            "line": 186,
            "system-out": [
              "                \"-m\","
            ]
          },
          {
            "name": "Mutant #692",
            "file": "chasten/database.py",
            "line": 188,
            "system-out": [
              "                \"-p\","
            ]
          },
          {
            "name": "Mutant #693",
            "file": "chasten/database.py",
            "line": 214,
            "system-out": [
              "        if not found_publish_platform_executable:"
            ]
          },
          {
            "name": "Mutant #694",
            "file": "chasten/database.py",
            "line": 216,
            "system-out": [
              "                f\":person_shrugging: Was not able to find '{datasette_platform}'\""
            ]
          },
          {
            "name": "Mutant #695",
            "file": "chasten/database.py",
            "line": 223,
            "system-out": [
              "                f\":sparkles: Using '{publish_platform_executable}' to publish a datasette\""
            ]
          },
          {
            "name": "Mutant #696",
            "file": "chasten/database.py",
            "line": 230,
            "system-out": [
              "        running_argument = \"\""
            ]
          },
          {
            "name": "Mutant #697",
            "file": "chasten/database.py",
            "line": 231,
            "system-out": [
              "        if datasette_platform == constants.chasten.Executable_Fly:"
            ]
          },
          {
            "name": "Mutant #698",
            "file": "chasten/database.py",
            "line": 232,
            "system-out": [
              "            running_argument = \"--app=chasten\""
            ]
          },
          {
            "name": "Mutant #699",
            "file": "chasten/database.py",
            "line": 233,
            "system-out": [
              "        elif datasette_platform == constants.chasten.Executable_Vercel:"
            ]
          },
          {
            "name": "Mutant #700",
            "file": "chasten/database.py",
            "line": 234,
            "system-out": [
              "            running_argument = \"--project=chasten\""
            ]
          },
          {
            "name": "Mutant #701",
            "file": "chasten/database.py",
            "line": 241,
            "system-out": [
              "                \"publish\","
            ]
          },
          {
            "name": "Mutant #702",
            "file": "chasten/database.py",
            "line": 273,
            "system-out": [
              "        \"frogmouth\","
            ]
          },
          {
            "name": "Mutant #703",
            "file": "chasten/database.py",
            "line": 276,
            "system-out": [
              "    executable = util.executable_name(\"frogmouth\", OpSystem)"
            ]
          },
          {
            "name": "Mutant #704",
            "file": "chasten/database.py",
            "line": 280,
            "system-out": [
              "        output.console.print(\"\\n\ud83d\udc38 Frogmouth Information\\n\")"
            ]
          },
          {
            "name": "Mutant #705",
            "file": "chasten/database.py",
            "line": 281,
            "system-out": [
              "        output.console.print(f\" {small_bullet_unicode} Venv: {sys.prefix}\")"
            ]
          },
          {
            "name": "Mutant #706",
            "file": "chasten/database.py",
            "line": 282,
            "system-out": [
              "        output.console.print(f\" {small_bullet_unicode} Program: {executable_path}\")"
            ]
          },
          {
            "name": "Mutant #707",
            "file": "chasten/database.py",
            "line": 287,
            "system-out": [
              "            \":person_shrugging: Was not able to find frogmouth executable try installing it separately\""
            ]
          },
          {
            "name": "Mutant #708",
            "file": "chasten/filesystem.py",
            "line": 64,
            "system-out": [
              "    \"config.yml\": CONFIGURATION_FILE_DEFAULT_CONTENTS,"
            ]
          },
          {
            "name": "Mutant #709",
            "file": "chasten/filesystem.py",
            "line": 65,
            "system-out": [
              "    \"checks.yml\": CHECKS_FILE_DEFAULT_CONTENTS,"
            ]
          },
          {
            "name": "Mutant #710",
            "file": "chasten/filesystem.py",
            "line": 73,
            "system-out": [
              "    if config is not None:"
            ]
          },
          {
            "name": "Mutant #711",
            "file": "chasten/filesystem.py",
            "line": 90,
            "system-out": [
              "    config: Optional[Path] = None, force: bool = False"
            ]
          },
          {
            "name": "Mutant #712",
            "file": "chasten/filesystem.py",
            "line": 104,
            "system-out": [
              "    chasten_user_config_dir_path.mkdir(parents=True)"
            ]
          },
          {
            "name": "Mutant #713",
            "file": "chasten/filesystem.py",
            "line": 117,
            "system-out": [
              "    chasten_user_config_main_file = chasten_user_config_dir_path / Path("
            ]
          },
          {
            "name": "Mutant #714",
            "file": "chasten/filesystem.py",
            "line": 131,
            "system-out": [
              "    if tree is None:"
            ]
          },
          {
            "name": "Mutant #715",
            "file": "chasten/filesystem.py",
            "line": 132,
            "system-out": [
              "        tree = Tree(f\":open_file_folder: {path.name}\")"
            ]
          },
          {
            "name": "Mutant #716",
            "file": "chasten/filesystem.py",
            "line": 136,
            "system-out": [
              "        tree = tree.add(f\":open_file_folder: {path.name}\")"
            ]
          },
          {
            "name": "Mutant #717",
            "file": "chasten/filesystem.py",
            "line": 143,
            "system-out": [
              "                tree.add(f\":page_facing_up: {item.name}\")"
            ]
          },
          {
            "name": "Mutant #718",
            "file": "chasten/filesystem.py",
            "line": 151,
            "system-out": [
              "    if file is not None:"
            ]
          },
          {
            "name": "Mutant #719",
            "file": "chasten/filesystem.py",
            "line": 153,
            "system-out": [
              "        if file.is_file() and file.exists():"
            ]
          },
          {
            "name": "Mutant #720",
            "file": "chasten/filesystem.py",
            "line": 154,
            "system-out": [
              "            return True"
            ]
          },
          {
            "name": "Mutant #721",
            "file": "chasten/filesystem.py",
            "line": 156,
            "system-out": [
              "    return False"
            ]
          },
          {
            "name": "Mutant #722",
            "file": "chasten/filesystem.py",
            "line": 162,
            "system-out": [
              "    if directory is not None:"
            ]
          },
          {
            "name": "Mutant #723",
            "file": "chasten/filesystem.py",
            "line": 164,
            "system-out": [
              "        if directory.is_dir() and directory.exists():"
            ]
          },
          {
            "name": "Mutant #724",
            "file": "chasten/filesystem.py",
            "line": 180,
            "system-out": [
              "    save: bool = False,"
            ]
          },
          {
            "name": "Mutant #725",
            "file": "chasten/filesystem.py",
            "line": 194,
            "system-out": [
              "        complete_results_file_name = f\"{constants.filesystem.Main_Results_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\""
            ]
          },
          {
            "name": "Mutant #726",
            "file": "chasten/filesystem.py",
            "line": 197,
            "system-out": [
              "        results_path_with_file = results_path / complete_results_file_name"
            ]
          },
          {
            "name": "Mutant #727",
            "file": "chasten/filesystem.py",
            "line": 198,
            "system-out": [
              "        results_json = results_content.model_dump_json(indent=2)"
            ]
          },
          {
            "name": "Mutant #728",
            "file": "chasten/filesystem.py",
            "line": 203,
            "system-out": [
              "            results_path_with_file.write_text(results_json, \"utf-8\")"
            ]
          },
          {
            "name": "Mutant #729",
            "file": "chasten/filesystem.py",
            "line": 222,
            "system-out": [
              "    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            ]
          },
          {
            "name": "Mutant #730",
            "file": "chasten/filesystem.py",
            "line": 229,
            "system-out": [
              "    complete_results_file_name = f\"{constants.filesystem.Main_Results_Combined_File_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}.{constants.filesystem.Results_Extension}\""
            ]
          },
          {
            "name": "Mutant #731",
            "file": "chasten/filesystem.py",
            "line": 232,
            "system-out": [
              "    results_path_with_file = results_path / complete_results_file_name"
            ]
          },
          {
            "name": "Mutant #732",
            "file": "chasten/filesystem.py",
            "line": 234,
            "system-out": [
              "    results_path_with_file.write_text(results_json, \"utf-8\")"
            ]
          },
          {
            "name": "Mutant #733",
            "file": "chasten/filesystem.py",
            "line": 252,
            "system-out": [
              "    combined_results_json_file = results_path / Path(combined_results_json)"
            ]
          },
          {
            "name": "Mutant #734",
            "file": "chasten/filesystem.py",
            "line": 259,
            "system-out": [
              "    complete_flattened_results_directory_name = f\"{constants.filesystem.Main_Results_Flattened_Directory_Name}-{projectname}-{formatted_datetime}-{results_file_uuid}\""
            ]
          },
          {
            "name": "Mutant #735",
            "file": "chasten/filesystem.py",
            "line": 262,
            "system-out": [
              "        results_path / complete_flattened_results_directory_name"
            ]
          },
          {
            "name": "Mutant #736",
            "file": "chasten/filesystem.py",
            "line": 269,
            "system-out": [
              "        flattened_output_directory / constants.datasette.Chasten_Database"
            ]
          },
          {
            "name": "Mutant #737",
            "file": "chasten/filesystem.py",
            "line": 279,
            "system-out": [
              "        csv=True,"
            ]
          },
          {
            "name": "Mutant #738",
            "file": "chasten/filesystem.py",
            "line": 280,
            "system-out": [
              "        sqlite=True,"
            ]
          },
          {
            "name": "Mutant #739",
            "file": "chasten/filesystem.py",
            "line": 294,
            "system-out": [
              "    json_dicts_list: List[Dict[Any, Any]] = []"
            ]
          },
          {
            "name": "Mutant #740",
            "file": "chasten/filesystem.py",
            "line": 298,
            "system-out": [
              "        json_dict = json.loads(json_path.read_text(\"utf-8\"))"
            ]
          },
          {
            "name": "Mutant #741",
            "file": "chasten/filesystem.py",
            "line": 311,
            "system-out": [
              "    if executable_path is not None:"
            ]
          },
          {
            "name": "Mutant #742",
            "file": "chasten/filesystem.py",
            "line": 312,
            "system-out": [
              "        return (True, executable_path)"
            ]
          },
          {
            "name": "Mutant #743",
            "file": "chasten/filesystem.py",
            "line": 315,
            "system-out": [
              "    return (False, constants.markers.Nothing)"
            ]
          },
          {
            "name": "Mutant #744",
            "file": "chasten/checks.py",
            "line": 78,
            "system-out": [
              "    if min_value is None and max_value is None:"
            ]
          },
          {
            "name": "Mutant #745",
            "file": "chasten/checks.py",
            "line": 78,
            "system-out": [
              "    if min_value is None and max_value is None:"
            ]
          },
          {
            "name": "Mutant #746",
            "file": "chasten/checks.py",
            "line": 78,
            "system-out": [
              "    if min_value is None and max_value is None:"
            ]
          },
          {
            "name": "Mutant #747",
            "file": "chasten/createchecks.py",
            "line": 56,
            "system-out": [
              "API_KEY_FILE = \"userapikey.txt\""
            ]
          },
          {
            "name": "Mutant #748",
            "file": "chasten/createchecks.py",
            "line": 63,
            "system-out": [
              "    with open(API_KEY_FILE, \"w\") as f:"
            ]
          },
          {
            "name": "Mutant #749",
            "file": "chasten/createchecks.py",
            "line": 64,
            "system-out": [
              "        f.write(key.decode() + \"\\n\" + encrypted_key)"
            ]
          },
          {
            "name": "Mutant #750",
            "file": "chasten/createchecks.py",
            "line": 64,
            "system-out": [
              "        f.write(key.decode() + \"\\n\" + encrypted_key)"
            ]
          },
          {
            "name": "Mutant #751",
            "file": "chasten/createchecks.py",
            "line": 64,
            "system-out": [
              "        f.write(key.decode() + \"\\n\" + encrypted_key)"
            ]
          },
          {
            "name": "Mutant #752",
            "file": "chasten/createchecks.py",
            "line": 68,
            "system-out": [
              "    with open(file, \"r\") as f:"
            ]
          },
          {
            "name": "Mutant #753",
            "file": "chasten/createchecks.py",
            "line": 69,
            "system-out": [
              "        lines = f.read().strip().split(\"\\n\")"
            ]
          },
          {
            "name": "Mutant #754",
            "file": "chasten/createchecks.py",
            "line": 70,
            "system-out": [
              "        if len(lines) == 2:  # noqa: PLR2004"
            ]
          },
          {
            "name": "Mutant #755",
            "file": "chasten/createchecks.py",
            "line": 70,
            "system-out": [
              "        if len(lines) == 2:  # noqa: PLR2004"
            ]
          },
          {
            "name": "Mutant #756",
            "file": "chasten/createchecks.py",
            "line": 71,
            "system-out": [
              "            key = lines[0].encode()"
            ]
          },
          {
            "name": "Mutant #757",
            "file": "chasten/createchecks.py",
            "line": 72,
            "system-out": [
              "            encrypted_key = lines[1]"
            ]
          },
          {
            "name": "Mutant #758",
            "file": "chasten/createchecks.py",
            "line": 81,
            "system-out": [
              "            model=\"gpt-3.5-turbo\","
            ]
          },
          {
            "name": "Mutant #759",
            "file": "chasten/createchecks.py",
            "line": 82,
            "system-out": [
              "            messages=[{\"role\": \"system\", \"content\": \"Test message\"}],"
            ]
          },
          {
            "name": "Mutant #760",
            "file": "chasten/createchecks.py",
            "line": 82,
            "system-out": [
              "            messages=[{\"role\": \"system\", \"content\": \"Test message\"}],"
            ]
          },
          {
            "name": "Mutant #761",
            "file": "chasten/createchecks.py",
            "line": 82,
            "system-out": [
              "            messages=[{\"role\": \"system\", \"content\": \"Test message\"}],"
            ]
          },
          {
            "name": "Mutant #762",
            "file": "chasten/createchecks.py",
            "line": 82,
            "system-out": [
              "            messages=[{\"role\": \"system\", \"content\": \"Test message\"}],"
            ]
          },
          {
            "name": "Mutant #763",
            "file": "chasten/createchecks.py",
            "line": 84,
            "system-out": [
              "        return True"
            ]
          },
          {
            "name": "Mutant #764",
            "file": "chasten/createchecks.py",
            "line": 86,
            "system-out": [
              "        return False"
            ]
          },
          {
            "name": "Mutant #765",
            "file": "chasten/createchecks.py",
            "line": 95,
            "system-out": [
              "            + \"in the same format as what is shown above(do not just generate the example use it as a framework nothing else): \""
            ]
          },
          {
            "name": "Mutant #766",
            "file": "chasten/createchecks.py",
            "line": 95,
            "system-out": [
              "            + \"in the same format as what is shown above(do not just generate the example use it as a framework nothing else): \""
            ]
          },
          {
            "name": "Mutant #767",
            "file": "chasten/createchecks.py",
            "line": 96,
            "system-out": [
              "            + user_input"
            ]
          },
          {
            "name": "Mutant #768",
            "file": "chasten/createchecks.py",
            "line": 103,
            "system-out": [
              "                    \"role\": \"system\","
            ]
          },
          {
            "name": "Mutant #769",
            "file": "chasten/createchecks.py",
            "line": 103,
            "system-out": [
              "                    \"role\": \"system\","
            ]
          },
          {
            "name": "Mutant #770",
            "file": "chasten/createchecks.py",
            "line": 104,
            "system-out": [
              "                    \"content\": f\"You are a helpful assistant that generates YAML configurations. Your task is to {prompts}\","
            ]
          },
          {
            "name": "Mutant #771",
            "file": "chasten/createchecks.py",
            "line": 104,
            "system-out": [
              "                    \"content\": f\"You are a helpful assistant that generates YAML configurations. Your task is to {prompts}\","
            ]
          },
          {
            "name": "Mutant #772",
            "file": "chasten/createchecks.py",
            "line": 109,
            "system-out": [
              "        generated_yaml = response.choices[0].message[\"content\"].strip()"
            ]
          },
          {
            "name": "Mutant #773",
            "file": "chasten/createchecks.py",
            "line": 109,
            "system-out": [
              "        generated_yaml = response.choices[0].message[\"content\"].strip()"
            ]
          },
          {
            "name": "Mutant #774",
            "file": "chasten/createchecks.py",
            "line": 112,
            "system-out": [
              "        with open(file, \"w\") as f:"
            ]
          },
          {
            "name": "Mutant #775",
            "file": "chasten/createchecks.py",
            "line": 118,
            "system-out": [
              "        return \"[red][Error][/red] There was an issue with the API key. Make sure you input your API key correctly.\""
            ]
          },
          {
            "name": "Mutant #776",
            "file": "chasten/checks.py",
            "line": 91,
            "system-out": [
              "            return True"
            ]
          },
          {
            "name": "Mutant #777",
            "file": "chasten/enumerations.py",
            "line": 9,
            "system-out": [
              "    CREATE = \"create\""
            ]
          },
          {
            "name": "Mutant #778",
            "file": "chasten/enumerations.py",
            "line": 10,
            "system-out": [
              "    VALIDATE = \"validate\""
            ]
          },
          {
            "name": "Mutant #779",
            "file": "chasten/enumerations.py",
            "line": 16,
            "system-out": [
              "    FLY = \"fly\""
            ]
          },
          {
            "name": "Mutant #780",
            "file": "chasten/enumerations.py",
            "line": 17,
            "system-out": [
              "    VERCEL = \"vercel\""
            ]
          },
          {
            "name": "Mutant #781",
            "file": "chasten/enumerations.py",
            "line": 23,
            "system-out": [
              "    CODE = \"code\""
            ]
          },
          {
            "name": "Mutant #782",
            "file": "chasten/enumerations.py",
            "line": 24,
            "system-out": [
              "    ID = \"id\""
            ]
          },
          {
            "name": "Mutant #783",
            "file": "chasten/enumerations.py",
            "line": 25,
            "system-out": [
              "    NONE = \"\""
            ]
          },
          {
            "name": "Mutant #784",
            "file": "chasten/enumerations.py",
            "line": 26,
            "system-out": [
              "    NAME = \"name\""
            ]
          },
          {
            "name": "Mutant #785",
            "file": "chasten/enumerations.py",
            "line": 27,
            "system-out": [
              "    PATTERN = \"pattern\""
            ]
          },
          {
            "name": "Mutant #786",
            "file": "chasten/constants.py",
            "line": 8,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #787",
            "file": "chasten/constants.py",
            "line": 8,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -3,9 +3,6 @@\n from dataclasses import dataclass\n from pathlib import Path\n \n-\n-# chasten constant\n-@dataclass(frozen=True)\n class Chasten:\n     \"\"\"Define the Chasten dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #788",
            "file": "chasten/constants.py",
            "line": 33,
            "system-out": [
              "    Analyze_Storage=Path(\"analysis.md\"),"
            ]
          },
          {
            "name": "Mutant #789",
            "file": "chasten/constants.py",
            "line": 34,
            "system-out": [
              "    Application_Name=\"chasten\","
            ]
          },
          {
            "name": "Mutant #790",
            "file": "chasten/constants.py",
            "line": 35,
            "system-out": [
              "    Application_Author=\"ChastenedTeam\","
            ]
          },
          {
            "name": "Mutant #791",
            "file": "chasten/constants.py",
            "line": 36,
            "system-out": [
              "    App_Storage=Path(\"check.txt\"),"
            ]
          },
          {
            "name": "Mutant #792",
            "file": "chasten/constants.py",
            "line": 37,
            "system-out": [
              "    API_Key_Storage=Path(\"userapikey.txt\"),"
            ]
          },
          {
            "name": "Mutant #793",
            "file": "chasten/constants.py",
            "line": 38,
            "system-out": [
              "    Chasten_Database_View=\"chasten_complete\","
            ]
          },
          {
            "name": "Mutant #794",
            "file": "chasten/constants.py",
            "line": 39,
            "system-out": [
              "    Emoji=\":dizzy:\","
            ]
          },
          {
            "name": "Mutant #795",
            "file": "chasten/constants.py",
            "line": 40,
            "system-out": [
              "    Executable_Fly=\"fly\","
            ]
          },
          {
            "name": "Mutant #796",
            "file": "chasten/constants.py",
            "line": 41,
            "system-out": [
              "    Executable_Vercel=\"vercel\","
            ]
          },
          {
            "name": "Mutant #797",
            "file": "chasten/constants.py",
            "line": 42,
            "system-out": [
              "    Https=\"https://\","
            ]
          },
          {
            "name": "Mutant #798",
            "file": "chasten/constants.py",
            "line": 43,
            "system-out": [
              "    Name=\"chasten\","
            ]
          },
          {
            "name": "Mutant #799",
            "file": "chasten/constants.py",
            "line": 44,
            "system-out": [
              "    Programming_Language=\"python\","
            ]
          },
          {
            "name": "Mutant #800",
            "file": "chasten/constants.py",
            "line": 45,
            "system-out": [
              "    Separator=\"/\","
            ]
          },
          {
            "name": "Mutant #801",
            "file": "chasten/constants.py",
            "line": 46,
            "system-out": [
              "    Server_Shutdown=\":person_shrugging: Shut down chasten's sylog server\","
            ]
          },
          {
            "name": "Mutant #802",
            "file": "chasten/constants.py",
            "line": 47,
            "system-out": [
              "    Tagline=\"chasten: Analyze the AST of Python Source Code\","
            ]
          },
          {
            "name": "Mutant #803",
            "file": "chasten/constants.py",
            "line": 48,
            "system-out": [
              "    Theme_Background=\"default\","
            ]
          },
          {
            "name": "Mutant #804",
            "file": "chasten/constants.py",
            "line": 49,
            "system-out": [
              "    Theme_Colors=\"ansi_dark\","
            ]
          },
          {
            "name": "Mutant #805",
            "file": "chasten/constants.py",
            "line": 50,
            "system-out": [
              "    Website=\":link: GitHub: https://github.com/gkapfham/chasten\","
            ]
          },
          {
            "name": "Mutant #806",
            "file": "chasten/constants.py",
            "line": 73,
            "system-out": [
              "    Check_Chasten=\"chasten\","
            ]
          },
          {
            "name": "Mutant #807",
            "file": "chasten/constants.py",
            "line": 74,
            "system-out": [
              "    Check_Code=\"code\","
            ]
          },
          {
            "name": "Mutant #808",
            "file": "chasten/constants.py",
            "line": 75,
            "system-out": [
              "    Check_Count=\"count\","
            ]
          },
          {
            "name": "Mutant #809",
            "file": "chasten/constants.py",
            "line": 76,
            "system-out": [
              "    Check_Confidence=80,"
            ]
          },
          {
            "name": "Mutant #810",
            "file": "chasten/constants.py",
            "line": 77,
            "system-out": [
              "    Check_File=\"checks-file\","
            ]
          },
          {
            "name": "Mutant #811",
            "file": "chasten/constants.py",
            "line": 78,
            "system-out": [
              "    Check_Id=\"id\","
            ]
          },
          {
            "name": "Mutant #812",
            "file": "chasten/constants.py",
            "line": 79,
            "system-out": [
              "    Checks_Label=\"checks\","
            ]
          },
          {
            "name": "Mutant #813",
            "file": "chasten/constants.py",
            "line": 80,
            "system-out": [
              "    Check_Max=\"max\","
            ]
          },
          {
            "name": "Mutant #814",
            "file": "chasten/constants.py",
            "line": 81,
            "system-out": [
              "    Check_Min=\"min\","
            ]
          },
          {
            "name": "Mutant #815",
            "file": "chasten/constants.py",
            "line": 82,
            "system-out": [
              "    Check_Name=\"name\","
            ]
          },
          {
            "name": "Mutant #816",
            "file": "chasten/constants.py",
            "line": 83,
            "system-out": [
              "    Check_Pattern=\"pattern\","
            ]
          },
          {
            "name": "Mutant #817",
            "file": "chasten/constants.py",
            "line": 100,
            "system-out": [
              "    Chasten_Database=\"chasten.db\","
            ]
          },
          {
            "name": "Mutant #818",
            "file": "chasten/constants.py",
            "line": 101,
            "system-out": [
              "    Datasette_Executable=\"datasette\","
            ]
          },
          {
            "name": "Mutant #819",
            "file": "chasten/constants.py",
            "line": 102,
            "system-out": [
              "    Datasette_Copyable_Install=\"--install=datasette-copyable\","
            ]
          },
          {
            "name": "Mutant #820",
            "file": "chasten/constants.py",
            "line": 103,
            "system-out": [
              "    Datasette_Export_Notebook=\"--install=datasette-export-notebook\","
            ]
          },
          {
            "name": "Mutant #821",
            "file": "chasten/constants.py",
            "line": 104,
            "system-out": [
              "    Datasette_Search_All=\"--install=datasette-search-all\","
            ]
          },
          {
            "name": "Mutant #822",
            "file": "chasten/constants.py",
            "line": 125,
            "system-out": [
              "    Current_Directory=\".\","
            ]
          },
          {
            "name": "Mutant #823",
            "file": "chasten/constants.py",
            "line": 126,
            "system-out": [
              "    Dash=\"-\","
            ]
          },
          {
            "name": "Mutant #824",
            "file": "chasten/constants.py",
            "line": 127,
            "system-out": [
              "    Dot=\".\","
            ]
          },
          {
            "name": "Mutant #825",
            "file": "chasten/constants.py",
            "line": 128,
            "system-out": [
              "    Main_Configuration_File=\"config.yml\","
            ]
          },
          {
            "name": "Mutant #826",
            "file": "chasten/constants.py",
            "line": 129,
            "system-out": [
              "    Main_Checks_File=\"checks.yml\","
            ]
          },
          {
            "name": "Mutant #827",
            "file": "chasten/constants.py",
            "line": 130,
            "system-out": [
              "    Main_Results_File_Name=\"chasten-results\","
            ]
          },
          {
            "name": "Mutant #828",
            "file": "chasten/constants.py",
            "line": 131,
            "system-out": [
              "    Main_Results_Combined_File_Name=\"chasten-integrated-results\","
            ]
          },
          {
            "name": "Mutant #829",
            "file": "chasten/constants.py",
            "line": 132,
            "system-out": [
              "    Main_Results_Flattened_Directory_Name=\"chasten-flattened-csvs-sqlite-db\","
            ]
          },
          {
            "name": "Mutant #830",
            "file": "chasten/constants.py",
            "line": 133,
            "system-out": [
              "    Results_Extension=\"json\","
            ]
          },
          {
            "name": "Mutant #831",
            "file": "chasten/constants.py",
            "line": 146,
            "system-out": [
              "humanreadable = Humanreadable(Yes=\"Yes\", No=\"No\")"
            ]
          },
          {
            "name": "Mutant #832",
            "file": "chasten/constants.py",
            "line": 146,
            "system-out": [
              "humanreadable = Humanreadable(Yes=\"Yes\", No=\"No\")"
            ]
          },
          {
            "name": "Mutant #833",
            "file": "chasten/constants.py",
            "line": 160,
            "system-out": [
              "    Function_Prefix=\"configure_logging_\","
            ]
          },
          {
            "name": "Mutant #834",
            "file": "chasten/constants.py",
            "line": 161,
            "system-out": [
              "    Richlog=\"chasten-richlog\","
            ]
          },
          {
            "name": "Mutant #835",
            "file": "chasten/constants.py",
            "line": 162,
            "system-out": [
              "    Syslog=\"chasten-syslog\","
            ]
          },
          {
            "name": "Mutant #836",
            "file": "chasten/constants.py",
            "line": 185,
            "system-out": [
              "    Debug=\"DEBUG\","
            ]
          },
          {
            "name": "Mutant #837",
            "file": "chasten/constants.py",
            "line": 186,
            "system-out": [
              "    Info=\"INFO\","
            ]
          },
          {
            "name": "Mutant #838",
            "file": "chasten/constants.py",
            "line": 187,
            "system-out": [
              "    Warning=\"WARNING\","
            ]
          },
          {
            "name": "Mutant #839",
            "file": "chasten/constants.py",
            "line": 188,
            "system-out": [
              "    Error=\"ERROR\","
            ]
          },
          {
            "name": "Mutant #840",
            "file": "chasten/constants.py",
            "line": 189,
            "system-out": [
              "    Critical=\"CRITICAL\","
            ]
          },
          {
            "name": "Mutant #841",
            "file": "chasten/constants.py",
            "line": 190,
            "system-out": [
              "    Console_Logging_Destination=\"CONSOLE\","
            ]
          },
          {
            "name": "Mutant #842",
            "file": "chasten/constants.py",
            "line": 191,
            "system-out": [
              "    Syslog_Logging_Destination=\"syslog\","
            ]
          },
          {
            "name": "Mutant #843",
            "file": "chasten/constants.py",
            "line": 192,
            "system-out": [
              "    Default_Logging_Destination=\"console\","
            ]
          },
          {
            "name": "Mutant #844",
            "file": "chasten/constants.py",
            "line": 193,
            "system-out": [
              "    Default_Logging_Level=\"ERROR\","
            ]
          },
          {
            "name": "Mutant #845",
            "file": "chasten/constants.py",
            "line": 194,
            "system-out": [
              "    Format=\"%(message)s\","
            ]
          },
          {
            "name": "Mutant #846",
            "file": "chasten/constants.py",
            "line": 195,
            "system-out": [
              "    Rich=\"Rich\","
            ]
          },
          {
            "name": "Mutant #847",
            "file": "chasten/constants.py",
            "line": 231,
            "system-out": [
              "    Bad_Fifteen=\"<15>\","
            ]
          },
          {
            "name": "Mutant #848",
            "file": "chasten/constants.py",
            "line": 232,
            "system-out": [
              "    Bad_Zero_Zero=\"\","
            ]
          },
          {
            "name": "Mutant #849",
            "file": "chasten/constants.py",
            "line": 233,
            "system-out": [
              "    Code_Context=5,"
            ]
          },
          {
            "name": "Mutant #850",
            "file": "chasten/constants.py",
            "line": 234,
            "system-out": [
              "    Comma_Space=\", \","
            ]
          },
          {
            "name": "Mutant #851",
            "file": "chasten/constants.py",
            "line": 235,
            "system-out": [
              "    Empty_Bytes=b\"\","
            ]
          },
          {
            "name": "Mutant #852",
            "file": "chasten/constants.py",
            "line": 236,
            "system-out": [
              "    Empty_String=\"\","
            ]
          },
          {
            "name": "Mutant #853",
            "file": "chasten/constants.py",
            "line": 237,
            "system-out": [
              "    Ellipse=\"...\","
            ]
          },
          {
            "name": "Mutant #854",
            "file": "chasten/constants.py",
            "line": 238,
            "system-out": [
              "    Forward_Slash=\"/\","
            ]
          },
          {
            "name": "Mutant #855",
            "file": "chasten/constants.py",
            "line": 240,
            "system-out": [
              "    Hidden=\".\","
            ]
          },
          {
            "name": "Mutant #856",
            "file": "chasten/constants.py",
            "line": 241,
            "system-out": [
              "    Indent=\"   \","
            ]
          },
          {
            "name": "Mutant #857",
            "file": "chasten/constants.py",
            "line": 242,
            "system-out": [
              "    Newline=\"\\n\","
            ]
          },
          {
            "name": "Mutant #858",
            "file": "chasten/constants.py",
            "line": 243,
            "system-out": [
              "    Non_Zero_Exit=1,"
            ]
          },
          {
            "name": "Mutant #859",
            "file": "chasten/constants.py",
            "line": 244,
            "system-out": [
              "    Nothing=\"\","
            ]
          },
          {
            "name": "Mutant #860",
            "file": "chasten/constants.py",
            "line": 245,
            "system-out": [
              "    Single_Quote=\"'\","
            ]
          },
          {
            "name": "Mutant #861",
            "file": "chasten/constants.py",
            "line": 246,
            "system-out": [
              "    Slice_One=1,"
            ]
          },
          {
            "name": "Mutant #862",
            "file": "chasten/constants.py",
            "line": 247,
            "system-out": [
              "    Small_Bullet_Unicode=\"\\u2022\","
            ]
          },
          {
            "name": "Mutant #863",
            "file": "chasten/constants.py",
            "line": 248,
            "system-out": [
              "    Space=\" \","
            ]
          },
          {
            "name": "Mutant #864",
            "file": "chasten/constants.py",
            "line": 249,
            "system-out": [
              "    Tab=\"\\t\","
            ]
          },
          {
            "name": "Mutant #865",
            "file": "chasten/constants.py",
            "line": 250,
            "system-out": [
              "    Underscore=\"_\","
            ]
          },
          {
            "name": "Mutant #866",
            "file": "chasten/constants.py",
            "line": 251,
            "system-out": [
              "    Xml=\"xml\","
            ]
          },
          {
            "name": "Mutant #867",
            "file": "chasten/constants.py",
            "line": 252,
            "system-out": [
              "    Zero=0,"
            ]
          },
          {
            "name": "Mutant #868",
            "file": "chasten/constants.py",
            "line": 253,
            "system-out": [
              "    Zero_Exit=0,"
            ]
          },
          {
            "name": "Mutant #869",
            "file": "chasten/constants.py",
            "line": 254,
            "system-out": [
              "    Percent_Multiplier=100,"
            ]
          },
          {
            "name": "Mutant #870",
            "file": "chasten/constants.py",
            "line": 268,
            "system-out": [
              "    Syslog=\":sparkles: Syslog server for receiving debugging information\","
            ]
          },
          {
            "name": "Mutant #871",
            "file": "chasten/constants.py",
            "line": 269,
            "system-out": [
              "    Test_Start=\":sparkles: Start to run test suite for the specified program\","
            ]
          },
          {
            "name": "Mutant #872",
            "file": "chasten/constants.py",
            "line": 288,
            "system-out": [
              "    Backup_Count=1,"
            ]
          },
          {
            "name": "Mutant #873",
            "file": "chasten/constants.py",
            "line": 289,
            "system-out": [
              "    Localhost=\"127.0.0.1\","
            ]
          },
          {
            "name": "Mutant #874",
            "file": "chasten/constants.py",
            "line": 290,
            "system-out": [
              "    Log_File=\".discover.log\","
            ]
          },
          {
            "name": "Mutant #875",
            "file": "chasten/constants.py",
            "line": 291,
            "system-out": [
              "    Max_Log_Size=1048576,"
            ]
          },
          {
            "name": "Mutant #876",
            "file": "chasten/constants.py",
            "line": 292,
            "system-out": [
              "    Poll_Interval=0.5,"
            ]
          },
          {
            "name": "Mutant #877",
            "file": "chasten/constants.py",
            "line": 293,
            "system-out": [
              "    Port=2525,"
            ]
          },
          {
            "name": "Mutant #878",
            "file": "chasten/constants.py",
            "line": 294,
            "system-out": [
              "    Utf8_Encoding=\"utf-8\","
            ]
          },
          {
            "name": "Mutant #879",
            "file": "chasten/database.py",
            "line": 195,
            "system-out": [
              "                \"-p\","
            ]
          },
          {
            "name": "Mutant #880",
            "file": "chasten/database.py",
            "line": 238,
            "system-out": [
              "        if metadata is not None:"
            ]
          },
          {
            "name": "Mutant #881",
            "file": "chasten/database.py",
            "line": 248,
            "system-out": [
              "                \"-m\","
            ]
          },
          {
            "name": "Mutant #882",
            "file": "chasten/database.py",
            "line": 255,
            "system-out": [
              "                \"publish\","
            ]
          },
          {
            "name": "Mutant #883",
            "file": "chasten/filesystem.py",
            "line": 165,
            "system-out": [
              "            return True"
            ]
          },
          {
            "name": "Mutant #884",
            "file": "chasten/filesystem.py",
            "line": 167,
            "system-out": [
              "    return False"
            ]
          },
          {
            "name": "Mutant #885",
            "file": "chasten/filesystem.py",
            "line": 249,
            "system-out": [
              "    formatted_datetime = str(datetime.now().strftime(\"%Y%m%d%H%M%S\"))"
            ]
          },
          {
            "name": "Mutant #886",
            "file": "chasten/createchecks.py",
            "line": 100,
            "system-out": [
              "            model=\"gpt-3.5-turbo\","
            ]
          },
          {
            "name": "Mutant #887",
            "file": "chasten/validate.py",
            "line": 14,
            "system-out": [
              "    \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #888",
            "file": "chasten/validate.py",
            "line": 14,
            "system-out": [
              "    \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #889",
            "file": "chasten/validate.py",
            "line": 15,
            "system-out": [
              "    \"required\": [],"
            ]
          },
          {
            "name": "Mutant #890",
            "file": "chasten/validate.py",
            "line": 16,
            "system-out": [
              "    \"properties\": {"
            ]
          },
          {
            "name": "Mutant #891",
            "file": "chasten/validate.py",
            "line": 17,
            "system-out": [
              "        \"chasten\": {"
            ]
          },
          {
            "name": "Mutant #892",
            "file": "chasten/validate.py",
            "line": 18,
            "system-out": [
              "            \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #893",
            "file": "chasten/validate.py",
            "line": 18,
            "system-out": [
              "            \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #894",
            "file": "chasten/validate.py",
            "line": 19,
            "system-out": [
              "            \"properties\": {"
            ]
          },
          {
            "name": "Mutant #895",
            "file": "chasten/validate.py",
            "line": 20,
            "system-out": [
              "                \"checks-file\": {"
            ]
          },
          {
            "name": "Mutant #896",
            "file": "chasten/validate.py",
            "line": 21,
            "system-out": [
              "                    \"type\": \"array\","
            ]
          },
          {
            "name": "Mutant #897",
            "file": "chasten/validate.py",
            "line": 21,
            "system-out": [
              "                    \"type\": \"array\","
            ]
          },
          {
            "name": "Mutant #898",
            "file": "chasten/validate.py",
            "line": 22,
            "system-out": [
              "                    \"items\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #899",
            "file": "chasten/validate.py",
            "line": 22,
            "system-out": [
              "                    \"items\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #900",
            "file": "chasten/validate.py",
            "line": 22,
            "system-out": [
              "                    \"items\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #901",
            "file": "chasten/validate.py",
            "line": 23,
            "system-out": [
              "                    \"required\": [],"
            ]
          },
          {
            "name": "Mutant #902",
            "file": "chasten/validate.py",
            "line": 26,
            "system-out": [
              "            \"additionalProperties\": False,"
            ]
          },
          {
            "name": "Mutant #903",
            "file": "chasten/validate.py",
            "line": 26,
            "system-out": [
              "            \"additionalProperties\": False,"
            ]
          },
          {
            "name": "Mutant #904",
            "file": "chasten/validate.py",
            "line": 37,
            "failure": [
              {
                "inner": "--- chasten/validate.py\n+++ chasten/validate.py\n@@ -34,7 +34,7 @@\n JSON_SCHEMA_CHECKS = {\n     \"type\": \"object\",\n     \"properties\": {\n-        \"checks\": {\n+        \"XXchecksXX\": {\n             \"type\": \"array\",\n             \"items\": {\n                 \"type\": \"object\",\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "        \"checks\": {"
            ]
          },
          {
            "name": "Mutant #905",
            "file": "chasten/validate.py",
            "line": 38,
            "system-out": [
              "            \"type\": \"array\","
            ]
          },
          {
            "name": "Mutant #906",
            "file": "chasten/validate.py",
            "line": 38,
            "system-out": [
              "            \"type\": \"array\","
            ]
          },
          {
            "name": "Mutant #907",
            "file": "chasten/validate.py",
            "line": 39,
            "failure": [
              {
                "inner": "--- chasten/validate.py\n+++ chasten/validate.py\n@@ -36,7 +36,7 @@\n     \"properties\": {\n         \"checks\": {\n             \"type\": \"array\",\n-            \"items\": {\n+            \"XXitemsXX\": {\n                 \"type\": \"object\",\n                 \"properties\": {\n                     \"name\": {\"type\": \"string\"},\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "            \"items\": {"
            ]
          },
          {
            "name": "Mutant #908",
            "file": "chasten/validate.py",
            "line": 40,
            "system-out": [
              "                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #909",
            "file": "chasten/validate.py",
            "line": 40,
            "system-out": [
              "                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #910",
            "file": "chasten/validate.py",
            "line": 41,
            "failure": [
              {
                "inner": "--- chasten/validate.py\n+++ chasten/validate.py\n@@ -38,7 +38,7 @@\n             \"type\": \"array\",\n             \"items\": {\n                 \"type\": \"object\",\n-                \"properties\": {\n+                \"XXpropertiesXX\": {\n                     \"name\": {\"type\": \"string\"},\n                     \"id\": {\"type\": \"string\"},\n                     \"description\": {\"type\": \"string\"},\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "                \"properties\": {"
            ]
          },
          {
            "name": "Mutant #911",
            "file": "chasten/validate.py",
            "line": 42,
            "system-out": [
              "                    \"name\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #912",
            "file": "chasten/validate.py",
            "line": 42,
            "system-out": [
              "                    \"name\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #913",
            "file": "chasten/validate.py",
            "line": 42,
            "system-out": [
              "                    \"name\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #914",
            "file": "chasten/validate.py",
            "line": 43,
            "system-out": [
              "                    \"id\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #915",
            "file": "chasten/validate.py",
            "line": 43,
            "system-out": [
              "                    \"id\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #916",
            "file": "chasten/validate.py",
            "line": 43,
            "system-out": [
              "                    \"id\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #917",
            "file": "chasten/validate.py",
            "line": 44,
            "system-out": [
              "                    \"description\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #918",
            "file": "chasten/validate.py",
            "line": 44,
            "system-out": [
              "                    \"description\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #919",
            "file": "chasten/validate.py",
            "line": 44,
            "system-out": [
              "                    \"description\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #920",
            "file": "chasten/validate.py",
            "line": 45,
            "system-out": [
              "                    \"pattern\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #921",
            "file": "chasten/validate.py",
            "line": 45,
            "system-out": [
              "                    \"pattern\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #922",
            "file": "chasten/validate.py",
            "line": 45,
            "system-out": [
              "                    \"pattern\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #923",
            "file": "chasten/validate.py",
            "line": 46,
            "system-out": [
              "                    \"code\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #924",
            "file": "chasten/validate.py",
            "line": 46,
            "system-out": [
              "                    \"code\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #925",
            "file": "chasten/validate.py",
            "line": 46,
            "system-out": [
              "                    \"code\": {\"type\": \"string\"},"
            ]
          },
          {
            "name": "Mutant #926",
            "file": "chasten/validate.py",
            "line": 47,
            "failure": [
              {
                "inner": "--- chasten/validate.py\n+++ chasten/validate.py\n@@ -44,7 +44,7 @@\n                     \"description\": {\"type\": \"string\"},\n                     \"pattern\": {\"type\": \"string\"},\n                     \"code\": {\"type\": \"string\"},\n-                    \"count\": {\n+                    \"XXcountXX\": {\n                         \"anyOf\": [\n                             {\n                                 \"type\": \"object\",\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "                    \"count\": {"
            ]
          },
          {
            "name": "Mutant #927",
            "file": "chasten/validate.py",
            "line": 48,
            "system-out": [
              "                        \"anyOf\": ["
            ]
          },
          {
            "name": "Mutant #928",
            "file": "chasten/validate.py",
            "line": 50,
            "system-out": [
              "                                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #929",
            "file": "chasten/validate.py",
            "line": 50,
            "system-out": [
              "                                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #930",
            "file": "chasten/validate.py",
            "line": 51,
            "system-out": [
              "                                \"properties\": {"
            ]
          },
          {
            "name": "Mutant #931",
            "file": "chasten/validate.py",
            "line": 52,
            "system-out": [
              "                                    \"min\": {"
            ]
          },
          {
            "name": "Mutant #932",
            "file": "chasten/validate.py",
            "line": 53,
            "system-out": [
              "                                        \"anyOf\": ["
            ]
          },
          {
            "name": "Mutant #933",
            "file": "chasten/validate.py",
            "line": 54,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #934",
            "file": "chasten/validate.py",
            "line": 54,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #935",
            "file": "chasten/validate.py",
            "line": 55,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #936",
            "file": "chasten/validate.py",
            "line": 55,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #937",
            "file": "chasten/validate.py",
            "line": 59,
            "system-out": [
              "                                \"required\": [\"min\"],"
            ]
          },
          {
            "name": "Mutant #938",
            "file": "chasten/validate.py",
            "line": 59,
            "system-out": [
              "                                \"required\": [\"min\"],"
            ]
          },
          {
            "name": "Mutant #939",
            "file": "chasten/validate.py",
            "line": 64,
            "system-out": [
              "                                    \"max\": {"
            ]
          },
          {
            "name": "Mutant #940",
            "file": "chasten/validate.py",
            "line": 71,
            "system-out": [
              "                                \"required\": [\"max\"],"
            ]
          },
          {
            "name": "Mutant #941",
            "file": "chasten/validate.py",
            "line": 71,
            "system-out": [
              "                                \"required\": [\"max\"],"
            ]
          },
          {
            "name": "Mutant #942",
            "file": "chasten/validate.py",
            "line": 89,
            "system-out": [
              "                                \"required\": [\"min\", \"max\"],"
            ]
          },
          {
            "name": "Mutant #943",
            "file": "chasten/validate.py",
            "line": 89,
            "system-out": [
              "                                \"required\": [\"min\", \"max\"],"
            ]
          },
          {
            "name": "Mutant #944",
            "file": "chasten/validate.py",
            "line": 89,
            "system-out": [
              "                                \"required\": [\"min\", \"max\"],"
            ]
          },
          {
            "name": "Mutant #945",
            "file": "chasten/validate.py",
            "line": 94,
            "system-out": [
              "                \"required\": [\"name\", \"id\", \"pattern\", \"code\"],"
            ]
          },
          {
            "name": "Mutant #946",
            "file": "chasten/validate.py",
            "line": 94,
            "system-out": [
              "                \"required\": [\"name\", \"id\", \"pattern\", \"code\"],"
            ]
          },
          {
            "name": "Mutant #947",
            "file": "chasten/validate.py",
            "line": 94,
            "system-out": [
              "                \"required\": [\"name\", \"id\", \"pattern\", \"code\"],"
            ]
          },
          {
            "name": "Mutant #948",
            "file": "chasten/validate.py",
            "line": 94,
            "system-out": [
              "                \"required\": [\"name\", \"id\", \"pattern\", \"code\"],"
            ]
          },
          {
            "name": "Mutant #949",
            "file": "chasten/validate.py",
            "line": 94,
            "system-out": [
              "                \"required\": [\"name\", \"id\", \"pattern\", \"code\"],"
            ]
          },
          {
            "name": "Mutant #950",
            "file": "chasten/validate.py",
            "line": 95,
            "system-out": [
              "                \"additionalProperties\": False,"
            ]
          },
          {
            "name": "Mutant #951",
            "file": "chasten/validate.py",
            "line": 95,
            "system-out": [
              "                \"additionalProperties\": False,"
            ]
          },
          {
            "name": "Mutant #952",
            "file": "chasten/validate.py",
            "line": 107,
            "system-out": [
              "    if constants.checks.Check_Chasten in configuration.keys():"
            ]
          },
          {
            "name": "Mutant #953",
            "file": "chasten/validate.py",
            "line": 109,
            "system-out": [
              "        if constants.checks.Check_File in configuration[constants.checks.Check_Chasten]:"
            ]
          },
          {
            "name": "Mutant #954",
            "file": "chasten/validate.py",
            "line": 116,
            "system-out": [
              "            return (True, checks_file_name_list)"
            ]
          },
          {
            "name": "Mutant #955",
            "file": "chasten/validate.py",
            "line": 118,
            "system-out": [
              "    return (False, [constants.markers.Empty_String])"
            ]
          },
          {
            "name": "Mutant #956",
            "file": "chasten/validate.py",
            "line": 130,
            "system-out": [
              "        return (True, constants.markers.Empty_String)"
            ]
          },
          {
            "name": "Mutant #957",
            "file": "chasten/validate.py",
            "line": 137,
            "system-out": [
              "        return (False, error_message)"
            ]
          },
          {
            "name": "Mutant #958",
            "file": "chasten/validate.py",
            "line": 152,
            "system-out": [
              "    verbose: bool = False,"
            ]
          },
          {
            "name": "Mutant #959",
            "file": "chasten/validate.py",
            "line": 158,
            "system-out": [
              "        f\":sparkles: Validated {file_name}? {util.get_human_readable_boolean(validated)}\""
            ]
          },
          {
            "name": "Mutant #960",
            "file": "chasten/validate.py",
            "line": 161,
            "system-out": [
              "    if not validated:"
            ]
          },
          {
            "name": "Mutant #961",
            "file": "chasten/validate.py",
            "line": 162,
            "system-out": [
              "        output.console.print(f\":person_shrugging: Validation errors:\\n\\n{errors}\")"
            ]
          },
          {
            "name": "Mutant #962",
            "file": "chasten/validate.py",
            "line": 165,
            "system-out": [
              "        output.opt_print_log(verbose, newline=\"\")"
            ]
          },
          {
            "name": "Mutant #963",
            "file": "chasten/validate.py",
            "line": 166,
            "system-out": [
              "        output.opt_print_log(verbose, label=f\":sparkles: Contents of {file_name}:\\n\")"
            ]
          },
          {
            "name": "Mutant #964",
            "file": "chasten/constants.py",
            "line": 55,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #965",
            "file": "chasten/constants.py",
            "line": 55,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -50,9 +50,6 @@\n     Website=\":link: GitHub: https://github.com/gkapfham/chasten\",\n )\n \n-\n-# checks constant\n-@dataclass(frozen=True)\n class Checks:\n     \"\"\"Define the Checks dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #966",
            "file": "chasten/constants.py",
            "line": 88,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #967",
            "file": "chasten/constants.py",
            "line": 88,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -83,9 +83,6 @@\n     Check_Pattern=\"pattern\",\n )\n \n-\n-# datasette constant\n-@dataclass(frozen=True)\n class Datasette:\n     \"\"\"Define the Datasette dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #968",
            "file": "chasten/constants.py",
            "line": 109,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #969",
            "file": "chasten/constants.py",
            "line": 109,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -104,9 +104,6 @@\n     Datasette_Search_All=\"--install=datasette-search-all\",\n )\n \n-\n-# filesystem constant\n-@dataclass(frozen=True)\n class Filesystem:\n     \"\"\"Define the Filesystem dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #970",
            "file": "chasten/constants.py",
            "line": 138,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #971",
            "file": "chasten/constants.py",
            "line": 138,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -133,9 +133,6 @@\n     Results_Extension=\"json\",\n )\n \n-\n-# humanreadable constant\n-@dataclass(frozen=True)\n class Humanreadable:\n     \"\"\"Define the Humanreadable dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #972",
            "file": "chasten/constants.py",
            "line": 150,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #973",
            "file": "chasten/constants.py",
            "line": 150,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -145,9 +145,6 @@\n \n humanreadable = Humanreadable(Yes=\"Yes\", No=\"No\")\n \n-\n-# logger constant\n-@dataclass(frozen=True)\n class Logger:\n     \"\"\"Define the Logger dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #974",
            "file": "chasten/constants.py",
            "line": 167,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #975",
            "file": "chasten/constants.py",
            "line": 167,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -162,9 +162,6 @@\n     Syslog=\"chasten-syslog\",\n )\n \n-\n-# logging constant\n-@dataclass(frozen=True)\n class Logging:\n     \"\"\"Define the Logging dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #976",
            "file": "chasten/constants.py",
            "line": 200,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #977",
            "file": "chasten/constants.py",
            "line": 200,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -195,9 +195,6 @@\n     Rich=\"Rich\",\n )\n \n-\n-# markers constant\n-@dataclass(frozen=True)\n class Markers:\n     \"\"\"Define the Markers dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #978",
            "file": "chasten/constants.py",
            "line": 239,
            "system-out": [
              "    Dot=\".\","
            ]
          },
          {
            "name": "Mutant #979",
            "file": "chasten/constants.py",
            "line": 259,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #980",
            "file": "chasten/constants.py",
            "line": 259,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -254,9 +254,6 @@\n     Percent_Multiplier=100,\n )\n \n-\n-# output constant\n-@dataclass(frozen=True)\n class Output:\n     \"\"\"Define the Output dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #981",
            "file": "chasten/constants.py",
            "line": 274,
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #982",
            "file": "chasten/constants.py",
            "line": 274,
            "failure": [
              {
                "inner": "--- chasten/constants.py\n+++ chasten/constants.py\n@@ -269,9 +269,6 @@\n     Test_Start=\":sparkles: Start to run test suite for the specified program\",\n )\n \n-\n-# server constant\n-@dataclass(frozen=True)\n class Server:\n     \"\"\"Define the Server dataclass for constant(s).\"\"\"\n \n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "@dataclass(frozen=True)"
            ]
          },
          {
            "name": "Mutant #983",
            "file": "chasten/debug.py",
            "line": 9,
            "system-out": [
              "    DEBUG = \"DEBUG\""
            ]
          },
          {
            "name": "Mutant #984",
            "file": "chasten/debug.py",
            "line": 10,
            "system-out": [
              "    INFO = \"INFO\""
            ]
          },
          {
            "name": "Mutant #985",
            "file": "chasten/debug.py",
            "line": 11,
            "system-out": [
              "    WARNING = \"WARNING\""
            ]
          },
          {
            "name": "Mutant #986",
            "file": "chasten/debug.py",
            "line": 12,
            "system-out": [
              "    ERROR = \"ERROR\""
            ]
          },
          {
            "name": "Mutant #987",
            "file": "chasten/debug.py",
            "line": 13,
            "system-out": [
              "    CRITICAL = \"CRITICAL\""
            ]
          },
          {
            "name": "Mutant #988",
            "file": "chasten/debug.py",
            "line": 19,
            "system-out": [
              "    CONSOLE = \"CONSOLE\""
            ]
          },
          {
            "name": "Mutant #989",
            "file": "chasten/debug.py",
            "line": 20,
            "system-out": [
              "    SYSLOG = \"SYSLOG\""
            ]
          },
          {
            "name": "Mutant #990",
            "file": "chasten/configApp.py",
            "line": 15,
            "system-out": [
              "    \"Check\": 0,"
            ]
          },
          {
            "name": "Mutant #991",
            "file": "chasten/configApp.py",
            "line": 15,
            "system-out": [
              "    \"Check\": 0,"
            ]
          },
          {
            "name": "Mutant #992",
            "file": "chasten/configApp.py",
            "line": 16,
            "system-out": [
              "    \"Matches\": 1,"
            ]
          },
          {
            "name": "Mutant #993",
            "file": "chasten/configApp.py",
            "line": 16,
            "system-out": [
              "    \"Matches\": 1,"
            ]
          },
          {
            "name": "Mutant #994",
            "file": "chasten/configApp.py",
            "line": 18,
            "system-out": [
              "CHECK_DEFAULT = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #995",
            "file": "chasten/configApp.py",
            "line": 18,
            "system-out": [
              "CHECK_DEFAULT = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #996",
            "file": "chasten/configApp.py",
            "line": 18,
            "system-out": [
              "CHECK_DEFAULT = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #997",
            "file": "chasten/configApp.py",
            "line": 28,
            "system-out": [
              "                check_list.append(strip_row.split(\",\"))"
            ]
          },
          {
            "name": "Mutant #998",
            "file": "chasten/configApp.py",
            "line": 34,
            "system-out": [
              "    if len(check_list) != 0:"
            ]
          },
          {
            "name": "Mutant #999",
            "file": "chasten/configApp.py",
            "line": 34,
            "system-out": [
              "    if len(check_list) != 0:"
            ]
          },
          {
            "name": "Mutant #1000",
            "file": "chasten/configApp.py",
            "line": 35,
            "system-out": [
              "        result = \"Make a YAML file that checks for:\""
            ]
          },
          {
            "name": "Mutant #1001",
            "file": "chasten/configApp.py",
            "line": 37,
            "system-out": [
              "            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            ]
          },
          {
            "name": "Mutant #1002",
            "file": "chasten/configApp.py",
            "line": 37,
            "system-out": [
              "            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            ]
          },
          {
            "name": "Mutant #1003",
            "file": "chasten/configApp.py",
            "line": 37,
            "system-out": [
              "            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            ]
          },
          {
            "name": "Mutant #1004",
            "file": "chasten/configApp.py",
            "line": 37,
            "system-out": [
              "            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            ]
          },
          {
            "name": "Mutant #1005",
            "file": "chasten/configApp.py",
            "line": 37,
            "system-out": [
              "            quantity = \"exactly\" if checks[2] == \"True\" else \"at minimum\""
            ]
          },
          {
            "name": "Mutant #1006",
            "file": "chasten/configApp.py",
            "line": 38,
            "system-out": [
              "            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\""
            ]
          },
          {
            "name": "Mutant #1007",
            "file": "chasten/configApp.py",
            "line": 38,
            "system-out": [
              "            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\""
            ]
          },
          {
            "name": "Mutant #1008",
            "file": "chasten/configApp.py",
            "line": 38,
            "system-out": [
              "            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\""
            ]
          },
          {
            "name": "Mutant #1009",
            "file": "chasten/configApp.py",
            "line": 38,
            "system-out": [
              "            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\""
            ]
          },
          {
            "name": "Mutant #1010",
            "file": "chasten/configApp.py",
            "line": 38,
            "system-out": [
              "            result += f\"\\n - {quantity} {checks[1]} {checks[0]}\""
            ]
          },
          {
            "name": "Mutant #1011",
            "file": "chasten/configApp.py",
            "line": 40,
            "system-out": [
              "    return \"[red][ERROR][/red] No checks were supplied\""
            ]
          },
          {
            "name": "Mutant #1012",
            "file": "chasten/configApp.py",
            "line": 46,
            "system-out": [
              "    with open(File, \"a\") as file:"
            ]
          },
          {
            "name": "Mutant #1013",
            "file": "chasten/configApp.py",
            "line": 47,
            "system-out": [
              "        file.write(f\"\\n{Pattern},{Matches},{Exact}\")  # Append input data to the file"
            ]
          },
          {
            "name": "Mutant #1014",
            "file": "chasten/configApp.py",
            "line": 51,
            "system-out": [
              "Check_Input = Input(placeholder=\"Check For:\", id=\"Check\", name=\"Check\")"
            ]
          },
          {
            "name": "Mutant #1015",
            "file": "chasten/configApp.py",
            "line": 51,
            "system-out": [
              "Check_Input = Input(placeholder=\"Check For:\", id=\"Check\", name=\"Check\")"
            ]
          },
          {
            "name": "Mutant #1016",
            "file": "chasten/configApp.py",
            "line": 51,
            "system-out": [
              "Check_Input = Input(placeholder=\"Check For:\", id=\"Check\", name=\"Check\")"
            ]
          },
          {
            "name": "Mutant #1017",
            "file": "chasten/configApp.py",
            "line": 53,
            "system-out": [
              "    placeholder=\"How many matches do you expect\","
            ]
          },
          {
            "name": "Mutant #1018",
            "file": "chasten/configApp.py",
            "line": 54,
            "system-out": [
              "    id=\"Matches\","
            ]
          },
          {
            "name": "Mutant #1019",
            "file": "chasten/configApp.py",
            "line": 55,
            "system-out": [
              "    name=\"Matches\","
            ]
          },
          {
            "name": "Mutant #1020",
            "file": "chasten/configApp.py",
            "line": 56,
            "system-out": [
              "    validators=Number(1, 500),  # Validate that Matches is a number between 1 and 500"
            ]
          },
          {
            "name": "Mutant #1021",
            "file": "chasten/configApp.py",
            "line": 56,
            "system-out": [
              "    validators=Number(1, 500),  # Validate that Matches is a number between 1 and 500"
            ]
          },
          {
            "name": "Mutant #1022",
            "file": "chasten/configApp.py",
            "line": 58,
            "system-out": [
              "Exact_button = Button(\"Exact\", id=\"Exact\")  # Button to trigger an action"
            ]
          },
          {
            "name": "Mutant #1023",
            "file": "chasten/configApp.py",
            "line": 58,
            "system-out": [
              "Exact_button = Button(\"Exact\", id=\"Exact\")  # Button to trigger an action"
            ]
          },
          {
            "name": "Mutant #1024",
            "file": "chasten/configApp.py",
            "line": 75,
            "system-out": [
              "        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button"
            ]
          },
          {
            "name": "Mutant #1025",
            "file": "chasten/configApp.py",
            "line": 75,
            "system-out": [
              "        yield Button(\"Submit Check!\", id=\"next\")  # Display the \"Next Check!\" button"
            ]
          },
          {
            "name": "Mutant #1026",
            "file": "chasten/configApp.py",
            "line": 76,
            "system-out": [
              "        yield Button(\"Done\", id=\"done\")"
            ]
          },
          {
            "name": "Mutant #1027",
            "file": "chasten/configApp.py",
            "line": 76,
            "system-out": [
              "        yield Button(\"Done\", id=\"done\")"
            ]
          },
          {
            "name": "Mutant #1028",
            "file": "chasten/configApp.py",
            "line": 77,
            "system-out": [
              "        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")"
            ]
          },
          {
            "name": "Mutant #1029",
            "file": "chasten/configApp.py",
            "line": 77,
            "system-out": [
              "        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")"
            ]
          },
          {
            "name": "Mutant #1030",
            "file": "chasten/configApp.py",
            "line": 77,
            "system-out": [
              "        yield Button(\"Clear Checks\", id=\"clear\", variant=\"error\")"
            ]
          },
          {
            "name": "Mutant #1031",
            "file": "chasten/configApp.py",
            "line": 114,
            "system-out": [
              "    Check: ClassVar[list] = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #1032",
            "file": "chasten/configApp.py",
            "line": 114,
            "system-out": [
              "    Check: ClassVar[list] = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #1033",
            "file": "chasten/configApp.py",
            "line": 114,
            "system-out": [
              "    Check: ClassVar[list] = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #1034",
            "file": "chasten/configApp.py",
            "line": 114,
            "system-out": [
              "    Check: ClassVar[list] = [\"\", \"1\", False]"
            ]
          },
          {
            "name": "Mutant #1035",
            "file": "chasten/configApp.py",
            "line": 115,
            "system-out": [
              "    Valid: bool = False"
            ]
          },
          {
            "name": "Mutant #1036",
            "file": "chasten/configApp.py",
            "line": 115,
            "system-out": [
              "    Valid: bool = False"
            ]
          },
          {
            "name": "Mutant #1037",
            "file": "chasten/configApp.py",
            "line": 119,
            "system-out": [
              "        self.Valid = False"
            ]
          },
          {
            "name": "Mutant #1038",
            "file": "chasten/configApp.py",
            "line": 120,
            "system-out": [
              "        if event.input.id == \"Check\":"
            ]
          },
          {
            "name": "Mutant #1039",
            "file": "chasten/configApp.py",
            "line": 120,
            "system-out": [
              "        if event.input.id == \"Check\":"
            ]
          },
          {
            "name": "Mutant #1040",
            "file": "chasten/configApp.py",
            "line": 122,
            "system-out": [
              "        elif event.validation_result is not None:"
            ]
          },
          {
            "name": "Mutant #1041",
            "file": "chasten/configApp.py",
            "line": 125,
            "system-out": [
              "                self.Valid = True"
            ]
          },
          {
            "name": "Mutant #1042",
            "file": "chasten/configApp.py",
            "line": 128,
            "system-out": [
              "        if event.button.id == \"Exact\":"
            ]
          },
          {
            "name": "Mutant #1043",
            "file": "chasten/configApp.py",
            "line": 128,
            "system-out": [
              "        if event.button.id == \"Exact\":"
            ]
          },
          {
            "name": "Mutant #1044",
            "file": "chasten/configApp.py",
            "line": 129,
            "system-out": [
              "            self.Check[2] = True  # Mark the \"Exact\" button as clicked"
            ]
          },
          {
            "name": "Mutant #1045",
            "file": "chasten/configApp.py",
            "line": 129,
            "system-out": [
              "            self.Check[2] = True  # Mark the \"Exact\" button as clicked"
            ]
          },
          {
            "name": "Mutant #1046",
            "file": "chasten/configApp.py",
            "line": 130,
            "system-out": [
              "            event.button.disabled = True  # Disable the \"Exact\" button after clicking"
            ]
          },
          {
            "name": "Mutant #1047",
            "file": "chasten/configApp.py",
            "line": 131,
            "system-out": [
              "        elif event.button.id == \"done\":"
            ]
          },
          {
            "name": "Mutant #1048",
            "file": "chasten/configApp.py",
            "line": 131,
            "system-out": [
              "        elif event.button.id == \"done\":"
            ]
          },
          {
            "name": "Mutant #1049",
            "file": "chasten/configApp.py",
            "line": 135,
            "system-out": [
              "        elif event.button.id == \"clear\":"
            ]
          },
          {
            "name": "Mutant #1050",
            "file": "chasten/configApp.py",
            "line": 135,
            "system-out": [
              "        elif event.button.id == \"clear\":"
            ]
          },
          {
            "name": "Mutant #1051",
            "file": "chasten/configApp.py",
            "line": 136,
            "system-out": [
              "            with open(CHECK_STORAGE, \"w\") as file:"
            ]
          },
          {
            "name": "Mutant #1052",
            "file": "chasten/configApp.py",
            "line": 138,
            "system-out": [
              "                    \"\""
            ]
          },
          {
            "name": "Mutant #1053",
            "file": "chasten/configApp.py",
            "line": 141,
            "system-out": [
              "            if event.button.id == \"next\":"
            ]
          },
          {
            "name": "Mutant #1054",
            "file": "chasten/configApp.py",
            "line": 141,
            "system-out": [
              "            if event.button.id == \"next\":"
            ]
          },
          {
            "name": "Mutant #1055",
            "file": "chasten/configApp.py",
            "line": 144,
            "system-out": [
              "                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]"
            ]
          },
          {
            "name": "Mutant #1056",
            "file": "chasten/configApp.py",
            "line": 144,
            "system-out": [
              "                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]"
            ]
          },
          {
            "name": "Mutant #1057",
            "file": "chasten/configApp.py",
            "line": 144,
            "system-out": [
              "                    CHECK_STORAGE, self.Check[0], self.Check[1], self.Check[2]"
            ]
          },
          {
            "name": "Mutant #1058",
            "file": "chasten/configApp.py",
            "line": 146,
            "system-out": [
              "                self.Check[0] = \"\""
            ]
          },
          {
            "name": "Mutant #1059",
            "file": "chasten/configApp.py",
            "line": 146,
            "system-out": [
              "                self.Check[0] = \"\""
            ]
          },
          {
            "name": "Mutant #1060",
            "file": "chasten/configApp.py",
            "line": 147,
            "system-out": [
              "                self.Check[1] = \"1\""
            ]
          },
          {
            "name": "Mutant #1061",
            "file": "chasten/configApp.py",
            "line": 147,
            "system-out": [
              "                self.Check[1] = \"1\""
            ]
          },
          {
            "name": "Mutant #1062",
            "file": "chasten/configApp.py",
            "line": 148,
            "system-out": [
              "                self.Check[2] = False"
            ]
          },
          {
            "name": "Mutant #1063",
            "file": "chasten/configApp.py",
            "line": 148,
            "system-out": [
              "                self.Check[2] = False"
            ]
          },
          {
            "name": "Mutant #1064",
            "file": "chasten/configApp.py",
            "line": 151,
            "system-out": [
              "                Exact_button.disabled = False  # Re-enable the \"Exact\" button"
            ]
          },
          {
            "name": "Mutant #1065",
            "file": "chasten/configApp.py",
            "line": 152,
            "system-out": [
              "                Check_Input.value = \"\""
            ]
          },
          {
            "name": "Mutant #1066",
            "file": "chasten/configApp.py",
            "line": 153,
            "system-out": [
              "                Match_Input.value = \"\"  # Refresh the application UI"
            ]
          },
          {
            "name": "Mutant #1067",
            "file": "chasten/configApp.py",
            "line": 155,
            "system-out": [
              "            self.query_one(Pretty).update([\"Invalid Input Please enter a Integer\"])"
            ]
          },
          {
            "name": "Mutant #1068",
            "file": "chasten/configApp.py",
            "line": 156,
            "system-out": [
              "            Match_Input.value = \"\"  # Clear the \"Matches\" input field"
            ]
          },
          {
            "name": "Mutant #1069",
            "file": "chasten/validate.py",
            "line": 35,
            "system-out": [
              "    \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1070",
            "file": "chasten/validate.py",
            "line": 35,
            "system-out": [
              "    \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1071",
            "file": "chasten/validate.py",
            "line": 36,
            "failure": [
              {
                "inner": "--- chasten/validate.py\n+++ chasten/validate.py\n@@ -33,7 +33,7 @@\n # see ./chasten in the root of the repository for the checks.yml file\n JSON_SCHEMA_CHECKS = {\n     \"type\": \"object\",\n-    \"properties\": {\n+    \"XXpropertiesXX\": {\n         \"checks\": {\n             \"type\": \"array\",\n             \"items\": {\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "    \"properties\": {"
            ]
          },
          {
            "name": "Mutant #1072",
            "file": "chasten/validate.py",
            "line": 62,
            "system-out": [
              "                                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1073",
            "file": "chasten/validate.py",
            "line": 62,
            "system-out": [
              "                                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1074",
            "file": "chasten/validate.py",
            "line": 63,
            "system-out": [
              "                                \"properties\": {"
            ]
          },
          {
            "name": "Mutant #1075",
            "file": "chasten/validate.py",
            "line": 65,
            "system-out": [
              "                                        \"anyOf\": ["
            ]
          },
          {
            "name": "Mutant #1076",
            "file": "chasten/validate.py",
            "line": 66,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #1077",
            "file": "chasten/validate.py",
            "line": 66,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #1078",
            "file": "chasten/validate.py",
            "line": 67,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #1079",
            "file": "chasten/validate.py",
            "line": 67,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #1080",
            "file": "chasten/validate.py",
            "line": 74,
            "system-out": [
              "                                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1081",
            "file": "chasten/validate.py",
            "line": 74,
            "system-out": [
              "                                \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1082",
            "file": "chasten/validate.py",
            "line": 75,
            "system-out": [
              "                                \"properties\": {"
            ]
          },
          {
            "name": "Mutant #1083",
            "file": "chasten/validate.py",
            "line": 76,
            "system-out": [
              "                                    \"min\": {"
            ]
          },
          {
            "name": "Mutant #1084",
            "file": "chasten/validate.py",
            "line": 77,
            "system-out": [
              "                                        \"anyOf\": ["
            ]
          },
          {
            "name": "Mutant #1085",
            "file": "chasten/validate.py",
            "line": 78,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #1086",
            "file": "chasten/validate.py",
            "line": 78,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #1087",
            "file": "chasten/validate.py",
            "line": 79,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #1088",
            "file": "chasten/validate.py",
            "line": 79,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #1089",
            "file": "chasten/validate.py",
            "line": 82,
            "system-out": [
              "                                    \"max\": {"
            ]
          },
          {
            "name": "Mutant #1090",
            "file": "chasten/validate.py",
            "line": 83,
            "system-out": [
              "                                        \"anyOf\": ["
            ]
          },
          {
            "name": "Mutant #1091",
            "file": "chasten/validate.py",
            "line": 84,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #1092",
            "file": "chasten/validate.py",
            "line": 84,
            "system-out": [
              "                                            {\"type\": \"integer\"},"
            ]
          },
          {
            "name": "Mutant #1093",
            "file": "chasten/validate.py",
            "line": 85,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #1094",
            "file": "chasten/validate.py",
            "line": 85,
            "system-out": [
              "                                            {\"type\": \"null\"},"
            ]
          },
          {
            "name": "Mutant #1095",
            "file": "chasten/process.py",
            "line": 17,
            "system-out": [
              "    include: bool = True,"
            ]
          },
          {
            "name": "Mutant #1096",
            "file": "chasten/process.py",
            "line": 24,
            "system-out": [
              "    if check_attribute is None or check_match is None:"
            ]
          },
          {
            "name": "Mutant #1097",
            "file": "chasten/process.py",
            "line": 24,
            "system-out": [
              "    if check_attribute is None or check_match is None:"
            ]
          },
          {
            "name": "Mutant #1098",
            "file": "chasten/process.py",
            "line": 24,
            "system-out": [
              "    if check_attribute is None or check_match is None:"
            ]
          },
          {
            "name": "Mutant #1099",
            "file": "chasten/process.py",
            "line": 36,
            "system-out": [
              "        if (fuzzy_value >= check_confidence) and include:"
            ]
          },
          {
            "name": "Mutant #1100",
            "file": "chasten/process.py",
            "line": 36,
            "system-out": [
              "        if (fuzzy_value >= check_confidence) and include:"
            ]
          },
          {
            "name": "Mutant #1101",
            "file": "chasten/process.py",
            "line": 41,
            "system-out": [
              "        elif (fuzzy_value < check_confidence) and not include:"
            ]
          },
          {
            "name": "Mutant #1102",
            "file": "chasten/process.py",
            "line": 41,
            "system-out": [
              "        elif (fuzzy_value < check_confidence) and not include:"
            ]
          },
          {
            "name": "Mutant #1103",
            "file": "chasten/process.py",
            "line": 41,
            "system-out": [
              "        elif (fuzzy_value < check_confidence) and not include:"
            ]
          },
          {
            "name": "Mutant #1104",
            "file": "chasten/process.py",
            "line": 73,
            "system-out": [
              "    match_dict: Dict[str, List[pyastgrepsearch.Match]] = {}"
            ]
          },
          {
            "name": "Mutant #1105",
            "file": "chasten/process.py",
            "line": 82,
            "system-out": [
              "        if current_match_file_name in match_dict:"
            ]
          },
          {
            "name": "Mutant #1106",
            "file": "chasten/process.py",
            "line": 89,
            "system-out": [
              "            current_match_list: List[pyastgrepsearch.Match] = []"
            ]
          },
          {
            "name": "Mutant #1107",
            "file": "chasten/process.py",
            "line": 109,
            "system-out": [
              "    return json.dumps(dict_list, indent=2)"
            ]
          },
          {
            "name": "Mutant #1108",
            "file": "chasten/main.py",
            "line": 31,
            "system-out": [
              "cli = typer.Typer(no_args_is_help=True)"
            ]
          },
          {
            "name": "Mutant #1109",
            "file": "chasten/main.py",
            "line": 54,
            "system-out": [
              "    output.logger.debug(f\"Display verbose output? {verbose}\")"
            ]
          },
          {
            "name": "Mutant #1110",
            "file": "chasten/main.py",
            "line": 55,
            "system-out": [
              "    output.logger.debug(f\"Debug level? {debug_level.value}\")"
            ]
          },
          {
            "name": "Mutant #1111",
            "file": "chasten/main.py",
            "line": 56,
            "system-out": [
              "    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            ]
          },
          {
            "name": "Mutant #1112",
            "file": "chasten/main.py",
            "line": 76,
            "system-out": [
              "    port: int = 8001,"
            ]
          },
          {
            "name": "Mutant #1113",
            "file": "chasten/main.py",
            "line": 77,
            "system-out": [
              "    publish: bool = False,"
            ]
          },
          {
            "name": "Mutant #1114",
            "file": "chasten/main.py",
            "line": 84,
            "system-out": [
              "        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\""
            ]
          },
          {
            "name": "Mutant #1115",
            "file": "chasten/main.py",
            "line": 84,
            "system-out": [
              "        f\"{constants.markers.Indent}{small_bullet_unicode} Database: '{output.shorten_file_name(str(database_path), 120)}'\""
            ]
          },
          {
            "name": "Mutant #1116",
            "file": "chasten/main.py",
            "line": 87,
            "system-out": [
              "        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\""
            ]
          },
          {
            "name": "Mutant #1117",
            "file": "chasten/main.py",
            "line": 87,
            "system-out": [
              "        f\"{constants.markers.Indent}{small_bullet_unicode} Metadata: '{output.shorten_file_name(str(metadata), 120)}'\""
            ]
          },
          {
            "name": "Mutant #1118",
            "file": "chasten/main.py",
            "line": 91,
            "system-out": [
              "    if not publish:"
            ]
          },
          {
            "name": "Mutant #1119",
            "file": "chasten/main.py",
            "line": 93,
            "system-out": [
              "            f\"{constants.markers.Indent}{small_bullet_unicode} Port: {port}\""
            ]
          },
          {
            "name": "Mutant #1120",
            "file": "chasten/main.py",
            "line": 106,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1121",
            "file": "chasten/main.py",
            "line": 108,
            "system-out": [
              "    filename: Path = typer.Option(\"checks.yml\", help=\"YAML file name\")"
            ]
          },
          {
            "name": "Mutant #1122",
            "file": "chasten/main.py",
            "line": 108,
            "system-out": [
              "    filename: Path = typer.Option(\"checks.yml\", help=\"YAML file name\")"
            ]
          },
          {
            "name": "Mutant #1123",
            "file": "chasten/main.py",
            "line": 129,
            "system-out": [
              "            api_key = input(\"Please Enter your openai API Key:\")"
            ]
          },
          {
            "name": "Mutant #1124",
            "file": "chasten/main.py",
            "line": 131,
            "system-out": [
              "            while not createchecks.is_valid_api_key(api_key):"
            ]
          },
          {
            "name": "Mutant #1125",
            "file": "chasten/main.py",
            "line": 133,
            "system-out": [
              "                    \"[red][ERROR][/red] Invalid API key. Please enter a valid API key.\""
            ]
          },
          {
            "name": "Mutant #1126",
            "file": "chasten/main.py",
            "line": 135,
            "system-out": [
              "                api_key = input(\"Please Enter your openai API Key:\")"
            ]
          },
          {
            "name": "Mutant #1127",
            "file": "chasten/main.py",
            "line": 149,
            "system-out": [
              "            f\"[red][ERROR][/red] No {CHECK_STORAGE} file exists\\n  - Rerun the command and specify checks\""
            ]
          },
          {
            "name": "Mutant #1128",
            "file": "chasten/main.py",
            "line": 160,
            "system-out": [
              "        \"--config\","
            ]
          },
          {
            "name": "Mutant #1129",
            "file": "chasten/main.py",
            "line": 161,
            "system-out": [
              "        \"-c\","
            ]
          },
          {
            "name": "Mutant #1130",
            "file": "chasten/main.py",
            "line": 162,
            "system-out": [
              "        help=\"A directory with configuration file(s), path to configuration file, or URL to configuration file.\","
            ]
          },
          {
            "name": "Mutant #1131",
            "file": "chasten/main.py",
            "line": 166,
            "system-out": [
              "        \"--debug-level\","
            ]
          },
          {
            "name": "Mutant #1132",
            "file": "chasten/main.py",
            "line": 167,
            "system-out": [
              "        \"-l\","
            ]
          },
          {
            "name": "Mutant #1133",
            "file": "chasten/main.py",
            "line": 168,
            "system-out": [
              "        help=\"Specify the level of debugging output.\","
            ]
          },
          {
            "name": "Mutant #1134",
            "file": "chasten/main.py",
            "line": 172,
            "system-out": [
              "        \"--debug-dest\","
            ]
          },
          {
            "name": "Mutant #1135",
            "file": "chasten/main.py",
            "line": 173,
            "system-out": [
              "        \"-t\","
            ]
          },
          {
            "name": "Mutant #1136",
            "file": "chasten/main.py",
            "line": 174,
            "system-out": [
              "        help=\"Specify the destination for debugging output.\","
            ]
          },
          {
            "name": "Mutant #1137",
            "file": "chasten/main.py",
            "line": 177,
            "system-out": [
              "        False,"
            ]
          },
          {
            "name": "Mutant #1138",
            "file": "chasten/main.py",
            "line": 178,
            "system-out": [
              "        help=\"Create configuration directory and files even if they exist\","
            ]
          },
          {
            "name": "Mutant #1139",
            "file": "chasten/main.py",
            "line": 180,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1140",
            "file": "chasten/main.py",
            "line": 180,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1141",
            "file": "chasten/main.py",
            "line": 198,
            "system-out": [
              "    if task == enumerations.ConfigureTask.VALIDATE:"
            ]
          },
          {
            "name": "Mutant #1142",
            "file": "chasten/main.py",
            "line": 205,
            "system-out": [
              "        if not validated:"
            ]
          },
          {
            "name": "Mutant #1143",
            "file": "chasten/main.py",
            "line": 207,
            "system-out": [
              "                \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\""
            ]
          },
          {
            "name": "Mutant #1144",
            "file": "chasten/main.py",
            "line": 211,
            "system-out": [
              "    if task == enumerations.ConfigureTask.CREATE:"
            ]
          },
          {
            "name": "Mutant #1145",
            "file": "chasten/main.py",
            "line": 217,
            "system-out": [
              "            if config is None:"
            ]
          },
          {
            "name": "Mutant #1146",
            "file": "chasten/main.py",
            "line": 235,
            "system-out": [
              "                f\":sparkles: Created configuration directory and file(s) in {created_directory_path}\""
            ]
          },
          {
            "name": "Mutant #1147",
            "file": "chasten/main.py",
            "line": 241,
            "system-out": [
              "            if not force:"
            ]
          },
          {
            "name": "Mutant #1148",
            "file": "chasten/main.py",
            "line": 243,
            "system-out": [
              "                    \"\\n:person_shrugging: Configuration directory already exists.\""
            ]
          },
          {
            "name": "Mutant #1149",
            "file": "chasten/main.py",
            "line": 246,
            "system-out": [
              "                    \"Use --force to recreate configuration directory and its containing files.\""
            ]
          },
          {
            "name": "Mutant #1150",
            "file": "chasten/main.py",
            "line": 253,
            "system-out": [
              "    project: str = typer.Argument(help=\"Name of the project.\"),"
            ]
          },
          {
            "name": "Mutant #1151",
            "file": "chasten/main.py",
            "line": 256,
            "system-out": [
              "        \"--xpath-version\","
            ]
          },
          {
            "name": "Mutant #1152",
            "file": "chasten/main.py",
            "line": 257,
            "system-out": [
              "        \"-xp\","
            ]
          },
          {
            "name": "Mutant #1153",
            "file": "chasten/main.py",
            "line": 258,
            "system-out": [
              "        help=\"Accepts different xpath version, runs xpath version two by default.\","
            ]
          },
          {
            "name": "Mutant #1154",
            "file": "chasten/main.py",
            "line": 261,
            "system-out": [
              "        (None, None, 0),"
            ]
          },
          {
            "name": "Mutant #1155",
            "file": "chasten/main.py",
            "line": 262,
            "system-out": [
              "        \"--check-include\","
            ]
          },
          {
            "name": "Mutant #1156",
            "file": "chasten/main.py",
            "line": 263,
            "system-out": [
              "        \"-i\","
            ]
          },
          {
            "name": "Mutant #1157",
            "file": "chasten/main.py",
            "line": 264,
            "system-out": [
              "        help=\"Attribute name, value, and match confidence level for inclusion.\","
            ]
          },
          {
            "name": "Mutant #1158",
            "file": "chasten/main.py",
            "line": 268,
            "system-out": [
              "        \"--check-exclude\","
            ]
          },
          {
            "name": "Mutant #1159",
            "file": "chasten/main.py",
            "line": 269,
            "system-out": [
              "        \"-e\","
            ]
          },
          {
            "name": "Mutant #1160",
            "file": "chasten/main.py",
            "line": 270,
            "system-out": [
              "        help=\"Attribute name, value, and match confidence level for exclusion.\","
            ]
          },
          {
            "name": "Mutant #1161",
            "file": "chasten/main.py",
            "line": 274,
            "system-out": [
              "        \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1162",
            "file": "chasten/main.py",
            "line": 275,
            "system-out": [
              "        \"-d\","
            ]
          },
          {
            "name": "Mutant #1163",
            "file": "chasten/main.py",
            "line": 276,
            "system-out": [
              "        help=\"A path (i.e., directory or file) with Python source code(s).\","
            ]
          },
          {
            "name": "Mutant #1164",
            "file": "chasten/main.py",
            "line": 277,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1165",
            "file": "chasten/main.py",
            "line": 278,
            "system-out": [
              "        file_okay=True,"
            ]
          },
          {
            "name": "Mutant #1166",
            "file": "chasten/main.py",
            "line": 279,
            "system-out": [
              "        dir_okay=True,"
            ]
          },
          {
            "name": "Mutant #1167",
            "file": "chasten/main.py",
            "line": 280,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1168",
            "file": "chasten/main.py",
            "line": 281,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1169",
            "file": "chasten/main.py",
            "line": 285,
            "system-out": [
              "        \"--save-directory\","
            ]
          },
          {
            "name": "Mutant #1170",
            "file": "chasten/main.py",
            "line": 286,
            "system-out": [
              "        \"-s\","
            ]
          },
          {
            "name": "Mutant #1171",
            "file": "chasten/main.py",
            "line": 287,
            "system-out": [
              "        help=\"A directory for saving output file(s).\","
            ]
          },
          {
            "name": "Mutant #1172",
            "file": "chasten/main.py",
            "line": 289,
            "system-out": [
              "        file_okay=False,"
            ]
          },
          {
            "name": "Mutant #1173",
            "file": "chasten/main.py",
            "line": 292,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1174",
            "file": "chasten/main.py",
            "line": 297,
            "system-out": [
              "        \"--view-xml\","
            ]
          },
          {
            "name": "Mutant #1175",
            "file": "chasten/main.py",
            "line": 298,
            "system-out": [
              "        \"-v\","
            ]
          },
          {
            "name": "Mutant #1176",
            "file": "chasten/main.py",
            "line": 299,
            "system-out": [
              "        help=\"Prints and saves the xml representation of the input file(s)\","
            ]
          },
          {
            "name": "Mutant #1177",
            "file": "chasten/main.py",
            "line": 303,
            "system-out": [
              "        \"--save-xml\","
            ]
          },
          {
            "name": "Mutant #1178",
            "file": "chasten/main.py",
            "line": 304,
            "system-out": [
              "        \"-sx\","
            ]
          },
          {
            "name": "Mutant #1179",
            "file": "chasten/main.py",
            "line": 305,
            "system-out": [
              "        help=\"Saves the xml representation of the input file(s)\","
            ]
          },
          {
            "name": "Mutant #1180",
            "file": "chasten/main.py",
            "line": 309,
            "system-out": [
              "        \"--markdown-storage\","
            ]
          },
          {
            "name": "Mutant #1181",
            "file": "chasten/main.py",
            "line": 310,
            "system-out": [
              "        \"-r\","
            ]
          },
          {
            "name": "Mutant #1182",
            "file": "chasten/main.py",
            "line": 311,
            "system-out": [
              "        help=\"A directory for storing results in a markdown file\","
            ]
          },
          {
            "name": "Mutant #1183",
            "file": "chasten/main.py",
            "line": 323,
            "system-out": [
              "        help=\"A directory with configuration file(s) or URL to configuration file.\","
            ]
          },
          {
            "name": "Mutant #1184",
            "file": "chasten/main.py",
            "line": 337,
            "system-out": [
              "    display: bool = typer.Option(False, help=\"Display results using frogmouth\"),"
            ]
          },
          {
            "name": "Mutant #1185",
            "file": "chasten/main.py",
            "line": 337,
            "system-out": [
              "    display: bool = typer.Option(False, help=\"Display results using frogmouth\"),"
            ]
          },
          {
            "name": "Mutant #1186",
            "file": "chasten/main.py",
            "line": 338,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Enable verbose mode output.\"),"
            ]
          },
          {
            "name": "Mutant #1187",
            "file": "chasten/main.py",
            "line": 338,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Enable verbose mode output.\"),"
            ]
          },
          {
            "name": "Mutant #1188",
            "file": "chasten/main.py",
            "line": 339,
            "system-out": [
              "    save: bool = typer.Option(False, help=\"Enable saving of output file(s).\"),"
            ]
          },
          {
            "name": "Mutant #1189",
            "file": "chasten/main.py",
            "line": 339,
            "system-out": [
              "    save: bool = typer.Option(False, help=\"Enable saving of output file(s).\"),"
            ]
          },
          {
            "name": "Mutant #1190",
            "file": "chasten/main.py",
            "line": 340,
            "system-out": [
              "    force: bool = typer.Option(False, help=\"Force creation of new markdown file\"),"
            ]
          },
          {
            "name": "Mutant #1191",
            "file": "chasten/main.py",
            "line": 340,
            "system-out": [
              "    force: bool = typer.Option(False, help=\"Force creation of new markdown file\"),"
            ]
          },
          {
            "name": "Mutant #1192",
            "file": "chasten/main.py",
            "line": 349,
            "system-out": [
              "    output.logger.debug(\"Analysis Started.\")"
            ]
          },
          {
            "name": "Mutant #1193",
            "file": "chasten/main.py",
            "line": 361,
            "system-out": [
              "    output.logger.debug(f\"Current version of chasten: {chasten_version}\")"
            ]
          },
          {
            "name": "Mutant #1194",
            "file": "chasten/main.py",
            "line": 364,
            "system-out": [
              "        attribute=str(checks.fix_check_criterion(check_include[0])),"
            ]
          },
          {
            "name": "Mutant #1195",
            "file": "chasten/main.py",
            "line": 365,
            "system-out": [
              "        value=str(checks.fix_check_criterion(check_include[1])),"
            ]
          },
          {
            "name": "Mutant #1196",
            "file": "chasten/main.py",
            "line": 366,
            "system-out": [
              "        confidence=int(checks.fix_check_criterion(check_include[2])),"
            ]
          },
          {
            "name": "Mutant #1197",
            "file": "chasten/main.py",
            "line": 369,
            "system-out": [
              "        attribute=str(checks.fix_check_criterion(check_exclude[0])),"
            ]
          },
          {
            "name": "Mutant #1198",
            "file": "chasten/main.py",
            "line": 370,
            "system-out": [
              "        value=str(checks.fix_check_criterion(check_exclude[1])),"
            ]
          },
          {
            "name": "Mutant #1199",
            "file": "chasten/main.py",
            "line": 371,
            "system-out": [
              "        confidence=int(checks.fix_check_criterion(check_exclude[2])),"
            ]
          },
          {
            "name": "Mutant #1200",
            "file": "chasten/main.py",
            "line": 395,
            "system-out": [
              "    if not validated:"
            ]
          },
          {
            "name": "Mutant #1201",
            "file": "chasten/main.py",
            "line": 397,
            "system-out": [
              "            \"\\n:person_shrugging: Cannot perform analysis due to configuration error(s).\\n\""
            ]
          },
          {
            "name": "Mutant #1202",
            "file": "chasten/main.py",
            "line": 399,
            "system-out": [
              "        output.logger.debug(\"Cannot perform analysis due to configuration error(s)\")"
            ]
          },
          {
            "name": "Mutant #1203",
            "file": "chasten/main.py",
            "line": 406,
            "system-out": [
              "    ]"
            ]
          },
          {
            "name": "Mutant #1204",
            "file": "chasten/main.py",
            "line": 410,
            "system-out": [
              "        check_list, include=True, *check_include"
            ]
          },
          {
            "name": "Mutant #1205",
            "file": "chasten/main.py",
            "line": 414,
            "system-out": [
              "        check_list, include=False, *check_exclude"
            ]
          },
          {
            "name": "Mutant #1206",
            "file": "chasten/main.py",
            "line": 421,
            "system-out": [
              "    if not filesystem.confirm_valid_directory("
            ]
          },
          {
            "name": "Mutant #1207",
            "file": "chasten/main.py",
            "line": 423,
            "system-out": [
              "    ) and not filesystem.confirm_valid_file(input_path):"
            ]
          },
          {
            "name": "Mutant #1208",
            "file": "chasten/main.py",
            "line": 423,
            "system-out": [
              "    ) and not filesystem.confirm_valid_file(input_path):"
            ]
          },
          {
            "name": "Mutant #1209",
            "file": "chasten/main.py",
            "line": 425,
            "system-out": [
              "            \"\\n:person_shrugging: Cannot perform analysis due to invalid search directory.\\n\""
            ]
          },
          {
            "name": "Mutant #1210",
            "file": "chasten/main.py",
            "line": 430,
            "system-out": [
              "        analysis_result = \"\""
            ]
          },
          {
            "name": "Mutant #1211",
            "file": "chasten/main.py",
            "line": 431,
            "system-out": [
              "        analysis_file_dir = store_result / ANALYSIS_FILE"
            ]
          },
          {
            "name": "Mutant #1212",
            "file": "chasten/main.py",
            "line": 439,
            "system-out": [
              "                    sys.exit(0)"
            ]
          },
          {
            "name": "Mutant #1213",
            "file": "chasten/main.py",
            "line": 442,
            "system-out": [
              "                        \"File already exists: use --force to recreate markdown directory.\""
            ]
          },
          {
            "name": "Mutant #1214",
            "file": "chasten/main.py",
            "line": 446,
            "system-out": [
              "                analysis_file_dir.write_text(\"\")"
            ]
          },
          {
            "name": "Mutant #1215",
            "file": "chasten/main.py",
            "line": 453,
            "system-out": [
              "    output.console.print(f\":sparkles: Analyzing Python source code in: {input_path}\")"
            ]
          },
          {
            "name": "Mutant #1216",
            "file": "chasten/main.py",
            "line": 456,
            "system-out": [
              "    output.console.print(f\":tada: Performing {len(check_list)} check(s):\")"
            ]
          },
          {
            "name": "Mutant #1217",
            "file": "chasten/main.py",
            "line": 459,
            "system-out": [
              "    check_status_list: List[bool] = []"
            ]
          },
          {
            "name": "Mutant #1218",
            "file": "chasten/main.py",
            "line": 461,
            "system-out": [
              "    if xpath == \"1.0\":"
            ]
          },
          {
            "name": "Mutant #1219",
            "file": "chasten/main.py",
            "line": 461,
            "system-out": [
              "    if xpath == \"1.0\":"
            ]
          },
          {
            "name": "Mutant #1220",
            "file": "chasten/main.py",
            "line": 462,
            "system-out": [
              "        output.logger.debug(\"Using XPath version 1.0\")"
            ]
          },
          {
            "name": "Mutant #1221",
            "file": "chasten/main.py",
            "line": 464,
            "system-out": [
              "        output.logger.debug(\"Using XPath version 2.0\")"
            ]
          },
          {
            "name": "Mutant #1222",
            "file": "chasten/main.py",
            "line": 479,
            "system-out": [
              "        output.logger.debug(f\"check id: {check_id}\")"
            ]
          },
          {
            "name": "Mutant #1223",
            "file": "chasten/main.py",
            "line": 488,
            "system-out": [
              "        if xpath == \"1.0\":"
            ]
          },
          {
            "name": "Mutant #1224",
            "file": "chasten/main.py",
            "line": 488,
            "system-out": [
              "        if xpath == \"1.0\":"
            ]
          },
          {
            "name": "Mutant #1225",
            "file": "chasten/main.py",
            "line": 490,
            "system-out": [
              "                paths=valid_directories, expression=current_xpath_pattern, xpath2=False"
            ]
          },
          {
            "name": "Mutant #1226",
            "file": "chasten/main.py",
            "line": 494,
            "system-out": [
              "                paths=valid_directories, expression=current_xpath_pattern, xpath2=True"
            ]
          },
          {
            "name": "Mutant #1227",
            "file": "chasten/main.py",
            "line": 520,
            "system-out": [
              "            check_status = True"
            ]
          },
          {
            "name": "Mutant #1228",
            "file": "chasten/main.py",
            "line": 525,
            "system-out": [
              "        current_xpath_pattern_escape = current_xpath_pattern.replace(\"[\", \"\\\\[\")"
            ]
          },
          {
            "name": "Mutant #1229",
            "file": "chasten/main.py",
            "line": 525,
            "system-out": [
              "        current_xpath_pattern_escape = current_xpath_pattern.replace(\"[\", \"\\\\[\")"
            ]
          },
          {
            "name": "Mutant #1230",
            "file": "chasten/main.py",
            "line": 528,
            "system-out": [
              "            f\"  {check_status_symbol} id: '{check_id}', name: '{check_name}'\""
            ]
          },
          {
            "name": "Mutant #1231",
            "file": "chasten/main.py",
            "line": 529,
            "system-out": [
              "            + f\", pattern: '{current_xpath_pattern_escape}', min={min_count}, max={max_count}\""
            ]
          },
          {
            "name": "Mutant #1232",
            "file": "chasten/main.py",
            "line": 529,
            "system-out": [
              "            + f\", pattern: '{current_xpath_pattern_escape}', min={min_count}, max={max_count}\""
            ]
          },
          {
            "name": "Mutant #1233",
            "file": "chasten/main.py",
            "line": 534,
            "system-out": [
              "                \"PASSED:\""
            ]
          },
          {
            "name": "Mutant #1234",
            "file": "chasten/main.py",
            "line": 535,
            "system-out": [
              "                if check_status_symbol == \"[green]\\u2713[/green]\""
            ]
          },
          {
            "name": "Mutant #1235",
            "file": "chasten/main.py",
            "line": 535,
            "system-out": [
              "                if check_status_symbol == \"[green]\\u2713[/green]\""
            ]
          },
          {
            "name": "Mutant #1236",
            "file": "chasten/main.py",
            "line": 536,
            "system-out": [
              "                else \"FAILED:\""
            ]
          },
          {
            "name": "Mutant #1237",
            "file": "chasten/main.py",
            "line": 539,
            "system-out": [
              "            analysis_result += ("
            ]
          },
          {
            "name": "Mutant #1238",
            "file": "chasten/main.py",
            "line": 539,
            "system-out": [
              "            analysis_result += ("
            ]
          },
          {
            "name": "Mutant #1239",
            "file": "chasten/main.py",
            "line": 540,
            "system-out": [
              "                f\"\\n# {check_pass} **ID:** '{check_id}', **Name:** '{check_name}'\""
            ]
          },
          {
            "name": "Mutant #1240",
            "file": "chasten/main.py",
            "line": 541,
            "system-out": [
              "                + f\", **Pattern:** '{current_xpath_pattern_escape}', min={min_count}, max={max_count}\\n\\n\""
            ]
          },
          {
            "name": "Mutant #1241",
            "file": "chasten/main.py",
            "line": 541,
            "system-out": [
              "                + f\", **Pattern:** '{current_xpath_pattern_escape}', min={min_count}, max={max_count}\\n\\n\""
            ]
          },
          {
            "name": "Mutant #1242",
            "file": "chasten/main.py",
            "line": 551,
            "system-out": [
              "        if len(match_generator_list) == 0:"
            ]
          },
          {
            "name": "Mutant #1243",
            "file": "chasten/main.py",
            "line": 551,
            "system-out": [
              "        if len(match_generator_list) == 0:"
            ]
          },
          {
            "name": "Mutant #1244",
            "file": "chasten/main.py",
            "line": 578,
            "system-out": [
              "                f\"    {small_bullet_unicode} {file_name} - {len(matches_list)} matches\""
            ]
          },
          {
            "name": "Mutant #1245",
            "file": "chasten/main.py",
            "line": 582,
            "system-out": [
              "                analysis_result += f\"    - {file_name} - {len(matches_list)} matches\\n\""
            ]
          },
          {
            "name": "Mutant #1246",
            "file": "chasten/main.py",
            "line": 582,
            "system-out": [
              "                analysis_result += f\"    - {file_name} - {len(matches_list)} matches\\n\""
            ]
          },
          {
            "name": "Mutant #1247",
            "file": "chasten/main.py",
            "line": 582,
            "system-out": [
              "                analysis_result += f\"    - {file_name} - {len(matches_list)} matches\\n\""
            ]
          },
          {
            "name": "Mutant #1248",
            "file": "chasten/main.py",
            "line": 587,
            "system-out": [
              "            if len(matches_list) > 0:"
            ]
          },
          {
            "name": "Mutant #1249",
            "file": "chasten/main.py",
            "line": 587,
            "system-out": [
              "            if len(matches_list) > 0:"
            ]
          },
          {
            "name": "Mutant #1250",
            "file": "chasten/main.py",
            "line": 588,
            "system-out": [
              "                current_result_source._filelines = matches_list[0].file_lines"
            ]
          },
          {
            "name": "Mutant #1251",
            "file": "chasten/main.py",
            "line": 607,
            "system-out": [
              "                        linematch=current_match.file_lines[position_end - 1].lstrip("
            ]
          },
          {
            "name": "Mutant #1252",
            "file": "chasten/main.py",
            "line": 607,
            "system-out": [
              "                        linematch=current_match.file_lines[position_end - 1].lstrip("
            ]
          },
          {
            "name": "Mutant #1253",
            "file": "chasten/main.py",
            "line": 613,
            "system-out": [
              "                                0,"
            ]
          },
          {
            "name": "Mutant #1254",
            "file": "chasten/main.py",
            "line": 614,
            "system-out": [
              "                                position_end - constants.markers.Code_Context,"
            ]
          },
          {
            "name": "Mutant #1255",
            "file": "chasten/main.py",
            "line": 616,
            "system-out": [
              "                            position_end + constants.markers.Code_Context,"
            ]
          },
          {
            "name": "Mutant #1256",
            "file": "chasten/main.py",
            "line": 629,
            "system-out": [
              "        output.console.print(f\"   = {len(match_generator_list)} total matches\\n\")"
            ]
          },
          {
            "name": "Mutant #1257",
            "file": "chasten/main.py",
            "line": 634,
            "system-out": [
              "        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\""
            ]
          },
          {
            "name": "Mutant #1258",
            "file": "chasten/main.py",
            "line": 634,
            "system-out": [
              "        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\""
            ]
          },
          {
            "name": "Mutant #1259",
            "file": "chasten/main.py",
            "line": 634,
            "system-out": [
              "        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\""
            ]
          },
          {
            "name": "Mutant #1260",
            "file": "chasten/main.py",
            "line": 634,
            "system-out": [
              "        f\":computer: {total_result[0]} / {total_result[1]} checks passed ({total_result[2]}%)\\n\""
            ]
          },
          {
            "name": "Mutant #1261",
            "file": "chasten/main.py",
            "line": 644,
            "system-out": [
              "        output.console.print(f\"\\n:sparkles: Saved the file '{saved_file_name}'\")"
            ]
          },
          {
            "name": "Mutant #1262",
            "file": "chasten/main.py",
            "line": 646,
            "system-out": [
              "    if save_XML is not None or view_XML is not None:"
            ]
          },
          {
            "name": "Mutant #1263",
            "file": "chasten/main.py",
            "line": 646,
            "system-out": [
              "    if save_XML is not None or view_XML is not None:"
            ]
          },
          {
            "name": "Mutant #1264",
            "file": "chasten/main.py",
            "line": 646,
            "system-out": [
              "    if save_XML is not None or view_XML is not None:"
            ]
          },
          {
            "name": "Mutant #1265",
            "file": "chasten/main.py",
            "line": 647,
            "system-out": [
              "        output.console.print(\":memo: Saving XML...\")"
            ]
          },
          {
            "name": "Mutant #1266",
            "file": "chasten/main.py",
            "line": 651,
            "system-out": [
              "                    each_file = Path(input_path) / Path(each_file)  # type: ignore # noqa: PLW2901"
            ]
          },
          {
            "name": "Mutant #1267",
            "file": "chasten/main.py",
            "line": 653,
            "system-out": [
              "                        not os.path.isdir(each_file)"
            ]
          },
          {
            "name": "Mutant #1268",
            "file": "chasten/main.py",
            "line": 655,
            "system-out": [
              "                        and str(each_file).endswith(\".py\")"
            ]
          },
          {
            "name": "Mutant #1269",
            "file": "chasten/main.py",
            "line": 655,
            "system-out": [
              "                        and str(each_file).endswith(\".py\")"
            ]
          },
          {
            "name": "Mutant #1270",
            "file": "chasten/main.py",
            "line": 661,
            "system-out": [
              "                            contents, each_file, auto_dedent=False"
            ]
          },
          {
            "name": "Mutant #1271",
            "file": "chasten/main.py",
            "line": 666,
            "system-out": [
              "                        if view_XML is not None:"
            ]
          },
          {
            "name": "Mutant #1272",
            "file": "chasten/main.py",
            "line": 669,
            "system-out": [
              "                                    xml_root, pretty_print=True"
            ]
          },
          {
            "name": "Mutant #1273",
            "file": "chasten/main.py",
            "line": 670,
            "system-out": [
              "                                ).decode(\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1274",
            "file": "chasten/main.py",
            "line": 674,
            "system-out": [
              "                            sub_file = Path(each_file) / Path(sub_file)  # type: ignore # noqa: PLW2901"
            ]
          },
          {
            "name": "Mutant #1275",
            "file": "chasten/main.py",
            "line": 675,
            "system-out": [
              "                            if str(sub_file).endswith(\".py\"):"
            ]
          },
          {
            "name": "Mutant #1276",
            "file": "chasten/main.py",
            "line": 678,
            "system-out": [
              "                                    contents, sub_file, auto_dedent=False"
            ]
          },
          {
            "name": "Mutant #1277",
            "file": "chasten/main.py",
            "line": 682,
            "system-out": [
              "                                if view_XML is not None:"
            ]
          },
          {
            "name": "Mutant #1278",
            "file": "chasten/main.py",
            "line": 685,
            "system-out": [
              "                                            xml_root, pretty_print=True"
            ]
          },
          {
            "name": "Mutant #1279",
            "file": "chasten/main.py",
            "line": 686,
            "system-out": [
              "                                        ).decode(\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1280",
            "file": "chasten/main.py",
            "line": 688,
            "system-out": [
              "            elif os.path.isfile(input_path) and str(input_path).endswith(\".py\"):"
            ]
          },
          {
            "name": "Mutant #1281",
            "file": "chasten/main.py",
            "line": 688,
            "system-out": [
              "            elif os.path.isfile(input_path) and str(input_path).endswith(\".py\"):"
            ]
          },
          {
            "name": "Mutant #1282",
            "file": "chasten/main.py",
            "line": 691,
            "system-out": [
              "                    contents, input_path, auto_dedent=False"
            ]
          },
          {
            "name": "Mutant #1283",
            "file": "chasten/main.py",
            "line": 695,
            "system-out": [
              "                if view_XML is not None:"
            ]
          },
          {
            "name": "Mutant #1284",
            "file": "chasten/main.py",
            "line": 697,
            "system-out": [
              "                        pyastgrep.xml.tostring(xml_root, pretty_print=True).decode("
            ]
          },
          {
            "name": "Mutant #1285",
            "file": "chasten/main.py",
            "line": 698,
            "system-out": [
              "                            \"utf-8\""
            ]
          },
          {
            "name": "Mutant #1286",
            "file": "chasten/main.py",
            "line": 702,
            "system-out": [
              "            output.console.print(\":sweat: Sorry, could not convert to xml.\")"
            ]
          },
          {
            "name": "Mutant #1287",
            "file": "chasten/main.py",
            "line": 707,
            "system-out": [
              "    elapsed_time = end_time - start_time"
            ]
          },
          {
            "name": "Mutant #1288",
            "file": "chasten/main.py",
            "line": 709,
            "system-out": [
              "    if not all_checks_passed:"
            ]
          },
          {
            "name": "Mutant #1289",
            "file": "chasten/main.py",
            "line": 710,
            "system-out": [
              "        output.console.print(\":sweat: At least one check did not pass.\")"
            ]
          },
          {
            "name": "Mutant #1290",
            "file": "chasten/main.py",
            "line": 713,
            "system-out": [
              "            analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1291",
            "file": "chasten/main.py",
            "line": 715,
            "system-out": [
              "                f\"\\n:sparkles: Results saved in: {os.path.abspath(analysis_file_dir)}\\n\""
            ]
          },
          {
            "name": "Mutant #1292",
            "file": "chasten/main.py",
            "line": 719,
            "system-out": [
              "        f\"\\n:joy: All checks passed. Elapsed Time: {elapsed_time} seconds\""
            ]
          },
          {
            "name": "Mutant #1293",
            "file": "chasten/main.py",
            "line": 721,
            "system-out": [
              "    output.logger.debug(\"Analysis complete.\")"
            ]
          },
          {
            "name": "Mutant #1294",
            "file": "chasten/main.py",
            "line": 725,
            "system-out": [
              "        analysis_file_dir.write_text(analysis_result, encoding=\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1295",
            "file": "chasten/main.py",
            "line": 726,
            "system-out": [
              "        output.console.print(f\"\\n:sparkles: Results saved in: {result_path}\\n\")"
            ]
          },
          {
            "name": "Mutant #1296",
            "file": "chasten/main.py",
            "line": 735,
            "system-out": [
              "        help=\"Directories, files, or globs for chasten's JSON result file(s).\","
            ]
          },
          {
            "name": "Mutant #1297",
            "file": "chasten/main.py",
            "line": 741,
            "system-out": [
              "        help=\"A directory for saving converted file(s).\","
            ]
          },
          {
            "name": "Mutant #1298",
            "file": "chasten/main.py",
            "line": 763,
            "system-out": [
              "        help=\"Create converted results files even if they exist\","
            ]
          },
          {
            "name": "Mutant #1299",
            "file": "chasten/main.py",
            "line": 778,
            "system-out": [
              "    output.logger.debug(\"Integrate function started.\")"
            ]
          },
          {
            "name": "Mutant #1300",
            "file": "chasten/main.py",
            "line": 781,
            "system-out": [
              "    output.console.print(\":sparkles: Combining data file(s) in:\")"
            ]
          },
          {
            "name": "Mutant #1301",
            "file": "chasten/main.py",
            "line": 782,
            "system-out": [
              "    output.logger.debug(\":sparkles: Combining data file(s) in:\")"
            ]
          },
          {
            "name": "Mutant #1302",
            "file": "chasten/main.py",
            "line": 788,
            "system-out": [
              "    output.console.print(f\"\\n:sparkles: Total of {count} files in all directories.\")"
            ]
          },
          {
            "name": "Mutant #1303",
            "file": "chasten/main.py",
            "line": 797,
            "system-out": [
              "        output.console.print(f\"\\n:sparkles: Saved the file '{combined_json_file_name}'\")"
            ]
          },
          {
            "name": "Mutant #1304",
            "file": "chasten/main.py",
            "line": 798,
            "system-out": [
              "        output.logger.debug(f\"Saved the file '{combined_json_file_name}'.\")"
            ]
          },
          {
            "name": "Mutant #1305",
            "file": "chasten/main.py",
            "line": 806,
            "system-out": [
              "    output.logger.debug(\"Flattened JSON and created SQLite database.\")"
            ]
          },
          {
            "name": "Mutant #1306",
            "file": "chasten/main.py",
            "line": 810,
            "system-out": [
              "            f\"\\n:sparkles: Created this directory structure in {Path(combined_flattened_directory).parent}:\""
            ]
          },
          {
            "name": "Mutant #1307",
            "file": "chasten/main.py",
            "line": 817,
            "system-out": [
              "        output.logger.debug(\"Integrate function completed successfully.\")"
            ]
          },
          {
            "name": "Mutant #1308",
            "file": "chasten/main.py",
            "line": 823,
            "system-out": [
              "        help=\"SQLite3 database file storing chasten's results.\","
            ]
          },
          {
            "name": "Mutant #1309",
            "file": "chasten/main.py",
            "line": 826,
            "system-out": [
              "        dir_okay=False,"
            ]
          },
          {
            "name": "Mutant #1310",
            "file": "chasten/main.py",
            "line": 832,
            "system-out": [
              "        8001,"
            ]
          },
          {
            "name": "Mutant #1311",
            "file": "chasten/main.py",
            "line": 833,
            "system-out": [
              "        \"--port\","
            ]
          },
          {
            "name": "Mutant #1312",
            "file": "chasten/main.py",
            "line": 834,
            "system-out": [
              "        \"-p\","
            ]
          },
          {
            "name": "Mutant #1313",
            "file": "chasten/main.py",
            "line": 835,
            "system-out": [
              "        help=\"Port on which to run a datasette instance\","
            ]
          },
          {
            "name": "Mutant #1314",
            "file": "chasten/main.py",
            "line": 839,
            "system-out": [
              "        \"--metadata\","
            ]
          },
          {
            "name": "Mutant #1315",
            "file": "chasten/main.py",
            "line": 840,
            "system-out": [
              "        \"-m\","
            ]
          },
          {
            "name": "Mutant #1316",
            "file": "chasten/main.py",
            "line": 841,
            "system-out": [
              "        help=\"Meta-data file storing database configuration.\","
            ]
          },
          {
            "name": "Mutant #1317",
            "file": "chasten/main.py",
            "line": 879,
            "system-out": [
              "    label = \":sparkles: Starting a local datasette instance:\""
            ]
          },
          {
            "name": "Mutant #1318",
            "file": "chasten/main.py",
            "line": 881,
            "system-out": [
              "        label, database_path, metadata, port, publish=False"
            ]
          },
          {
            "name": "Mutant #1319",
            "file": "chasten/main.py",
            "line": 890,
            "system-out": [
              "        publish=False,"
            ]
          },
          {
            "name": "Mutant #1320",
            "file": "chasten/main.py",
            "line": 920,
            "system-out": [
              "        \"--platform\","
            ]
          },
          {
            "name": "Mutant #1321",
            "file": "chasten/main.py",
            "line": 922,
            "system-out": [
              "        help=\"Specify the deployment platform for datasette.\","
            ]
          },
          {
            "name": "Mutant #1322",
            "file": "chasten/main.py",
            "line": 954,
            "system-out": [
              "        f\":wave: Make sure that you have previously logged into the '{datasette_platform.value}' platform\""
            ]
          },
          {
            "name": "Mutant #1323",
            "file": "chasten/main.py",
            "line": 957,
            "system-out": [
              "    label = f\":sparkles: Publishing a datasette to {datasette_platform.value}:\""
            ]
          },
          {
            "name": "Mutant #1324",
            "file": "chasten/main.py",
            "line": 958,
            "system-out": [
              "    display_serve_or_publish_details(label, database_path, metadata, publish=True)"
            ]
          },
          {
            "name": "Mutant #1325",
            "file": "chasten/main.py",
            "line": 966,
            "system-out": [
              "        publish=True,"
            ]
          },
          {
            "name": "Mutant #1326",
            "file": "chasten/main.py",
            "line": 993,
            "system-out": [
              "    typer.echo(f\"chasten {version_string}\")"
            ]
          },
          {
            "name": "Mutant #1327",
            "file": "chasten/main.py",
            "line": 153,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1328",
            "file": "chasten/main.py",
            "line": 194,
            "system-out": [
              "    output.logger.debug(f\"Display verbose output? {verbose}\")"
            ]
          },
          {
            "name": "Mutant #1329",
            "file": "chasten/main.py",
            "line": 195,
            "system-out": [
              "    output.logger.debug(f\"Debug level? {debug_level.value}\")"
            ]
          },
          {
            "name": "Mutant #1330",
            "file": "chasten/main.py",
            "line": 196,
            "system-out": [
              "    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            ]
          },
          {
            "name": "Mutant #1331",
            "file": "chasten/main.py",
            "line": 251,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1332",
            "file": "chasten/main.py",
            "line": 267,
            "system-out": [
              "        (None, None, 0),"
            ]
          },
          {
            "name": "Mutant #1333",
            "file": "chasten/main.py",
            "line": 288,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1334",
            "file": "chasten/main.py",
            "line": 290,
            "system-out": [
              "        dir_okay=True,"
            ]
          },
          {
            "name": "Mutant #1335",
            "file": "chasten/main.py",
            "line": 291,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1336",
            "file": "chasten/main.py",
            "line": 293,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1337",
            "file": "chasten/main.py",
            "line": 312,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1338",
            "file": "chasten/main.py",
            "line": 313,
            "system-out": [
              "        file_okay=False,"
            ]
          },
          {
            "name": "Mutant #1339",
            "file": "chasten/main.py",
            "line": 314,
            "system-out": [
              "        dir_okay=True,"
            ]
          },
          {
            "name": "Mutant #1340",
            "file": "chasten/main.py",
            "line": 315,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1341",
            "file": "chasten/main.py",
            "line": 316,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1342",
            "file": "chasten/main.py",
            "line": 317,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1343",
            "file": "chasten/main.py",
            "line": 321,
            "system-out": [
              "        \"--config\","
            ]
          },
          {
            "name": "Mutant #1344",
            "file": "chasten/main.py",
            "line": 322,
            "system-out": [
              "        \"-c\","
            ]
          },
          {
            "name": "Mutant #1345",
            "file": "chasten/main.py",
            "line": 327,
            "system-out": [
              "        \"--debug-level\","
            ]
          },
          {
            "name": "Mutant #1346",
            "file": "chasten/main.py",
            "line": 328,
            "system-out": [
              "        \"-l\","
            ]
          },
          {
            "name": "Mutant #1347",
            "file": "chasten/main.py",
            "line": 329,
            "system-out": [
              "        help=\"Specify the level of debugging output.\","
            ]
          },
          {
            "name": "Mutant #1348",
            "file": "chasten/main.py",
            "line": 333,
            "system-out": [
              "        \"--debug-dest\","
            ]
          },
          {
            "name": "Mutant #1349",
            "file": "chasten/main.py",
            "line": 334,
            "system-out": [
              "        \"-t\","
            ]
          },
          {
            "name": "Mutant #1350",
            "file": "chasten/main.py",
            "line": 335,
            "system-out": [
              "        help=\"Specify the destination for debugging output.\","
            ]
          },
          {
            "name": "Mutant #1351",
            "file": "chasten/main.py",
            "line": 345,
            "system-out": [
              "    output.logger.debug(f\"Display verbose output? {verbose}\")"
            ]
          },
          {
            "name": "Mutant #1352",
            "file": "chasten/main.py",
            "line": 346,
            "system-out": [
              "    output.logger.debug(f\"Debug level? {debug_level.value}\")"
            ]
          },
          {
            "name": "Mutant #1353",
            "file": "chasten/main.py",
            "line": 347,
            "system-out": [
              "    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            ]
          },
          {
            "name": "Mutant #1354",
            "file": "chasten/main.py",
            "line": 434,
            "system-out": [
              "            if not force:"
            ]
          },
          {
            "name": "Mutant #1355",
            "file": "chasten/main.py",
            "line": 731,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1356",
            "file": "chasten/main.py",
            "line": 733,
            "system-out": [
              "    project: str = typer.Argument(help=\"Name of the project.\"),"
            ]
          },
          {
            "name": "Mutant #1357",
            "file": "chasten/__main__.py",
            "line": 5,
            "system-out": [
              "cli(prog_name=\"chasten\")"
            ]
          },
          {
            "name": "Mutant #1358",
            "file": "chasten/main.py",
            "line": 739,
            "system-out": [
              "        \"--save-directory\","
            ]
          },
          {
            "name": "Mutant #1359",
            "file": "chasten/main.py",
            "line": 740,
            "system-out": [
              "        \"-s\","
            ]
          },
          {
            "name": "Mutant #1360",
            "file": "chasten/output.py",
            "line": 16,
            "system-out": [
              "logger: logging.Logger = logging.getLogger()"
            ]
          },
          {
            "name": "Mutant #1361",
            "file": "chasten/output.py",
            "line": 45,
            "system-out": [
              "        console.print(\":sparkles: Configured with these parameters:\")"
            ]
          },
          {
            "name": "Mutant #1362",
            "file": "chasten/output.py",
            "line": 50,
            "system-out": [
              "                f\"{constants.markers.Indent}{configuration_current} = {configurations[configuration_current]}\""
            ]
          },
          {
            "name": "Mutant #1363",
            "file": "chasten/output.py",
            "line": 72,
            "system-out": [
              "        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline"
            ]
          },
          {
            "name": "Mutant #1364",
            "file": "chasten/output.py",
            "line": 72,
            "system-out": [
              "        constants.chasten.Emoji + constants.markers.Space + constants.chasten.Tagline"
            ]
          },
          {
            "name": "Mutant #1365",
            "file": "chasten/output.py",
            "line": 95,
            "system-out": [
              "    console.print(\":sparkles: Finished running test suite for the specified program\")"
            ]
          },
          {
            "name": "Mutant #1366",
            "file": "chasten/output.py",
            "line": 108,
            "system-out": [
              "    grouped_files: Dict[Path, List[str]] = {}"
            ]
          },
          {
            "name": "Mutant #1367",
            "file": "chasten/output.py",
            "line": 122,
            "system-out": [
              "        if directory not in grouped_files:"
            ]
          },
          {
            "name": "Mutant #1368",
            "file": "chasten/output.py",
            "line": 132,
            "system-out": [
              "    if len(file_name) > max_length:"
            ]
          },
          {
            "name": "Mutant #1369",
            "file": "chasten/output.py",
            "line": 133,
            "system-out": [
              "        return \"... \" + file_name[-(max_length - 3) :]"
            ]
          },
          {
            "name": "Mutant #1370",
            "file": "chasten/output.py",
            "line": 133,
            "system-out": [
              "        return \"... \" + file_name[-(max_length - 3) :]"
            ]
          },
          {
            "name": "Mutant #1371",
            "file": "chasten/output.py",
            "line": 133,
            "system-out": [
              "        return \"... \" + file_name[-(max_length - 3) :]"
            ]
          },
          {
            "name": "Mutant #1372",
            "file": "chasten/output.py",
            "line": 133,
            "system-out": [
              "        return \"... \" + file_name[-(max_length - 3) :]"
            ]
          },
          {
            "name": "Mutant #1373",
            "file": "chasten/output.py",
            "line": 133,
            "system-out": [
              "        return \"... \" + file_name[-(max_length - 3) :]"
            ]
          },
          {
            "name": "Mutant #1374",
            "file": "chasten/output.py",
            "line": 148,
            "system-out": [
              "        console.print(f\"{small_bullet_unicode} Directory: {directory}\")"
            ]
          },
          {
            "name": "Mutant #1375",
            "file": "chasten/output.py",
            "line": 149,
            "system-out": [
              "        filecount = 0"
            ]
          },
          {
            "name": "Mutant #1376",
            "file": "chasten/output.py",
            "line": 151,
            "system-out": [
              "            filecount = +1"
            ]
          },
          {
            "name": "Mutant #1377",
            "file": "chasten/output.py",
            "line": 151,
            "system-out": [
              "            filecount = +1"
            ]
          },
          {
            "name": "Mutant #1378",
            "file": "chasten/output.py",
            "line": 153,
            "system-out": [
              "                f\"  {small_bullet_unicode} File: '{shorten_file_name(file_name, 120)}'\""
            ]
          },
          {
            "name": "Mutant #1379",
            "file": "chasten/output.py",
            "line": 153,
            "system-out": [
              "                f\"  {small_bullet_unicode} File: '{shorten_file_name(file_name, 120)}'\""
            ]
          },
          {
            "name": "Mutant #1380",
            "file": "chasten/output.py",
            "line": 156,
            "system-out": [
              "                f\"  {small_bullet_unicode} file(s) {int(filecount)} in this directory\""
            ]
          },
          {
            "name": "Mutant #1381",
            "file": "chasten/output.py",
            "line": 160,
            "system-out": [
              "def print_analysis_details(chasten: results.Chasten, verbose: bool = False) -> None:"
            ]
          },
          {
            "name": "Mutant #1382",
            "file": "chasten/output.py",
            "line": 169,
            "system-out": [
              "    if not verbose:"
            ]
          },
          {
            "name": "Mutant #1383",
            "file": "chasten/output.py",
            "line": 171,
            "system-out": [
              "    opt_print_log(verbose, label=\"\\n:tada: Results from the analysis:\")"
            ]
          },
          {
            "name": "Mutant #1384",
            "file": "chasten/output.py",
            "line": 175,
            "system-out": [
              "        current_check: results.Check = current_source.check  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1385",
            "file": "chasten/output.py",
            "line": 177,
            "system-out": [
              "        console.print(\"\\n:tada: Check:\")"
            ]
          },
          {
            "name": "Mutant #1386",
            "file": "chasten/output.py",
            "line": 205,
            "system-out": [
              "                expand=False,"
            ]
          },
          {
            "name": "Mutant #1387",
            "file": "chasten/output.py",
            "line": 206,
            "system-out": [
              "                title=f\"{combined_attribute_label}\","
            ]
          },
          {
            "name": "Mutant #1388",
            "file": "chasten/output.py",
            "line": 209,
            "system-out": [
              "        if len(current_check._matches) > 0:  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1389",
            "file": "chasten/output.py",
            "line": 209,
            "system-out": [
              "        if len(current_check._matches) > 0:  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1390",
            "file": "chasten/output.py",
            "line": 214,
            "system-out": [
              "                label=f\":tada: Found a total of {len(current_check._matches)} matches for '{check_name}' in {current_source.filename}\","
            ]
          },
          {
            "name": "Mutant #1391",
            "file": "chasten/output.py",
            "line": 221,
            "system-out": [
              "                    opt_print_log(verbose, label=\":sparkles: Matching source code:\")"
            ]
          },
          {
            "name": "Mutant #1392",
            "file": "chasten/output.py",
            "line": 234,
            "system-out": [
              "                    all_lines_for_marking = deepcopy(all_lines)"
            ]
          },
          {
            "name": "Mutant #1393",
            "file": "chasten/output.py",
            "line": 237,
            "system-out": [
              "                            0, position_end - constants.markers.Code_Context"
            ]
          },
          {
            "name": "Mutant #1394",
            "file": "chasten/output.py",
            "line": 237,
            "system-out": [
              "                            0, position_end - constants.markers.Code_Context"
            ]
          },
          {
            "name": "Mutant #1395",
            "file": "chasten/output.py",
            "line": 239,
            "system-out": [
              "                        + constants.markers.Code_Context"
            ]
          },
          {
            "name": "Mutant #1396",
            "file": "chasten/output.py",
            "line": 249,
            "system-out": [
              "                        \"\\n\".join(str(line) for line in lines),"
            ]
          },
          {
            "name": "Mutant #1397",
            "file": "chasten/output.py",
            "line": 253,
            "system-out": [
              "                        line_numbers=True,"
            ]
          },
          {
            "name": "Mutant #1398",
            "file": "chasten/output.py",
            "line": 255,
            "system-out": [
              "                            max(1, position_end - constants.markers.Code_Context + 1)"
            ]
          },
          {
            "name": "Mutant #1399",
            "file": "chasten/output.py",
            "line": 255,
            "system-out": [
              "                            max(1, position_end - constants.markers.Code_Context + 1)"
            ]
          },
          {
            "name": "Mutant #1400",
            "file": "chasten/output.py",
            "line": 255,
            "system-out": [
              "                            max(1, position_end - constants.markers.Code_Context + 1)"
            ]
          },
          {
            "name": "Mutant #1401",
            "file": "chasten/output.py",
            "line": 255,
            "system-out": [
              "                            max(1, position_end - constants.markers.Code_Context + 1)"
            ]
          },
          {
            "name": "Mutant #1402",
            "file": "chasten/output.py",
            "line": 264,
            "system-out": [
              "                            expand=False,"
            ]
          },
          {
            "name": "Mutant #1403",
            "file": "chasten/output.py",
            "line": 265,
            "system-out": [
              "                            title=f\"{current_match.path}:{position_end}:{column_offset}\","
            ]
          },
          {
            "name": "Mutant #1404",
            "file": "chasten/main.py",
            "line": 742,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1405",
            "file": "chasten/main.py",
            "line": 743,
            "system-out": [
              "        file_okay=False,"
            ]
          },
          {
            "name": "Mutant #1406",
            "file": "chasten/main.py",
            "line": 744,
            "system-out": [
              "        dir_okay=True,"
            ]
          },
          {
            "name": "Mutant #1407",
            "file": "chasten/main.py",
            "line": 745,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1408",
            "file": "chasten/main.py",
            "line": 746,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1409",
            "file": "chasten/main.py",
            "line": 747,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1410",
            "file": "chasten/main.py",
            "line": 751,
            "system-out": [
              "        \"--debug-level\","
            ]
          },
          {
            "name": "Mutant #1411",
            "file": "chasten/main.py",
            "line": 752,
            "system-out": [
              "        \"-l\","
            ]
          },
          {
            "name": "Mutant #1412",
            "file": "chasten/main.py",
            "line": 753,
            "system-out": [
              "        help=\"Specify the level of debugging output.\","
            ]
          },
          {
            "name": "Mutant #1413",
            "file": "chasten/main.py",
            "line": 757,
            "system-out": [
              "        \"--debug-dest\","
            ]
          },
          {
            "name": "Mutant #1414",
            "file": "chasten/main.py",
            "line": 758,
            "system-out": [
              "        \"-t\","
            ]
          },
          {
            "name": "Mutant #1415",
            "file": "chasten/main.py",
            "line": 759,
            "system-out": [
              "        help=\"Specify the destination for debugging output.\","
            ]
          },
          {
            "name": "Mutant #1416",
            "file": "chasten/main.py",
            "line": 762,
            "system-out": [
              "        False,"
            ]
          },
          {
            "name": "Mutant #1417",
            "file": "chasten/main.py",
            "line": 765,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1418",
            "file": "chasten/main.py",
            "line": 765,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1419",
            "file": "chasten/main.py",
            "line": 820,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1420",
            "file": "chasten/main.py",
            "line": 824,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1421",
            "file": "chasten/main.py",
            "line": 825,
            "system-out": [
              "        file_okay=True,"
            ]
          },
          {
            "name": "Mutant #1422",
            "file": "chasten/main.py",
            "line": 827,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1423",
            "file": "chasten/main.py",
            "line": 828,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1424",
            "file": "chasten/main.py",
            "line": 829,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1425",
            "file": "chasten/main.py",
            "line": 842,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1426",
            "file": "chasten/main.py",
            "line": 843,
            "system-out": [
              "        file_okay=True,"
            ]
          },
          {
            "name": "Mutant #1427",
            "file": "chasten/main.py",
            "line": 844,
            "system-out": [
              "        dir_okay=False,"
            ]
          },
          {
            "name": "Mutant #1428",
            "file": "tests/test_configApp.py",
            "line": 10,
            "system-out": [
              "ALPHABET = \"0123456789!@#$%^&*()_+-=[]|:;'<>.?/~`AaBbCcDdEeFfGgHhIiJjKkLlMmNnOoPpQqRrSsTtUuVvWwXxYyZz\""
            ]
          },
          {
            "name": "Mutant #1429",
            "file": "tests/test_configApp.py",
            "line": 17,
            "system-out": [
              "    [\"for loop\", \"2\", \"True\"],"
            ]
          },
          {
            "name": "Mutant #1430",
            "file": "tests/test_configApp.py",
            "line": 17,
            "system-out": [
              "    [\"for loop\", \"2\", \"True\"],"
            ]
          },
          {
            "name": "Mutant #1431",
            "file": "tests/test_configApp.py",
            "line": 17,
            "system-out": [
              "    [\"for loop\", \"2\", \"True\"],"
            ]
          },
          {
            "name": "Mutant #1432",
            "file": "tests/test_configApp.py",
            "line": 18,
            "system-out": [
              "    [\"while loop\", \"3\", \"False\"],"
            ]
          },
          {
            "name": "Mutant #1433",
            "file": "tests/test_configApp.py",
            "line": 18,
            "system-out": [
              "    [\"while loop\", \"3\", \"False\"],"
            ]
          },
          {
            "name": "Mutant #1434",
            "file": "tests/test_configApp.py",
            "line": 18,
            "system-out": [
              "    [\"while loop\", \"3\", \"False\"],"
            ]
          },
          {
            "name": "Mutant #1435",
            "file": "tests/test_configApp.py",
            "line": 19,
            "system-out": [
              "    [\"function\", \"1\", \"False\"],"
            ]
          },
          {
            "name": "Mutant #1436",
            "file": "tests/test_configApp.py",
            "line": 19,
            "system-out": [
              "    [\"function\", \"1\", \"False\"],"
            ]
          },
          {
            "name": "Mutant #1437",
            "file": "tests/test_configApp.py",
            "line": 19,
            "system-out": [
              "    [\"function\", \"1\", \"False\"],"
            ]
          },
          {
            "name": "Mutant #1438",
            "file": "tests/test_configApp.py",
            "line": 20,
            "system-out": [
              "    [\"assert statement\", \"1\", \"True\"],"
            ]
          },
          {
            "name": "Mutant #1439",
            "file": "tests/test_configApp.py",
            "line": 20,
            "system-out": [
              "    [\"assert statement\", \"1\", \"True\"],"
            ]
          },
          {
            "name": "Mutant #1440",
            "file": "tests/test_configApp.py",
            "line": 20,
            "system-out": [
              "    [\"assert statement\", \"1\", \"True\"],"
            ]
          },
          {
            "name": "Mutant #1441",
            "file": "tests/test_configApp.py",
            "line": 35,
            "system-out": [
              "    expected_check = \"Make a YAML file that checks for:\\n - exactly 2 for loop\\n - at minimum 3 while loop\\n - at minimum 1 function\\n - exactly 1 assert statement\""
            ]
          },
          {
            "name": "Mutant #1442",
            "file": "tests/test_configApp.py",
            "line": 36,
            "system-out": [
              "    assert configApp.write_checks(CSV_CHECK_LIST) == expected_check"
            ]
          },
          {
            "name": "Mutant #1443",
            "file": "tests/test_configApp.py",
            "line": 42,
            "system-out": [
              "    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\""
            ]
          },
          {
            "name": "Mutant #1444",
            "file": "tests/test_configApp.py",
            "line": 42,
            "system-out": [
              "    assert configApp.write_checks([]) == \"[red][ERROR][/red] No checks were supplied\""
            ]
          },
          {
            "name": "Mutant #1445",
            "file": "tests/test_configApp.py",
            "line": 49,
            "system-out": [
              "    file = tmp_dir / \"check_test.txt\""
            ]
          },
          {
            "name": "Mutant #1446",
            "file": "tests/test_configApp.py",
            "line": 49,
            "system-out": [
              "    file = tmp_dir / \"check_test.txt\""
            ]
          },
          {
            "name": "Mutant #1447",
            "file": "tests/test_configApp.py",
            "line": 52,
            "system-out": [
              "    assert configApp.split_file(file) == CSV_CHECK_LIST"
            ]
          },
          {
            "name": "Mutant #1448",
            "file": "tests/test_configApp.py",
            "line": 57,
            "system-out": [
              "    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            ]
          },
          {
            "name": "Mutant #1449",
            "file": "tests/test_configApp.py",
            "line": 57,
            "system-out": [
              "    Pattern=st.text(alphabet=ALPHABET, min_size=3, max_size=150),"
            ]
          },
          {
            "name": "Mutant #1450",
            "file": "tests/test_configApp.py",
            "line": 58,
            "system-out": [
              "    Matches=st.integers(min_value=1, max_value=500),"
            ]
          },
          {
            "name": "Mutant #1451",
            "file": "tests/test_configApp.py",
            "line": 58,
            "system-out": [
              "    Matches=st.integers(min_value=1, max_value=500),"
            ]
          },
          {
            "name": "Mutant #1452",
            "file": "tests/test_configApp.py",
            "line": 60,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1453",
            "file": "tests/test_configApp.py",
            "line": 61,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1454",
            "file": "tests/test_configApp.py",
            "line": 62,
            "system-out": [
              "@settings(suppress_health_check=[HealthCheck.function_scoped_fixture])"
            ]
          },
          {
            "name": "Mutant #1455",
            "file": "tests/test_configApp.py",
            "line": 70,
            "system-out": [
              "    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1456",
            "file": "tests/test_configApp.py",
            "line": 70,
            "system-out": [
              "    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1457",
            "file": "tests/test_configApp.py",
            "line": 70,
            "system-out": [
              "    assert f\"\\n{Pattern},{Matches},{Exact}\" in file.read_text(\"utf-8\")"
            ]
          },
          {
            "name": "Mutant #1458",
            "file": "chasten/main.py",
            "line": 845,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1459",
            "file": "chasten/main.py",
            "line": 846,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1460",
            "file": "chasten/main.py",
            "line": 847,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1461",
            "file": "chasten/main.py",
            "line": 851,
            "system-out": [
              "        \"--debug-level\","
            ]
          },
          {
            "name": "Mutant #1462",
            "file": "chasten/main.py",
            "line": 852,
            "system-out": [
              "        \"-l\","
            ]
          },
          {
            "name": "Mutant #1463",
            "file": "chasten/main.py",
            "line": 853,
            "system-out": [
              "        help=\"Specify the level of debugging output.\","
            ]
          },
          {
            "name": "Mutant #1464",
            "file": "chasten/main.py",
            "line": 857,
            "system-out": [
              "        \"--debug-dest\","
            ]
          },
          {
            "name": "Mutant #1465",
            "file": "chasten/main.py",
            "line": 858,
            "system-out": [
              "        \"-t\","
            ]
          },
          {
            "name": "Mutant #1466",
            "file": "chasten/main.py",
            "line": 859,
            "system-out": [
              "        help=\"Specify the destination for debugging output.\","
            ]
          },
          {
            "name": "Mutant #1467",
            "file": "chasten/main.py",
            "line": 861,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1468",
            "file": "chasten/main.py",
            "line": 861,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1469",
            "file": "chasten/main.py",
            "line": 875,
            "system-out": [
              "    output.logger.debug(f\"Display verbose output? {verbose}\")"
            ]
          },
          {
            "name": "Mutant #1470",
            "file": "chasten/main.py",
            "line": 876,
            "system-out": [
              "    output.logger.debug(f\"Debug level? {debug_level.value}\")"
            ]
          },
          {
            "name": "Mutant #1471",
            "file": "chasten/main.py",
            "line": 877,
            "system-out": [
              "    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            ]
          },
          {
            "name": "Mutant #1472",
            "file": "chasten/main.py",
            "line": 895,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1473",
            "file": "chasten/main.py",
            "line": 898,
            "system-out": [
              "        help=\"SQLite3 database file storing chasten's results.\","
            ]
          },
          {
            "name": "Mutant #1474",
            "file": "chasten/main.py",
            "line": 899,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1475",
            "file": "chasten/main.py",
            "line": 900,
            "system-out": [
              "        file_okay=True,"
            ]
          },
          {
            "name": "Mutant #1476",
            "file": "chasten/main.py",
            "line": 901,
            "system-out": [
              "        dir_okay=False,"
            ]
          },
          {
            "name": "Mutant #1477",
            "file": "chasten/main.py",
            "line": 902,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1478",
            "file": "chasten/main.py",
            "line": 903,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1479",
            "file": "chasten/main.py",
            "line": 904,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1480",
            "file": "chasten/main.py",
            "line": 908,
            "system-out": [
              "        \"--metadata\","
            ]
          },
          {
            "name": "Mutant #1481",
            "file": "chasten/main.py",
            "line": 909,
            "system-out": [
              "        \"-m\","
            ]
          },
          {
            "name": "Mutant #1482",
            "file": "chasten/main.py",
            "line": 910,
            "system-out": [
              "        help=\"Meta-data file storing database configuration.\","
            ]
          },
          {
            "name": "Mutant #1483",
            "file": "chasten/main.py",
            "line": 911,
            "system-out": [
              "        exists=True,"
            ]
          },
          {
            "name": "Mutant #1484",
            "file": "chasten/main.py",
            "line": 912,
            "system-out": [
              "        file_okay=True,"
            ]
          },
          {
            "name": "Mutant #1485",
            "file": "chasten/main.py",
            "line": 913,
            "system-out": [
              "        dir_okay=False,"
            ]
          },
          {
            "name": "Mutant #1486",
            "file": "tests/test_database.py",
            "line": 11,
            "system-out": [
              "    chasten_database_name: str = \".example_database\""
            ]
          },
          {
            "name": "Mutant #1487",
            "file": "tests/test_database.py",
            "line": 11,
            "system-out": [
              "    chasten_database_name: str = \".example_database\""
            ]
          },
          {
            "name": "Mutant #1488",
            "file": "tests/test_database.py",
            "line": 16,
            "system-out": [
              "    os.remove(\".example_database\")"
            ]
          },
          {
            "name": "Mutant #1489",
            "file": "chasten/main.py",
            "line": 914,
            "system-out": [
              "        readable=True,"
            ]
          },
          {
            "name": "Mutant #1490",
            "file": "chasten/main.py",
            "line": 915,
            "system-out": [
              "        writable=True,"
            ]
          },
          {
            "name": "Mutant #1491",
            "file": "chasten/main.py",
            "line": 916,
            "system-out": [
              "        resolve_path=True,"
            ]
          },
          {
            "name": "Mutant #1492",
            "file": "tests/test_debug.py",
            "line": 10,
            "system-out": [
              "    assert DebugLevel.DEBUG == \"DEBUG\""
            ]
          },
          {
            "name": "Mutant #1493",
            "file": "tests/test_debug.py",
            "line": 10,
            "system-out": [
              "    assert DebugLevel.DEBUG == \"DEBUG\""
            ]
          },
          {
            "name": "Mutant #1494",
            "file": "tests/test_debug.py",
            "line": 11,
            "system-out": [
              "    assert DebugLevel.INFO == \"INFO\""
            ]
          },
          {
            "name": "Mutant #1495",
            "file": "tests/test_debug.py",
            "line": 11,
            "system-out": [
              "    assert DebugLevel.INFO == \"INFO\""
            ]
          },
          {
            "name": "Mutant #1496",
            "file": "tests/test_debug.py",
            "line": 12,
            "system-out": [
              "    assert DebugLevel.WARNING == \"WARNING\""
            ]
          },
          {
            "name": "Mutant #1497",
            "file": "tests/test_debug.py",
            "line": 12,
            "system-out": [
              "    assert DebugLevel.WARNING == \"WARNING\""
            ]
          },
          {
            "name": "Mutant #1498",
            "file": "tests/test_debug.py",
            "line": 13,
            "system-out": [
              "    assert DebugLevel.ERROR == \"ERROR\""
            ]
          },
          {
            "name": "Mutant #1499",
            "file": "tests/test_debug.py",
            "line": 13,
            "system-out": [
              "    assert DebugLevel.ERROR == \"ERROR\""
            ]
          },
          {
            "name": "Mutant #1500",
            "file": "tests/test_debug.py",
            "line": 14,
            "system-out": [
              "    assert DebugLevel.CRITICAL == \"CRITICAL\""
            ]
          },
          {
            "name": "Mutant #1501",
            "file": "tests/test_debug.py",
            "line": 14,
            "system-out": [
              "    assert DebugLevel.CRITICAL == \"CRITICAL\""
            ]
          },
          {
            "name": "Mutant #1502",
            "file": "tests/test_debug.py",
            "line": 28,
            "system-out": [
              "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1503",
            "file": "tests/test_debug.py",
            "line": 28,
            "system-out": [
              "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1504",
            "file": "tests/test_debug.py",
            "line": 28,
            "system-out": [
              "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1505",
            "file": "tests/test_debug.py",
            "line": 28,
            "system-out": [
              "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1506",
            "file": "tests/test_debug.py",
            "line": 28,
            "system-out": [
              "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1507",
            "file": "tests/test_debug.py",
            "line": 28,
            "system-out": [
              "    assert list(DebugLevel) == [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1508",
            "file": "tests/test_debug.py",
            "line": 33,
            "system-out": [
              "    assert DebugDestination.CONSOLE == \"CONSOLE\""
            ]
          },
          {
            "name": "Mutant #1509",
            "file": "tests/test_debug.py",
            "line": 33,
            "system-out": [
              "    assert DebugDestination.CONSOLE == \"CONSOLE\""
            ]
          },
          {
            "name": "Mutant #1510",
            "file": "tests/test_debug.py",
            "line": 34,
            "system-out": [
              "    assert DebugDestination.SYSLOG == \"SYSLOG\""
            ]
          },
          {
            "name": "Mutant #1511",
            "file": "tests/test_debug.py",
            "line": 34,
            "system-out": [
              "    assert DebugDestination.SYSLOG == \"SYSLOG\""
            ]
          },
          {
            "name": "Mutant #1512",
            "file": "tests/test_debug.py",
            "line": 45,
            "system-out": [
              "    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            ]
          },
          {
            "name": "Mutant #1513",
            "file": "tests/test_debug.py",
            "line": 45,
            "system-out": [
              "    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            ]
          },
          {
            "name": "Mutant #1514",
            "file": "tests/test_debug.py",
            "line": 45,
            "system-out": [
              "    assert list(DebugDestination) == [\"CONSOLE\", \"SYSLOG\"]"
            ]
          },
          {
            "name": "Mutant #1515",
            "file": "tests/test_debug.py",
            "line": 51,
            "system-out": [
              "        DebugLevel(\"INVALID\")"
            ]
          },
          {
            "name": "Mutant #1516",
            "file": "tests/test_debug.py",
            "line": 57,
            "system-out": [
              "        DebugDestination(\"INVALID\")"
            ]
          },
          {
            "name": "Mutant #1517",
            "file": "chasten/main.py",
            "line": 921,
            "system-out": [
              "        \"-p\","
            ]
          },
          {
            "name": "Mutant #1518",
            "file": "chasten/main.py",
            "line": 926,
            "system-out": [
              "        \"--debug-level\","
            ]
          },
          {
            "name": "Mutant #1519",
            "file": "chasten/main.py",
            "line": 927,
            "system-out": [
              "        \"-l\","
            ]
          },
          {
            "name": "Mutant #1520",
            "file": "chasten/main.py",
            "line": 928,
            "system-out": [
              "        help=\"Specify the level of debugging output.\","
            ]
          },
          {
            "name": "Mutant #1521",
            "file": "chasten/main.py",
            "line": 932,
            "system-out": [
              "        \"--debug-dest\","
            ]
          },
          {
            "name": "Mutant #1522",
            "file": "chasten/main.py",
            "line": 933,
            "system-out": [
              "        \"-t\","
            ]
          },
          {
            "name": "Mutant #1523",
            "file": "chasten/main.py",
            "line": 934,
            "system-out": [
              "        help=\"Specify the destination for debugging output.\","
            ]
          },
          {
            "name": "Mutant #1524",
            "file": "chasten/main.py",
            "line": 936,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1525",
            "file": "chasten/main.py",
            "line": 936,
            "system-out": [
              "    verbose: bool = typer.Option(False, help=\"Display verbose debugging output\"),"
            ]
          },
          {
            "name": "Mutant #1526",
            "file": "chasten/main.py",
            "line": 949,
            "system-out": [
              "    output.logger.debug(f\"Display verbose output? {verbose}\")"
            ]
          },
          {
            "name": "Mutant #1527",
            "file": "chasten/main.py",
            "line": 950,
            "system-out": [
              "    output.logger.debug(f\"Debug level? {debug_level.value}\")"
            ]
          },
          {
            "name": "Mutant #1528",
            "file": "chasten/main.py",
            "line": 951,
            "system-out": [
              "    output.logger.debug(f\"Debug destination? {debug_destination.value}\")"
            ]
          },
          {
            "name": "Mutant #1529",
            "file": "chasten/main.py",
            "line": 971,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1530",
            "file": "chasten/main.py",
            "line": 987,
            "system-out": [
              "@cli.command()"
            ]
          },
          {
            "name": "Mutant #1531",
            "file": "tests/test_configuration.py",
            "line": 11,
            "system-out": [
              "@given(applicationname=strategies.text(), applicationauthor=strategies.text())"
            ]
          },
          {
            "name": "Mutant #1532",
            "file": "tests/test_configuration.py",
            "line": 12,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1533",
            "file": "tests/test_configuration.py",
            "line": 21,
            "system-out": [
              "    assert applicationname in user_config_dir_str"
            ]
          },
          {
            "name": "Mutant #1534",
            "file": "tests/test_configuration.py",
            "line": 26,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1535",
            "file": "tests/test_configuration.py",
            "line": 26,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1536",
            "file": "tests/test_configuration.py",
            "line": 26,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1537",
            "file": "tests/test_configuration.py",
            "line": 26,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1538",
            "file": "tests/test_configuration.py",
            "line": 26,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1539",
            "file": "tests/test_configuration.py",
            "line": 28,
            "system-out": [
              "    debug_dest=strategies.sampled_from([\"CONSOLE\", \"SYSLOG\"]),"
            ]
          },
          {
            "name": "Mutant #1540",
            "file": "tests/test_configuration.py",
            "line": 28,
            "system-out": [
              "    debug_dest=strategies.sampled_from([\"CONSOLE\", \"SYSLOG\"]),"
            ]
          },
          {
            "name": "Mutant #1541",
            "file": "tests/test_configuration.py",
            "line": 29,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1542",
            "file": "tests/test_configuration.py",
            "line": 43,
            "system-out": [
              "    debug_dest=strategies.sampled_from([\"CONSOLE-WRONG\", \"SYSLOG-WRONG\"]),"
            ]
          },
          {
            "name": "Mutant #1543",
            "file": "tests/test_configuration.py",
            "line": 43,
            "system-out": [
              "    debug_dest=strategies.sampled_from([\"CONSOLE-WRONG\", \"SYSLOG-WRONG\"]),"
            ]
          },
          {
            "name": "Mutant #1544",
            "file": "tests/test_configuration.py",
            "line": 50,
            "system-out": [
              "    assert not created"
            ]
          },
          {
            "name": "Mutant #1545",
            "file": "tests/test_util.py",
            "line": 14,
            "system-out": [
              "    assert util.get_human_readable_boolean(answer=True) == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1546",
            "file": "tests/test_util.py",
            "line": 14,
            "system-out": [
              "    assert util.get_human_readable_boolean(answer=True) == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1547",
            "file": "tests/test_util.py",
            "line": 14,
            "system-out": [
              "    assert util.get_human_readable_boolean(answer=True) == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1548",
            "file": "tests/test_util.py",
            "line": 15,
            "system-out": [
              "    assert util.get_human_readable_boolean(answer=False) == \"No\""
            ]
          },
          {
            "name": "Mutant #1549",
            "file": "tests/test_util.py",
            "line": 15,
            "system-out": [
              "    assert util.get_human_readable_boolean(answer=False) == \"No\""
            ]
          },
          {
            "name": "Mutant #1550",
            "file": "tests/test_util.py",
            "line": 15,
            "system-out": [
              "    assert util.get_human_readable_boolean(answer=False) == \"No\""
            ]
          },
          {
            "name": "Mutant #1551",
            "file": "tests/test_util.py",
            "line": 18,
            "system-out": [
              "@given(answer=st.booleans())"
            ]
          },
          {
            "name": "Mutant #1552",
            "file": "tests/test_util.py",
            "line": 19,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1553",
            "file": "tests/test_util.py",
            "line": 31,
            "system-out": [
              "        assert str_answer == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1554",
            "file": "tests/test_util.py",
            "line": 31,
            "system-out": [
              "        assert str_answer == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1555",
            "file": "tests/test_util.py",
            "line": 33,
            "system-out": [
              "        assert str_answer == \"No\""
            ]
          },
          {
            "name": "Mutant #1556",
            "file": "tests/test_util.py",
            "line": 33,
            "system-out": [
              "        assert str_answer == \"No\""
            ]
          },
          {
            "name": "Mutant #1557",
            "file": "tests/test_util.py",
            "line": 36,
            "system-out": [
              "@given(url=provisional.urls())"
            ]
          },
          {
            "name": "Mutant #1558",
            "file": "tests/test_util.py",
            "line": 41,
            "system-out": [
              "    assert result is True"
            ]
          },
          {
            "name": "Mutant #1559",
            "file": "tests/test_util.py",
            "line": 41,
            "system-out": [
              "    assert result is True"
            ]
          },
          {
            "name": "Mutant #1560",
            "file": "tests/test_util.py",
            "line": 44,
            "system-out": [
              "@given(check_status_list=st.lists(st.booleans()))"
            ]
          },
          {
            "name": "Mutant #1561",
            "file": "tests/test_util.py",
            "line": 49,
            "system-out": [
              "    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier"
            ]
          },
          {
            "name": "Mutant #1562",
            "file": "tests/test_util.py",
            "line": 49,
            "system-out": [
              "    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier"
            ]
          },
          {
            "name": "Mutant #1563",
            "file": "tests/test_util.py",
            "line": 49,
            "system-out": [
              "    assert constants.markers.Zero <= stats[2] <= constants.markers.Percent_Multiplier"
            ]
          },
          {
            "name": "Mutant #1564",
            "file": "tests/test_util.py",
            "line": 50,
            "system-out": [
              "    assert stats[0] <= stats[1]"
            ]
          },
          {
            "name": "Mutant #1565",
            "file": "tests/test_util.py",
            "line": 50,
            "system-out": [
              "    assert stats[0] <= stats[1]"
            ]
          },
          {
            "name": "Mutant #1566",
            "file": "tests/test_util.py",
            "line": 50,
            "system-out": [
              "    assert stats[0] <= stats[1]"
            ]
          },
          {
            "name": "Mutant #1567",
            "file": "tests/test_createchecks.py",
            "line": 11,
            "system-out": [
              "    return os.getenv(\"API_KEY\")"
            ]
          },
          {
            "name": "Mutant #1568",
            "file": "tests/test_createchecks.py",
            "line": 14,
            "system-out": [
              "@pytest.mark.api"
            ]
          },
          {
            "name": "Mutant #1569",
            "file": "tests/test_createchecks.py",
            "line": 18,
            "system-out": [
              "    if not valid_api_key:"
            ]
          },
          {
            "name": "Mutant #1570",
            "file": "tests/test_createchecks.py",
            "line": 19,
            "system-out": [
              "        pytest.skip(\"No valid API key found in the environment variables\")"
            ]
          },
          {
            "name": "Mutant #1571",
            "file": "tests/test_createchecks.py",
            "line": 22,
            "system-out": [
              "    assert result is True"
            ]
          },
          {
            "name": "Mutant #1572",
            "file": "tests/test_createchecks.py",
            "line": 22,
            "system-out": [
              "    assert result is True"
            ]
          },
          {
            "name": "Mutant #1573",
            "file": "tests/test_createchecks.py",
            "line": 36,
            "system-out": [
              "    test_genscript = \"Write: 'Hello, World'\""
            ]
          },
          {
            "name": "Mutant #1574",
            "file": "tests/test_createchecks.py",
            "line": 37,
            "system-out": [
              "    file_path = \"test_checks.yml\""
            ]
          },
          {
            "name": "Mutant #1575",
            "file": "tests/test_createchecks.py",
            "line": 46,
            "system-out": [
              "    assert result is not None"
            ]
          },
          {
            "name": "Mutant #1576",
            "file": "tests/test_createchecks.py",
            "line": 50,
            "system-out": [
              "    with open(file_path, \"r\") as f:"
            ]
          },
          {
            "name": "Mutant #1577",
            "file": "tests/test_createchecks.py",
            "line": 52,
            "system-out": [
              "        assert \"Hello, World\" in content"
            ]
          },
          {
            "name": "Mutant #1578",
            "file": "tests/test_createchecks.py",
            "line": 52,
            "system-out": [
              "        assert \"Hello, World\" in content"
            ]
          },
          {
            "name": "Mutant #1579",
            "file": "tests/test_filesystem.py",
            "line": 16,
            "system-out": [
              "    directory_str = str(Path(\"./tests/\"))"
            ]
          },
          {
            "name": "Mutant #1580",
            "file": "tests/test_filesystem.py",
            "line": 19,
            "system-out": [
              "    assert confirmation is True"
            ]
          },
          {
            "name": "Mutant #1581",
            "file": "tests/test_filesystem.py",
            "line": 19,
            "system-out": [
              "    assert confirmation is True"
            ]
          },
          {
            "name": "Mutant #1582",
            "file": "tests/test_filesystem.py",
            "line": 24,
            "system-out": [
              "    directory_str = str(Path(\"./testsNOT/\"))"
            ]
          },
          {
            "name": "Mutant #1583",
            "file": "tests/test_filesystem.py",
            "line": 27,
            "system-out": [
              "    assert confirmation is False"
            ]
          },
          {
            "name": "Mutant #1584",
            "file": "tests/test_filesystem.py",
            "line": 27,
            "system-out": [
              "    assert confirmation is False"
            ]
          },
          {
            "name": "Mutant #1585",
            "file": "tests/test_filesystem.py",
            "line": 28,
            "system-out": [
              "    assert filesystem.confirm_valid_directory(None) is False"
            ]
          },
          {
            "name": "Mutant #1586",
            "file": "tests/test_filesystem.py",
            "line": 28,
            "system-out": [
              "    assert filesystem.confirm_valid_directory(None) is False"
            ]
          },
          {
            "name": "Mutant #1587",
            "file": "tests/test_filesystem.py",
            "line": 33,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            ]
          },
          {
            "name": "Mutant #1588",
            "file": "tests/test_filesystem.py",
            "line": 33,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            ]
          },
          {
            "name": "Mutant #1589",
            "file": "tests/test_filesystem.py",
            "line": 33,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystem.py\"))"
            ]
          },
          {
            "name": "Mutant #1590",
            "file": "tests/test_filesystem.py",
            "line": 41,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            ]
          },
          {
            "name": "Mutant #1591",
            "file": "tests/test_filesystem.py",
            "line": 41,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            ]
          },
          {
            "name": "Mutant #1592",
            "file": "tests/test_filesystem.py",
            "line": 41,
            "system-out": [
              "    file_str = str(Path(\"./tests\") / Path(\"test_filesystemNOT.py.py\"))"
            ]
          },
          {
            "name": "Mutant #1593",
            "file": "tests/test_filesystem.py",
            "line": 45,
            "system-out": [
              "    assert filesystem.confirm_valid_file(None) is False"
            ]
          },
          {
            "name": "Mutant #1594",
            "file": "tests/test_filesystem.py",
            "line": 45,
            "system-out": [
              "    assert filesystem.confirm_valid_file(None) is False"
            ]
          },
          {
            "name": "Mutant #1595",
            "file": "tests/test_filesystem.py",
            "line": 48,
            "system-out": [
              "@given(directory=strategies.builds(pathlib.Path))"
            ]
          },
          {
            "name": "Mutant #1596",
            "file": "tests/test_filesystem.py",
            "line": 49,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1597",
            "file": "tests/test_filesystem.py",
            "line": 55,
            "system-out": [
              "@given(file=strategies.builds(pathlib.Path))"
            ]
          },
          {
            "name": "Mutant #1598",
            "file": "tests/test_filesystem.py",
            "line": 67,
            "system-out": [
              "    (tmp_dir / \"file1.txt\").touch()"
            ]
          },
          {
            "name": "Mutant #1599",
            "file": "tests/test_filesystem.py",
            "line": 67,
            "system-out": [
              "    (tmp_dir / \"file1.txt\").touch()"
            ]
          },
          {
            "name": "Mutant #1600",
            "file": "tests/test_filesystem.py",
            "line": 68,
            "system-out": [
              "    (tmp_dir / \"subdir1\").mkdir()"
            ]
          },
          {
            "name": "Mutant #1601",
            "file": "tests/test_filesystem.py",
            "line": 68,
            "system-out": [
              "    (tmp_dir / \"subdir1\").mkdir()"
            ]
          },
          {
            "name": "Mutant #1602",
            "file": "tests/test_filesystem.py",
            "line": 69,
            "system-out": [
              "    (tmp_dir / \"subdir2\").mkdir()"
            ]
          },
          {
            "name": "Mutant #1603",
            "file": "tests/test_filesystem.py",
            "line": 69,
            "system-out": [
              "    (tmp_dir / \"subdir2\").mkdir()"
            ]
          },
          {
            "name": "Mutant #1604",
            "file": "tests/test_filesystem.py",
            "line": 70,
            "system-out": [
              "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()"
            ]
          },
          {
            "name": "Mutant #1605",
            "file": "tests/test_filesystem.py",
            "line": 70,
            "system-out": [
              "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()"
            ]
          },
          {
            "name": "Mutant #1606",
            "file": "tests/test_filesystem.py",
            "line": 70,
            "system-out": [
              "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()"
            ]
          },
          {
            "name": "Mutant #1607",
            "file": "tests/test_filesystem.py",
            "line": 70,
            "system-out": [
              "    (tmp_dir / \"subdir2\" / \"file2.txt\").touch()"
            ]
          },
          {
            "name": "Mutant #1608",
            "file": "tests/test_filesystem.py",
            "line": 76,
            "system-out": [
              "    assert tree.label == f\":open_file_folder: {tmp_dir.name}\""
            ]
          },
          {
            "name": "Mutant #1609",
            "file": "tests/test_filesystem.py",
            "line": 76,
            "system-out": [
              "    assert tree.label == f\":open_file_folder: {tmp_dir.name}\""
            ]
          },
          {
            "name": "Mutant #1610",
            "file": "tests/test_filesystem.py",
            "line": 78,
            "system-out": [
              "    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1611",
            "file": "tests/test_filesystem.py",
            "line": 78,
            "system-out": [
              "    dirs = [node.label for node in tree.children if \":open_file_folder:\" in node.label]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1612",
            "file": "tests/test_filesystem.py",
            "line": 79,
            "system-out": [
              "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1613",
            "file": "tests/test_filesystem.py",
            "line": 79,
            "system-out": [
              "    files = [node.label for node in tree.children if \":page_facing_up:\" in node.label]  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1614",
            "file": "tests/test_filesystem.py",
            "line": 80,
            "system-out": [
              "    assert set(dirs) == {"
            ]
          },
          {
            "name": "Mutant #1615",
            "file": "tests/test_filesystem.py",
            "line": 81,
            "system-out": [
              "        f\":open_file_folder: {p.name}\" for p in tmp_dir.iterdir() if p.is_dir()"
            ]
          },
          {
            "name": "Mutant #1616",
            "file": "tests/test_filesystem.py",
            "line": 83,
            "system-out": [
              "    assert set(files) == {"
            ]
          },
          {
            "name": "Mutant #1617",
            "file": "tests/test_filesystem.py",
            "line": 84,
            "system-out": [
              "        f\":page_facing_up: {p.name}\" for p in tmp_dir.iterdir() if p.is_file()"
            ]
          },
          {
            "name": "Mutant #1618",
            "file": "tests/test_filesystem.py",
            "line": 96,
            "system-out": [
              "    assert tree.label == f\":open_file_folder: {directory.name}\""
            ]
          },
          {
            "name": "Mutant #1619",
            "file": "tests/test_filesystem.py",
            "line": 96,
            "system-out": [
              "    assert tree.label == f\":open_file_folder: {directory.name}\""
            ]
          },
          {
            "name": "Mutant #1620",
            "file": "tests/test_filesystem.py",
            "line": 101,
            "system-out": [
              "        if \":open_file_folder:\" in node.label:  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1621",
            "file": "tests/test_filesystem.py",
            "line": 101,
            "system-out": [
              "        if \":open_file_folder:\" in node.label:  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1622",
            "file": "tests/test_filesystem.py",
            "line": 102,
            "system-out": [
              "            dirs.append(node.label[19:])  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1623",
            "file": "tests/test_filesystem.py",
            "line": 104,
            "system-out": [
              "            files.append(node.label[17:])  # type: ignore"
            ]
          },
          {
            "name": "Mutant #1624",
            "file": "tests/test_filesystem.py",
            "line": 106,
            "system-out": [
              "    assert set(dirs) == set(p.name for p in directory.iterdir() if p.is_dir())"
            ]
          },
          {
            "name": "Mutant #1625",
            "file": "tests/test_filesystem.py",
            "line": 107,
            "system-out": [
              "    assert set(files) == set(p.name for p in directory.iterdir() if p.is_file())"
            ]
          },
          {
            "name": "Mutant #1626",
            "file": "tests/test_filesystem.py",
            "line": 110,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1627",
            "file": "tests/test_filesystem.py",
            "line": 110,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1628",
            "file": "tests/test_filesystem.py",
            "line": 116,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1629",
            "file": "tests/test_filesystem.py",
            "line": 116,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1630",
            "file": "tests/test_filesystem.py",
            "line": 117,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1631",
            "file": "tests/test_filesystem.py",
            "line": 117,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1632",
            "file": "tests/test_filesystem.py",
            "line": 119,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1633",
            "file": "tests/test_filesystem.py",
            "line": 138,
            "system-out": [
              "        filesystem.create_configuration_directory(force=False)"
            ]
          },
          {
            "name": "Mutant #1634",
            "file": "tests/test_filesystem.py",
            "line": 173,
            "system-out": [
              "    filesystem.create_configuration_directory(force=True)"
            ]
          },
          {
            "name": "Mutant #1635",
            "file": "tests/test_filesystem.py",
            "line": 180,
            "system-out": [
              "    config = tmp_path / \"config\""
            ]
          },
          {
            "name": "Mutant #1636",
            "file": "tests/test_filesystem.py",
            "line": 180,
            "system-out": [
              "    config = tmp_path / \"config\""
            ]
          },
          {
            "name": "Mutant #1637",
            "file": "tests/test_filesystem.py",
            "line": 182,
            "system-out": [
              "    assert filesystem.detect_configuration(config) == str(config)"
            ]
          },
          {
            "name": "Mutant #1638",
            "file": "tests/test_filesystem.py",
            "line": 199,
            "system-out": [
              "    assert detected_directory == str(dir_path)"
            ]
          },
          {
            "name": "Mutant #1639",
            "file": "tests/test_filesystem.py",
            "line": 217,
            "system-out": [
              "    main_configuation_file = dir_path / \"config.yml\""
            ]
          },
          {
            "name": "Mutant #1640",
            "file": "tests/test_filesystem.py",
            "line": 217,
            "system-out": [
              "    main_configuation_file = dir_path / \"config.yml\""
            ]
          },
          {
            "name": "Mutant #1641",
            "file": "tests/test_filesystem.py",
            "line": 222,
            "system-out": [
              "        == filesystem.CONFIGURATION_FILE_DEFAULT_CONTENTS"
            ]
          },
          {
            "name": "Mutant #1642",
            "file": "tests/test_filesystem.py",
            "line": 241,
            "system-out": [
              "    main_configuation_file = dir_path / \"checks.yml\""
            ]
          },
          {
            "name": "Mutant #1643",
            "file": "tests/test_filesystem.py",
            "line": 241,
            "system-out": [
              "    main_configuation_file = dir_path / \"checks.yml\""
            ]
          },
          {
            "name": "Mutant #1644",
            "file": "tests/test_filesystem.py",
            "line": 244,
            "system-out": [
              "    assert main_configuation_file.read_text() == filesystem.CHECKS_FILE_DEFAULT_CONTENTS"
            ]
          },
          {
            "name": "Mutant #1645",
            "file": "tests/test_configApp.py",
            "line": 66,
            "system-out": [
              "    file = tmp_dir / \"check_test.txt\""
            ]
          },
          {
            "name": "Mutant #1646",
            "file": "tests/test_configApp.py",
            "line": 66,
            "system-out": [
              "    file = tmp_dir / \"check_test.txt\""
            ]
          },
          {
            "name": "Mutant #1647",
            "file": "tests/test_configuration.py",
            "line": 30,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1648",
            "file": "tests/test_configuration.py",
            "line": 41,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1649",
            "file": "tests/test_configuration.py",
            "line": 41,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1650",
            "file": "tests/test_configuration.py",
            "line": 41,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1651",
            "file": "tests/test_configuration.py",
            "line": 41,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1652",
            "file": "tests/test_configuration.py",
            "line": 41,
            "system-out": [
              "        [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]"
            ]
          },
          {
            "name": "Mutant #1653",
            "file": "tests/test_configuration.py",
            "line": 44,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1654",
            "file": "tests/test_configuration.py",
            "line": 45,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1655",
            "file": "tests/test_util.py",
            "line": 25,
            "system-out": [
              "@given(answer=st.booleans())"
            ]
          },
          {
            "name": "Mutant #1656",
            "file": "tests/test_util.py",
            "line": 26,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1657",
            "file": "tests/test_util.py",
            "line": 37,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1658",
            "file": "tests/test_util.py",
            "line": 45,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1659",
            "file": "tests/test_createchecks.py",
            "line": 33,
            "system-out": [
              "@pytest.mark.api"
            ]
          },
          {
            "name": "Mutant #1660",
            "file": "tests/test_createchecks.py",
            "line": 39,
            "system-out": [
              "    if not valid_api_key:"
            ]
          },
          {
            "name": "Mutant #1661",
            "file": "tests/test_createchecks.py",
            "line": 40,
            "system-out": [
              "        pytest.skip(\"No valid API key found in the environment variables\")"
            ]
          },
          {
            "name": "Mutant #1662",
            "file": "tests/test_filesystem.py",
            "line": 36,
            "system-out": [
              "    assert confirmation is True"
            ]
          },
          {
            "name": "Mutant #1663",
            "file": "tests/test_filesystem.py",
            "line": 36,
            "system-out": [
              "    assert confirmation is True"
            ]
          },
          {
            "name": "Mutant #1664",
            "file": "tests/test_process.py",
            "line": 18,
            "system-out": [
              "                    path=Path(\".\"),"
            ]
          },
          {
            "name": "Mutant #1665",
            "file": "tests/test_process.py",
            "line": 29,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1666",
            "file": "tests/test_process.py",
            "line": 30,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1667",
            "file": "tests/test_process.py",
            "line": 35,
            "system-out": [
              "    assert set(filtered) == set("
            ]
          },
          {
            "name": "Mutant #1668",
            "file": "tests/test_process.py",
            "line": 40,
            "system-out": [
              "@given(match_list=st.lists(st.integers()))"
            ]
          },
          {
            "name": "Mutant #1669",
            "file": "tests/test_process.py",
            "line": 46,
            "system-out": [
              "    assert filtered == []"
            ]
          },
          {
            "name": "Mutant #1670",
            "file": "tests/test_process.py",
            "line": 49,
            "system-out": [
              "@given(match_list=st.lists(st.integers()), data_type=st.just(int))"
            ]
          },
          {
            "name": "Mutant #1671",
            "file": "tests/test_process.py",
            "line": 54,
            "system-out": [
              "    if match_list == []:"
            ]
          },
          {
            "name": "Mutant #1672",
            "file": "tests/test_process.py",
            "line": 55,
            "system-out": [
              "        assert filtered == []"
            ]
          },
          {
            "name": "Mutant #1673",
            "file": "tests/test_process.py",
            "line": 57,
            "system-out": [
              "        assert filtered != []"
            ]
          },
          {
            "name": "Mutant #1674",
            "file": "tests/test_filesystem.py",
            "line": 44,
            "system-out": [
              "    assert confirmation is False"
            ]
          },
          {
            "name": "Mutant #1675",
            "file": "tests/test_filesystem.py",
            "line": 44,
            "system-out": [
              "    assert confirmation is False"
            ]
          },
          {
            "name": "Mutant #1676",
            "file": "tests/test_filesystem.py",
            "line": 56,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1677",
            "file": "tests/test_validate.py",
            "line": 13,
            "system-out": [
              "        \"chasten\": {"
            ]
          },
          {
            "name": "Mutant #1678",
            "file": "tests/test_validate.py",
            "line": 14,
            "system-out": [
              "            \"checks-file\": [\"checks.yml\"],"
            ]
          },
          {
            "name": "Mutant #1679",
            "file": "tests/test_validate.py",
            "line": 14,
            "system-out": [
              "            \"checks-file\": [\"checks.yml\"],"
            ]
          },
          {
            "name": "Mutant #1680",
            "file": "tests/test_validate.py",
            "line": 19,
            "system-out": [
              "    assert not errors"
            ]
          },
          {
            "name": "Mutant #1681",
            "file": "tests/test_validate.py",
            "line": 26,
            "system-out": [
              "            \"checks-file\": \"checks.yml\","
            ]
          },
          {
            "name": "Mutant #1682",
            "file": "tests/test_validate.py",
            "line": 26,
            "system-out": [
              "            \"checks-file\": \"checks.yml\","
            ]
          },
          {
            "name": "Mutant #1683",
            "file": "tests/test_validate.py",
            "line": 30,
            "system-out": [
              "    assert not is_valid"
            ]
          },
          {
            "name": "Mutant #1684",
            "file": "tests/test_validate.py",
            "line": 32,
            "system-out": [
              "    assert \"is not of type\" in errors"
            ]
          },
          {
            "name": "Mutant #1685",
            "file": "tests/test_validate.py",
            "line": 32,
            "system-out": [
              "    assert \"is not of type\" in errors"
            ]
          },
          {
            "name": "Mutant #1686",
            "file": "tests/test_validate.py",
            "line": 36,
            "system-out": [
              "    config=strategies.fixed_dictionaries({\"chasten\": strategies.fixed_dictionaries({})})"
            ]
          },
          {
            "name": "Mutant #1687",
            "file": "tests/test_validate.py",
            "line": 37,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1688",
            "file": "tests/test_validate.py",
            "line": 38,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1689",
            "file": "tests/test_validate.py",
            "line": 46,
            "system-out": [
              "@given(from_schema(JSON_SCHEMA_CONFIG))"
            ]
          },
          {
            "name": "Mutant #1690",
            "file": "tests/test_validate.py",
            "line": 47,
            "system-out": [
              "@settings(suppress_health_check=[HealthCheck.too_slow])"
            ]
          },
          {
            "name": "Mutant #1691",
            "file": "tests/test_filesystem.py",
            "line": 88,
            "system-out": [
              "@given(directory=strategies.builds(pathlib.Path))"
            ]
          },
          {
            "name": "Mutant #1692",
            "file": "tests/test_checks.py",
            "line": 18,
            "system-out": [
              "    \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1693",
            "file": "tests/test_checks.py",
            "line": 18,
            "system-out": [
              "    \"type\": \"object\","
            ]
          },
          {
            "name": "Mutant #1694",
            "file": "tests/test_checks.py",
            "line": 19,
            "system-out": [
              "    \"properties\": {"
            ]
          },
          {
            "name": "Mutant #1695",
            "file": "tests/test_checks.py",
            "line": 20,
            "system-out": [
              "        \"count\": {"
            ]
          },
          {
            "name": "Mutant #1696",
            "file": "tests/test_checks.py",
            "line": 21,
            "system-out": [
              "            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]"
            ]
          },
          {
            "name": "Mutant #1697",
            "file": "tests/test_checks.py",
            "line": 21,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -18,7 +18,7 @@\n     \"type\": \"object\",\n     \"properties\": {\n         \"count\": {\n-            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]\n+            **JSON_SCHEMA_CHECKS[\"XXpropertiesXX\"][\"checks\"][\"items\"][\"properties\"][\"count\"]\n         }\n     },\n }\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]"
            ]
          },
          {
            "name": "Mutant #1698",
            "file": "tests/test_checks.py",
            "line": 21,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -18,7 +18,7 @@\n     \"type\": \"object\",\n     \"properties\": {\n         \"count\": {\n-            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]\n+            **JSON_SCHEMA_CHECKS[\"properties\"][\"XXchecksXX\"][\"items\"][\"properties\"][\"count\"]\n         }\n     },\n }\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]"
            ]
          },
          {
            "name": "Mutant #1699",
            "file": "tests/test_checks.py",
            "line": 21,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -18,7 +18,7 @@\n     \"type\": \"object\",\n     \"properties\": {\n         \"count\": {\n-            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]\n+            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"XXitemsXX\"][\"properties\"][\"count\"]\n         }\n     },\n }\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]"
            ]
          },
          {
            "name": "Mutant #1700",
            "file": "tests/test_checks.py",
            "line": 21,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -18,7 +18,7 @@\n     \"type\": \"object\",\n     \"properties\": {\n         \"count\": {\n-            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]\n+            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"XXpropertiesXX\"][\"count\"]\n         }\n     },\n }\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]"
            ]
          },
          {
            "name": "Mutant #1701",
            "file": "tests/test_checks.py",
            "line": 21,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -18,7 +18,7 @@\n     \"type\": \"object\",\n     \"properties\": {\n         \"count\": {\n-            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]\n+            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"XXcountXX\"]\n         }\n     },\n }\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "            **JSON_SCHEMA_CHECKS[\"properties\"][\"checks\"][\"items\"][\"properties\"][\"count\"]"
            ]
          },
          {
            "name": "Mutant #1702",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1703",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1704",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1705",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1706",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1707",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1708",
            "file": "tests/test_checks.py",
            "line": 29,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"min\": 1, \"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1709",
            "file": "tests/test_checks.py",
            "line": 31,
            "system-out": [
              "    assert min_count == 1"
            ]
          },
          {
            "name": "Mutant #1710",
            "file": "tests/test_checks.py",
            "line": 31,
            "system-out": [
              "    assert min_count == 1"
            ]
          },
          {
            "name": "Mutant #1711",
            "file": "tests/test_checks.py",
            "line": 32,
            "system-out": [
              "    assert max_count == 10  # noqa"
            ]
          },
          {
            "name": "Mutant #1712",
            "file": "tests/test_checks.py",
            "line": 32,
            "system-out": [
              "    assert max_count == 10  # noqa"
            ]
          },
          {
            "name": "Mutant #1713",
            "file": "tests/test_checks.py",
            "line": 37,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1714",
            "file": "tests/test_checks.py",
            "line": 37,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1715",
            "file": "tests/test_checks.py",
            "line": 37,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1716",
            "file": "tests/test_checks.py",
            "line": 37,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1717",
            "file": "tests/test_checks.py",
            "line": 37,
            "system-out": [
              "    check = {\"name\": \"test\", \"count\": {\"max\": 10}}"
            ]
          },
          {
            "name": "Mutant #1718",
            "file": "tests/test_checks.py",
            "line": 39,
            "system-out": [
              "    assert min_count is None"
            ]
          },
          {
            "name": "Mutant #1719",
            "file": "tests/test_checks.py",
            "line": 46,
            "system-out": [
              "        \"name\": \"test\","
            ]
          },
          {
            "name": "Mutant #1720",
            "file": "tests/test_checks.py",
            "line": 46,
            "system-out": [
              "        \"name\": \"test\","
            ]
          },
          {
            "name": "Mutant #1721",
            "file": "tests/test_checks.py",
            "line": 48,
            "system-out": [
              "            \"min\": 1,"
            ]
          },
          {
            "name": "Mutant #1722",
            "file": "tests/test_checks.py",
            "line": 48,
            "system-out": [
              "            \"min\": 1,"
            ]
          },
          {
            "name": "Mutant #1723",
            "file": "tests/test_checks.py",
            "line": 53,
            "system-out": [
              "    assert max_count is None"
            ]
          },
          {
            "name": "Mutant #1724",
            "file": "tests/test_checks.py",
            "line": 58,
            "system-out": [
              "    check = {\"name\": \"test\"}"
            ]
          },
          {
            "name": "Mutant #1725",
            "file": "tests/test_checks.py",
            "line": 58,
            "system-out": [
              "    check = {\"name\": \"test\"}"
            ]
          },
          {
            "name": "Mutant #1726",
            "file": "tests/test_checks.py",
            "line": 68,
            "system-out": [
              "        \"description\": \"described test\","
            ]
          },
          {
            "name": "Mutant #1727",
            "file": "tests/test_checks.py",
            "line": 68,
            "system-out": [
              "        \"description\": \"described test\","
            ]
          },
          {
            "name": "Mutant #1728",
            "file": "tests/test_checks.py",
            "line": 73,
            "system-out": [
              "    assert \"described test\" == extract_description(check)"
            ]
          },
          {
            "name": "Mutant #1729",
            "file": "tests/test_checks.py",
            "line": 73,
            "system-out": [
              "    assert \"described test\" == extract_description(check)"
            ]
          },
          {
            "name": "Mutant #1730",
            "file": "tests/test_checks.py",
            "line": 84,
            "system-out": [
              "    assert \"\" == extract_description(check)"
            ]
          },
          {
            "name": "Mutant #1731",
            "file": "tests/test_checks.py",
            "line": 84,
            "system-out": [
              "    assert \"\" == extract_description(check)"
            ]
          },
          {
            "name": "Mutant #1732",
            "file": "tests/test_checks.py",
            "line": 88,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -85,7 +85,7 @@\n \n \n @pytest.mark.parametrize(\n-    \"bool_status,expected\",\n+    \"XXbool_status,expectedXX\",\n     [\n         (True, \":smiley: Did the check pass? Yes\"),\n         (False, \":worried: Did the check pass? No\"),\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "    \"bool_status,expected\","
            ]
          },
          {
            "name": "Mutant #1733",
            "file": "tests/test_checks.py",
            "line": 90,
            "system-out": [
              "        (True, \":smiley: Did the check pass? Yes\"),"
            ]
          },
          {
            "name": "Mutant #1734",
            "file": "tests/test_checks.py",
            "line": 90,
            "system-out": [
              "        (True, \":smiley: Did the check pass? Yes\"),"
            ]
          },
          {
            "name": "Mutant #1735",
            "file": "tests/test_checks.py",
            "line": 91,
            "system-out": [
              "        (False, \":worried: Did the check pass? No\"),"
            ]
          },
          {
            "name": "Mutant #1736",
            "file": "tests/test_checks.py",
            "line": 91,
            "system-out": [
              "        (False, \":worried: Did the check pass? No\"),"
            ]
          },
          {
            "name": "Mutant #1737",
            "file": "tests/test_checks.py",
            "line": 93,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1738",
            "file": "tests/test_checks.py",
            "line": 96,
            "system-out": [
              "    assert make_checks_status_message(bool_status) == expected"
            ]
          },
          {
            "name": "Mutant #1739",
            "file": "tests/test_checks.py",
            "line": 99,
            "system-out": [
              "@given(st.dictionaries(st.text(), st.integers()))"
            ]
          },
          {
            "name": "Mutant #1740",
            "file": "tests/test_checks.py",
            "line": 100,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1741",
            "file": "tests/test_checks.py",
            "line": 104,
            "system-out": [
              "    assert isinstance(min_count, int) or min_count is None"
            ]
          },
          {
            "name": "Mutant #1742",
            "file": "tests/test_checks.py",
            "line": 104,
            "system-out": [
              "    assert isinstance(min_count, int) or min_count is None"
            ]
          },
          {
            "name": "Mutant #1743",
            "file": "tests/test_checks.py",
            "line": 105,
            "system-out": [
              "    assert isinstance(max_count, int) or max_count is None"
            ]
          },
          {
            "name": "Mutant #1744",
            "file": "tests/test_checks.py",
            "line": 105,
            "system-out": [
              "    assert isinstance(max_count, int) or max_count is None"
            ]
          },
          {
            "name": "Mutant #1745",
            "file": "tests/test_checks.py",
            "line": 108,
            "system-out": [
              "@given(from_schema(JSON_SCHEMA_COUNT))"
            ]
          },
          {
            "name": "Mutant #1746",
            "file": "tests/test_checks.py",
            "line": 110,
            "system-out": [
              "@settings(suppress_health_check=[HealthCheck.too_slow])"
            ]
          },
          {
            "name": "Mutant #1747",
            "file": "tests/test_checks.py",
            "line": 119,
            "failure": [
              {
                "inner": "--- tests/test_checks.py\n+++ tests/test_checks.py\n@@ -116,7 +116,7 @@\n \n \n @pytest.mark.parametrize(\n-    \"count,min_value,max_value,expected\",\n+    \"XXcount,min_value,max_value,expectedXX\",\n     [\n         (5, 0, 10, True),\n         (5, 4, 6, True),\n",
                "type": "failure",
                "message": "bad_survived"
              }
            ],
            "system-out": [
              "    \"count,min_value,max_value,expected\","
            ]
          },
          {
            "name": "Mutant #1748",
            "file": "tests/test_checks.py",
            "line": 121,
            "system-out": [
              "        (5, 0, 10, True),"
            ]
          },
          {
            "name": "Mutant #1749",
            "file": "tests/test_checks.py",
            "line": 121,
            "system-out": [
              "        (5, 0, 10, True),"
            ]
          },
          {
            "name": "Mutant #1750",
            "file": "tests/test_checks.py",
            "line": 121,
            "system-out": [
              "        (5, 0, 10, True),"
            ]
          },
          {
            "name": "Mutant #1751",
            "file": "tests/test_checks.py",
            "line": 121,
            "system-out": [
              "        (5, 0, 10, True),"
            ]
          },
          {
            "name": "Mutant #1752",
            "file": "tests/test_checks.py",
            "line": 122,
            "system-out": [
              "        (5, 4, 6, True),"
            ]
          },
          {
            "name": "Mutant #1753",
            "file": "tests/test_checks.py",
            "line": 122,
            "system-out": [
              "        (5, 4, 6, True),"
            ]
          },
          {
            "name": "Mutant #1754",
            "file": "tests/test_checks.py",
            "line": 122,
            "system-out": [
              "        (5, 4, 6, True),"
            ]
          },
          {
            "name": "Mutant #1755",
            "file": "tests/test_checks.py",
            "line": 122,
            "system-out": [
              "        (5, 4, 6, True),"
            ]
          },
          {
            "name": "Mutant #1756",
            "file": "tests/test_checks.py",
            "line": 123,
            "system-out": [
              "        (1, 1, 1, True),"
            ]
          },
          {
            "name": "Mutant #1757",
            "file": "tests/test_checks.py",
            "line": 123,
            "system-out": [
              "        (1, 1, 1, True),"
            ]
          },
          {
            "name": "Mutant #1758",
            "file": "tests/test_checks.py",
            "line": 123,
            "system-out": [
              "        (1, 1, 1, True),"
            ]
          },
          {
            "name": "Mutant #1759",
            "file": "tests/test_checks.py",
            "line": 123,
            "system-out": [
              "        (1, 1, 1, True),"
            ]
          },
          {
            "name": "Mutant #1760",
            "file": "tests/test_checks.py",
            "line": 124,
            "system-out": [
              "        (1, None, 1, True),"
            ]
          },
          {
            "name": "Mutant #1761",
            "file": "tests/test_checks.py",
            "line": 124,
            "system-out": [
              "        (1, None, 1, True),"
            ]
          },
          {
            "name": "Mutant #1762",
            "file": "tests/test_checks.py",
            "line": 124,
            "system-out": [
              "        (1, None, 1, True),"
            ]
          },
          {
            "name": "Mutant #1763",
            "file": "tests/test_checks.py",
            "line": 125,
            "system-out": [
              "        (1, 1, None, True),"
            ]
          },
          {
            "name": "Mutant #1764",
            "file": "tests/test_checks.py",
            "line": 125,
            "system-out": [
              "        (1, 1, None, True),"
            ]
          },
          {
            "name": "Mutant #1765",
            "file": "tests/test_checks.py",
            "line": 125,
            "system-out": [
              "        (1, 1, None, True),"
            ]
          },
          {
            "name": "Mutant #1766",
            "file": "tests/test_checks.py",
            "line": 126,
            "system-out": [
              "        (1, None, None, True),"
            ]
          },
          {
            "name": "Mutant #1767",
            "file": "tests/test_checks.py",
            "line": 126,
            "system-out": [
              "        (1, None, None, True),"
            ]
          },
          {
            "name": "Mutant #1768",
            "file": "tests/test_checks.py",
            "line": 127,
            "system-out": [
              "        (5, 6, 4, False),"
            ]
          },
          {
            "name": "Mutant #1769",
            "file": "tests/test_checks.py",
            "line": 127,
            "system-out": [
              "        (5, 6, 4, False),"
            ]
          },
          {
            "name": "Mutant #1770",
            "file": "tests/test_checks.py",
            "line": 127,
            "system-out": [
              "        (5, 6, 4, False),"
            ]
          },
          {
            "name": "Mutant #1771",
            "file": "tests/test_checks.py",
            "line": 127,
            "system-out": [
              "        (5, 6, 4, False),"
            ]
          },
          {
            "name": "Mutant #1772",
            "file": "tests/test_checks.py",
            "line": 128,
            "system-out": [
              "        (1, 4, 6, False),"
            ]
          },
          {
            "name": "Mutant #1773",
            "file": "tests/test_checks.py",
            "line": 128,
            "system-out": [
              "        (1, 4, 6, False),"
            ]
          },
          {
            "name": "Mutant #1774",
            "file": "tests/test_checks.py",
            "line": 128,
            "system-out": [
              "        (1, 4, 6, False),"
            ]
          },
          {
            "name": "Mutant #1775",
            "file": "tests/test_checks.py",
            "line": 128,
            "system-out": [
              "        (1, 4, 6, False),"
            ]
          },
          {
            "name": "Mutant #1776",
            "file": "tests/test_checks.py",
            "line": 129,
            "system-out": [
              "        (1, 2, None, False),"
            ]
          },
          {
            "name": "Mutant #1777",
            "file": "tests/test_checks.py",
            "line": 129,
            "system-out": [
              "        (1, 2, None, False),"
            ]
          },
          {
            "name": "Mutant #1778",
            "file": "tests/test_checks.py",
            "line": 129,
            "system-out": [
              "        (1, 2, None, False),"
            ]
          },
          {
            "name": "Mutant #1779",
            "file": "tests/test_checks.py",
            "line": 130,
            "system-out": [
              "        (3, None, 2, False),"
            ]
          },
          {
            "name": "Mutant #1780",
            "file": "tests/test_checks.py",
            "line": 130,
            "system-out": [
              "        (3, None, 2, False),"
            ]
          },
          {
            "name": "Mutant #1781",
            "file": "tests/test_checks.py",
            "line": 130,
            "system-out": [
              "        (3, None, 2, False),"
            ]
          },
          {
            "name": "Mutant #1782",
            "file": "tests/test_checks.py",
            "line": 136,
            "system-out": [
              "    assert result == expected"
            ]
          },
          {
            "name": "Mutant #1783",
            "file": "tests/test_checks.py",
            "line": 141,
            "system-out": [
              "    st.integers(min_value=0, max_value=25),"
            ]
          },
          {
            "name": "Mutant #1784",
            "file": "tests/test_checks.py",
            "line": 141,
            "system-out": [
              "    st.integers(min_value=0, max_value=25),"
            ]
          },
          {
            "name": "Mutant #1785",
            "file": "tests/test_filesystem.py",
            "line": 89,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1786",
            "file": "tests/test_filesystem.py",
            "line": 123,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1787",
            "file": "tests/test_filesystem.py",
            "line": 123,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1788",
            "file": "tests/test_filesystem.py",
            "line": 131,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1789",
            "file": "tests/test_filesystem.py",
            "line": 131,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1790",
            "file": "tests/test_filesystem.py",
            "line": 132,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1791",
            "file": "tests/test_filesystem.py",
            "line": 132,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1792",
            "file": "tests/test_filesystem.py",
            "line": 134,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1793",
            "file": "tests/test_filesystem.py",
            "line": 141,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1794",
            "file": "tests/test_filesystem.py",
            "line": 141,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1795",
            "file": "tests/test_filesystem.py",
            "line": 149,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1796",
            "file": "tests/test_filesystem.py",
            "line": 149,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1797",
            "file": "tests/test_filesystem.py",
            "line": 150,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1798",
            "file": "tests/test_filesystem.py",
            "line": 150,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1799",
            "file": "tests/test_filesystem.py",
            "line": 152,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1800",
            "file": "tests/test_filesystem.py",
            "line": 156,
            "system-out": [
              "        filesystem.create_configuration_directory(force=False)"
            ]
          },
          {
            "name": "Mutant #1801",
            "file": "tests/test_filesystem.py",
            "line": 159,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1802",
            "file": "tests/test_filesystem.py",
            "line": 159,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1803",
            "file": "tests/test_filesystem.py",
            "line": 167,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1804",
            "file": "tests/test_filesystem.py",
            "line": 167,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1805",
            "file": "tests/test_filesystem.py",
            "line": 168,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1806",
            "file": "tests/test_filesystem.py",
            "line": 168,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1807",
            "file": "tests/test_filesystem.py",
            "line": 170,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1808",
            "file": "tests/test_filesystem.py",
            "line": 185,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1809",
            "file": "tests/test_filesystem.py",
            "line": 185,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1810",
            "file": "tests/test_filesystem.py",
            "line": 193,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1811",
            "file": "tests/test_filesystem.py",
            "line": 193,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1812",
            "file": "tests/test_filesystem.py",
            "line": 194,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1813",
            "file": "tests/test_filesystem.py",
            "line": 194,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1814",
            "file": "tests/test_filesystem.py",
            "line": 196,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1815",
            "file": "tests/test_filesystem.py",
            "line": 202,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1816",
            "file": "tests/test_filesystem.py",
            "line": 202,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1817",
            "file": "tests/test_filesystem.py",
            "line": 208,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1818",
            "file": "tests/test_filesystem.py",
            "line": 208,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1819",
            "file": "tests/test_filesystem.py",
            "line": 209,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1820",
            "file": "tests/test_filesystem.py",
            "line": 209,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1821",
            "file": "tests/test_filesystem.py",
            "line": 211,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1822",
            "file": "tests/test_filesystem.py",
            "line": 226,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1823",
            "file": "tests/test_filesystem.py",
            "line": 226,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1824",
            "file": "tests/test_filesystem.py",
            "line": 232,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1825",
            "file": "tests/test_filesystem.py",
            "line": 232,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1826",
            "file": "tests/test_filesystem.py",
            "line": 233,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1827",
            "file": "tests/test_filesystem.py",
            "line": 233,
            "system-out": [
              "    dir_path = tmp_path / \".chasten\""
            ]
          },
          {
            "name": "Mutant #1828",
            "file": "tests/test_filesystem.py",
            "line": 235,
            "system-out": [
              "    assert result == dir_path"
            ]
          },
          {
            "name": "Mutant #1829",
            "file": "tests/test_process.py",
            "line": 41,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1830",
            "file": "tests/test_process.py",
            "line": 50,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1831",
            "file": "tests/test_validate.py",
            "line": 25,
            "system-out": [
              "        \"chasten\": {"
            ]
          },
          {
            "name": "Mutant #1832",
            "file": "tests/test_validate.py",
            "line": 43,
            "system-out": [
              "    assert not errors"
            ]
          },
          {
            "name": "Mutant #1833",
            "file": "tests/test_validate.py",
            "line": 48,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1834",
            "file": "tests/test_validate.py",
            "line": 53,
            "system-out": [
              "    assert not errors"
            ]
          },
          {
            "name": "Mutant #1835",
            "file": "tests/test_main.py",
            "line": 77,
            "system-out": [
              "@pytest.fixture"
            ]
          },
          {
            "name": "Mutant #1836",
            "file": "tests/test_main.py",
            "line": 89,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #1837",
            "file": "tests/test_main.py",
            "line": 91,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #1838",
            "file": "tests/test_main.py",
            "line": 94,
            "system-out": [
              "    configuration_directory = test_one / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1839",
            "file": "tests/test_main.py",
            "line": 94,
            "system-out": [
              "    configuration_directory = test_one / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1840",
            "file": "tests/test_main.py",
            "line": 97,
            "system-out": [
              "    configuration_file = configuration_directory_path / \"config.yml\""
            ]
          },
          {
            "name": "Mutant #1841",
            "file": "tests/test_main.py",
            "line": 97,
            "system-out": [
              "    configuration_file = configuration_directory_path / \"config.yml\""
            ]
          },
          {
            "name": "Mutant #1842",
            "file": "tests/test_main.py",
            "line": 100,
            "system-out": [
              "    checks_file = configuration_directory_path / \"checks.yml\""
            ]
          },
          {
            "name": "Mutant #1843",
            "file": "tests/test_main.py",
            "line": 100,
            "system-out": [
              "    checks_file = configuration_directory_path / \"checks.yml\""
            ]
          },
          {
            "name": "Mutant #1844",
            "file": "tests/test_main.py",
            "line": 107,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1845",
            "file": "tests/test_main.py",
            "line": 109,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1846",
            "file": "tests/test_main.py",
            "line": 111,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1847",
            "file": "tests/test_main.py",
            "line": 113,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1848",
            "file": "tests/test_main.py",
            "line": 116,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #1849",
            "file": "tests/test_main.py",
            "line": 116,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #1850",
            "file": "tests/test_main.py",
            "line": 125,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1851",
            "file": "tests/test_main.py",
            "line": 125,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1852",
            "file": "tests/test_main.py",
            "line": 138,
            "system-out": [
              "    assert result.exit_code in [0, 1]"
            ]
          },
          {
            "name": "Mutant #1853",
            "file": "tests/test_main.py",
            "line": 138,
            "system-out": [
              "    assert result.exit_code in [0, 1]"
            ]
          },
          {
            "name": "Mutant #1854",
            "file": "tests/test_main.py",
            "line": 138,
            "system-out": [
              "    assert result.exit_code in [0, 1]"
            ]
          },
          {
            "name": "Mutant #1855",
            "file": "tests/test_main.py",
            "line": 161,
            "system-out": [
              "    assert result.exit_code != 0"
            ]
          },
          {
            "name": "Mutant #1856",
            "file": "tests/test_main.py",
            "line": 161,
            "system-out": [
              "    assert result.exit_code != 0"
            ]
          },
          {
            "name": "Mutant #1857",
            "file": "tests/test_main.py",
            "line": 162,
            "system-out": [
              "    assert \"Missing argument\" in result.output"
            ]
          },
          {
            "name": "Mutant #1858",
            "file": "tests/test_main.py",
            "line": 162,
            "system-out": [
              "    assert \"Missing argument\" in result.output"
            ]
          },
          {
            "name": "Mutant #1859",
            "file": "tests/test_main.py",
            "line": 169,
            "system-out": [
              "    project_name = \"test\""
            ]
          },
          {
            "name": "Mutant #1860",
            "file": "tests/test_main.py",
            "line": 172,
            "system-out": [
              "    wrong_config_dir = \"config\""
            ]
          },
          {
            "name": "Mutant #1861",
            "file": "tests/test_main.py",
            "line": 186,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #1862",
            "file": "tests/test_main.py",
            "line": 186,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #1863",
            "file": "tests/test_main.py",
            "line": 187,
            "system-out": [
              "    assert \"Cannot perform analysis due to configuration\" in result.output"
            ]
          },
          {
            "name": "Mutant #1864",
            "file": "tests/test_main.py",
            "line": 187,
            "system-out": [
              "    assert \"Cannot perform analysis due to configuration\" in result.output"
            ]
          },
          {
            "name": "Mutant #1865",
            "file": "tests/test_main.py",
            "line": 193,
            "system-out": [
              "    _ = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #1866",
            "file": "tests/test_main.py",
            "line": 194,
            "system-out": [
              "    test_one_incorrect_name = \"test_oneFF\""
            ]
          },
          {
            "name": "Mutant #1867",
            "file": "tests/test_main.py",
            "line": 218,
            "system-out": [
              "    assert result.exit_code == 2  # noqa"
            ]
          },
          {
            "name": "Mutant #1868",
            "file": "tests/test_main.py",
            "line": 218,
            "system-out": [
              "    assert result.exit_code == 2  # noqa"
            ]
          },
          {
            "name": "Mutant #1869",
            "file": "tests/test_main.py",
            "line": 219,
            "system-out": [
              "    assert \"Usage:\" in result.output"
            ]
          },
          {
            "name": "Mutant #1870",
            "file": "tests/test_main.py",
            "line": 219,
            "system-out": [
              "    assert \"Usage:\" in result.output"
            ]
          },
          {
            "name": "Mutant #1871",
            "file": "tests/test_main.py",
            "line": 229,
            "system-out": [
              "    correct_config_dir = tmpdir.mkdir(\"config\")"
            ]
          },
          {
            "name": "Mutant #1872",
            "file": "tests/test_main.py",
            "line": 353,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1873",
            "file": "tests/test_main.py",
            "line": 353,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1874",
            "file": "tests/test_main.py",
            "line": 361,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1875",
            "file": "tests/test_main.py",
            "line": 361,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1876",
            "file": "tests/test_main.py",
            "line": 366,
            "system-out": [
              "            \"configure\","
            ]
          },
          {
            "name": "Mutant #1877",
            "file": "tests/test_main.py",
            "line": 367,
            "system-out": [
              "            \"create\","
            ]
          },
          {
            "name": "Mutant #1878",
            "file": "tests/test_main.py",
            "line": 383,
            "system-out": [
              "    config_directory = Path(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1879",
            "file": "tests/test_main.py",
            "line": 383,
            "system-out": [
              "    config_directory = Path(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1880",
            "file": "tests/test_main.py",
            "line": 398,
            "system-out": [
              "@given(directory=strategies.builds(Path))"
            ]
          },
          {
            "name": "Mutant #1881",
            "file": "tests/test_main.py",
            "line": 399,
            "system-out": [
              "@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])"
            ]
          },
          {
            "name": "Mutant #1882",
            "file": "tests/test_main.py",
            "line": 400,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1883",
            "file": "tests/test_main.py",
            "line": 427,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #1884",
            "file": "tests/test_main.py",
            "line": 427,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #1885",
            "file": "tests/test_main.py",
            "line": 437,
            "system-out": [
              "            \"--markdown-storage\","
            ]
          },
          {
            "name": "Mutant #1886",
            "file": "tests/test_main.py",
            "line": 442,
            "system-out": [
              "    assert \"\u2728 Results saved in:\" in result.output"
            ]
          },
          {
            "name": "Mutant #1887",
            "file": "tests/test_main.py",
            "line": 442,
            "system-out": [
              "    assert \"\u2728 Results saved in:\" in result.output"
            ]
          },
          {
            "name": "Mutant #1888",
            "file": "tests/test_main.py",
            "line": 449,
            "system-out": [
              "    file = tmp_dir / \"analysis.md\""
            ]
          },
          {
            "name": "Mutant #1889",
            "file": "tests/test_main.py",
            "line": 449,
            "system-out": [
              "    file = tmp_dir / \"analysis.md\""
            ]
          },
          {
            "name": "Mutant #1890",
            "file": "tests/test_main.py",
            "line": 475,
            "system-out": [
              "        \"File already exists: use --force to recreate markdown directory.\""
            ]
          },
          {
            "name": "Mutant #1891",
            "file": "tests/test_main.py",
            "line": 476,
            "system-out": [
              "        in result.output"
            ]
          },
          {
            "name": "Mutant #1892",
            "file": "tests/test_main.py",
            "line": 504,
            "system-out": [
              "            \"--force\","
            ]
          },
          {
            "name": "Mutant #1893",
            "file": "tests/test_checks.py",
            "line": 40,
            "system-out": [
              "    assert max_count == 10  # noqa"
            ]
          },
          {
            "name": "Mutant #1894",
            "file": "tests/test_checks.py",
            "line": 40,
            "system-out": [
              "    assert max_count == 10  # noqa"
            ]
          },
          {
            "name": "Mutant #1895",
            "file": "tests/test_checks.py",
            "line": 47,
            "system-out": [
              "        \"count\": {"
            ]
          },
          {
            "name": "Mutant #1896",
            "file": "tests/test_checks.py",
            "line": 52,
            "system-out": [
              "    assert min_count == 1"
            ]
          },
          {
            "name": "Mutant #1897",
            "file": "tests/test_checks.py",
            "line": 52,
            "system-out": [
              "    assert min_count == 1"
            ]
          },
          {
            "name": "Mutant #1898",
            "file": "tests/test_checks.py",
            "line": 60,
            "system-out": [
              "    assert min_count is None"
            ]
          },
          {
            "name": "Mutant #1899",
            "file": "tests/test_checks.py",
            "line": 61,
            "system-out": [
              "    assert max_count is None"
            ]
          },
          {
            "name": "Mutant #1900",
            "file": "tests/test_checks.py",
            "line": 67,
            "system-out": [
              "        \"name\": \"test\","
            ]
          },
          {
            "name": "Mutant #1901",
            "file": "tests/test_checks.py",
            "line": 67,
            "system-out": [
              "        \"name\": \"test\","
            ]
          },
          {
            "name": "Mutant #1902",
            "file": "tests/test_checks.py",
            "line": 69,
            "system-out": [
              "        \"count\": {"
            ]
          },
          {
            "name": "Mutant #1903",
            "file": "tests/test_checks.py",
            "line": 70,
            "system-out": [
              "            \"min\": 1,"
            ]
          },
          {
            "name": "Mutant #1904",
            "file": "tests/test_checks.py",
            "line": 70,
            "system-out": [
              "            \"min\": 1,"
            ]
          },
          {
            "name": "Mutant #1905",
            "file": "tests/test_checks.py",
            "line": 79,
            "system-out": [
              "        \"name\": \"test\","
            ]
          },
          {
            "name": "Mutant #1906",
            "file": "tests/test_checks.py",
            "line": 79,
            "system-out": [
              "        \"name\": \"test\","
            ]
          },
          {
            "name": "Mutant #1907",
            "file": "tests/test_checks.py",
            "line": 80,
            "system-out": [
              "        \"count\": {"
            ]
          },
          {
            "name": "Mutant #1908",
            "file": "tests/test_checks.py",
            "line": 81,
            "system-out": [
              "            \"min\": 1,"
            ]
          },
          {
            "name": "Mutant #1909",
            "file": "tests/test_checks.py",
            "line": 81,
            "system-out": [
              "            \"min\": 1,"
            ]
          },
          {
            "name": "Mutant #1910",
            "file": "tests/test_checks.py",
            "line": 109,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1911",
            "file": "tests/test_checks.py",
            "line": 114,
            "system-out": [
              "    assert isinstance(min_count, int) or min_count is None"
            ]
          },
          {
            "name": "Mutant #1912",
            "file": "tests/test_checks.py",
            "line": 114,
            "system-out": [
              "    assert isinstance(min_count, int) or min_count is None"
            ]
          },
          {
            "name": "Mutant #1913",
            "file": "tests/test_checks.py",
            "line": 115,
            "system-out": [
              "    assert isinstance(max_count, int) or max_count is None"
            ]
          },
          {
            "name": "Mutant #1914",
            "file": "tests/test_checks.py",
            "line": 115,
            "system-out": [
              "    assert isinstance(max_count, int) or max_count is None"
            ]
          },
          {
            "name": "Mutant #1915",
            "file": "tests/test_checks.py",
            "line": 132,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1916",
            "file": "tests/test_checks.py",
            "line": 142,
            "system-out": [
              "    st.integers(min_value=0, max_value=25),"
            ]
          },
          {
            "name": "Mutant #1917",
            "file": "tests/test_checks.py",
            "line": 142,
            "system-out": [
              "    st.integers(min_value=0, max_value=25),"
            ]
          },
          {
            "name": "Mutant #1918",
            "file": "tests/test_checks.py",
            "line": 143,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1919",
            "file": "tests/test_checks.py",
            "line": 144,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1920",
            "file": "tests/test_main.py",
            "line": 122,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #1921",
            "file": "tests/test_main.py",
            "line": 129,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1922",
            "file": "tests/test_main.py",
            "line": 130,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1923",
            "file": "tests/test_main.py",
            "line": 133,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1924",
            "file": "tests/test_main.py",
            "line": 135,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1925",
            "file": "tests/test_main.py",
            "line": 144,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #1926",
            "file": "tests/test_main.py",
            "line": 147,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1927",
            "file": "tests/test_main.py",
            "line": 147,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1928",
            "file": "tests/test_main.py",
            "line": 152,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1929",
            "file": "tests/test_main.py",
            "line": 153,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1930",
            "file": "tests/test_main.py",
            "line": 155,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1931",
            "file": "tests/test_main.py",
            "line": 157,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1932",
            "file": "tests/test_main.py",
            "line": 168,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #1933",
            "file": "tests/test_main.py",
            "line": 177,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1934",
            "file": "tests/test_main.py",
            "line": 179,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1935",
            "file": "tests/test_main.py",
            "line": 181,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1936",
            "file": "tests/test_main.py",
            "line": 183,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1937",
            "file": "tests/test_main.py",
            "line": 195,
            "system-out": [
              "    project_name = \"test\""
            ]
          },
          {
            "name": "Mutant #1938",
            "file": "tests/test_main.py",
            "line": 198,
            "system-out": [
              "    wrong_config_dir = \"config\""
            ]
          },
          {
            "name": "Mutant #1939",
            "file": "tests/test_main.py",
            "line": 203,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1940",
            "file": "tests/test_main.py",
            "line": 205,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1941",
            "file": "tests/test_main.py",
            "line": 207,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1942",
            "file": "tests/test_constants.py",
            "line": 14,
            "system-out": [
              "    assert constants.filesystem.Current_Directory == \".\""
            ]
          },
          {
            "name": "Mutant #1943",
            "file": "tests/test_constants.py",
            "line": 14,
            "system-out": [
              "    assert constants.filesystem.Current_Directory == \".\""
            ]
          },
          {
            "name": "Mutant #1944",
            "file": "tests/test_constants.py",
            "line": 15,
            "system-out": [
              "    assert constants.filesystem.Main_Configuration_File == \"config.yml\""
            ]
          },
          {
            "name": "Mutant #1945",
            "file": "tests/test_constants.py",
            "line": 15,
            "system-out": [
              "    assert constants.filesystem.Main_Configuration_File == \"config.yml\""
            ]
          },
          {
            "name": "Mutant #1946",
            "file": "tests/test_constants.py",
            "line": 16,
            "system-out": [
              "    assert constants.humanreadable.Yes == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1947",
            "file": "tests/test_constants.py",
            "line": 16,
            "system-out": [
              "    assert constants.humanreadable.Yes == \"Yes\""
            ]
          },
          {
            "name": "Mutant #1948",
            "file": "tests/test_constants.py",
            "line": 17,
            "system-out": [
              "    assert constants.humanreadable.No == \"No\""
            ]
          },
          {
            "name": "Mutant #1949",
            "file": "tests/test_constants.py",
            "line": 17,
            "system-out": [
              "    assert constants.humanreadable.No == \"No\""
            ]
          },
          {
            "name": "Mutant #1950",
            "file": "tests/test_constants.py",
            "line": 27,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #1951",
            "file": "tests/test_constants.py",
            "line": 28,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #1952",
            "file": "tests/test_constants.py",
            "line": 34,
            "system-out": [
              "    assert fs.Current_Directory == directory"
            ]
          },
          {
            "name": "Mutant #1953",
            "file": "tests/test_constants.py",
            "line": 36,
            "system-out": [
              "    assert hr.Yes == yes"
            ]
          },
          {
            "name": "Mutant #1954",
            "file": "tests/test_constants.py",
            "line": 37,
            "system-out": [
              "    assert hr.No == no"
            ]
          },
          {
            "name": "Mutant #1955",
            "file": "tests/test_constants.py",
            "line": 48,
            "system-out": [
              "        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))"
            ]
          },
          {
            "name": "Mutant #1956",
            "file": "tests/test_constants.py",
            "line": 48,
            "system-out": [
              "        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))"
            ]
          },
          {
            "name": "Mutant #1957",
            "file": "tests/test_constants.py",
            "line": 48,
            "system-out": [
              "        fs.Current_Directory = str(Path(\"/new\") / Path(\"path\"))"
            ]
          },
          {
            "name": "Mutant #1958",
            "file": "tests/test_constants.py",
            "line": 50,
            "system-out": [
              "        hr.Yes = \"YES\""
            ]
          },
          {
            "name": "Mutant #1959",
            "file": "tests/test_constants.py",
            "line": 52,
            "system-out": [
              "        hr.No = \"NO\""
            ]
          },
          {
            "name": "Mutant #1960",
            "file": "tests/test_constants.py",
            "line": 70,
            "system-out": [
              "    if dir1 != dir2:"
            ]
          },
          {
            "name": "Mutant #1961",
            "file": "tests/test_constants.py",
            "line": 71,
            "system-out": [
              "        assert fs1 != fs2"
            ]
          },
          {
            "name": "Mutant #1962",
            "file": "tests/test_constants.py",
            "line": 73,
            "system-out": [
              "        assert fs1 == fs2"
            ]
          },
          {
            "name": "Mutant #1963",
            "file": "tests/test_constants.py",
            "line": 76,
            "system-out": [
              "@given(directory=strategies.text(), filename=strategies.text(), extra=strategies.text())"
            ]
          },
          {
            "name": "Mutant #1964",
            "file": "tests/test_constants.py",
            "line": 82,
            "system-out": [
              "    assert dir1 == dir2"
            ]
          },
          {
            "name": "Mutant #1965",
            "file": "tests/test_constants.py",
            "line": 89,
            "system-out": [
              "    assert fs1 == fs2"
            ]
          },
          {
            "name": "Mutant #1966",
            "file": "tests/test_main.py",
            "line": 209,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1967",
            "file": "tests/test_main.py",
            "line": 214,
            "system-out": [
              "    assert result.exit_code != 0"
            ]
          },
          {
            "name": "Mutant #1968",
            "file": "tests/test_main.py",
            "line": 214,
            "system-out": [
              "    assert result.exit_code != 0"
            ]
          },
          {
            "name": "Mutant #1969",
            "file": "tests/test_main.py",
            "line": 225,
            "system-out": [
              "    test_one = tmpdir.mkdir(\"test_one\")"
            ]
          },
          {
            "name": "Mutant #1970",
            "file": "tests/test_main.py",
            "line": 226,
            "system-out": [
              "    project_name = \"test\""
            ]
          },
          {
            "name": "Mutant #1971",
            "file": "tests/test_main.py",
            "line": 234,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1972",
            "file": "tests/test_main.py",
            "line": 236,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1973",
            "file": "tests/test_main.py",
            "line": 238,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1974",
            "file": "tests/test_main.py",
            "line": 240,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1975",
            "file": "tests/test_main.py",
            "line": 243,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #1976",
            "file": "tests/test_main.py",
            "line": 243,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #1977",
            "file": "tests/test_main.py",
            "line": 244,
            "system-out": [
              "    assert \"Cannot perform analysis due to configuration\" in result.output"
            ]
          },
          {
            "name": "Mutant #1978",
            "file": "tests/test_main.py",
            "line": 244,
            "system-out": [
              "    assert \"Cannot perform analysis due to configuration\" in result.output"
            ]
          },
          {
            "name": "Mutant #1979",
            "file": "tests/test_main.py",
            "line": 368,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1980",
            "file": "tests/test_main.py",
            "line": 371,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #1981",
            "file": "tests/test_main.py",
            "line": 371,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #1982",
            "file": "tests/test_main.py",
            "line": 374,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1983",
            "file": "tests/test_main.py",
            "line": 374,
            "system-out": [
              "@patch(\"chasten.configuration.user_config_dir\")"
            ]
          },
          {
            "name": "Mutant #1984",
            "file": "tests/test_main.py",
            "line": 382,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1985",
            "file": "tests/test_main.py",
            "line": 382,
            "system-out": [
              "    mock_user_config_dir.return_value = str(tmp_path / \".chasten\")"
            ]
          },
          {
            "name": "Mutant #1986",
            "file": "tests/test_main.py",
            "line": 390,
            "system-out": [
              "            \"configure\","
            ]
          },
          {
            "name": "Mutant #1987",
            "file": "tests/test_main.py",
            "line": 391,
            "system-out": [
              "            \"create\","
            ]
          },
          {
            "name": "Mutant #1988",
            "file": "tests/test_main.py",
            "line": 392,
            "system-out": [
              "            \"--verbose\","
            ]
          },
          {
            "name": "Mutant #1989",
            "file": "tests/test_main.py",
            "line": 395,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #1990",
            "file": "tests/test_main.py",
            "line": 395,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #1991",
            "file": "tests/test_main.py",
            "line": 403,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #1992",
            "file": "tests/test_main.py",
            "line": 406,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1993",
            "file": "tests/test_main.py",
            "line": 406,
            "system-out": [
              "    configuration_directory = cwd / Path(\".chasten\")"
            ]
          },
          {
            "name": "Mutant #1994",
            "file": "tests/test_main.py",
            "line": 410,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #1995",
            "file": "tests/test_main.py",
            "line": 412,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #1996",
            "file": "tests/test_main.py",
            "line": 414,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #1997",
            "file": "tests/test_main.py",
            "line": 418,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #1998",
            "file": "tests/test_main.py",
            "line": 418,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #1999",
            "file": "tests/test_main.py",
            "line": 424,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #2000",
            "file": "tests/test_main.py",
            "line": 431,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #2001",
            "file": "tests/test_main.py",
            "line": 432,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #2002",
            "file": "tests/test_main.py",
            "line": 435,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #2003",
            "file": "tests/test_main.py",
            "line": 441,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #2004",
            "file": "tests/test_main.py",
            "line": 441,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #2005",
            "file": "tests/test_main.py",
            "line": 454,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #2006",
            "file": "tests/test_main.py",
            "line": 457,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #2007",
            "file": "tests/test_main.py",
            "line": 457,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #2008",
            "file": "tests/test_main.py",
            "line": 462,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #2009",
            "file": "tests/test_main.py",
            "line": 463,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #2010",
            "file": "tests/test_main.py",
            "line": 466,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #2011",
            "file": "tests/test_main.py",
            "line": 468,
            "system-out": [
              "            \"--markdown-storage\","
            ]
          },
          {
            "name": "Mutant #2012",
            "file": "tests/test_main.py",
            "line": 473,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #2013",
            "file": "tests/test_main.py",
            "line": 473,
            "system-out": [
              "    assert result.exit_code == 1"
            ]
          },
          {
            "name": "Mutant #2014",
            "file": "tests/test_main.py",
            "line": 483,
            "system-out": [
              "    file = tmp_dir / \"analysis.md\""
            ]
          },
          {
            "name": "Mutant #2015",
            "file": "tests/test_main.py",
            "line": 483,
            "system-out": [
              "    file = tmp_dir / \"analysis.md\""
            ]
          },
          {
            "name": "Mutant #2016",
            "file": "tests/test_main.py",
            "line": 488,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #2017",
            "file": "tests/test_main.py",
            "line": 491,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #2018",
            "file": "tests/test_main.py",
            "line": 491,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #2019",
            "file": "tests/test_main.py",
            "line": 496,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #2020",
            "file": "tests/test_main.py",
            "line": 497,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #2021",
            "file": "tests/test_main.py",
            "line": 500,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #2022",
            "file": "tests/test_main.py",
            "line": 502,
            "system-out": [
              "            \"--markdown-storage\","
            ]
          },
          {
            "name": "Mutant #2023",
            "file": "tests/test_main.py",
            "line": 508,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #2024",
            "file": "tests/test_main.py",
            "line": 508,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #2025",
            "file": "tests/test_main.py",
            "line": 509,
            "system-out": [
              "    assert \"\u2728 Results saved in:\" in result.output"
            ]
          },
          {
            "name": "Mutant #2026",
            "file": "tests/test_main.py",
            "line": 509,
            "system-out": [
              "    assert \"\u2728 Results saved in:\" in result.output"
            ]
          },
          {
            "name": "Mutant #2027",
            "file": "tests/test_main.py",
            "line": 512,
            "system-out": [
              "@given(directory=strategies.builds(Path))"
            ]
          },
          {
            "name": "Mutant #2028",
            "file": "tests/test_main.py",
            "line": 513,
            "system-out": [
              "@settings(deadline=None, suppress_health_check=[HealthCheck.function_scoped_fixture])"
            ]
          },
          {
            "name": "Mutant #2029",
            "file": "tests/test_main.py",
            "line": 514,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #2030",
            "file": "tests/test_main.py",
            "line": 516,
            "system-out": [
              "    project_name = \"testing\""
            ]
          },
          {
            "name": "Mutant #2031",
            "file": "tests/test_main.py",
            "line": 519,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #2032",
            "file": "tests/test_main.py",
            "line": 519,
            "system-out": [
              "    configuration_directory = str(cwd) + \"/.chasten\""
            ]
          },
          {
            "name": "Mutant #2033",
            "file": "tests/test_main.py",
            "line": 523,
            "system-out": [
              "            \"analyze\","
            ]
          },
          {
            "name": "Mutant #2034",
            "file": "tests/test_main.py",
            "line": 524,
            "system-out": [
              "            \"--search-path\","
            ]
          },
          {
            "name": "Mutant #2035",
            "file": "tests/test_main.py",
            "line": 527,
            "system-out": [
              "            \"--config\","
            ]
          },
          {
            "name": "Mutant #2036",
            "file": "tests/test_main.py",
            "line": 529,
            "system-out": [
              "            \"--markdown-storage\","
            ]
          },
          {
            "name": "Mutant #2037",
            "file": "tests/test_main.py",
            "line": 531,
            "system-out": [
              "            \"--force\","
            ]
          },
          {
            "name": "Mutant #2038",
            "file": "tests/test_main.py",
            "line": 534,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #2039",
            "file": "tests/test_main.py",
            "line": 534,
            "system-out": [
              "    assert result.exit_code == 0"
            ]
          },
          {
            "name": "Mutant #2040",
            "file": "tests/test_constants.py",
            "line": 43,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #2041",
            "file": "tests/test_constants.py",
            "line": 44,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #2042",
            "file": "tests/test_constants.py",
            "line": 60,
            "system-out": [
              ")"
            ]
          },
          {
            "name": "Mutant #2043",
            "file": "tests/test_constants.py",
            "line": 61,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          },
          {
            "name": "Mutant #2044",
            "file": "tests/test_constants.py",
            "line": 77,
            "system-out": [
              "@pytest.mark.fuzz"
            ]
          }
        ]
      }
    ]
  }
}